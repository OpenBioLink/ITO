{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) PLOT_0_POL - Ratio-corrected create CSV export from ITO\n",
    "(Work in progress)\n",
    "\n",
    "This plot is based on the original PLOT_0 notebook. It takes in consideration the floor and the ceiling values, asl well as the metrics (posivite vs. negative) to plot the curves.\n",
    "\n",
    "This notebook is used to export the information from sparql into a csv file.\n",
    "\n",
    "It should be executed as base for individual plot created with the notebooks\n",
    "PLOT_1, PLOT_2, PLOT_3 and PLOT_4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Adjust display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install SPARQLWrapper\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn\n",
    "#!pip install sparqlwrapper\n",
    "#!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some modules\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import seaborn as sns\n",
    "from SPARQLWrapper import SPARQLWrapper, N3, JSON\n",
    "from rdflib import Graph\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define here the end point  (i.e. where the blazergraph instance is running)\n",
    "\n",
    "#endpoint = \"http://localhost:9999/blazegraph/sparql\" # SPARQL endpoint hosting ITO.owl\n",
    "\n",
    "\n",
    "#current one\n",
    "endpoint = \"http://192.168.56.1:9999/blazegraph/sparql\"\n",
    "        \n",
    "#endpoint = \"http://149.148.106.153:9999/blazegraph/sparql\"\n",
    "prefixes = \"\"\"\n",
    "PREFIX edam: <http://edamontology.org/>\n",
    "PREFIX obo:  <http://purl.obolibrary.org/obo/>\n",
    "PREFIX ito:  <https://identifiers.org/ito#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "\"\"\"\n",
    "\n",
    "def query(service, query, numeric_cols = []):\n",
    "    \"\"\"\n",
    "    Helper function to convert SPARQL results into a Pandas data frame.\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(service)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    result = sparql.query()\n",
    "\n",
    "    processed_results = json.load(result.response)\n",
    "    cols = processed_results['head']['vars']\n",
    "\n",
    "    out = []\n",
    "    for row in processed_results['results']['bindings']:\n",
    "        item = []\n",
    "        for c in cols:\n",
    "            item.append(row.get(c, {}).get('value'))\n",
    "        out.append(item)\n",
    "        \n",
    "    df = pd.DataFrame(out, columns=cols)\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this function to escape some desired_benchmark names that might contain special chars.\n",
    "def escape(s):\n",
    "    return s.translate(str.maketrans({  \"'\":   r\"\\'\",\n",
    "                                        '\"':   r'\\\"',\n",
    "                                        \"\\\\\":  r\"\\\\\",\n",
    "                                        \"\\r\":  r\"\\r\",\n",
    "                                        \"\\n\":  r\"\\n\"}))\n",
    "\n",
    "#Query database for selected ito and get one ratio dataframe per desired measure. Example provided.\n",
    "def create_ratio(desired_measure, desired_benchmark, ds_count, selected_ito, metricName_negative_list):\n",
    "    \n",
    "    #escape string here, this is needed once some names contain special chars in the query.\n",
    "    desired_benchmark = escape(desired_benchmark)\n",
    "    print(\"Creating ratio df for \",desired_measure,\", \",desired_benchmark,\", ds_count=\",ds_count)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    PREFIX edam: <http://edamontology.org/>\n",
    "    PREFIX obo:  <http://purl.obolibrary.org/obo/>\n",
    "    PREFIX ito:  <https://identifiers.org/ito:>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "\n",
    "    SELECT *\n",
    "    WHERE {\n",
    "    \n",
    "        ?paper a edam:data_0971 . \n",
    "        ?paper rdfs:label ?paperTitle. \n",
    "        ?paper obo:date ?date. \n",
    "\n",
    "        ?benchmark_process_individual \trdfs:seeAlso ?paper ;\n",
    "                                        rdfs:label ?model_label ;\n",
    "                                        a ?benchmark_process_class . # this will create a place holder for the rdfs:type results that contains the information about the individual\n",
    "        \n",
    "        ?benchmark_process_class rdfs:label ?benchmark_process_class_label ;\n",
    "                                 rdfs:subClassOf*   \"\"\"+selected_ito+\"\"\" . # this limits for the NLP class\n",
    "        \n",
    "\n",
    "        ?performance_measure rdfs:subPropertyOf* ito:performance_measure .\n",
    "        ?performance_measure rdfs:label ?metricName .\n",
    "\n",
    "\n",
    "\n",
    "        ?performance_measure rdfs:label ?metricName .\n",
    "        ?benchmark_process_individual ?performance_measure ?result .\t\n",
    "\n",
    "        FILTER regex(?metricName, \"^\"\"\"+ desired_measure +\"\"\"$\" ). # this searches a specific match\n",
    "        FILTER regex(?benchmark_process_class_label, \"^\"\"\"+desired_benchmark+\"\"\"$\" ). # this searches a specific match\n",
    "\n",
    "\n",
    "\n",
    "    } ORDER by ?date\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #send query via API\n",
    "    sparql = SPARQLWrapper(endpoint)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    result = sparql.query()\n",
    "\n",
    "    #process results as JSON\n",
    "    processed_results = json.load(result.response)\n",
    "\n",
    "    #Use accessory function to process results\n",
    "    cols = processed_results['head']['vars']\n",
    "\n",
    "    out = []\n",
    "    for row in processed_results['results']['bindings']:\n",
    "        item = []\n",
    "        for c in cols:\n",
    "            item.append(row.get(c, {}).get('value'))\n",
    "\n",
    "        out.append(item)\n",
    "\n",
    "    #this is the final df containing the results of the query\n",
    "    df = pd.DataFrame(out, columns=cols)\n",
    "    \n",
    "    if len(df.index)==0:\n",
    "        return None\n",
    "           \n",
    "    #Set date column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    #Keep only the model name\n",
    "    df.new = df.replace(to_replace =' model in .*$', value = '', regex = True)\n",
    "\n",
    "    #Change the result column to numeric type\n",
    "    df.new[\"result\"] = pd.to_numeric(df.new[\"result\"]) \n",
    "\n",
    "    #Create dataframe to store state of art results\n",
    "    sota = pd.DataFrame(columns = df.new.columns)\n",
    "\n",
    "    \n",
    "    ###\n",
    "    if desired_measure in metricName_negative_list:\n",
    "    \n",
    "        #ATTENTION: this modification using the minus signal is necessary in order to plot correctly the curve.\n",
    "        #Although the numbers are decreasing, the curve is showing an upward pattern.\n",
    "\n",
    "        df.new[\"result\"] = -df.new[\"result\"]\n",
    "\n",
    "        #Create dataframe to store state of art results\n",
    "        sota = pd.DataFrame(columns = df.new.columns)\n",
    "\n",
    "        best_value = min(df.new[\"result\"])\n",
    "        i=0\n",
    "\n",
    "        for result in df.new[\"result\"]:        \n",
    "            if result >= best_value:\n",
    "                best_value = result\n",
    "                sota_add = pd.DataFrame(df.new.iloc[i]).transpose()\n",
    "                sota = sota.append(sota_add)            \n",
    "            i = i+1    \n",
    "    \n",
    "    else:\n",
    "        #Create dataframe to store state of art results\n",
    "        sota = pd.DataFrame(columns = df.new.columns)\n",
    "\n",
    "        best_value = 0\n",
    "        i=0\n",
    "\n",
    "        for result in df.new[\"result\"]:        \n",
    "            if result > best_value:\n",
    "                best_value = result\n",
    "                sota_add = pd.DataFrame(df.new.iloc[i]).transpose()\n",
    "                sota = sota.append(sota_add)            \n",
    "            i = i+1    \n",
    "    \n",
    "    \n",
    "    ###\n",
    "    #/////commented block\n",
    "    #best_value = 0\n",
    "    #i=0\n",
    "\n",
    "    #for result in df.new[\"result\"]:        \n",
    "    #        if result > best_value:\n",
    "    #            best_value = result\n",
    "    #            sota_add = pd.DataFrame(df.new.iloc[i]).transpose()\n",
    "    #            sota = sota.append(sota_add)            \n",
    "    #        i = i+1    \n",
    "\n",
    "    #This variable is containing the data points to plot the state of the art line        \n",
    "    #sota\n",
    "    \n",
    "    #/////commented block\n",
    "\n",
    "    #this is a copy to use as hovertemplate below\n",
    "    y=df.new[\"result\"].astype(str)\n",
    "\n",
    "\n",
    "    #create this data frame to store the ratios\n",
    "    ratio_df = pd.DataFrame(columns = [\"ds_count\", \n",
    "                                       \"task\",\n",
    "                                       \"ds\", \n",
    "                                       \"date\",\n",
    "                                       \"model_label\",\n",
    "                                       \"value\",\n",
    "                                       \"percent_of_max_sota\",\n",
    "                                       \"gain\",\n",
    "                                       \"ratio\",\n",
    "                                       \"max_sota\"])\n",
    "\n",
    "\n",
    "    #This block collects the rate of the benchmarkings along the years and saves it\n",
    "    #ratio_df = pd.DataFrame(columns = [\"ds_count\", \"ds\", \"date\", \"value\",\"gain\",\"ratio\",\"max_sota\"])\n",
    "\n",
    "    print(\"###SOTA RESULTS: \"+str(len(sota[\"result\"])))\n",
    "    if (len(sota[\"result\"]>0)) :\n",
    "        max(sota[\"result\"])\n",
    "        min(sota[\"result\"])\n",
    "\n",
    "        i=0\n",
    "        for res in sota[\"result\"]:\n",
    "            if sota.loc[sota.index[i], 'result'] <= max(sota[\"result\"]) :\n",
    "                if(i == 0):\n",
    "                    gain = sota.loc[sota.index[i], 'result']\n",
    "                    ratio = round( gain / (max(sota[\"result\"] - sota.loc[sota.index[0], 'result'])  ) ,4)\n",
    "                    \n",
    "                else :\n",
    "                    gain = round(sota.loc[sota.index[i], 'result'] - sota.loc[sota.index[i-1], 'result'],4)\n",
    "                    ratio = round( gain / (max(sota[\"result\"] - sota.loc[sota.index[0], 'result'])  ) ,4)\n",
    "                    \n",
    "                #this is only to check if the calculation is correct\n",
    "                #print(str(sota.loc[sota.index[i], 'result'])+\" - \"+ str(sota.loc[sota.index[i-1], 'result']) + \" == \"+ str(gain) +\" Ratio == \"+str(ratio))\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                #ratio = round( gain / max(sota[\"result\"]) ,2)\n",
    "                \n",
    "                \n",
    "                #total = round((sota.loc[sota.index[i+1], 'result'] - sota.loc[sota.index[i], 'result'] ),2)\n",
    "                #print(sota[\"result\"][i+1] - sota[\"result\"][i])\n",
    "                #OK print(total.astype(str)+ \" : \" + max(sota[\"result\"]).astype(str) )\n",
    "\n",
    "                #year=sota.loc[sota.index[i], 'date'].strftime('%Y-%m-%d')\n",
    "                year=sota.loc[sota.index[i], 'date'].strftime('%Y-%m')\n",
    "                value=sota.loc[sota.index[i], 'result'].astype(str)\n",
    "                percent_of_max_sota=round((sota.loc[sota.index[i], 'result'] / max(sota[\"result\"]) * 100),2)\n",
    "                benchmarking=sota.loc[sota.index[i], 'benchmark_process_class_label']\n",
    "                model_label=sota.loc[sota.index[i], 'model_label']\n",
    "\n",
    "                #clears the name of the task\n",
    "\n",
    "                task=re.sub(\"^.*\\s-\\s\",\"\",benchmarking)\n",
    "                task=re.sub(\" benchmarking\",\"\",task)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #benchmarking = df.replace(to_replace =' model in .*$', value = '', regex = True)\n",
    "\n",
    "\n",
    "                #reduce the name of the benchmark\n",
    "                #benchmarking = re.sub(r'\\-.*',\"\",benchmarking) \n",
    "                #re.sub(r'\\.\\.\\..*',\"\",test)\n",
    "\n",
    "                new_row = {'ds_count':ds_count,\n",
    "                           'task':task,\n",
    "                           'ds':benchmarking, \n",
    "                           'date':year,\n",
    "                           'model_label':model_label,\n",
    "                           'value':value, \n",
    "                           'percent_of_max_sota':percent_of_max_sota.astype(float),  \n",
    "                           'gain':gain.astype(str), \n",
    "                           'ratio':ratio.astype(str), \n",
    "                           'max_sota':max(sota[\"result\"]).astype(str)}\n",
    "\n",
    "                ratio_df = ratio_df.append(new_row, ignore_index=True)\n",
    "\n",
    "                i = i+1\n",
    "    return ratio_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_polarity():\n",
    "    df_metric_all = pd.read_csv(\"df_metric_all.csv\")\n",
    "\n",
    "    df_metric_all = df_metric_all[df_metric_all[\"ranking\"]<=2]\n",
    "    df_metric_all = df_metric_all[df_metric_all[\"ranking\"]>0]\n",
    "    df_metric_all = df_metric_all[df_metric_all[\"metrics\"]!=\"No. parameters\"]\n",
    "\n",
    "    #calculate polarity \n",
    "    #report df\n",
    "    polarity_df = pd.DataFrame(columns=['task','datasets','metricName','rank_1', 'rank_2', 'polarity'])\n",
    "\n",
    "    #iterate over tasks\n",
    "    for task in df_metric_all[\"task\"].unique():\n",
    "        #iterate over datasets\n",
    "        for dataset in df_metric_all[df_metric_all[\"task\"]==task][\"datasets\"].unique():\n",
    "            #iterate over metrics\n",
    "            for metric in df_metric_all[df_metric_all[\"task\"]==task][\"metrics\"].unique():\n",
    "\n",
    "                #get ranks 1 and 2, compare and set polarity\n",
    "                try:\n",
    "                    rank_1 = df_metric_all[(df_metric_all[\"task\"] == task) & (df_metric_all[\"datasets\"] == dataset) & (df_metric_all[\"metrics\"] == metric ) & (df_metric_all[\"ranking\"] == 1 )]\n",
    "                    rank_2 = df_metric_all[(df_metric_all[\"task\"] == task) & (df_metric_all[\"datasets\"] == dataset) & (df_metric_all[\"metrics\"] == metric ) & (df_metric_all[\"ranking\"] == 2 )]\n",
    "                    polarity = float(rank_1.value.iloc[0]) - float(rank_2.value.iloc[0])\n",
    "                    if(polarity >=0):\n",
    "                        polarity = \"pos\"\n",
    "                    else:\n",
    "                        polarity = \"neg\"\n",
    "\n",
    "                    #print(\"metricName:\"+metric + \"\\trank_1:\"+rank_1[\"value\"].iloc[0]+\"\\trank_2:\"+rank_2[\"value\"].iloc[0]+\"\\tpolarity:\"+polarity)\n",
    "\n",
    "                    #save to report df\n",
    "                    polarity_df = polarity_df.append({'task':task,\n",
    "                                                      'datasets':dataset,\n",
    "                                                      'metricName':metric,\n",
    "                                                      'rank_1':rank_1[\"value\"].iloc[0],\n",
    "                                                      'rank_2':rank_2[\"value\"].iloc[0],\n",
    "                                                      'polarity':polarity},\n",
    "                                                      ignore_index=True)\n",
    "                #skip if metric is not present for such dataset    \n",
    "                except:\n",
    "                    next\n",
    "\n",
    "\n",
    "    \n",
    "    return(polarity_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return ratio_df_all dataframe per desired measure\n",
    "def get_ratio_df_all_per_measure(desired_measure, selected_ito, metricName_negative_list):\n",
    "\n",
    "    \n",
    "    query = \"\"\"\n",
    "        PREFIX edam: <http://edamontology.org/>\n",
    "        PREFIX obo:  <http://purl.obolibrary.org/obo/>\n",
    "        PREFIX ito:  <https://identifiers.org/ito:>\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "\n",
    "        SELECT *\n",
    "        WHERE {\n",
    "            ?paper a edam:data_0971 . \n",
    "            ?paper rdfs:label ?paperTitle. \n",
    "            ?paper obo:date ?date. \n",
    "\n",
    "            ?benchmark_process_individual \trdfs:seeAlso ?paper ;\n",
    "                                            rdfs:label ?model_label ;\n",
    "                                            a ?benchmark_process_class . # this will create a place holder for the rdfs:type results that contains the information about the individual\n",
    "\n",
    "            ?benchmark_process_class rdfs:label ?benchmark_process_class_label ;\n",
    "                                     rdfs:subClassOf*  \"\"\"+selected_ito+\"\"\" . # this limits for the NLP class\n",
    "\n",
    "\n",
    "            ?performance_measure rdfs:subPropertyOf* ito:performance_measure .\n",
    "            ?performance_measure rdfs:label ?metricName .\n",
    "\n",
    "\n",
    "\n",
    "            ?performance_measure rdfs:label ?metricName .\n",
    "            ?benchmark_process_individual ?performance_measure ?result .\t\n",
    "\n",
    "\n",
    "            FILTER regex(?metricName, \"^\"\"\"+ desired_measure +\"\"\"$\" ) . # this searches a specific match\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        } ORDER by ?date\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    #send query via API\n",
    "    sparql = SPARQLWrapper(endpoint)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    result = sparql.query()\n",
    "\n",
    "    #process results as JSON\n",
    "    processed_results = json.load(result.response)\n",
    "\n",
    "    #Use accessory function to process results\n",
    "    cols = processed_results['head']['vars']\n",
    "\n",
    "    out = []\n",
    "    for row in processed_results['results']['bindings']:\n",
    "        item = []\n",
    "        for c in cols:\n",
    "            item.append(row.get(c, {}).get('value'))\n",
    "\n",
    "            out.append(item)\n",
    "\n",
    "\n",
    "    #this is the final df containing the results of the query\n",
    "    df2 = pd.DataFrame(out, columns=cols)\n",
    "\n",
    "    #now get the unique list of benchmark datasets\n",
    "    benchmark_process_class_label = df2[\"benchmark_process_class_label\"].unique()\n",
    "\n",
    "    #start here the ds_count, which is actually the unique combination of 'desired_measure' and 'desired_benchmark'\n",
    "    ds_count = 1\n",
    "    #this place holder will contain the plots to be contatenated in the final plot\n",
    "    plt_data = []\n",
    "\n",
    "    #create final ratio_df_all for all the combinations\n",
    "    ratio_df_all = pd.DataFrame(columns = [\"ds_count\", \n",
    "                                           \"task\",\n",
    "                                           \"ds\", \n",
    "                                           \"date\",\n",
    "                                           \"model_label\",\n",
    "                                           \"value\",\n",
    "                                           \"percent_of_max_sota\",\n",
    "                                           \"gain\",\n",
    "                                           \"ratio\",\n",
    "                                           \"max_sota\"])\n",
    "    #fig = go.Figure()\n",
    "\n",
    "    #iterate over the benchmark list to create the ratio_df_all, which will be used to plot later\n",
    "    for desired_benchmark in benchmark_process_class_label:\n",
    "\n",
    "        #print(desired_benchmark)\n",
    "        ratio_df = create_ratio(desired_measure,desired_benchmark,ds_count, selected_ito, metricName_negative_list) #read from the memory to get this polarity information\n",
    "        #print(\"ds_count: \",ds_count)\n",
    "        #ratio_df = create_ratio(desired_measure,\"Citeseer\",ds_count)\n",
    "\n",
    "        if ratio_df is None:\n",
    "                print(\"null\")  \n",
    "        elif len(ratio_df.index)>0:\n",
    "            #print(desired_benchmark)  \n",
    "            ratio_df_all = ratio_df_all.append(ratio_df, ignore_index=True)\n",
    "        \n",
    "        #ds_count = ds_count + 1\n",
    "\n",
    "    \n",
    "    if len(ratio_df_all.index) > 0:\n",
    "        \n",
    "        print(\"number of sota per dataset/metric: \",len(ratio_df_all.index))\n",
    "        #edit here the column with the benchmark name\n",
    "        ratio_df_all = ratio_df_all.replace(to_replace =' \\- .*', value = '', regex = True)\n",
    "\n",
    "        #add a column representing the percentual of the max obtained value per value\n",
    "        #ratio_df_all[\"percent\"] = round(ratio_df_all[\"value\"].astype(float)/max(ratio_df_all[\"total\"].astype(float)),2)*100\n",
    "\n",
    "        #add one extra column wihth the desired measure name in order to condendate the plot\n",
    "        ratio_df_all[\"merge\"]=desired_measure\n",
    "\n",
    "\n",
    "        \n",
    "    return ratio_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_ratio_df_per_ito(metricName_df, metricName_negative_list):\n",
    "    #this will concatenate all the get_ratio_df_all_per_measure into only one df.\n",
    "    get_ratio_df_all_per_global = pd.DataFrame(columns = [\"ds_count\", \n",
    "                                                          \"task\",\n",
    "                                                          \"ds\", \n",
    "                                                          \"date\",\n",
    "                                                          \"model_label\",\n",
    "                                                          \"value\",\n",
    "                                                          \"percent_of_max_sota\",\n",
    "                                                          \"gain\",\n",
    "                                                          \"ratio\",\n",
    "                                                          \"max_sota\",\n",
    "                                                          \"percent_of_max_metric\"])\n",
    "\n",
    "    for desired_measure in metricName_df:\n",
    "\n",
    "        #desired_measure = \"Accuracy\"\n",
    "        #this is necessary to query the database correctly, it will be editaded later in the code.\n",
    "        desired_measure = re.escape(desired_measure).replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        print(\"#######\",desired_measure)\n",
    "\n",
    "        #Call external function to get the ratio per metric for a selected ito\n",
    "        ratio_df_all_per_measure=get_ratio_df_all_per_measure(desired_measure, selected_ito, metricName_negative_list)\n",
    "\n",
    "        if len(ratio_df_all_per_measure)>0:\n",
    "            #this percentage has to be calculated out of the function, \n",
    "            #because it congreate the maximum obtained value accross all benchmarks\n",
    "            ratio_df_all_per_measure[\"value\"]=ratio_df_all_per_measure[\"value\"].astype(float)\n",
    "            ratio_df_all_per_measure[\"percent_of_max_metric\"] = round(ratio_df_all_per_measure[\"value\"] / max(ratio_df_all_per_measure[\"value\"]),2)\n",
    "\n",
    "            #save the results of the function to the global dataframe\n",
    "            get_ratio_df_all_per_global=get_ratio_df_all_per_global.append(ratio_df_all_per_measure)\n",
    "    \n",
    "    return(get_ratio_df_all_per_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query all the metrics collected for the selected selected_ito\n",
    "def get_metrics_df(selected_ito):\n",
    "    query = \"\"\"\n",
    "        PREFIX edam: <http://edamontology.org/>\n",
    "        PREFIX obo:  <http://purl.obolibrary.org/obo/>\n",
    "        PREFIX ito:  <https://identifiers.org/ito:>\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "\n",
    "        SELECT *\n",
    "        WHERE {\n",
    "                ?paper a edam:data_0971 . \n",
    "                ?paper rdfs:label ?paperTitle. \n",
    "                ?paper obo:date ?date. \n",
    "\n",
    "                ?benchmark_process_individual \trdfs:seeAlso ?paper ;\n",
    "                                                rdfs:label ?model_label ;\n",
    "                                                a ?benchmark_process_class . # this will create a place holder for the rdfs:type results that contains the information about the individual\n",
    "\n",
    "                ?benchmark_process_class rdfs:label ?benchmark_process_class_label ;\n",
    "                                         rdfs:subClassOf* \"\"\"+selected_ito+\"\"\" . # this limits for the NLP class\n",
    "\n",
    "                ?performance_measure rdfs:subPropertyOf* ito:performance_measure .\n",
    "                ?performance_measure rdfs:label ?metricName .\n",
    "\n",
    "\n",
    "                ?performance_measure rdfs:label ?metricName .\n",
    "                ?benchmark_process_individual ?performance_measure ?result\n",
    "            } ORDER by ?date\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    #send query via API\n",
    "    sparql = SPARQLWrapper(endpoint)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    result = sparql.query()\n",
    "\n",
    "    #process results as JSON\n",
    "    processed_results = json.load(result.response)\n",
    "\n",
    "    #Use accessory function to process results\n",
    "    cols = processed_results['head']['vars']\n",
    "\n",
    "    out = []\n",
    "    for row in processed_results['results']['bindings']:\n",
    "        item = []\n",
    "        for c in cols:\n",
    "            item.append(row.get(c, {}).get('value'))\n",
    "\n",
    "            out.append(item)\n",
    "\n",
    "\n",
    "    #this is the final df containing the results of the query\n",
    "    metricName_df = pd.DataFrame(out, columns=cols)\n",
    "\n",
    "    #get unique benchmark_process_class_label\n",
    "    #benchmark_process_class_label = df2[\"benchmark_process_class_label\"].unique()\n",
    "\n",
    "    #get unique metricName\n",
    "    metricName_df = metricName_df[\"metricName\"].unique()\n",
    "\n",
    "\n",
    "    print(\"Number of metrics: \",len(metricName_df))\n",
    "    \n",
    "    return(metricName_df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_task_trajectory(ito, class_label):\n",
    "    import pandas as pd\n",
    "    input_file_name=\"get_ratio_df_all_per_global_\"+ito+\".csv\"\n",
    "    get_ratio_df_all_per_global = pd.read_csv(input_file_name)\n",
    "\n",
    "    # drop first column\n",
    "    get_ratio_df_all_per_global = get_ratio_df_all_per_global.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "\n",
    "    # change the column to name the facets of the plot\n",
    "    get_ratio_df_all_per_global = get_ratio_df_all_per_global.rename(\n",
    "        columns={\"merge\": \"metricName\"}\n",
    "    )\n",
    "    get_ratio_df_all_per_global[\"metricName\"] = get_ratio_df_all_per_global[\n",
    "        \"metricName\"\n",
    "    ].str.replace(\"\\\\\", \"\")\n",
    "\n",
    "    get_ratio_df_all_per_global[\"unique_ds\"] = (\n",
    "        get_ratio_df_all_per_global[\"ds\"].astype(str)\n",
    "        + \", \"\n",
    "        + get_ratio_df_all_per_global[\"metricName\"]\n",
    "    )\n",
    "    get_ratio_df_all_per_global[\"unique_task\"] = (\n",
    "        get_ratio_df_all_per_global[\"task\"].astype(str)\n",
    "        + \", \"\n",
    "        + get_ratio_df_all_per_global[\"metricName\"]\n",
    "    )\n",
    "\n",
    "    get_ratio_df_all_per_global[\"unique_task_ds_metric\"] = (\n",
    "        get_ratio_df_all_per_global[\"task\"].astype(str)\n",
    "        + \", \"\n",
    "        + get_ratio_df_all_per_global[\"ds\"].astype(str)\n",
    "        + \", \"\n",
    "        + get_ratio_df_all_per_global[\"metricName\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    #calculate average data frame using 'RATIO' as criteria FOR unique_task\n",
    "    #This graph is fine, however, it will display overlapped datasets used for the same task in the same trajectory.\n",
    "    traj = get_ratio_df_all_per_global.copy()\n",
    "\n",
    "    #task causing some problems\n",
    "    traj = traj.drop(traj[traj[\"metricName\"]==\"Parameters\"].index)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # this will delete from the traj data frame, all the ds/tasks which the counts are equal to 1\n",
    "    # pd.set_option(\"display.max_rows\", None)\n",
    "    count_df = pd.DataFrame(traj[\"ds\"].value_counts())\n",
    "    count_df[count_df.ds == 1].index\n",
    "\n",
    "    \n",
    "    # the symbol ~ selects reverse to .isin\n",
    "    \n",
    "    traj = traj[~traj[\"ds\"].isin(count_df[count_df.ds == 1].index)]\n",
    "\n",
    "    \n",
    "\n",
    "    count_df = pd.DataFrame(traj[\"task\"].value_counts())\n",
    "    count_df[count_df.task == 1].index\n",
    "\n",
    "    \n",
    "    traj = traj[~traj[\"task\"].isin(count_df[count_df.task == 1].index)]\n",
    "\n",
    "    if(len(traj) == 0):\n",
    "        return(\"Not enough points to plot trajectory\")\n",
    "    \n",
    "    \n",
    "    # this function is declared to add the anchor dots (white dots) to the trajectory\n",
    "    def add_white(category):\n",
    "        fig_traj.add_trace(\n",
    "            go.Scatter(\n",
    "                x=average_summary_OUT[\"date\"],\n",
    "                y=average_summary_OUT[category],\n",
    "                mode=\"markers\",\n",
    "                name=None,\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                    color=\"white\",\n",
    "                    # opacity=0.5,\n",
    "                ),\n",
    "                hovertemplate=average_summary_OUT[category]\n",
    "                + \"<BR>category: \"\n",
    "                + average_summary_OUT[category]\n",
    "                + \"<BR>date: \"\n",
    "                + average_summary_OUT[\"date\"].astype(\"string\")\n",
    "                + \"<BR>ratio: \"\n",
    "                + average_summary_OUT[\"ratio\"].astype(\"string\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # variable_to_plot = \"ratio\"\n",
    "    # choose here which grouping variable to use\n",
    "    average_summary = pd.DataFrame(traj.groupby([\"task\", \"date\"])[\"ratio\"].mean())\n",
    "\n",
    "    # DROP anchors\n",
    "    # average_summary = average_summary.drop(average_summary[average_summary[\"ratio\"]>0.5].index)\n",
    "\n",
    "\n",
    "    average_summary.sort_values(by=[\"date\"], ascending=True)\n",
    "\n",
    "    average_summary.reset_index(inplace=True)\n",
    "    # average_summary[\"date\"]=pd.to_datetime(average_summary['date'])\n",
    "    # average_summary[\"date\"]=average_summary[\"date\"].dt.year\n",
    "    average_summary[\"in_trajectory\"] = 1\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for t in average_summary.task.unique():\n",
    "        sota_per = 0\n",
    "        # here the date can't be unique, because we want to look for the best value per year\n",
    "        for v in average_summary[average_summary[\"task\"] == t].ratio:\n",
    "            per = average_summary[\n",
    "                (average_summary[\"task\"] == t) & (average_summary[\"ratio\"] == v)\n",
    "            ].ratio.astype(float)\n",
    "            per = per.iloc[0]\n",
    "            if per >= sota_per:\n",
    "                # print(per)\n",
    "                sota_per = per\n",
    "                average_summary.loc[i, \"in_trajectory\"] = \"IN\"\n",
    "            else:\n",
    "                # average_summary = average_summary.drop(i)\n",
    "                average_summary.loc[i, \"in_trajectory\"] = \"IN\"  # change back to OUT\n",
    "                # sota_per = per\n",
    "            i = i + 1\n",
    "\n",
    "    # Add OUT to high gain values, normally those of the first results. They will be displayed as white dots.\n",
    "    # NOTE\n",
    "    # Ignore this for heatmap\n",
    "    #average_summary.loc[average_summary[\"ratio\"] > 0.5, \"in_trajectory\"] = \"OUT\"\n",
    "\n",
    "    average_summary[\"ratio\"] = average_summary[\"ratio\"].apply(lambda x: round(x, 2))\n",
    "    # average_summary = average_summary.rename(columns={'gain': 'gain'})\n",
    "\n",
    "    # needs to rename here to average of percentage of maximum sota\n",
    "\n",
    "    \n",
    "    ###NOW PLOT IT\n",
    "    # try using plotly\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    from plotly.validators.scatter.marker import SymbolValidator\n",
    "\n",
    "    average_summary_IN = average_summary[average_summary[\"in_trajectory\"] == \"IN\"]\n",
    "    average_summary_OUT = average_summary[average_summary[\"in_trajectory\"] == \"OUT\"]\n",
    "    \n",
    "    \n",
    "    # This block will take the values from average_summary_IN and delete those that have only one arrow per trajectory\n",
    "    count_df = pd.DataFrame(average_summary_IN[\"task\"].value_counts())\n",
    "    count_df[count_df.task == 1].index\n",
    "    average_summary_IN = average_summary_IN[\n",
    "        ~average_summary_IN[\"task\"].isin(count_df[count_df.task == 1].index)\n",
    "    ]\n",
    "    # this will delete from the traj data frame, all the tasks which the average_summary_IN counts are equal to 1\n",
    "    # meaning single arrows will be excluded from the plot\n",
    "\n",
    "    \n",
    "    fig_traj = px.line(average_summary_IN, x=\"date\", y=\"task\", color=\"task\")\n",
    "\n",
    "    # this trace adds first all the dates with a data point attached to it\n",
    "    # fig3_df=average_summary[average_summary[\"in_trajectory\"]==\"OUT\"]\n",
    "    # fig3_df[\"date\"]=pd.to_datetime(fig3_df['date'])\n",
    "    # fig3_df[\"date\"]=fig3_df[\"date\"].dt.year\n",
    "\n",
    "\n",
    "    # then as use the average_summary df to add only the data that forms a trajectory#\n",
    "    # this value/date is the average of the percentual of maximum value achieved for the metrics at that date.\n",
    "\n",
    "    # This adds/remove those points with value < 1 and > 0.5\n",
    "    \n",
    "\n",
    "    fig_traj.add_trace(\n",
    "        go.Scatter(\n",
    "            x=average_summary_IN[\"date\"],\n",
    "            y=average_summary_IN[\"task\"],\n",
    "            mode=\"markers\",\n",
    "            name=None,\n",
    "            hovertemplate=average_summary_IN[\"task\"]\n",
    "            + \"<BR>task: \"\n",
    "            + average_summary_IN[\"task\"]\n",
    "            + \"<BR>date: \"\n",
    "            + average_summary_IN[\"date\"].astype(\"string\")\n",
    "            + \"<BR>ratio: \"\n",
    "            + average_summary_IN[\"ratio\"].astype(\"string\"),\n",
    "            marker=dict(\n",
    "                size=15,  # alpha ratio\n",
    "                symbol=48,  # https://plotly.com/python/marker-style/\n",
    "                opacity=0.7,  # alpha ratio\n",
    "                color=average_summary_IN[\"ratio\"],  # set color equal to a variable\n",
    "                colorscale=\"YlGn\",  # one of plotly colorscales\n",
    "                colorbar=dict(title=\"ratio\", lenmode=\"pixels\"),\n",
    "                showscale=True,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    add_white(\"task\")\n",
    "    \n",
    "    fig_traj.update_traces(\n",
    "        marker=dict(line=dict(color=\"black\", width=1)),\n",
    "        line=dict(width=1, color=\"black\"),\n",
    "    )\n",
    "\n",
    "    fig_traj.update_xaxes(showgrid=True, gridcolor=\"lightBlue\", title=\"Year\")\n",
    "    fig_traj.update_yaxes(showgrid=True, gridcolor=\"lightBlue\", title=ito+\": \"+class_label)\n",
    "\n",
    "    fig_traj.update_layout(\n",
    "        #title=\"Trajectory for ratio (task per year)\",\n",
    "        title_text='Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.',\n",
    "        showlegend=False,\n",
    "        plot_bgcolor=\"white\",\n",
    "        height=2000,\n",
    "        width=900,\n",
    "        xaxis=dict(\n",
    "            tickmode=\"auto\",\n",
    "        ),\n",
    "    )  # set the background colour)\n",
    "\n",
    "    # fig.update_layout(margin_pad=1)\n",
    "\n",
    "    fig_traj.show()\n",
    "    fig_traj.write_image(\"top_classes_trajectory_plots/\"+ito+\".png\")\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://192.168.56.1:9999/blazegraph/sparql'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_level_class</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00101</td>\n",
       "      <td>Vision process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00113</td>\n",
       "      <td>Miscellaneous process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00115</td>\n",
       "      <td>Fundamental AI process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00126</td>\n",
       "      <td>Biomedical AI process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00131</td>\n",
       "      <td>Time Series process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00137</td>\n",
       "      <td>Graph process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00141</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00145</td>\n",
       "      <td>Audio process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00310</td>\n",
       "      <td>Adversarial process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00485</td>\n",
       "      <td>Computer code process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00491</td>\n",
       "      <td>Question answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00528</td>\n",
       "      <td>Knowledge base process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00600</td>\n",
       "      <td>Robotics process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00873</td>\n",
       "      <td>Playing Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://identifiers.org/ito:ITO_01532</td>\n",
       "      <td>Art-related process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://identifiers.org/ito:ITO_00506x</td>\n",
       "      <td>Reasoning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           top_level_class                  class_label\n",
       "0    https://identifiers.org/ito:ITO_00101               Vision process\n",
       "1    https://identifiers.org/ito:ITO_00113        Miscellaneous process\n",
       "2    https://identifiers.org/ito:ITO_00115       Fundamental AI process\n",
       "3    https://identifiers.org/ito:ITO_00126        Biomedical AI process\n",
       "4    https://identifiers.org/ito:ITO_00131          Time Series process\n",
       "5    https://identifiers.org/ito:ITO_00137                Graph process\n",
       "6    https://identifiers.org/ito:ITO_00141  Natural Language Processing\n",
       "7    https://identifiers.org/ito:ITO_00145                Audio process\n",
       "8    https://identifiers.org/ito:ITO_00310          Adversarial process\n",
       "9    https://identifiers.org/ito:ITO_00485        Computer code process\n",
       "10   https://identifiers.org/ito:ITO_00491           Question answering\n",
       "11   https://identifiers.org/ito:ITO_00528       Knowledge base process\n",
       "12   https://identifiers.org/ito:ITO_00600             Robotics process\n",
       "13   https://identifiers.org/ito:ITO_00873                Playing Games\n",
       "14   https://identifiers.org/ito:ITO_01532          Art-related process\n",
       "15  https://identifiers.org/ito:ITO_00506x                    Reasoning"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First select here the list with all top levels that will be used\n",
    "query = \"\"\"\n",
    "        PREFIX ito: <https://identifiers.org/ito:>\n",
    "        SELECT ?top_level_class ?class_label\n",
    "        WHERE { ?top_level_class rdfs:subClassOf ito:ITO_01625 ;\n",
    "                         rdfs:label ?class_label .\n",
    "                FILTER(?top_level_class != ito:Benchmarking) \n",
    "                FILTER(?top_level_class != ito:ITO_01524) \n",
    "              }\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "#send query via API\n",
    "sparql = SPARQLWrapper(endpoint)\n",
    "sparql.setQuery(query)\n",
    "sparql.setReturnFormat(JSON)\n",
    "result = sparql.query()\n",
    "\n",
    "#process results as JSON\n",
    "processed_results = json.load(result.response)\n",
    "\n",
    "#Use accessory function to process results\n",
    "cols = processed_results['head']['vars']\n",
    "\n",
    "out = []\n",
    "for row in processed_results['results']['bindings']:\n",
    "    item = []\n",
    "    for c in cols:\n",
    "        item.append(row.get(c, {}).get('value'))\n",
    "        out.append(item)\n",
    "\n",
    "#this is the final df containing the results of the query\n",
    "top_level = pd.DataFrame(out, columns=cols)\n",
    "\n",
    "top_level = top_level.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "top_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metrics:  250\n"
     ]
    }
   ],
   "source": [
    "#Retrieve metrics used for ito\n",
    "selected_ito = \"ito:ITO_00141\"\n",
    "metricName_df = get_metrics_df(selected_ito)     \n",
    "#remove here metrics with problems\n",
    "metricName_df = metricName_df[metricName_df!=\"Accuracy (pose)\"]\n",
    "metricName_df = metricName_df[metricName_df!=\"F1 (Sequence)\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>% Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MRR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Cased sacreBLEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>ICAT Score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "0                 F1\n",
       "1           Accuracy\n",
       "2                PPL\n",
       "3    % Test Accuracy\n",
       "4                MRR\n",
       "..               ...\n",
       "245  Cased sacreBLEU\n",
       "246       ICAT Score\n",
       "247               PA\n",
       "248               DE\n",
       "249               BA\n",
       "\n",
       "[250 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metricName_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics polarities\n",
    "### Start with the call for the metrics polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>metricName</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Video Retrieval</td>\n",
       "      <td>MSR-VTT-1kA</td>\n",
       "      <td>video-to-text R@1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>42.7</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Video Retrieval</td>\n",
       "      <td>MSVD</td>\n",
       "      <td>video-to-text R@1</td>\n",
       "      <td>58.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                task     datasets         metricName rank_1 rank_2 polarity\n",
       "577  Video Retrieval  MSR-VTT-1kA  video-to-text R@1   43.5   42.7      pos\n",
       "601  Video Retrieval         MSVD  video-to-text R@1   58.7   62.0      neg"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_polarity[metrics_polarity[\"metricName\"]==\"video-to-text R@1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all negative metrics (takes 1-2min to run)\n",
    "metrics_polarity = get_metrics_polarity()\n",
    "\n",
    "metricName_negative_list = metrics_polarity[metrics_polarity[\"polarity\"]==\"neg\"][\"metricName\"].unique()\n",
    "metricName_negative_list = metricName_negative_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metricName</th>\n",
       "      <th>polarity</th>\n",
       "      <th>datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE (Subject-exposed)</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three pixel error</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># of clusters (k)</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>% Test Accuracy</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0..5sec</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1-1</td>\n",
       "      <td>pos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10 sec</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10%</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10-20% Mask PSNR</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14 gestures accuracy</td>\n",
       "      <td>pos</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metricName polarity  datasets\n",
       "0   RMSE (Subject-exposed)      neg         1\n",
       "1        three pixel error      neg         1\n",
       "2        # of clusters (k)      pos         1\n",
       "3          % Test Accuracy      pos         1\n",
       "4                  0..5sec      neg         1\n",
       "5                      1-1      pos         2\n",
       "6                   10 sec      pos         1\n",
       "7                      10%      pos         1\n",
       "8         10-20% Mask PSNR      pos         1\n",
       "9     14 gestures accuracy      pos         3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup some pandas display modes\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#get polarity report\n",
    "polarity_df_report = pd.DataFrame(metrics_polarity.groupby(['metricName', 'polarity'])['datasets'].count())\n",
    "#order\n",
    "polarity_df_report = polarity_df_report.sort_index(ascending=True)\n",
    "\n",
    "#display\n",
    "polarity_df_report_2 = polarity_df_report.copy()\n",
    "\n",
    "polarity_df_report_2.reset_index(inplace=True)  \n",
    "\n",
    "#print the polarity report\n",
    "polarity_df_report_2.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metricName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE (Subject-exposed)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three pixel error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># of clusters (k)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% Test Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0..5sec</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 sec</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-20% Mask PSNR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 gestures accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20-30% Mask PSNR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28 gestures accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 sec</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-fold Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30 sec</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30-40% Mask PSNR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3DIoU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3DPCK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40-50% Mask PSNR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5..20sec</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABX-across</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACC@1-100Clients</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACC@1-10Clients</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACC@1-50Clients</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACER</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADDS AUC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AED</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AKD</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMrTRE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AOP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP 0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP Hard</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP Medium</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP at 10' Elevation error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP at 15' Azimuth error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP75</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP@0.15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP@0.7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APH/L2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APL</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APc</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APf</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APr</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR75</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR@100</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARI</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARL</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC (ABPA)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC (Aspergillus)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC (Diabetes)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC (E. Coli)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC (I. Obstruction)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC (K. Pneumonia)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC (val)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-J</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-J&amp;F</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-ROC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC0.08 private</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC@0.1 (all)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVERAGE MAE</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG-CDS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abs Rel</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (10-fold)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (5-fold)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (8 emotion)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (ADD)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (AV I)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (AV II)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (Body + Fingers + Face joints)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (Body + Fingers joints)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (Body joints)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (CS)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (CV I)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (CV II)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (CV)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (Cross-Setup)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (Cross-Subject)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (Cross-View)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (Cross-View, Avg)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (Inter-Patient)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (RGB+pose)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (TEST-DB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (TRAIN-DB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (easy)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (hard)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (median)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (val)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy(on validation set)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actions Top-1 (S1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actions Top-1 (S2)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animals</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average 3D Error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Accuracy (10 times)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Class Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average MAE</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average MPJPE (mm)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Orientation Similarity</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Overlap</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average PSNR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Per-Class Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Precision</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Precision at 0.5 3D IoU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Recall</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Return (NoOp)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Success Rate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average accuracy of 3 splits</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average-AP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average-mAP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG#1-2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU (EN-DE)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU-1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU-4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backpack</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Error Rate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bare MR^-2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bits per dim</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIDER</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIDEr</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL#1-2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMC1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMC10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMC5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COL</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPU (sec)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSIM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chamfer (cm)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chamfer Distance</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City level (25 km)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class Average IoU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class IOU</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classification Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classification Error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conn</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Continent level (2500 km)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country level (750 km)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3R</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAC (K=6)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELETE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFID</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decidability</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dice</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dice (Average)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dice (SE)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dice Score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diversity</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Driving Score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E-Measure</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EER</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM (Quasar-T)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EO</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edit</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English-Wiki (open) F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entity F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equal Error Rate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Rate</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error rate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exact Match</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exact Span F1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Execution Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expected Average Overlap (EAO)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-BC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Measure</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Measure (Seen)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Measure (Unseen)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Score@1%</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-measure</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-measure (Decay)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-measure (Mean)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-measure (Recall)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (1dAVb)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (AF)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (LBBB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (Quasar-T)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (RBBB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (SB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (ST)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (Sequence)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (Set)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (micro)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 (v2)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 - macro</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Full</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Newswire</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score (@IoU = 0.2)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score (@IoU = 0.3)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score (Augmented)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score (Canonical)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1@10%</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1@25%</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1@50%</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1c (v2)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FED</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID-0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID-1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID-10k-training-steps</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID-2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID-4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID-50k</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID-5k-training-steps</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID-8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR95</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPS on CPU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR@0.1(%, all)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSIM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FVD score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F_NMI</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame (fps)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame-mAP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frames Needed</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full MRP F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full UCCA F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fullset (public)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G-Score (BLEU, Accuracy)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @0.01% FAR Impersonation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @0.01% FAR Obfuscation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @0.01% FAR Overall</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @0.01% FAR Plastic Surgery</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @0.1% FAR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @0.1% FAR Impersonation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @0.1% FAR Obfuscation</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @0.1% FAR Overall</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @0.1% FAR Plastic Surgery</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @1% FAR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @1% FAR Impersonation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @1% FAR Obfuscation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAR @1% FAR Overall</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFLOPs</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grad</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grad Det-Jac</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR@20</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hamming Loss</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmonic mean</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hat</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hausdorff</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hausdorff Distance (mm)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heavy MR^-2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hit@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hit@20</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hits@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hits@10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holder Binary F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humans</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I. Obstruction</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDF1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image-Level Recall</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image-to-text R@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image-to-text R@10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image-to-text R@5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In-domain</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inception Score</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inception score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instance Average IoU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpolation Error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intra-FID</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU [256 distractors]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU [32 distractors]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU [4 distractors]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU mean</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IoU overall</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J&amp;F</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J&amp;F 1st frame</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J&amp;F@60s</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J@60s</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard (Decay)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard (Mean)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard (Recall)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard (Seen)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard (Unseen)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joint</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KEEP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KILT-EM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KILT-F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KILT-RL</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kappa</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kendall's Tau</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kernel Inception Distance</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2 Loss (10^-4)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LCC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LCS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPIPS</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPP MRP F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPP UCCA F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSE-C</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSE-D</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT-ACC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laptop (Acc)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laptop (F1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laptop 2014 (F1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Local</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log-Spectral Distance</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long-Tailed Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE (10% missing)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE (10% of data as GT)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE (Arousal)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE (Expectancy)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE (PM2.5)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE (Power)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE (Valence)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE (trained with other data)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE [bpm, session-wise]</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE for DBP [mmHg]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE for SBP [mmHg]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAR, walking, 1,000ms</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAR, walking, 400ms</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX E-MEASURE</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX F-MEASURE</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME (%, all)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METEOR</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIoU (13 classes)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIoU (16 classes)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MJPE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MKR</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMrTRE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOTA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOTP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPJAE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPJPE</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPJPE (CA)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPJPE (CS)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPVPE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MR (K=1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MR (K=6)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRPE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRR (x 100)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRR@20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS-SSIM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE (10% missing)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE (10^-2, 50% missing)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE (10^2, 50% missing)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE stdev</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE(10^3)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro Precision</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro Recall</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro-F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro-F1 (20% training data)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro-F1 (60% training data)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro-F1 (80% training data)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean ADD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean AP @ 0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Acc (Restaurant + Laptop)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Error Rate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean F-measure</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean F1 (WSJ)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean IoU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean IoU (class)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean NME</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean NME</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean PCK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean PCK@0.2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Rank</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Reconstruction Error (mm)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean class accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean mAP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean target overlap ratio</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium Human-Normalized Score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meteor (EN-DE)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Precision</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Recall</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro-F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro-F1 (20% training data)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro-F1 (80% training data)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiWOZ (Inform)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiWOZ (Success)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG (x 100)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIQE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIST</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLDA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM#5-6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NME</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neg Jacob Det</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neg. F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NegLL</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalized Pose Error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalized Precision</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalized cPSNR</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Noun@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Frames Per View</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Views</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O (Average of Measures)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OMQ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OOB Rate (10^âˆ’3)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Out-of-domain</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall IoU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@10%</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@30%</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA-MPJPE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA-MPVPE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARENT</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCK3D (CA)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCK3D (CS)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCK@0.1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCK@0.2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCK@0.3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCK@0.4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCK@0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCKh</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCKh-0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCKh@0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCP3D</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PESQ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PO</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV (VEB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PQ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PQst</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PQth</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR-AUC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSNR</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSNR (Raw)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSNR (sRGB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSNR-B</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameters (M)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial MR^-2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patch Matching</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patch Retrieval</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patch Verification</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Path Difference</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Path Length</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson Correlation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Per-Class Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Per-class Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Per-pixel Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage Error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage correct</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permuted Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perplexity</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player Distance</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Point-to-surface distance (cm)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pos. F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pr@0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pr@0.7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pr@0.9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision@0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision@0.6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision@0.7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision@0.8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision@0.9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision@20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quality</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Question Answering</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-Prec</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R@1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R@10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R@100</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R@16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R@2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R@32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R@4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R@5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R@8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCL</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE (Subject-naÃ¯ve)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE log</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC-AUC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-L</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE-SU4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RRSE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank-1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank-1 Recognition Rate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank-10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank-5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reasonable MR^-2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reasonable Miss Rate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reference images</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region level (200 km)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relation F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant (Acc)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant (F1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant 2014 (F1)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant 2015 (F1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant 2016 (F1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Route Completion</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runtime(s)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S-Measure</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SARI</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPICE</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQ Rel</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSIM</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSIM (Raw)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSIM (sRGB)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Search time (s)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity (VEB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence Retrieval</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence-pair Classification</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shen F-1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size (MB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smatch</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoothed BLEU-4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman Correlation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speed  (FPS)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speed (FPS)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speed(ms/f)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sq Rel</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step Change (10^âˆ’3)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street level (1 km)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Structured Prediction</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Success Rate 0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface normal consistency</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAR @ FAR=0.0001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAR @ FAR=0.001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAR @ FAR=0.01</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIoU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target Binary F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temporal awareness</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test AP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test perplexity</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text-to-image R@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text-to-image R@10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text-to-image R@5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time (ms)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 1 Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 1 Error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 5 Accuracy</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-1 (%)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-1 Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-1 Error Rate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-1 Localization Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-1 accuracy %</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-10 Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-5 (%)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-5 Accuracy</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-5 Error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UCC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UCS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unpermuted Accuracy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Study Score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V-Measure</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VI</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Val</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation mIoU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verb@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vid acc@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vid acc@5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Video hit@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Video hit@5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Video-mAP 0.5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted Average F1-score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted F-Measure</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted Macro-F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted-F1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word Error Rate (WER)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolute relative error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amota</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg-mAP (0.1-0.5)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg-mAP (0.1-0.9)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg-mAP (0.3-0.7)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg. log MAE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_fp_quality</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_label</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_pairwise</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_spatial</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bits/dimension</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpd</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brier-minFDE (K=6)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free-form mask l1 err</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free-form mask l2 err</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inference time (ms)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAAE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAOE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP (@0.1, Through-wall)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP (@0.1, Visible)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP (All-search &amp; Single-shot)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP (Val)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP @0.5:0.95</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.7</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.75</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP IOU@0.95</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP(V2T)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@0.1:0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@0.1:0.7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@0.25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@0.3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@0.4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@0.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@0.50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@0.50 (CS)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@0.50 (CV)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAP@AVG(0.1:0.9)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mASE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mATE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mAVE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mIOU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mIoU</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mIoU (13 classes)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mIoU (KMeans)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mPC [AP50]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mPC [AP]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mPrec</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mRec</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask AP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask-IS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask-SSIM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max E-Measure</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max E-measure</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max F-Measure</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean Corruption Error (mCE)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean E-Measure</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean Recall @20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanIOU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minADE (K=1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minADE (K=6)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minFDE (K=1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minFDE (K=6)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse (10^-3)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nDCG@5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nats</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pose</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rPC [%]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank-1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank-10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank-5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank1(V2T)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rect mask l1 error</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rect mask l2 err</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sMOTSA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tOF</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-to-video Mean Rank</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-to-video Median Rank</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-to-video R@1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-to-video R@10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-to-video R@5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-to-video R@50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation mean average precision</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-to-text Median Rank</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-to-text R@1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-to-text R@10</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-to-text R@5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Î´1.25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         polarity\n",
       "metricName                                       \n",
       " RMSE (Subject-exposed)                         1\n",
       " three pixel error                              1\n",
       "# of clusters (k)                               1\n",
       "% Test Accuracy                                 1\n",
       "0..5sec                                         1\n",
       "1-1                                             1\n",
       "10 sec                                          1\n",
       "10%                                             1\n",
       "10-20% Mask PSNR                                1\n",
       "14 gestures accuracy                            1\n",
       "20-30% Mask PSNR                                1\n",
       "28 gestures accuracy                            1\n",
       "3 sec                                           1\n",
       "3-fold Accuracy                                 1\n",
       "30 sec                                          1\n",
       "30-40% Mask PSNR                                1\n",
       "3DIoU                                           1\n",
       "3DPCK                                           1\n",
       "40-50% Mask PSNR                                1\n",
       "5..20sec                                        1\n",
       "AAA                                             1\n",
       "ABX-across                                      1\n",
       "ACC                                             1\n",
       "ACC@1-100Clients                                2\n",
       "ACC@1-10Clients                                 1\n",
       "ACC@1-50Clients                                 1\n",
       "ACER                                            1\n",
       "ADD                                             1\n",
       "ADDS AUC                                        1\n",
       "AED                                             2\n",
       "AKD                                             2\n",
       "AMT                                             1\n",
       "AMrTRE                                          1\n",
       "AOP                                             1\n",
       "AP                                              2\n",
       "AP 0.5                                          1\n",
       "AP Hard                                         1\n",
       "AP Medium                                       1\n",
       "AP at 10' Elevation error                       1\n",
       "AP at 15' Azimuth error                         1\n",
       "AP50                                            1\n",
       "AP75                                            1\n",
       "AP@0.15                                         1\n",
       "AP@0.7                                          1\n",
       "APH/L2                                          1\n",
       "APL                                             1\n",
       "APM                                             1\n",
       "APc                                             1\n",
       "APf                                             1\n",
       "APr                                             1\n",
       "AR                                              1\n",
       "AR50                                            1\n",
       "AR75                                            1\n",
       "AR@100                                          1\n",
       "ARI                                             1\n",
       "ARL                                             1\n",
       "ARM                                             1\n",
       "AUC                                             1\n",
       "AUC (ABPA)                                      1\n",
       "AUC (Aspergillus)                               1\n",
       "AUC (Diabetes)                                  1\n",
       "AUC (E. Coli)                                   1\n",
       "AUC (I. Obstruction)                            1\n",
       "AUC (K. Pneumonia)                              1\n",
       "AUC (val)                                       1\n",
       "AUC-J                                           1\n",
       "AUC-J&F                                         1\n",
       "AUC-ROC                                         1\n",
       "AUC0.08 private                                 1\n",
       "AUC@0.1 (all)                                   1\n",
       "AUROC                                           1\n",
       "AVERAGE MAE                                     2\n",
       "AVG                                             1\n",
       "AVG-CDS                                         1\n",
       "Abs Rel                                         2\n",
       "Acc                                             2\n",
       "Accuracy                                        2\n",
       "Accuracy                                        1\n",
       "Accuracy (%)                                    2\n",
       "Accuracy (10-fold)                              1\n",
       "Accuracy (5-fold)                               1\n",
       "Accuracy (8 emotion)                            1\n",
       "Accuracy (ADD)                                  1\n",
       "Accuracy (AV I)                                 1\n",
       "Accuracy (AV II)                                1\n",
       "Accuracy (Body + Fingers + Face joints)         1\n",
       "Accuracy (Body + Fingers joints)                1\n",
       "Accuracy (Body joints)                          1\n",
       "Accuracy (CS)                                   1\n",
       "Accuracy (CV I)                                 1\n",
       "Accuracy (CV II)                                1\n",
       "Accuracy (CV)                                   1\n",
       "Accuracy (Cross-Setup)                          2\n",
       "Accuracy (Cross-Subject)                        1\n",
       "Accuracy (Cross-View)                           1\n",
       "Accuracy (Cross-View, Avg)                      1\n",
       "Accuracy (Inter-Patient)                        1\n",
       "Accuracy (RGB+pose)                             1\n",
       "Accuracy (TEST-DB)                              1\n",
       "Accuracy (TRAIN-DB)                             1\n",
       "Accuracy (Test)                                 1\n",
       "Accuracy (easy)                                 1\n",
       "Accuracy (hard)                                 1\n",
       "Accuracy (median)                               1\n",
       "Accuracy (val)                                  1\n",
       "Accuracy(on validation set)                     1\n",
       "Action@1                                        1\n",
       "Actions Top-1 (S1)                              1\n",
       "Actions Top-1 (S2)                              1\n",
       "Animals                                         1\n",
       "Aspect                                          1\n",
       "Average                                         1\n",
       "Average 3D Error                                1\n",
       "Average Accuracy                                1\n",
       "Average Accuracy (10 times)                     1\n",
       "Average Class Accuracy                          1\n",
       "Average F1                                      1\n",
       "Average MAE                                     2\n",
       "Average MPJPE (mm)                              1\n",
       "Average Orientation Similarity                  1\n",
       "Average Overlap                                 1\n",
       "Average PSNR                                    1\n",
       "Average Per-Class Accuracy                      1\n",
       "Average Precision                               1\n",
       "Average Precision at 0.5 3D IoU                 1\n",
       "Average Recall                                  1\n",
       "Average Return (NoOp)                           1\n",
       "Average Success Rate                            1\n",
       "Average accuracy of 3 splits                    1\n",
       "Average-AP                                      1\n",
       "Average-mAP                                     1\n",
       "Avg                                             1\n",
       "Avg F1                                          1\n",
       "Avg.                                            1\n",
       "B1                                              2\n",
       "B2                                              2\n",
       "B3                                              2\n",
       "B4                                              2\n",
       "BG#1-2                                          1\n",
       "BLEU                                            2\n",
       "BLEU (EN-DE)                                    1\n",
       "BLEU score                                      1\n",
       "BLEU-1                                          1\n",
       "BLEU-4                                          1\n",
       "Backpack                                        1\n",
       "Balanced Error Rate                             1\n",
       "Bare MR^-2                                      1\n",
       "Bits per dim                                    1\n",
       "CC                                              1\n",
       "CD                                              1\n",
       "CIDER                                           1\n",
       "CIDEr                                           1\n",
       "CIS                                             1\n",
       "CL#1-2                                          1\n",
       "CMC1                                            1\n",
       "CMC10                                           1\n",
       "CMC5                                            1\n",
       "COL                                             1\n",
       "CPU (sec)                                       1\n",
       "CR                                              1\n",
       "CS                                              1\n",
       "CSIM                                            1\n",
       "Chamfer (cm)                                    1\n",
       "Chamfer Distance                                1\n",
       "City level (25 km)                              1\n",
       "Class Average IoU                               1\n",
       "Class IOU                                       2\n",
       "Classification Accuracy                         1\n",
       "Classification Error                            1\n",
       "Conn                                            1\n",
       "Continent level (2500 km)                       1\n",
       "Country level (750 km)                          1\n",
       "D3R                                             1\n",
       "DAC (K=6)                                       1\n",
       "DELETE                                          1\n",
       "DFID                                            1\n",
       "DLD                                             1\n",
       "DSC                                             1\n",
       "Decidability                                    1\n",
       "Dice                                            1\n",
       "Dice (Average)                                  1\n",
       "Dice (SE)                                       1\n",
       "Dice Score                                      1\n",
       "Diversity                                       1\n",
       "Driving Score                                   1\n",
       "E-Measure                                       1\n",
       "EC                                              1\n",
       "EER                                             2\n",
       "EM                                              2\n",
       "EM (Quasar-T)                                   1\n",
       "EMD                                             1\n",
       "EO                                              1\n",
       "Edit                                            2\n",
       "English-Wiki (open) F1                          1\n",
       "Entity F1                                       1\n",
       "Equal Error Rate                                1\n",
       "Error Rate                                      2\n",
       "Error rate                                      1\n",
       "Exact Match                                     1\n",
       "Exact Span F1                                   2\n",
       "Execution Accuracy                              1\n",
       "Expected Average Overlap (EAO)                  1\n",
       "F                                               1\n",
       "F-BC                                            1\n",
       "F-Measure                                       1\n",
       "F-Measure (Seen)                                2\n",
       "F-Measure (Unseen)                              2\n",
       "F-Score                                         1\n",
       "F-Score@1%                                      1\n",
       "F-measure                                       1\n",
       "F-measure (Decay)                               2\n",
       "F-measure (Mean)                                1\n",
       "F-measure (Recall)                              1\n",
       "F0.5                                            1\n",
       "F1                                              2\n",
       "F1 (1dAVb)                                      1\n",
       "F1 (AF)                                         1\n",
       "F1 (LBBB)                                       1\n",
       "F1 (Quasar-T)                                   1\n",
       "F1 (RBBB)                                       1\n",
       "F1 (SB)                                         1\n",
       "F1 (ST)                                         1\n",
       "F1 (Sequence)                                   1\n",
       "F1 (Set)                                        1\n",
       "F1 (micro)                                      1\n",
       "F1 (v2)                                         1\n",
       "F1 - macro                                      1\n",
       "F1 Full                                         1\n",
       "F1 Newswire                                     1\n",
       "F1 Score                                        1\n",
       "F1 score                                        2\n",
       "F1-Score                                        1\n",
       "F1-score                                        2\n",
       "F1-score (@IoU = 0.2)                           1\n",
       "F1-score (@IoU = 0.3)                           1\n",
       "F1-score (Augmented)                            2\n",
       "F1-score (Canonical)                            1\n",
       "F1@10%                                          2\n",
       "F1@25%                                          2\n",
       "F1@50%                                          1\n",
       "F1c (v2)                                        1\n",
       "FDE                                             1\n",
       "FED                                             1\n",
       "FID                                             2\n",
       "FID-0                                           1\n",
       "FID-1                                           1\n",
       "FID-10k-training-steps                          1\n",
       "FID-2                                           1\n",
       "FID-4                                           1\n",
       "FID-50k                                         1\n",
       "FID-5k-training-steps                           1\n",
       "FID-8                                           1\n",
       "FPR95                                           1\n",
       "FPS                                             1\n",
       "FPS on CPU                                      1\n",
       "FR@0.1(%, all)                                  1\n",
       "FSD                                             1\n",
       "FSIM                                            1\n",
       "FVD score                                       1\n",
       "F_NMI                                           1\n",
       "Frame (fps)                                     1\n",
       "Frame-mAP                                       1\n",
       "Frames Needed                                   1\n",
       "Full MRP F1                                     1\n",
       "Full UCCA F1                                    1\n",
       "Fullset (public)                                1\n",
       "G-Score (BLEU, Accuracy)                        1\n",
       "GAR @0.01% FAR Impersonation                    1\n",
       "GAR @0.01% FAR Obfuscation                      1\n",
       "GAR @0.01% FAR Overall                          1\n",
       "GAR @0.01% FAR Plastic Surgery                  1\n",
       "GAR @0.1% FAR                                   1\n",
       "GAR @0.1% FAR Impersonation                     1\n",
       "GAR @0.1% FAR Obfuscation                       2\n",
       "GAR @0.1% FAR Overall                           2\n",
       "GAR @0.1% FAR Plastic Surgery                   1\n",
       "GAR @1% FAR                                     1\n",
       "GAR @1% FAR Impersonation                       1\n",
       "GAR @1% FAR Obfuscation                         1\n",
       "GAR @1% FAR Overall                             1\n",
       "GFLOPs                                          1\n",
       "Gender                                          1\n",
       "Grad                                            1\n",
       "Grad Det-Jac                                    1\n",
       "HR@20                                           2\n",
       "Hamming Loss                                    1\n",
       "Harmonic mean                                   1\n",
       "Hat                                             1\n",
       "Hausdorff                                       1\n",
       "Hausdorff Distance (mm)                         1\n",
       "Heavy MR^-2                                     1\n",
       "Hit@1                                           1\n",
       "Hit@20                                          2\n",
       "Hits@1                                          1\n",
       "Hits@10                                         1\n",
       "Holder Binary F1                                1\n",
       "Humans                                          1\n",
       "I. Obstruction                                  1\n",
       "IDF1                                            1\n",
       "IS                                              2\n",
       "Image-Level Recall                              1\n",
       "Image-to-text R@1                               1\n",
       "Image-to-text R@10                              1\n",
       "Image-to-text R@5                               1\n",
       "In-domain                                       1\n",
       "Inception Score                                 2\n",
       "Inception score                                 1\n",
       "Instance Average IoU                            1\n",
       "Interpolation Error                             1\n",
       "Intra-FID                                       1\n",
       "IoU                                             2\n",
       "IoU [256 distractors]                           1\n",
       "IoU [32 distractors]                            1\n",
       "IoU [4 distractors]                             1\n",
       "IoU mean                                        1\n",
       "IoU overall                                     2\n",
       "J&F                                             1\n",
       "J&F 1st frame                                   1\n",
       "J&F@60s                                         1\n",
       "J@60s                                           1\n",
       "Jaccard (Decay)                                 2\n",
       "Jaccard (Mean)                                  1\n",
       "Jaccard (Recall)                                2\n",
       "Jaccard (Seen)                                  1\n",
       "Jaccard (Unseen)                                2\n",
       "Joint                                           1\n",
       "KEEP                                            1\n",
       "KILT-EM                                         1\n",
       "KILT-F1                                         1\n",
       "KILT-RL                                         1\n",
       "Kappa                                           1\n",
       "Kendall's Tau                                   1\n",
       "Kernel Inception Distance                       1\n",
       "L1                                              2\n",
       "L2 Loss (10^-4)                                 1\n",
       "LAS                                             1\n",
       "LCC                                             1\n",
       "LCS                                             1\n",
       "LLE                                             1\n",
       "LPIPS                                           2\n",
       "LPP MRP F1                                      1\n",
       "LPP UCCA F1                                     1\n",
       "LSE-C                                           1\n",
       "LSE-D                                           1\n",
       "LT-ACC                                          1\n",
       "Laptop (Acc)                                    1\n",
       "Laptop (F1)                                     1\n",
       "Laptop 2014 (F1)                                1\n",
       "Local                                           1\n",
       "Log-Spectral Distance                           1\n",
       "Long-Tailed Accuracy                            1\n",
       "MAE                                             2\n",
       "MAE (10% missing)                               1\n",
       "MAE (10% of data as GT)                         1\n",
       "MAE (Arousal)                                   1\n",
       "MAE (Expectancy)                                1\n",
       "MAE (PM2.5)                                     1\n",
       "MAE (Power)                                     1\n",
       "MAE (Valence)                                   1\n",
       "MAE (trained with other data)                   1\n",
       "MAE [bpm, session-wise]                         2\n",
       "MAE for DBP [mmHg]                              1\n",
       "MAE for SBP [mmHg]                              1\n",
       "MAP                                             2\n",
       "MAP                                             1\n",
       "MAR, walking, 1,000ms                           1\n",
       "MAR, walking, 400ms                             1\n",
       "MAX E-MEASURE                                   2\n",
       "MAX F-MEASURE                                   2\n",
       "ME (%, all)                                     1\n",
       "METEOR                                          2\n",
       "MIoU (13 classes)                               1\n",
       "MIoU (16 classes)                               1\n",
       "MJPE                                            1\n",
       "MKR                                             2\n",
       "MMD                                             1\n",
       "MMrTRE                                          1\n",
       "MOTA                                            1\n",
       "MOTP                                            1\n",
       "MPE                                             1\n",
       "MPJAE                                           1\n",
       "MPJPE                                           2\n",
       "MPJPE (CA)                                      1\n",
       "MPJPE (CS)                                      1\n",
       "MPS                                             1\n",
       "MPVPE                                           1\n",
       "MR (K=1)                                        1\n",
       "MR (K=6)                                        1\n",
       "MRPE                                            1\n",
       "MRR                                             1\n",
       "MRR (x 100)                                     1\n",
       "MRR@20                                          1\n",
       "MS-SSIM                                         1\n",
       "MSE                                             1\n",
       "MSE (10% missing)                               1\n",
       "MSE (10^-2, 50% missing)                        1\n",
       "MSE (10^2, 50% missing)                         1\n",
       "MSE stdev                                       1\n",
       "MSE(10^3)                                       1\n",
       "Macro F1                                        1\n",
       "Macro Precision                                 1\n",
       "Macro Recall                                    1\n",
       "Macro-F1                                        1\n",
       "Macro-F1 (20% training data)                    1\n",
       "Macro-F1 (60% training data)                    1\n",
       "Macro-F1 (80% training data)                    1\n",
       "Mean                                            1\n",
       "Mean ADD                                        1\n",
       "Mean AP @ 0.5                                   1\n",
       "Mean Acc (Restaurant + Laptop)                  1\n",
       "Mean Accuracy                                   1\n",
       "Mean Error Rate                                 1\n",
       "Mean F-measure                                  1\n",
       "Mean F1 (WSJ)                                   1\n",
       "Mean IoU                                        1\n",
       "Mean IoU (class)                                1\n",
       "Mean NME                                        1\n",
       "Mean NME                                        1\n",
       "Mean PCK                                        1\n",
       "Mean PCK@0.2                                    1\n",
       "Mean Rank                                       1\n",
       "Mean Reconstruction Error (mm)                  1\n",
       "Mean class accuracy                             1\n",
       "Mean mAP                                        1\n",
       "Mean target overlap ratio                       1\n",
       "Medium Human-Normalized Score                   1\n",
       "Meteor (EN-DE)                                  1\n",
       "Micro F1                                        1\n",
       "Micro Precision                                 1\n",
       "Micro Recall                                    1\n",
       "Micro-F1                                        1\n",
       "Micro-F1 (20% training data)                    1\n",
       "Micro-F1 (80% training data)                    1\n",
       "MultiWOZ (Inform)                               1\n",
       "MultiWOZ (Success)                              1\n",
       "NDCG (x 100)                                    1\n",
       "NDS                                             1\n",
       "NIQE                                            1\n",
       "NIST                                            1\n",
       "NLDA                                            1\n",
       "NM#5-6                                          1\n",
       "NME                                             1\n",
       "NSS                                             1\n",
       "Neg Jacob Det                                   1\n",
       "Neg. F1                                         1\n",
       "NegLL                                           1\n",
       "Normalized Pose Error                           1\n",
       "Normalized Precision                            1\n",
       "Normalized cPSNR                                1\n",
       "Noun@1                                          1\n",
       "Number of Frames Per View                       1\n",
       "Number of Views                                 1\n",
       "O (Average of Measures)                         1\n",
       "OMQ                                             1\n",
       "OOB Rate (10^âˆ’3)                                1\n",
       "ORD                                             1\n",
       "ORD                                             1\n",
       "Out-of-domain                                   1\n",
       "Overall                                         1\n",
       "Overall Accuracy                                1\n",
       "Overall IoU                                     1\n",
       "P                                               1\n",
       "P@10%                                           1\n",
       "P@30%                                           1\n",
       "P@5                                             1\n",
       "PA-MPJPE                                        1\n",
       "PA-MPVPE                                        1\n",
       "PARENT                                          1\n",
       "PC                                              1\n",
       "PCK                                             1\n",
       "PCK3D (CA)                                      1\n",
       "PCK3D (CS)                                      1\n",
       "PCK@0.1                                         1\n",
       "PCK@0.2                                         2\n",
       "PCK@0.3                                         1\n",
       "PCK@0.4                                         1\n",
       "PCK@0.5                                         1\n",
       "PCKh                                            2\n",
       "PCKh-0.5                                        1\n",
       "PCKh@0.5                                        1\n",
       "PCP3D                                           1\n",
       "PESQ                                            1\n",
       "PO                                              1\n",
       "PPV (VEB)                                       1\n",
       "PQ                                              1\n",
       "PQst                                            1\n",
       "PQth                                            2\n",
       "PR-AUC                                          1\n",
       "PRC                                             1\n",
       "PSNR                                            2\n",
       "PSNR (Raw)                                      1\n",
       "PSNR (sRGB)                                     1\n",
       "PSNR-B                                          2\n",
       "Parameters (M)                                  1\n",
       "Partial MR^-2                                   1\n",
       "Patch Matching                                  1\n",
       "Patch Retrieval                                 1\n",
       "Patch Verification                              1\n",
       "Path Difference                                 1\n",
       "Path Length                                     1\n",
       "Pearson Correlation                             1\n",
       "Per-Class Accuracy                              1\n",
       "Per-class Accuracy                              1\n",
       "Per-pixel Accuracy                              1\n",
       "Percentage Error                                1\n",
       "Percentage correct                              1\n",
       "Percentage error                                1\n",
       "Permuted Accuracy                               1\n",
       "Perplexity                                      1\n",
       "Player Distance                                 1\n",
       "Point-to-surface distance (cm)                  1\n",
       "Pos. F1                                         1\n",
       "Pr@0.5                                          1\n",
       "Pr@0.7                                          1\n",
       "Pr@0.9                                          1\n",
       "Precision                                       2\n",
       "Precision@0.5                                   1\n",
       "Precision@0.6                                   1\n",
       "Precision@0.7                                   1\n",
       "Precision@0.8                                   1\n",
       "Precision@0.9                                   1\n",
       "Precision@20                                    1\n",
       "Quality                                         1\n",
       "Question Answering                              1\n",
       "R                                               1\n",
       "R-Prec                                          2\n",
       "R@1                                             2\n",
       "R@10                                            1\n",
       "R@100                                           1\n",
       "R@16                                            1\n",
       "R@2                                             1\n",
       "R@32                                            1\n",
       "R@4                                             1\n",
       "R@5                                             1\n",
       "R@8                                             1\n",
       "RC                                              1\n",
       "RCL                                             1\n",
       "RMSE                                            2\n",
       "RMSE (Subject-naÃ¯ve)                            1\n",
       "RMSE log                                        1\n",
       "ROC AUC                                         1\n",
       "ROC-AUC                                         1\n",
       "ROUGE                                           1\n",
       "ROUGE-1                                         1\n",
       "ROUGE-2                                         2\n",
       "ROUGE-L                                         2\n",
       "ROUGE-SU4                                       1\n",
       "RRSE                                            1\n",
       "Rank-1                                          1\n",
       "Rank-1 Recognition Rate                         1\n",
       "Rank-10                                         1\n",
       "Rank-5                                          2\n",
       "Real                                            1\n",
       "Reasonable MR^-2                                1\n",
       "Reasonable Miss Rate                            1\n",
       "Recall                                          2\n",
       "Recall@10                                       1\n",
       "Recall@5                                        1\n",
       "Recall@50                                       1\n",
       "Reference images                                1\n",
       "Region level (200 km)                           1\n",
       "Relation F1                                     1\n",
       "Restaurant (Acc)                                1\n",
       "Restaurant (F1)                                 1\n",
       "Restaurant 2014 (F1)                            2\n",
       "Restaurant 2015 (F1)                            1\n",
       "Restaurant 2016 (F1)                            1\n",
       "Route Completion                                1\n",
       "Runtime(s)                                      1\n",
       "S-Measure                                       1\n",
       "SAD                                             1\n",
       "SARI                                            1\n",
       "SPICE                                           2\n",
       "SQ Rel                                          1\n",
       "SSIM                                            2\n",
       "SSIM (Raw)                                      1\n",
       "SSIM (sRGB)                                     2\n",
       "Score                                           1\n",
       "Search time (s)                                 1\n",
       "Sensitivity                                     1\n",
       "Sensitivity (VEB)                               1\n",
       "Sentence Retrieval                              1\n",
       "Sentence-pair Classification                    1\n",
       "Sentiment                                       1\n",
       "Shen F-1                                        1\n",
       "Size (MB)                                       1\n",
       "Smatch                                          1\n",
       "Smoothed BLEU-4                                 1\n",
       "Spearman Correlation                            1\n",
       "Speed  (FPS)                                    2\n",
       "Speed (FPS)                                     1\n",
       "Speed(ms/f)                                     1\n",
       "Sq Rel                                          1\n",
       "Step Change (10^âˆ’3)                             1\n",
       "Street level (1 km)                             1\n",
       "Structured Prediction                           1\n",
       "Success Rate 0.5                                1\n",
       "Surface normal consistency                      1\n",
       "TAR @ FAR=0.0001                                1\n",
       "TAR @ FAR=0.001                                 1\n",
       "TAR @ FAR=0.01                                  1\n",
       "TC                                              1\n",
       "TIoU                                            1\n",
       "TTA                                             1\n",
       "Target Binary F1                                1\n",
       "Temporal awareness                              1\n",
       "Test AP                                         1\n",
       "Test Error                                      1\n",
       "Test perplexity                                 1\n",
       "Text-to-image R@1                               1\n",
       "Text-to-image R@10                              1\n",
       "Text-to-image R@5                               1\n",
       "Time (ms)                                       1\n",
       "Top 1 Accuracy                                  1\n",
       "Top 1 Error                                     1\n",
       "Top 5 Accuracy                                  2\n",
       "Top-1                                           1\n",
       "Top-1 (%)                                       1\n",
       "Top-1 Accuracy                                  1\n",
       "Top-1 Error Rate                                1\n",
       "Top-1 Localization Accuracy                     1\n",
       "Top-1 accuracy %                                1\n",
       "Top-10 Accuracy                                 1\n",
       "Top-3                                           1\n",
       "Top-5 (%)                                       1\n",
       "Top-5 Accuracy                                  2\n",
       "Top-5 Error                                     1\n",
       "UA                                              1\n",
       "UAS                                             1\n",
       "UCC                                             1\n",
       "UCS                                             1\n",
       "Unpermuted Accuracy                             1\n",
       "User Study Score                                1\n",
       "V-Measure                                       1\n",
       "VI                                              1\n",
       "Val                                             1\n",
       "Validation mIoU                                 1\n",
       "Verb@1                                          1\n",
       "Vid acc@1                                       1\n",
       "Vid acc@5                                       1\n",
       "Video hit@1                                     1\n",
       "Video hit@5                                     1\n",
       "Video-mAP 0.5                                   2\n",
       "Weighted Average F1-score                       1\n",
       "Weighted F-Measure                              1\n",
       "Weighted F1                                     1\n",
       "Weighted Macro-F1                               1\n",
       "Weighted-F1                                     1\n",
       "Word Error Rate (WER)                           1\n",
       "absolute relative error                         1\n",
       "amota                                           1\n",
       "avg-mAP (0.1-0.5)                               1\n",
       "avg-mAP (0.1-0.9)                               1\n",
       "avg-mAP (0.3-0.7)                               1\n",
       "avg. log MAE                                    1\n",
       "avg_fp_quality                                  1\n",
       "avg_label                                       1\n",
       "avg_pairwise                                    1\n",
       "avg_spatial                                     1\n",
       "bits/dimension                                  2\n",
       "bpd                                             1\n",
       "brier-minFDE (K=6)                              1\n",
       "classification score                            1\n",
       "count                                           1\n",
       "free-form mask l1 err                           1\n",
       "free-form mask l2 err                           1\n",
       "inference time (ms)                             1\n",
       "mAAE                                            1\n",
       "mAOE                                            1\n",
       "mAP                                             2\n",
       "mAP (@0.1, Through-wall)                        1\n",
       "mAP (@0.1, Visible)                             1\n",
       "mAP (All-search & Single-shot)                  1\n",
       "mAP (Val)                                       1\n",
       "mAP @0.5:0.95                                   1\n",
       "mAP IOU@0.1                                     1\n",
       "mAP IOU@0.2                                     1\n",
       "mAP IOU@0.3                                     1\n",
       "mAP IOU@0.4                                     1\n",
       "mAP IOU@0.5                                     1\n",
       "mAP IOU@0.6                                     2\n",
       "mAP IOU@0.7                                     2\n",
       "mAP IOU@0.75                                    1\n",
       "mAP IOU@0.8                                     1\n",
       "mAP IOU@0.9                                     1\n",
       "mAP IOU@0.95                                    1\n",
       "mAP(V2T)                                        1\n",
       "mAP@0.1:0.5                                     1\n",
       "mAP@0.1:0.7                                     1\n",
       "mAP@0.25                                        1\n",
       "mAP@0.3                                         1\n",
       "mAP@0.4                                         1\n",
       "mAP@0.5                                         1\n",
       "mAP@0.50                                        1\n",
       "mAP@0.50 (CS)                                   1\n",
       "mAP@0.50 (CV)                                   1\n",
       "mAP@AVG(0.1:0.9)                                1\n",
       "mASE                                            1\n",
       "mATE                                            1\n",
       "mAVE                                            1\n",
       "mIOU                                            1\n",
       "mIoU                                            2\n",
       "mIoU (13 classes)                               1\n",
       "mIoU (KMeans)                                   1\n",
       "mPC [AP50]                                      1\n",
       "mPC [AP]                                        1\n",
       "mPrec                                           1\n",
       "mRec                                            1\n",
       "mask AP                                         1\n",
       "mask-IS                                         1\n",
       "mask-SSIM                                       1\n",
       "max E-Measure                                   2\n",
       "max E-measure                                   2\n",
       "max F-Measure                                   2\n",
       "mean Corruption Error (mCE)                     1\n",
       "mean E-Measure                                  1\n",
       "mean Recall @20                                 1\n",
       "meanIOU                                         1\n",
       "minADE (K=1)                                    1\n",
       "minADE (K=6)                                    1\n",
       "minFDE (K=1)                                    1\n",
       "minFDE (K=6)                                    1\n",
       "mse (10^-3)                                     1\n",
       "nDCG@5                                          1\n",
       "nats                                            1\n",
       "pose                                            1\n",
       "rPC [%]                                         1\n",
       "rank-1                                          1\n",
       "rank-10                                         1\n",
       "rank-5                                          1\n",
       "rank1                                           1\n",
       "rank1(V2T)                                      1\n",
       "rect mask l1 error                              1\n",
       "rect mask l2 err                                1\n",
       "sMOTSA                                          1\n",
       "spl                                             1\n",
       "tOF                                             1\n",
       "text-to-video Mean Rank                         2\n",
       "text-to-video Median Rank                       2\n",
       "text-to-video R@1                               1\n",
       "text-to-video R@10                              1\n",
       "text-to-video R@5                               1\n",
       "text-to-video R@50                              1\n",
       "validation mean average precision               1\n",
       "video-to-text Median Rank                       1\n",
       "video-to-text R@1                               2\n",
       "video-to-text R@10                              2\n",
       "video-to-text R@5                               2\n",
       "Î´1.25                                           1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summarise how many different polarities are observed for each metric\n",
    "metrics_polarity_counts =  pd.DataFrame(polarity_df_report_2.groupby(['metricName'])['polarity'].count())\n",
    "\n",
    "metrics_polarity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count how many metrics have been assigned to two polarities\n",
    "len(metrics_polarity_counts[metrics_polarity_counts[\"polarity\"]==2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metricName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACC@1-100Clients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVERAGE MAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abs Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Accuracy (%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Accuracy (Cross-Setup)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Average MAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BLEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Class IOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Edit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Error Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Exact Span F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>F-Measure (Seen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>F-Measure (Unseen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>F-measure (Decay)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>F1 score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>F1-score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>F1-score (Augmented)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>F1@10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>F1@25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GAR @0.1% FAR Obfuscation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GAR @0.1% FAR Overall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HR@20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Hit@20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>IS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Inception Score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>IoU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>IoU overall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Jaccard (Decay)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Jaccard (Recall)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Jaccard (Unseen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LPIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>MAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MAE [bpm, session-wise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MAX E-MEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>MAX F-MEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>METEOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>MKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>MPJPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PCK@0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PCKh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>PQth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PSNR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>PSNR-B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>R-Prec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>R@1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>RMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ROUGE-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ROUGE-L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Rank-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Restaurant 2014 (F1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SPICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SSIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SSIM (sRGB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Speed  (FPS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Top 5 Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Top-5 Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Video-mAP 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>bits/dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>mAP IOU@0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>mAP IOU@0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>mIoU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>max E-Measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>max E-measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>max F-Measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>text-to-video Mean Rank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>text-to-video Median Rank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>video-to-text R@1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>video-to-text R@10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>video-to-text R@5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   metricName\n",
       "0            ACC@1-100Clients\n",
       "1                         AED\n",
       "2                         AKD\n",
       "3                          AP\n",
       "4                 AVERAGE MAE\n",
       "5                     Abs Rel\n",
       "6                         Acc\n",
       "7                    Accuracy\n",
       "8                Accuracy (%)\n",
       "9      Accuracy (Cross-Setup)\n",
       "10                Average MAE\n",
       "11                         B1\n",
       "12                         B2\n",
       "13                         B3\n",
       "14                         B4\n",
       "15                       BLEU\n",
       "16                  Class IOU\n",
       "17                        EER\n",
       "18                         EM\n",
       "19                       Edit\n",
       "20                 Error Rate\n",
       "21              Exact Span F1\n",
       "22           F-Measure (Seen)\n",
       "23         F-Measure (Unseen)\n",
       "24          F-measure (Decay)\n",
       "25                         F1\n",
       "26                   F1 score\n",
       "27                   F1-score\n",
       "28       F1-score (Augmented)\n",
       "29                     F1@10%\n",
       "30                     F1@25%\n",
       "31                        FID\n",
       "32  GAR @0.1% FAR Obfuscation\n",
       "33      GAR @0.1% FAR Overall\n",
       "34                      HR@20\n",
       "35                     Hit@20\n",
       "36                         IS\n",
       "37            Inception Score\n",
       "38                        IoU\n",
       "39                IoU overall\n",
       "40            Jaccard (Decay)\n",
       "41           Jaccard (Recall)\n",
       "42           Jaccard (Unseen)\n",
       "43                         L1\n",
       "44                      LPIPS\n",
       "45                        MAE\n",
       "46    MAE [bpm, session-wise]\n",
       "47                        MAP\n",
       "48              MAX E-MEASURE\n",
       "49              MAX F-MEASURE\n",
       "50                     METEOR\n",
       "51                        MKR\n",
       "52                      MPJPE\n",
       "53                    PCK@0.2\n",
       "54                       PCKh\n",
       "55                       PQth\n",
       "56                       PSNR\n",
       "57                     PSNR-B\n",
       "58                  Precision\n",
       "59                     R-Prec\n",
       "60                        R@1\n",
       "61                       RMSE\n",
       "62                    ROUGE-2\n",
       "63                    ROUGE-L\n",
       "64                     Rank-5\n",
       "65                     Recall\n",
       "66       Restaurant 2014 (F1)\n",
       "67                      SPICE\n",
       "68                       SSIM\n",
       "69                SSIM (sRGB)\n",
       "70               Speed  (FPS)\n",
       "71             Top 5 Accuracy\n",
       "72             Top-5 Accuracy\n",
       "73              Video-mAP 0.5\n",
       "74             bits/dimension\n",
       "75                        mAP\n",
       "76                mAP IOU@0.6\n",
       "77                mAP IOU@0.7\n",
       "78                       mIoU\n",
       "79              max E-Measure\n",
       "80              max E-measure\n",
       "81              max F-Measure\n",
       "82    text-to-video Mean Rank\n",
       "83  text-to-video Median Rank\n",
       "84          video-to-text R@1\n",
       "85         video-to-text R@10\n",
       "86          video-to-text R@5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metrics_polarity_counts[metrics_polarity_counts[\"polarity\"]==2].index\n",
    "pd.DataFrame(metrics_polarity_counts[metrics_polarity_counts[\"polarity\"]==2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACC@1-100Clients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVERAGE MAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abs Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Accuracy (%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Accuracy (Cross-Setup)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Average MAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BLEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Class IOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Edit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Error Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Exact Span F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>F-Measure (Seen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>F-Measure (Unseen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>F-measure (Decay)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>F1 score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>F1-score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>F1-score (Augmented)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>F1@10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>F1@25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GAR @0.1% FAR Obfuscation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GAR @0.1% FAR Overall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HR@20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Hit@20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>IS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Inception Score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>IoU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>IoU overall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Jaccard (Decay)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Jaccard (Recall)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Jaccard (Unseen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LPIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>MAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MAE [bpm, session-wise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MAX E-MEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>MAX F-MEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>METEOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>MKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>MPJPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PCK@0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PCKh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>PQth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PSNR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>PSNR-B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>R-Prec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>R@1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>RMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ROUGE-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ROUGE-L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Rank-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Restaurant 2014 (F1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SPICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SSIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SSIM (sRGB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Speed  (FPS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Top 5 Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Top-5 Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Video-mAP 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>bits/dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>mAP IOU@0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>mAP IOU@0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>mIoU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>max E-Measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>max E-measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>max F-Measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>text-to-video Mean Rank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>text-to-video Median Rank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>video-to-text R@1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>video-to-text R@10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>video-to-text R@5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      metrics\n",
       "0            ACC@1-100Clients\n",
       "1                         AED\n",
       "2                         AKD\n",
       "3                          AP\n",
       "4                 AVERAGE MAE\n",
       "5                     Abs Rel\n",
       "6                         Acc\n",
       "7                    Accuracy\n",
       "8                Accuracy (%)\n",
       "9      Accuracy (Cross-Setup)\n",
       "10                Average MAE\n",
       "11                         B1\n",
       "12                         B2\n",
       "13                         B3\n",
       "14                         B4\n",
       "15                       BLEU\n",
       "16                  Class IOU\n",
       "17                        EER\n",
       "18                         EM\n",
       "19                       Edit\n",
       "20                 Error Rate\n",
       "21              Exact Span F1\n",
       "22           F-Measure (Seen)\n",
       "23         F-Measure (Unseen)\n",
       "24          F-measure (Decay)\n",
       "25                         F1\n",
       "26                   F1 score\n",
       "27                   F1-score\n",
       "28       F1-score (Augmented)\n",
       "29                     F1@10%\n",
       "30                     F1@25%\n",
       "31                        FID\n",
       "32  GAR @0.1% FAR Obfuscation\n",
       "33      GAR @0.1% FAR Overall\n",
       "34                      HR@20\n",
       "35                     Hit@20\n",
       "36                         IS\n",
       "37            Inception Score\n",
       "38                        IoU\n",
       "39                IoU overall\n",
       "40            Jaccard (Decay)\n",
       "41           Jaccard (Recall)\n",
       "42           Jaccard (Unseen)\n",
       "43                         L1\n",
       "44                      LPIPS\n",
       "45                        MAE\n",
       "46    MAE [bpm, session-wise]\n",
       "47                        MAP\n",
       "48              MAX E-MEASURE\n",
       "49              MAX F-MEASURE\n",
       "50                     METEOR\n",
       "51                        MKR\n",
       "52                      MPJPE\n",
       "53                    PCK@0.2\n",
       "54                       PCKh\n",
       "55                       PQth\n",
       "56                       PSNR\n",
       "57                     PSNR-B\n",
       "58                  Precision\n",
       "59                     R-Prec\n",
       "60                        R@1\n",
       "61                       RMSE\n",
       "62                    ROUGE-2\n",
       "63                    ROUGE-L\n",
       "64                     Rank-5\n",
       "65                     Recall\n",
       "66       Restaurant 2014 (F1)\n",
       "67                      SPICE\n",
       "68                       SSIM\n",
       "69                SSIM (sRGB)\n",
       "70               Speed  (FPS)\n",
       "71             Top 5 Accuracy\n",
       "72             Top-5 Accuracy\n",
       "73              Video-mAP 0.5\n",
       "74             bits/dimension\n",
       "75                        mAP\n",
       "76                mAP IOU@0.6\n",
       "77                mAP IOU@0.7\n",
       "78                       mIoU\n",
       "79              max E-Measure\n",
       "80              max E-measure\n",
       "81              max F-Measure\n",
       "82    text-to-video Mean Rank\n",
       "83  text-to-video Median Rank\n",
       "84          video-to-text R@1\n",
       "85         video-to-text R@10\n",
       "86          video-to-text R@5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list=metrics_polarity_counts[metrics_polarity_counts[\"polarity\"]==2].index\n",
    "example = pd.DataFrame({\"metrics\":metrics_list})\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metricName</th>\n",
       "      <th>curatedPolarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACC@1-100Clients</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AED</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AKD</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVERAGE MAE</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abs Rel</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acc</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Accuracy (%)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Accuracy (Cross-Setup)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Average MAE</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B1</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B2</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B3</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B4</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BLEU</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Class IOU</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EER</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EM</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Edit</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Error Rate</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Exact Span F1</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>F-Measure (Seen)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>F-Measure (Unseen)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>F1</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>F1-score (Augmented)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>F1@10%</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>F1@25%</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FID</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GAR @0.1% FAR Obfuscation</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GAR @0.1% FAR Overall</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HR@20</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Hit@20</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>IS</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Inception Score</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>IoU</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>IoU overall</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Jaccard (Decay)</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Jaccard (Recall)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Jaccard (Unseen)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>L1</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LPIPS</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>MAE</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>MAE [bpm, session-wise]</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MAP</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MAX E-MEASURE</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MAX F-MEASURE</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>METEOR</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>MKR</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>MPJPE</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>PCK@0.2</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PCKh</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PQth</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>PSNR</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PSNR-B</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Precision</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>R-Prec</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>R@1</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ROUGE-2</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ROUGE-L</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Rank-5</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Recall</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Restaurant 2014 (F1)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>SPICE</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SSIM</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SSIM (sRGB)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Speed (FPS)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Top 5 Accuracy</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Top-5 Accuracy</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Video-mAP 0.5</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>mAP</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>mAP IOU@0.6</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mAP IOU@0.7</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>mIoU</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>max E-Measure</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>max E-measure</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>max F-Measure</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>text-to-video Mean Rank</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>text-to-video Median Rank</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>video-to-text R@1</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>video-to-text R@10</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>video-to-text R@5</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   metricName curatedPolarity\n",
       "0            ACC@1-100Clients             pos\n",
       "1                         AED             neg\n",
       "2                         AKD             neg\n",
       "3                          AP             pos\n",
       "4                 AVERAGE MAE             neg\n",
       "5                     Abs Rel             pos\n",
       "6                         Acc             pos\n",
       "7                    Accuracy             pos\n",
       "8                Accuracy (%)             pos\n",
       "9      Accuracy (Cross-Setup)             pos\n",
       "10                Average MAE             neg\n",
       "11                         B1             pos\n",
       "12                         B2             pos\n",
       "13                         B3             pos\n",
       "14                         B4             pos\n",
       "15                       BLEU             pos\n",
       "16                  Class IOU             pos\n",
       "17                        EER             neg\n",
       "18                         EM             pos\n",
       "19                       Edit             pos\n",
       "20                 Error Rate             neg\n",
       "21              Exact Span F1             pos\n",
       "22           F-Measure (Seen)             pos\n",
       "23         F-Measure (Unseen)             pos\n",
       "24                         F1             pos\n",
       "25                   F1 score             pos\n",
       "26                   F1-score             pos\n",
       "27       F1-score (Augmented)             pos\n",
       "28                     F1@10%             pos\n",
       "29                     F1@25%             pos\n",
       "30                        FID             neg\n",
       "31  GAR @0.1% FAR Obfuscation             pos\n",
       "32      GAR @0.1% FAR Overall             pos\n",
       "33                      HR@20             pos\n",
       "34                     Hit@20             pos\n",
       "35                         IS             pos\n",
       "36            Inception Score             pos\n",
       "37                        IoU             pos\n",
       "38                IoU overall             pos\n",
       "39            Jaccard (Decay)             neg\n",
       "40           Jaccard (Recall)             pos\n",
       "41           Jaccard (Unseen)             pos\n",
       "42                         L1             neg\n",
       "43                      LPIPS             neg\n",
       "44                        MAE             neg\n",
       "45    MAE [bpm, session-wise]             neg\n",
       "46                        MAP             pos\n",
       "47              MAX E-MEASURE             pos\n",
       "48              MAX F-MEASURE             pos\n",
       "49                     METEOR             pos\n",
       "50                        MKR             neg\n",
       "51                      MPJPE             neg\n",
       "52                    PCK@0.2             pos\n",
       "53                       PCKh             pos\n",
       "54                       PQth             pos\n",
       "55                       PSNR             pos\n",
       "56                     PSNR-B             pos\n",
       "57                  Precision             pos\n",
       "58                     R-Prec             pos\n",
       "59                        R@1             pos\n",
       "60                       RMSE             neg\n",
       "61                    ROUGE-2             pos\n",
       "62                    ROUGE-L             pos\n",
       "63                     Rank-5             pos\n",
       "64                     Recall             pos\n",
       "65       Restaurant 2014 (F1)             pos\n",
       "66                      SPICE             pos\n",
       "67                       SSIM             pos\n",
       "68                SSIM (sRGB)             pos\n",
       "69                Speed (FPS)             pos\n",
       "70             Top 5 Accuracy             pos\n",
       "71             Top-5 Accuracy             pos\n",
       "72              Video-mAP 0.5             pos\n",
       "73                        mAP             pos\n",
       "74                mAP IOU@0.6             pos\n",
       "75                mAP IOU@0.7             pos\n",
       "76                       mIoU             pos\n",
       "77              max E-Measure             pos\n",
       "78              max E-measure             pos\n",
       "79              max F-Measure             pos\n",
       "80    text-to-video Mean Rank             neg\n",
       "81  text-to-video Median Rank             neg\n",
       "82          video-to-text R@1             pos\n",
       "83         video-to-text R@10             pos\n",
       "84          video-to-text R@5             pos"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_w_2_polarities=[\"ACC@1-100Clients\",\n",
    "\"AED\",\n",
    "\"AKD\",\n",
    "\"AP\",\n",
    "\"AVERAGE MAE\",\n",
    "\"Abs Rel\",\n",
    "\"Acc\",\n",
    "\"Accuracy\",\n",
    "\"Accuracy (%)\",\n",
    "\"Accuracy (Cross-Setup)\",\n",
    "\"Average MAE\",\n",
    "\"B1\",\n",
    "\"B2\",\n",
    "\"B3\",\n",
    "\"B4\",\n",
    "\"BLEU\",\n",
    "\"Class IOU\",\n",
    "\"EER\",\n",
    "\"EM\",\n",
    "\"Edit\",\n",
    "\"Error Rate\",\n",
    "\"Exact Span F1\",\n",
    "\"F-Measure (Seen)\",\n",
    "\"F-Measure (Unseen)\",\n",
    "\"F1\",\n",
    "\"F1 score\",\n",
    "\"F1-score\",\n",
    "\"F1-score (Augmented)\",\n",
    "\"F1@10%\",\n",
    "\"F1@25%\",\n",
    "\"FID\",\n",
    "\"GAR @0.1% FAR Obfuscation\",\n",
    "\"GAR @0.1% FAR Overall\",\n",
    "\"HR@20\",\n",
    "\"Hit@20\",\n",
    "\"IS\",\n",
    "\"Inception Score\",\n",
    "\"IoU\",\n",
    "\"IoU overall\",\n",
    "\"Jaccard (Decay)\",\n",
    "\"Jaccard (Recall)\",\n",
    "\"Jaccard (Unseen)\",\n",
    "\"L1\",\n",
    "\"LPIPS\",\n",
    "\"MAE\",\n",
    "\"MAE [bpm, session-wise]\",\n",
    "\"MAP\",\n",
    "\"MAX E-MEASURE\",\n",
    "\"MAX F-MEASURE\",\n",
    "\"METEOR\",\n",
    "\"MKR\",\n",
    "\"MPJPE\",\n",
    "\"PCK@0.2\",\n",
    "\"PCKh\",\n",
    "\"PQth\",\n",
    "\"PSNR\",\n",
    "\"PSNR-B\",\n",
    "\"Precision\",\n",
    "\"R-Prec\",\n",
    "\"R@1\",\n",
    "\"RMSE\",\n",
    "\"ROUGE-2\",\n",
    "\"ROUGE-L\",\n",
    "\"Rank-5\",\n",
    "\"Recall\",\n",
    "\"Restaurant 2014 (F1)\",\n",
    "\"SPICE\",\n",
    "\"SSIM\",\n",
    "\"SSIM (sRGB)\",\n",
    "\"Speed (FPS)\",\n",
    "\"Top 5 Accuracy\",\n",
    "\"Top-5 Accuracy\",\n",
    "\"Video-mAP 0.5\",\n",
    "\"mAP\",\n",
    "\"mAP IOU@0.6\",\n",
    "\"mAP IOU@0.7\",\n",
    "\"mIoU\",\n",
    "\"max E-Measure\",\n",
    "\"max E-measure\",\n",
    "\"max F-Measure\",\n",
    "\"text-to-video Mean Rank\",\n",
    "\"text-to-video Median Rank\",\n",
    "\"video-to-text R@1\",\n",
    "\"video-to-text R@10\",\n",
    "\"video-to-text R@5\"]\n",
    "\n",
    "metrics_w_2_polarities_curation=[\"pos\",\n",
    "\"neg\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"neg\",\n",
    "\"neg\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"neg\",\n",
    "\"neg\",\n",
    "\"pos\",\n",
    "\"pos\",\n",
    "\"pos\"]\n",
    "\n",
    "\n",
    "curation_metrics_w_2_polarities = {'metricName':metrics_w_2_polarities,'curatedPolarity':metrics_w_2_polarities_curation}\n",
    "\n",
    "curation_metrics_w_2_polarities=pd.DataFrame(curation_metrics_w_2_polarities)\n",
    "\n",
    "curation_metrics_w_2_polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' RMSE (Subject-exposed)', ' three pixel error', '# of clusters (k)',\n",
       "       '% Test Accuracy', '0..5sec', '1-1', '10 sec', '10%',\n",
       "       '10-20% Mask PSNR', '14 gestures accuracy',\n",
       "       ...\n",
       "       'sMOTSA', 'spl', 'tOF', 'text-to-video R@1', 'text-to-video R@10',\n",
       "       'text-to-video R@5', 'text-to-video R@50',\n",
       "       'validation mean average precision', 'video-to-text Median Rank',\n",
       "       'Î´1.25'],\n",
       "      dtype='object', name='metricName', length=662)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the metrics with one polarity\n",
    "metrics_w_1_polarity = metrics_polarity_counts[metrics_polarity_counts[\"polarity\"]==1].index\n",
    "metrics_w_1_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' RMSE (Subject-exposed)',\n",
       " ' three pixel error',\n",
       " '# of clusters (k)',\n",
       " '% Test Accuracy',\n",
       " '0..5sec',\n",
       " '1-1',\n",
       " '10 sec',\n",
       " '10%',\n",
       " '10-20% Mask PSNR',\n",
       " '14 gestures accuracy',\n",
       " '20-30% Mask PSNR',\n",
       " '28 gestures accuracy',\n",
       " '3 sec',\n",
       " '3-fold Accuracy',\n",
       " '30 sec',\n",
       " '30-40% Mask PSNR',\n",
       " '3DIoU',\n",
       " '3DPCK',\n",
       " '40-50% Mask PSNR',\n",
       " '5..20sec',\n",
       " 'AAA',\n",
       " 'ABX-across',\n",
       " 'ACC',\n",
       " 'ACC@1-10Clients',\n",
       " 'ACC@1-50Clients',\n",
       " 'ACER',\n",
       " 'ADD',\n",
       " 'ADDS AUC',\n",
       " 'AMT',\n",
       " 'AMrTRE',\n",
       " 'AOP',\n",
       " 'AP 0.5',\n",
       " 'AP Hard',\n",
       " 'AP Medium',\n",
       " \"AP at 10' Elevation error\",\n",
       " \"AP at 15' Azimuth error\",\n",
       " 'AP50',\n",
       " 'AP75',\n",
       " 'AP@0.15',\n",
       " 'AP@0.7',\n",
       " 'APH/L2',\n",
       " 'APL',\n",
       " 'APM',\n",
       " 'APc',\n",
       " 'APf',\n",
       " 'APr',\n",
       " 'AR',\n",
       " 'AR50',\n",
       " 'AR75',\n",
       " 'AR@100',\n",
       " 'ARI',\n",
       " 'ARL',\n",
       " 'ARM',\n",
       " 'AUC',\n",
       " 'AUC (ABPA)',\n",
       " 'AUC (Aspergillus)',\n",
       " 'AUC (Diabetes)',\n",
       " 'AUC (E. Coli)',\n",
       " 'AUC (I. Obstruction)',\n",
       " 'AUC (K. Pneumonia)',\n",
       " 'AUC (val)',\n",
       " 'AUC-J',\n",
       " 'AUC-J&F',\n",
       " 'AUC-ROC',\n",
       " 'AUC0.08 private',\n",
       " 'AUC@0.1 (all)',\n",
       " 'AUROC',\n",
       " 'AVG',\n",
       " 'AVG-CDS',\n",
       " 'Accuracy ',\n",
       " 'Accuracy (10-fold)',\n",
       " 'Accuracy (5-fold)',\n",
       " 'Accuracy (8 emotion)',\n",
       " 'Accuracy (ADD)',\n",
       " 'Accuracy (AV I)',\n",
       " 'Accuracy (AV II)',\n",
       " 'Accuracy (Body + Fingers + Face joints)',\n",
       " 'Accuracy (Body + Fingers joints)',\n",
       " 'Accuracy (Body joints)',\n",
       " 'Accuracy (CS)',\n",
       " 'Accuracy (CV I)',\n",
       " 'Accuracy (CV II)',\n",
       " 'Accuracy (CV)',\n",
       " 'Accuracy (Cross-Subject)',\n",
       " 'Accuracy (Cross-View)',\n",
       " 'Accuracy (Cross-View, Avg)',\n",
       " 'Accuracy (Inter-Patient)',\n",
       " 'Accuracy (RGB+pose)',\n",
       " 'Accuracy (TEST-DB)',\n",
       " 'Accuracy (TRAIN-DB)',\n",
       " 'Accuracy (Test)',\n",
       " 'Accuracy (easy)',\n",
       " 'Accuracy (hard)',\n",
       " 'Accuracy (median)',\n",
       " 'Accuracy (val)',\n",
       " 'Accuracy(on validation set)',\n",
       " 'Action@1',\n",
       " 'Actions Top-1 (S1)',\n",
       " 'Actions Top-1 (S2)',\n",
       " 'Animals',\n",
       " 'Aspect',\n",
       " 'Average',\n",
       " 'Average 3D Error',\n",
       " 'Average Accuracy',\n",
       " 'Average Accuracy (10 times)',\n",
       " 'Average Class Accuracy ',\n",
       " 'Average F1',\n",
       " 'Average MPJPE (mm)',\n",
       " 'Average Orientation Similarity',\n",
       " 'Average Overlap',\n",
       " 'Average PSNR',\n",
       " 'Average Per-Class Accuracy',\n",
       " 'Average Precision',\n",
       " 'Average Precision at 0.5 3D IoU',\n",
       " 'Average Recall',\n",
       " 'Average Return (NoOp)',\n",
       " 'Average Success Rate',\n",
       " 'Average accuracy of 3 splits',\n",
       " 'Average-AP',\n",
       " 'Average-mAP',\n",
       " 'Avg',\n",
       " 'Avg F1',\n",
       " 'Avg.',\n",
       " 'BG#1-2',\n",
       " 'BLEU (EN-DE)',\n",
       " 'BLEU score',\n",
       " 'BLEU-1',\n",
       " 'BLEU-4',\n",
       " 'Backpack',\n",
       " 'Balanced Error Rate',\n",
       " 'Bare MR^-2',\n",
       " 'Bits per dim',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'CIDER',\n",
       " 'CIDEr',\n",
       " 'CIS',\n",
       " 'CL#1-2',\n",
       " 'CMC1',\n",
       " 'CMC10',\n",
       " 'CMC5',\n",
       " 'COL',\n",
       " 'CPU (sec)',\n",
       " 'CR',\n",
       " 'CS',\n",
       " 'CSIM',\n",
       " 'Chamfer (cm)',\n",
       " 'Chamfer Distance',\n",
       " 'City level (25 km)',\n",
       " 'Class Average IoU',\n",
       " 'Classification Accuracy',\n",
       " 'Classification Error',\n",
       " 'Conn',\n",
       " 'Continent level (2500 km)',\n",
       " 'Country level (750 km)',\n",
       " 'D3R',\n",
       " 'DAC (K=6)',\n",
       " 'DELETE',\n",
       " 'DFID',\n",
       " 'DLD',\n",
       " 'DSC',\n",
       " 'Decidability',\n",
       " 'Dice',\n",
       " 'Dice (Average)',\n",
       " 'Dice (SE)',\n",
       " 'Dice Score',\n",
       " 'Diversity',\n",
       " 'Driving Score',\n",
       " 'E-Measure',\n",
       " 'EC',\n",
       " 'EM (Quasar-T)',\n",
       " 'EMD',\n",
       " 'EO',\n",
       " 'English-Wiki (open) F1',\n",
       " 'Entity F1',\n",
       " 'Equal Error Rate',\n",
       " 'Error rate',\n",
       " 'Exact Match',\n",
       " 'Execution Accuracy',\n",
       " 'Expected Average Overlap (EAO)',\n",
       " 'F',\n",
       " 'F-BC',\n",
       " 'F-Measure',\n",
       " 'F-Score',\n",
       " 'F-Score@1%',\n",
       " 'F-measure',\n",
       " 'F-measure (Mean)',\n",
       " 'F-measure (Recall)',\n",
       " 'F0.5',\n",
       " 'F1 (1dAVb)',\n",
       " 'F1 (AF)',\n",
       " 'F1 (LBBB)',\n",
       " 'F1 (Quasar-T)',\n",
       " 'F1 (RBBB)',\n",
       " 'F1 (SB)',\n",
       " 'F1 (ST)',\n",
       " 'F1 (Sequence)',\n",
       " 'F1 (Set)',\n",
       " 'F1 (micro)',\n",
       " 'F1 (v2)',\n",
       " 'F1 - macro',\n",
       " 'F1 Full',\n",
       " 'F1 Newswire',\n",
       " 'F1 Score',\n",
       " 'F1-Score',\n",
       " 'F1-score (@IoU = 0.2)',\n",
       " 'F1-score (@IoU = 0.3)',\n",
       " 'F1-score (Canonical)',\n",
       " 'F1@50%',\n",
       " 'F1c (v2)',\n",
       " 'FDE',\n",
       " 'FED',\n",
       " 'FID-0',\n",
       " 'FID-1',\n",
       " 'FID-10k-training-steps',\n",
       " 'FID-2',\n",
       " 'FID-4',\n",
       " 'FID-50k',\n",
       " 'FID-5k-training-steps',\n",
       " 'FID-8',\n",
       " 'FPR95',\n",
       " 'FPS',\n",
       " 'FPS on CPU',\n",
       " 'FR@0.1(%, all)',\n",
       " 'FSD',\n",
       " 'FSIM',\n",
       " 'FVD score',\n",
       " 'F_NMI',\n",
       " 'Frame (fps)',\n",
       " 'Frame-mAP',\n",
       " 'Frames Needed',\n",
       " 'Full MRP F1',\n",
       " 'Full UCCA F1',\n",
       " 'Fullset (public)',\n",
       " 'G-Score (BLEU, Accuracy)',\n",
       " 'GAR @0.01% FAR Impersonation',\n",
       " 'GAR @0.01% FAR Obfuscation',\n",
       " 'GAR @0.01% FAR Overall',\n",
       " 'GAR @0.01% FAR Plastic Surgery',\n",
       " 'GAR @0.1% FAR',\n",
       " 'GAR @0.1% FAR Impersonation',\n",
       " 'GAR @0.1% FAR Plastic Surgery',\n",
       " 'GAR @1% FAR',\n",
       " 'GAR @1% FAR Impersonation',\n",
       " 'GAR @1% FAR Obfuscation',\n",
       " 'GAR @1% FAR Overall',\n",
       " 'GFLOPs',\n",
       " 'Gender',\n",
       " 'Grad',\n",
       " 'Grad Det-Jac',\n",
       " 'Hamming Loss',\n",
       " 'Harmonic mean',\n",
       " 'Hat',\n",
       " 'Hausdorff',\n",
       " 'Hausdorff Distance (mm)',\n",
       " 'Heavy MR^-2',\n",
       " 'Hit@1',\n",
       " 'Hits@1',\n",
       " 'Hits@10',\n",
       " 'Holder Binary F1',\n",
       " 'Humans',\n",
       " 'I. Obstruction',\n",
       " 'IDF1',\n",
       " 'Image-Level Recall',\n",
       " 'Image-to-text R@1',\n",
       " 'Image-to-text R@10',\n",
       " 'Image-to-text R@5',\n",
       " 'In-domain',\n",
       " 'Inception score',\n",
       " 'Instance Average IoU',\n",
       " 'Interpolation Error',\n",
       " 'Intra-FID',\n",
       " 'IoU [256 distractors]',\n",
       " 'IoU [32 distractors]',\n",
       " 'IoU [4 distractors]',\n",
       " 'IoU mean',\n",
       " 'J&F',\n",
       " 'J&F 1st frame',\n",
       " 'J&F@60s',\n",
       " 'J@60s',\n",
       " 'Jaccard (Mean)',\n",
       " 'Jaccard (Seen)',\n",
       " 'Joint',\n",
       " 'KEEP',\n",
       " 'KILT-EM',\n",
       " 'KILT-F1',\n",
       " 'KILT-RL',\n",
       " 'Kappa',\n",
       " \"Kendall's Tau\",\n",
       " 'Kernel Inception Distance',\n",
       " 'L2 Loss (10^-4)',\n",
       " 'LAS',\n",
       " 'LCC',\n",
       " 'LCS',\n",
       " 'LLE',\n",
       " 'LPP MRP F1',\n",
       " 'LPP UCCA F1',\n",
       " 'LSE-C',\n",
       " 'LSE-D',\n",
       " 'LT-ACC',\n",
       " 'Laptop (Acc)',\n",
       " 'Laptop (F1)',\n",
       " 'Laptop 2014 (F1)',\n",
       " 'Local',\n",
       " 'Log-Spectral Distance',\n",
       " 'Long-Tailed Accuracy',\n",
       " 'MAE (10% missing)',\n",
       " 'MAE (10% of data as GT)',\n",
       " 'MAE (Arousal)',\n",
       " 'MAE (Expectancy)',\n",
       " 'MAE (PM2.5)',\n",
       " 'MAE (Power)',\n",
       " 'MAE (Valence)',\n",
       " 'MAE (trained with other data)',\n",
       " 'MAE for DBP [mmHg]',\n",
       " 'MAE for SBP [mmHg]',\n",
       " 'MAP ',\n",
       " 'MAR, walking, 1,000ms',\n",
       " 'MAR, walking, 400ms',\n",
       " 'ME (%, all) ',\n",
       " 'MIoU (13 classes)',\n",
       " 'MIoU (16 classes)',\n",
       " 'MJPE',\n",
       " 'MMD',\n",
       " 'MMrTRE',\n",
       " 'MOTA',\n",
       " 'MOTP',\n",
       " 'MPE',\n",
       " 'MPJAE',\n",
       " 'MPJPE (CA)',\n",
       " 'MPJPE (CS)',\n",
       " 'MPS',\n",
       " 'MPVPE',\n",
       " 'MR (K=1)',\n",
       " 'MR (K=6)',\n",
       " 'MRPE',\n",
       " 'MRR',\n",
       " 'MRR (x 100)',\n",
       " 'MRR@20',\n",
       " 'MS-SSIM',\n",
       " 'MSE',\n",
       " 'MSE (10% missing)',\n",
       " 'MSE (10^-2, 50% missing)',\n",
       " 'MSE (10^2, 50% missing)',\n",
       " 'MSE stdev',\n",
       " 'MSE(10^3)',\n",
       " 'Macro F1',\n",
       " 'Macro Precision',\n",
       " 'Macro Recall',\n",
       " 'Macro-F1',\n",
       " 'Macro-F1 (20% training data)',\n",
       " 'Macro-F1 (60% training data)',\n",
       " 'Macro-F1 (80% training data)',\n",
       " 'Mean',\n",
       " 'Mean ADD',\n",
       " 'Mean AP @ 0.5',\n",
       " 'Mean Acc (Restaurant + Laptop)',\n",
       " 'Mean Accuracy',\n",
       " 'Mean Error Rate',\n",
       " 'Mean F-measure',\n",
       " 'Mean F1 (WSJ)',\n",
       " 'Mean IoU',\n",
       " 'Mean IoU (class)',\n",
       " 'Mean NME',\n",
       " 'Mean NME ',\n",
       " 'Mean PCK',\n",
       " 'Mean PCK@0.2',\n",
       " 'Mean Rank',\n",
       " 'Mean Reconstruction Error (mm)',\n",
       " 'Mean class accuracy',\n",
       " 'Mean mAP',\n",
       " 'Mean target overlap ratio',\n",
       " 'Medium Human-Normalized Score',\n",
       " 'Meteor (EN-DE)',\n",
       " 'Micro F1',\n",
       " 'Micro Precision',\n",
       " 'Micro Recall',\n",
       " 'Micro-F1',\n",
       " 'Micro-F1 (20% training data)',\n",
       " 'Micro-F1 (80% training data)',\n",
       " 'MultiWOZ (Inform)',\n",
       " 'MultiWOZ (Success)',\n",
       " 'NDCG (x 100)',\n",
       " 'NDS',\n",
       " 'NIQE',\n",
       " 'NIST',\n",
       " 'NLDA',\n",
       " 'NM#5-6 ',\n",
       " 'NME',\n",
       " 'NSS',\n",
       " 'Neg Jacob Det',\n",
       " 'Neg. F1',\n",
       " 'NegLL',\n",
       " 'Normalized Pose Error',\n",
       " 'Normalized Precision',\n",
       " 'Normalized cPSNR',\n",
       " 'Noun@1',\n",
       " 'Number of Frames Per View',\n",
       " 'Number of Views',\n",
       " 'O (Average of Measures)',\n",
       " 'OMQ',\n",
       " 'OOB Rate (10^âˆ’3) ',\n",
       " 'ORD',\n",
       " 'ORD ',\n",
       " 'Out-of-domain',\n",
       " 'Overall',\n",
       " 'Overall Accuracy',\n",
       " 'Overall IoU',\n",
       " 'P',\n",
       " 'P@10%',\n",
       " 'P@30%',\n",
       " 'P@5',\n",
       " 'PA-MPJPE',\n",
       " 'PA-MPVPE',\n",
       " 'PARENT',\n",
       " 'PC',\n",
       " 'PCK',\n",
       " 'PCK3D (CA)',\n",
       " 'PCK3D (CS)',\n",
       " 'PCK@0.1',\n",
       " 'PCK@0.3',\n",
       " 'PCK@0.4',\n",
       " 'PCK@0.5',\n",
       " 'PCKh-0.5',\n",
       " 'PCKh@0.5',\n",
       " 'PCP3D',\n",
       " 'PESQ',\n",
       " 'PO',\n",
       " 'PPV (VEB)',\n",
       " 'PQ',\n",
       " 'PQst',\n",
       " 'PR-AUC',\n",
       " 'PRC',\n",
       " 'PSNR (Raw)',\n",
       " 'PSNR (sRGB)',\n",
       " 'Parameters (M)',\n",
       " 'Partial MR^-2',\n",
       " 'Patch Matching',\n",
       " 'Patch Retrieval',\n",
       " 'Patch Verification',\n",
       " 'Path Difference',\n",
       " 'Path Length',\n",
       " 'Pearson Correlation',\n",
       " 'Per-Class Accuracy',\n",
       " 'Per-class Accuracy',\n",
       " 'Per-pixel Accuracy',\n",
       " 'Percentage Error',\n",
       " 'Percentage correct',\n",
       " 'Percentage error',\n",
       " 'Permuted Accuracy',\n",
       " 'Perplexity',\n",
       " 'Player Distance ',\n",
       " 'Point-to-surface distance (cm)',\n",
       " 'Pos. F1',\n",
       " 'Pr@0.5',\n",
       " 'Pr@0.7',\n",
       " 'Pr@0.9',\n",
       " 'Precision@0.5',\n",
       " 'Precision@0.6',\n",
       " 'Precision@0.7',\n",
       " 'Precision@0.8',\n",
       " 'Precision@0.9',\n",
       " 'Precision@20',\n",
       " 'Quality',\n",
       " 'Question Answering',\n",
       " 'R',\n",
       " 'R@10',\n",
       " 'R@100',\n",
       " 'R@16',\n",
       " 'R@2',\n",
       " 'R@32',\n",
       " 'R@4',\n",
       " 'R@5',\n",
       " 'R@8',\n",
       " 'RC',\n",
       " 'RCL',\n",
       " 'RMSE (Subject-naÃ¯ve)',\n",
       " 'RMSE log',\n",
       " 'ROC AUC',\n",
       " 'ROC-AUC',\n",
       " 'ROUGE',\n",
       " 'ROUGE-1',\n",
       " 'ROUGE-SU4',\n",
       " 'RRSE',\n",
       " 'Rank-1',\n",
       " 'Rank-1 Recognition Rate',\n",
       " 'Rank-10',\n",
       " 'Real',\n",
       " 'Reasonable MR^-2',\n",
       " 'Reasonable Miss Rate',\n",
       " 'Recall@10',\n",
       " 'Recall@5',\n",
       " 'Recall@50',\n",
       " 'Reference images',\n",
       " 'Region level (200 km)',\n",
       " 'Relation F1',\n",
       " 'Restaurant (Acc)',\n",
       " 'Restaurant (F1)',\n",
       " 'Restaurant 2015 (F1)',\n",
       " 'Restaurant 2016 (F1)',\n",
       " 'Route Completion',\n",
       " 'Runtime(s)',\n",
       " 'S-Measure',\n",
       " 'SAD',\n",
       " 'SARI',\n",
       " 'SQ Rel',\n",
       " 'SSIM (Raw)',\n",
       " 'Score',\n",
       " 'Search time (s)',\n",
       " 'Sensitivity',\n",
       " 'Sensitivity (VEB)',\n",
       " 'Sentence Retrieval',\n",
       " 'Sentence-pair Classification',\n",
       " 'Sentiment',\n",
       " 'Shen F-1',\n",
       " 'Size (MB)',\n",
       " 'Smatch',\n",
       " 'Smoothed BLEU-4',\n",
       " 'Spearman Correlation',\n",
       " 'Speed (FPS)',\n",
       " 'Speed(ms/f)',\n",
       " 'Sq Rel',\n",
       " 'Step Change (10^âˆ’3)',\n",
       " 'Street level (1 km)',\n",
       " 'Structured Prediction',\n",
       " 'Success Rate 0.5',\n",
       " 'Surface normal consistency',\n",
       " 'TAR @ FAR=0.0001',\n",
       " 'TAR @ FAR=0.001',\n",
       " 'TAR @ FAR=0.01',\n",
       " 'TC',\n",
       " 'TIoU',\n",
       " 'TTA',\n",
       " 'Target Binary F1',\n",
       " 'Temporal awareness',\n",
       " 'Test AP',\n",
       " 'Test Error',\n",
       " 'Test perplexity',\n",
       " 'Text-to-image R@1',\n",
       " 'Text-to-image R@10',\n",
       " 'Text-to-image R@5',\n",
       " 'Time (ms)',\n",
       " 'Top 1 Accuracy',\n",
       " 'Top 1 Error',\n",
       " 'Top-1',\n",
       " 'Top-1 (%)',\n",
       " 'Top-1 Accuracy',\n",
       " 'Top-1 Error Rate',\n",
       " 'Top-1 Localization Accuracy',\n",
       " 'Top-1 accuracy %',\n",
       " 'Top-10 Accuracy',\n",
       " 'Top-3',\n",
       " 'Top-5 (%)',\n",
       " 'Top-5 Error',\n",
       " 'UA',\n",
       " 'UAS',\n",
       " 'UCC',\n",
       " 'UCS',\n",
       " 'Unpermuted Accuracy',\n",
       " 'User Study Score',\n",
       " 'V-Measure',\n",
       " 'VI',\n",
       " 'Val',\n",
       " 'Validation mIoU',\n",
       " 'Verb@1',\n",
       " 'Vid acc@1',\n",
       " 'Vid acc@5',\n",
       " 'Video hit@1 ',\n",
       " 'Video hit@5',\n",
       " 'Weighted Average F1-score',\n",
       " 'Weighted F-Measure',\n",
       " 'Weighted F1',\n",
       " 'Weighted Macro-F1',\n",
       " 'Weighted-F1',\n",
       " 'Word Error Rate (WER)',\n",
       " 'absolute relative error',\n",
       " 'amota',\n",
       " 'avg-mAP (0.1-0.5)',\n",
       " 'avg-mAP (0.1-0.9)',\n",
       " 'avg-mAP (0.3-0.7)',\n",
       " 'avg. log MAE',\n",
       " 'avg_fp_quality',\n",
       " 'avg_label',\n",
       " 'avg_pairwise',\n",
       " 'avg_spatial',\n",
       " 'bpd',\n",
       " 'brier-minFDE (K=6)',\n",
       " 'classification score',\n",
       " 'count',\n",
       " 'free-form mask l1 err',\n",
       " 'free-form mask l2 err',\n",
       " 'inference time (ms)',\n",
       " 'mAAE',\n",
       " 'mAOE',\n",
       " 'mAP (@0.1, Through-wall)',\n",
       " 'mAP (@0.1, Visible)',\n",
       " 'mAP (All-search & Single-shot)',\n",
       " 'mAP (Val)',\n",
       " 'mAP @0.5:0.95',\n",
       " 'mAP IOU@0.1',\n",
       " 'mAP IOU@0.2',\n",
       " 'mAP IOU@0.3',\n",
       " 'mAP IOU@0.4',\n",
       " 'mAP IOU@0.5',\n",
       " 'mAP IOU@0.75',\n",
       " 'mAP IOU@0.8',\n",
       " 'mAP IOU@0.9',\n",
       " 'mAP IOU@0.95',\n",
       " 'mAP(V2T)',\n",
       " 'mAP@0.1:0.5',\n",
       " 'mAP@0.1:0.7',\n",
       " 'mAP@0.25',\n",
       " 'mAP@0.3',\n",
       " 'mAP@0.4',\n",
       " 'mAP@0.5',\n",
       " 'mAP@0.50',\n",
       " 'mAP@0.50 (CS)',\n",
       " 'mAP@0.50 (CV)',\n",
       " 'mAP@AVG(0.1:0.9)',\n",
       " 'mASE',\n",
       " 'mATE',\n",
       " 'mAVE',\n",
       " 'mIOU',\n",
       " 'mIoU (13 classes)',\n",
       " 'mIoU (KMeans)',\n",
       " 'mPC [AP50]',\n",
       " 'mPC [AP]',\n",
       " 'mPrec',\n",
       " 'mRec',\n",
       " 'mask AP',\n",
       " 'mask-IS',\n",
       " 'mask-SSIM',\n",
       " 'mean Corruption Error (mCE)',\n",
       " 'mean E-Measure',\n",
       " 'mean Recall @20',\n",
       " 'meanIOU',\n",
       " 'minADE (K=1)',\n",
       " 'minADE (K=6)',\n",
       " 'minFDE (K=1)',\n",
       " 'minFDE (K=6)',\n",
       " 'mse (10^-3)',\n",
       " 'nDCG@5',\n",
       " 'nats',\n",
       " 'pose',\n",
       " 'rPC [%]',\n",
       " 'rank-1',\n",
       " 'rank-10',\n",
       " 'rank-5',\n",
       " 'rank1',\n",
       " 'rank1(V2T)',\n",
       " 'rect mask l1 error',\n",
       " 'rect mask l2 err',\n",
       " 'sMOTSA',\n",
       " 'spl',\n",
       " 'tOF',\n",
       " 'text-to-video R@1',\n",
       " 'text-to-video R@10',\n",
       " 'text-to-video R@5',\n",
       " 'text-to-video R@50',\n",
       " 'validation mean average precision',\n",
       " 'video-to-text Median Rank',\n",
       " 'Î´1.25']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_w_1_polarity.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metricName</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE (Subject-exposed)</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three pixel error</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># of clusters (k)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>% Test Accuracy</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0..5sec</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metricName polarity\n",
       "0   RMSE (Subject-exposed)      neg\n",
       "1        three pixel error      neg\n",
       "2        # of clusters (k)      pos\n",
       "3          % Test Accuracy      pos\n",
       "4                  0..5sec      neg"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_w_1_polarity_df = polarity_df_report_2[polarity_df_report_2['metricName'] .isin(metrics_w_1_polarity.tolist())][[\"metricName\",\"polarity\"]]\n",
    "metrics_w_1_polarity_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metricName</th>\n",
       "      <th>curatedPolarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACC@1-100Clients</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AED</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AKD</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVERAGE MAE</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         metricName curatedPolarity\n",
       "0  ACC@1-100Clients             pos\n",
       "1               AED             neg\n",
       "2               AKD             neg\n",
       "3                AP             pos\n",
       "4       AVERAGE MAE             neg"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#curation_metrics_w_2_polarities[curation_metrics_w_2_polarities[\"metricName\"]==\"AED\"]\n",
    "curation_metrics_w_2_polarities.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Speed (FPS)']\n"
     ]
    }
   ],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "\n",
    "print(intersection(curation_metrics_w_2_polarities[\"metricName\"].tolist(), metrics_w_1_polarity_df[\"metricName\"].tolist()))\n",
    "\n",
    "\n",
    "#Check this intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue from here (14-09-2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTINUE FROM HERE... how to exclude the negative polarities that have two reported polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\tneg\n",
      "Accuracy\tneg\n",
      "PPL\tpos\n",
      "% Test Accuracy\tpos\n",
      "MRR\tpos\n",
      "Accuracy (2 classes)\tpos\n",
      "MAP\tneg\n",
      "RE+ Micro F1\tpos\n",
      "RE Micro F1\tpos\n",
      "NER Micro F1\tpos\n",
      "BLEU score\tpos\n",
      "Avg F1\tpos\n",
      "Test perplexity\tneg\n",
      "Validation perplexity\tpos\n",
      "BLEU-1\tpos\n",
      "F1 score\tneg\n",
      "Pearson Correlation\tpos\n",
      "Spearman Correlation\tpos\n",
      "MSE\tneg\n",
      "P-at-1\tpos\n",
      "Mean Error Rate\tneg\n",
      "Accuracy (trained on 10k)\tpos\n",
      "Accuracy (trained on 1k)\tpos\n",
      "Error\tpos\n",
      "Percentage correct\tpos\n",
      "Average\tneg\n",
      "DVD\tpos\n",
      "Books\tpos\n",
      "Electronics\tpos\n",
      "Kitchen\tpos\n",
      "CNN\tpos\n",
      "Daily Mail\tpos\n",
      "LAS\tpos\n",
      "UAS\tpos\n",
      "POS\tpos\n",
      "R10-at-1\tpos\n",
      "R10-at-2\tpos\n",
      "R10-at-5\tpos\n",
      "R2-at-1\tpos\n",
      "% Train Accuracy\tpos\n",
      "Parameters\tpos\n",
      "P-at-10%\tpos\n",
      "P-at-30%\tpos\n",
      "CR\tpos\n",
      "ROUGE-1\tpos\n",
      "ROUGE-2\tneg\n",
      "ROUGE-L\tneg\n",
      "Restaurant (Acc)\tpos\n",
      "Laptop (Acc)\tneg\n",
      "Mean Acc (Restaurant + Laptop)\tpos\n",
      "BLEU\tneg\n",
      "Micro Precision\tpos\n",
      "In-KB Accuracy\tpos\n",
      "Bit per Character (BPC)\tpos\n",
      "Accuracy-CN\tpos\n",
      "Accuracy-NE\tpos\n",
      "Unigram Acc\tpos\n",
      "N-gram F1\tpos\n",
      "ROUGE\tneg\n",
      "Number of params\tpos\n",
      "Avg accuracy\tpos\n",
      "R-at-1\tpos\n",
      "R-at-10\tpos\n",
      "R-at-5\tpos\n",
      "Mean Rank\tneg\n",
      "Precision\tneg\n",
      "Recall\tneg\n",
      "EM (Quasar-T)\tpos\n",
      "F1 (Quasar-T)\tpos\n",
      "Joint\tpos\n",
      "Area\tpos\n",
      "Food\tpos\n",
      "Price\tpos\n",
      "Request\tpos\n",
      "Params\tpos\n",
      "F0.5\tpos\n",
      "F1 Newswire\tpos\n",
      "EM\tneg\n",
      "BLEU-4\tpos\n",
      "BLEU-2\tpos\n",
      "BLEU-3\tpos\n",
      "BLEU-5\tpos\n",
      "Inception score\tpos\n",
      "FID\tneg\n",
      "Aspect\tpos\n",
      "Sentiment\tneg\n",
      "P-at-5\tpos\n",
      "F1 Full\tpos\n",
      "Rouge-L\tpos\n",
      "overall\tpos\n",
      "1 in 10 R-at-2\tpos\n",
      "Sequence error\tpos\n",
      "Perplexity\tneg\n",
      "KL\tpos\n",
      "NLL\tpos\n",
      "Micro-F1\tpos\n",
      "NDCG (x 100)\tpos\n",
      "MRR (x 100)\tpos\n",
      "Mean\tneg\n",
      "Average Recall\tpos\n",
      "F1-score\tneg\n",
      "SICK-E\tpos\n",
      "SICK-R\tpos\n",
      "14 gestures accuracy\tpos\n",
      "Average Precision\tpos\n",
      "MAE (Valence)\tneg\n",
      "MAE (Arousal)\tpos\n",
      "MAE (Expectancy)\tpos\n",
      "MAE (Power)\tneg\n",
      "Weighted-F1\tpos\n",
      "UA\tpos\n",
      "Macro-F1\tpos\n",
      "Weighted Accuracy\tpos\n",
      "Per-class Accuracy (Unrelated)\tpos\n",
      "Per-class Accuracy (Agree)\tpos\n",
      "Per-class Accuracy (Disagree)\tpos\n",
      "Per-class Accuracy (Discuss)\tpos\n",
      "Consistency\tpos\n",
      "Plausibility\tpos\n",
      "Validity\tpos\n",
      "Distribution\tpos\n",
      "DLD\tpos\n",
      "count\tpos\n",
      "Binary\tpos\n",
      "Open\tpos\n",
      "Execution Accuracy\tpos\n",
      "Exact Match Accuracy\tpos\n",
      "Error rate\tneg\n",
      "Senseval 2\tpos\n",
      "Senseval 3\tpos\n",
      "SemEval 2013\tpos\n",
      "SemEval 2015\tpos\n",
      "F1 (surface form)\tpos\n",
      "1-of-100 Accuracy\tpos\n",
      "1 in 2 R-at-1\tpos\n",
      "1 in 10 R-at-1\tpos\n",
      "1 in 10 R-at-5\tpos\n",
      "Test\tpos\n",
      "Holder Binary F1\tpos\n",
      "Target Binary F1\tpos\n",
      "Mean F1 (WSJ)\tpos\n",
      "Max F1 (WSJ)\tpos\n",
      "Exact Span F1\tneg\n",
      "nDCG-at-20\tpos\n",
      "P-at-20\tpos\n",
      "LPIPS\tneg\n",
      "Acc\tneg\n",
      "Real\tneg\n",
      "SOA-C\tpos\n",
      "CIDEr\tpos\n",
      "NIST\tpos\n",
      "All\tpos\n",
      "GLEU\tpos\n",
      "SemEval 2007\tpos\n",
      "RACE-m\tpos\n",
      "RACE-h\tpos\n",
      "RACE\tpos\n",
      "Mismatched\tpos\n",
      "Matched\tpos\n",
      "v2v error\tpos\n",
      "RE+ Macro F1\tpos\n",
      "NER Macro F1\tpos\n",
      "Accuracy (%)\tneg\n",
      "Average Cross-Ent\tpos\n",
      "AUC\tpos\n",
      "Score\tpos\n",
      "BEP\tpos\n",
      "F-measure\tpos\n",
      "Macro F1\tpos\n",
      "Micro F1\tpos\n",
      "10 fold Cross validation\tpos\n",
      "MAE\tneg\n",
      "Dev\tpos\n",
      "In-domain\tpos\n",
      "Overall\tpos\n",
      "Out-of-domain\tpos\n",
      "F1-Score\tpos\n",
      "Micro-F1 strong\tpos\n",
      "Macro-F1 strong\tpos\n",
      "SacreBLEU\tpos\n",
      "Mean F1 (WSJ10)\tpos\n",
      "Entity F1\tpos\n",
      "Relation F1\tpos\n",
      "ROUGE-SU4\tneg\n",
      "HEQD\tpos\n",
      "HEQQ\tpos\n",
      "Max F1 (WSJ10)\tpos\n",
      "infNDCG\tpos\n",
      "rsim\tpos\n",
      "Pointing Game Accuracy\tpos\n",
      "Slot F1 Score\tpos\n",
      "Intent Accuracy\tpos\n",
      "R@50\tpos\n",
      "F1 (Long)\tpos\n",
      "F1 (Short)\tpos\n",
      "Bits per byte\tpos\n",
      "interest (human)\tpos\n",
      "relevance (human)\tpos\n",
      "Accuracy (3-way)\tpos\n",
      "Accuracy (4-way)\tpos\n",
      "Binary Accuracy\tpos\n",
      "Laptop (F1)\tpos\n",
      "Restaurant (F1)\tpos\n",
      "Phoneme Error Rate\tpos\n",
      "Word Error Rate (WER)\tneg\n",
      "Accuracy (10 classes)\tpos\n",
      "mAP\tneg\n",
      "Diacritic Error Rate\tpos\n",
      "JOINT-F1\tpos\n",
      "Smatch\tpos\n",
      "Audio Quality MOS\tpos\n",
      "nDCG-at-5\tpos\n",
      "nDCG-at-3\tpos\n",
      "P-at-3\tpos\n",
      "RP-at-5\tpos\n",
      "nDCG-at-1\tpos\n",
      "Ign F1\tpos\n",
      "Restaurant 2014 (F1)\tneg\n",
      "Laptop 2014 (F1)\tpos\n",
      "Restaurant 2015 (F1)\tpos\n",
      "A1\tpos\n",
      "A2\tpos\n",
      "A3\tpos\n",
      "ERR-at-20\tpos\n",
      "Accuracy (High)\tpos\n",
      "Accuracy (Middle)\tpos\n",
      "Macro Recall\tpos\n",
      "Micro Recall\tpos\n",
      "Macro Precision\tpos\n",
      "Bias (F/M)\tpos\n",
      "Overall F1\tpos\n",
      "Masculine F1 (M)\tpos\n",
      "Feminine F1 (F)\tpos\n",
      "Accuracy (Dev)\tpos\n",
      "Accuracy (Test-P)\tpos\n",
      "Accuracy (Test-U)\tpos\n",
      "number\tpos\n",
      "unanswerable\tpos\n",
      "yes/no\tpos\n",
      "other\tpos\n",
      "ROUGE-3\tpos\n",
      "R^2\tpos\n",
      "Recall-at-10\tpos\n",
      "SPICE\tneg\n",
      "Weighted Macro-F1\tpos\n",
      "Cased sacreBLEU\tpos\n",
      "ICAT Score\tpos\n",
      "PA\tpos\n",
      "DE\tpos\n",
      "BA\tpos\n"
     ]
    }
   ],
   "source": [
    "for met in metricName_df:\n",
    "    #print(met)\n",
    "    if met in metricName_negative_list:\n",
    "        print(met + \"\\tneg\")\n",
    "    else:\n",
    "        print(met + \"\\tpos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COL',\n",
       " 'FDE',\n",
       " 'absolute relative error',\n",
       " 'RMSE',\n",
       " 'D3R',\n",
       " 'ORD',\n",
       " 'Î´1.25',\n",
       " 'ORD ',\n",
       " 'Abs Rel',\n",
       " 'RMSE log',\n",
       " 'SQ Rel',\n",
       " ' three pixel error',\n",
       " 'SSIM',\n",
       " 'NIQE',\n",
       " 'FID',\n",
       " 'PSNR',\n",
       " 'FED',\n",
       " 'LPIPS',\n",
       " 'Fullset (public)',\n",
       " 'Mean Error Rate',\n",
       " 'Mean NME ',\n",
       " 'Mean NME',\n",
       " 'Error rate',\n",
       " 'pose',\n",
       " 'NME',\n",
       " 'Mean Reconstruction Error (mm)',\n",
       " 'Equal Error Rate',\n",
       " 'MAE',\n",
       " 'NLDA',\n",
       " 'GAR @0.1% FAR Obfuscation',\n",
       " 'GAR @0.1% FAR Overall',\n",
       " 'GAR @1% FAR Impersonation',\n",
       " 'GAR @1% FAR Obfuscation',\n",
       " 'GAR @1% FAR Overall',\n",
       " 'Reasonable Miss Rate',\n",
       " 'Heavy MR^-2',\n",
       " 'Partial MR^-2',\n",
       " 'Reasonable MR^-2',\n",
       " 'LCS',\n",
       " 'MIoU (13 classes)',\n",
       " 'Quality',\n",
       " 'IS',\n",
       " 'Kernel Inception Distance',\n",
       " 'Top 1 Error',\n",
       " 'mean Corruption Error (mCE)',\n",
       " 'Top-1 Error Rate',\n",
       " 'Word Error Rate (WER)',\n",
       " 'Percentage error',\n",
       " 'BLEU',\n",
       " 'Mean Rank',\n",
       " 'R@1',\n",
       " 'Mean',\n",
       " 'MultiWOZ (Inform)',\n",
       " 'MultiWOZ (Success)',\n",
       " 'Average MPJPE (mm)',\n",
       " 'MSE',\n",
       " 'MRPE',\n",
       " 'OOB Rate (10^âˆ’3) ',\n",
       " 'Path Length',\n",
       " 'Step Change (10^âˆ’3)',\n",
       " 'MAE (PM2.5)',\n",
       " 'MAE (10% missing)',\n",
       " 'MSE (10^2, 50% missing)',\n",
       " 'L2 Loss (10^-4)',\n",
       " 'MSE (10% missing)',\n",
       " 'MAE (10% of data as GT)',\n",
       " 'Meteor (EN-DE)',\n",
       " 'F1 score',\n",
       " 'Hausdorff',\n",
       " 'Class IOU',\n",
       " 'DFID',\n",
       " 'Classification Error',\n",
       " 'free-form mask l1 err',\n",
       " 'free-form mask l2 err',\n",
       " 'rect mask l2 err',\n",
       " 'Real',\n",
       " 'mask-IS',\n",
       " 'mask-SSIM',\n",
       " 'PCKh',\n",
       " 'Inception Score',\n",
       " 'AUC (Aspergillus)',\n",
       " 'AUC (I. Obstruction)',\n",
       " 'I. Obstruction',\n",
       " 'mAP',\n",
       " 'Test Error',\n",
       " 'FVD score',\n",
       " 'text-to-video Mean Rank',\n",
       " 'text-to-video Median Rank',\n",
       " 'video-to-text R@1',\n",
       " 'video-to-text R@10',\n",
       " 'video-to-text R@5',\n",
       " 'tOF',\n",
       " 'Interpolation Error',\n",
       " 'F1-score (Augmented)',\n",
       " 'FPS on CPU',\n",
       " 'Top 5 Accuracy',\n",
       " 'mAP IOU@0.8',\n",
       " 'mAP IOU@0.9',\n",
       " 'EER',\n",
       " 'Top-5 Accuracy',\n",
       " 'Accuracy',\n",
       " 'Video-mAP 0.5',\n",
       " 'mAP IOU@0.7',\n",
       " 'mAP IOU@0.6',\n",
       " 'mAP IOU@0.75',\n",
       " 'R-Prec',\n",
       " 'EM',\n",
       " 'F1',\n",
       " 'L1',\n",
       " 'Accuracy (Cross-Setup)',\n",
       " 'Accuracy (Body + Fingers + Face joints)',\n",
       " 'Accuracy (Body joints)',\n",
       " 'MSE (10^-2, 50% missing)',\n",
       " 'NegLL',\n",
       " 'mse (10^-3)',\n",
       " 'RRSE',\n",
       " 'avg_pairwise',\n",
       " 'avg_spatial',\n",
       " 'mean Recall @20',\n",
       " 'Recall',\n",
       " 'ROUGE-2',\n",
       " 'ROUGE-SU4',\n",
       " 'ROUGE',\n",
       " 'Precision',\n",
       " 'Mean class accuracy',\n",
       " 'Actions Top-1 (S2)',\n",
       " 'MMD',\n",
       " 'FSD',\n",
       " 'Average MAE',\n",
       " '0..5sec',\n",
       " '5..20sec',\n",
       " 'Average',\n",
       " '3 sec',\n",
       " 'EC',\n",
       " 'EO',\n",
       " 'PC',\n",
       " 'PO',\n",
       " ' RMSE (Subject-exposed)',\n",
       " 'RMSE (Subject-naÃ¯ve)',\n",
       " 'Perplexity',\n",
       " 'F1-score',\n",
       " 'AP',\n",
       " 'PQth',\n",
       " 'Time (ms)',\n",
       " 'IoU [4 distractors]',\n",
       " 'Top-5 Error',\n",
       " 'MAE (Power)',\n",
       " 'MAE (Valence)',\n",
       " 'Edit',\n",
       " 'F1@10%',\n",
       " 'Acc',\n",
       " 'F1@25%',\n",
       " 'Average 3D Error',\n",
       " 'LPP UCCA F1',\n",
       " 'MJPE',\n",
       " 'MPJPE',\n",
       " 'PA-MPJPE',\n",
       " 'MPJAE',\n",
       " 'MPJPE (CA)',\n",
       " 'MPJPE (CS)',\n",
       " 'MAE (trained with other data)',\n",
       " 'MAR, walking, 1,000ms',\n",
       " 'MAR, walking, 400ms',\n",
       " 'mAP (@0.1, Visible)',\n",
       " 'Sentiment',\n",
       " 'Laptop (Acc)',\n",
       " 'Restaurant 2014 (F1)',\n",
       " 'Exact Span F1',\n",
       " 'Sensitivity (VEB)',\n",
       " 'F-Measure (Seen)',\n",
       " 'Chamfer Distance',\n",
       " 'PSNR-B',\n",
       " 'Size (MB)',\n",
       " 'SSIM (sRGB)',\n",
       " 'ROUGE-L',\n",
       " 'LSE-C',\n",
       " 'Hit@20',\n",
       " 'HR@20',\n",
       " 'PA-MPVPE',\n",
       " 'Normalized Pose Error',\n",
       " 'inference time (ms)',\n",
       " 'mAOE',\n",
       " 'mATE',\n",
       " 'mAVE',\n",
       " 'Balanced Error Rate',\n",
       " 'MAP',\n",
       " 'max E-Measure',\n",
       " 'max F-Measure',\n",
       " 'Test perplexity',\n",
       " 'MAE [bpm, session-wise]',\n",
       " 'MAE for DBP [mmHg]',\n",
       " 'MAE for SBP [mmHg]',\n",
       " 'Log-Spectral Distance',\n",
       " 'Accuracy (%)',\n",
       " 'Grad Det-Jac',\n",
       " 'Hausdorff Distance (mm)',\n",
       " 'AMrTRE',\n",
       " 'Patch Verification',\n",
       " 'FPR95',\n",
       " 'ACER',\n",
       " 'CD',\n",
       " 'EMD',\n",
       " 'IoU',\n",
       " 'AED',\n",
       " 'AKD',\n",
       " 'MKR',\n",
       " 'GFLOPs',\n",
       " 'Percentage Error',\n",
       " 'Rank-5',\n",
       " 'MR (K=6)',\n",
       " 'brier-minFDE (K=6)',\n",
       " 'minADE (K=6)',\n",
       " 'mRec',\n",
       " 'IoU overall',\n",
       " 'Frame (fps)',\n",
       " 'Speed  (FPS)',\n",
       " 'Jaccard (Decay)',\n",
       " 'F-measure (Decay)',\n",
       " 'Jaccard (Recall)',\n",
       " 'AVERAGE MAE',\n",
       " 'max E-measure',\n",
       " 'MAX E-MEASURE',\n",
       " 'MAX F-MEASURE',\n",
       " 'Conn',\n",
       " 'Grad',\n",
       " 'MSE(10^3)',\n",
       " 'SAD',\n",
       " 'ABX-across',\n",
       " 'nats',\n",
       " 'Bits per dim',\n",
       " 'FID-5k-training-steps',\n",
       " 'bits/dimension',\n",
       " 'Intra-FID',\n",
       " 'bpd',\n",
       " 'FID-10k-training-steps',\n",
       " 'FID-50k',\n",
       " 'Parameters (M)',\n",
       " 'mIoU',\n",
       " 'Normalized cPSNR',\n",
       " 'Chamfer (cm)',\n",
       " 'Point-to-surface distance (cm)',\n",
       " 'Surface normal consistency',\n",
       " 'avg. log MAE',\n",
       " 'MPE',\n",
       " 'Question Answering',\n",
       " 'Sentence Retrieval',\n",
       " 'Sentence-pair Classification',\n",
       " 'F-Measure (Unseen)',\n",
       " 'Jaccard (Unseen)',\n",
       " 'ACC@1-100Clients',\n",
       " 'Error Rate',\n",
       " 'Long-Tailed Accuracy',\n",
       " 'B4',\n",
       " 'B1',\n",
       " 'B2',\n",
       " 'B3',\n",
       " 'METEOR',\n",
       " 'SPICE',\n",
       " 'Neg. F1',\n",
       " 'PCK@0.2',\n",
       " 'FID-0',\n",
       " 'FID-1',\n",
       " 'FID-2',\n",
       " 'FID-4',\n",
       " 'FID-8']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricName_negative_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Error']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricName_df=[\"Error\"]\n",
    "metricName_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ito:ITO_00141'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### F1\n",
      "Creating ratio df for  F1 ,  ACL-ARC - Citation Intent Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-3b3f263d94a4>:85: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.new = df.replace(to_replace =' model in .*$', value = '', regex = True)\n",
      "<ipython-input-81-3b3f263d94a4>:177: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  ratio = round( gain / (max(sota[\"result\"] - sota.loc[sota.index[0], 'result'])  ) ,4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "-41.0 - -41.0 == -41.0 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  MRPC - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-85.9 - -83.1 == -85.9 Ratio == -30.6786\n",
      "-83.1 - -85.9 == 2.8 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  MSRP - Paraphrase Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-81.48 - -81.3 == -81.48 Ratio == -452.6667\n",
      "-81.3 - -81.48 == 0.18 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  WebQuestions - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-29.7 - -29.7 == -29.7 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SciERC - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-65.12 - -64.2 == -65.12 Ratio == -70.7826\n",
      "-64.2 - -65.12 == 0.92 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  SensEval 2 Lexical Sample - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-66.2 - -66.2 == -66.2 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SensEval 3 Lexical Sample - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-73.4 - -72.5 == -73.4 Ratio == -81.5556\n",
      "-73.4 - -73.4 == 0.0 Ratio == 0.0\n",
      "-72.5 - -73.4 == 0.9 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  SimpleQuestions - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-63.9 - -63.9 == -63.9 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  MSRA - Chinese Word Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-97.4 - -97.4 == -97.4 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  Google Dataset - Sentence Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-0.82 - -0.8 == -0.82 Ratio == -41.0\n",
      "-0.81 - -0.82 == 0.01 Ratio == 0.5\n",
      "-0.8 - -0.81 == 0.01 Ratio == 0.5\n",
      "Creating ratio df for  F1 ,  Ontonotes v5 (English) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL 2003 (English) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL++ - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  SemEval 2013 Task 12 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-67.0 - -66.7 == -67.0 Ratio == -223.3333\n",
      "-66.7 - -67.0 == 0.3 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  SemEval 2007 Task 17 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-64.2 - -60.7 == -64.2 Ratio == -18.3429\n",
      "-60.7 - -64.2 == 3.5 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  SensEval 2 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "-73.6 - -72.0 == -73.6 Ratio == -46.0\n",
      "-72.4 - -73.6 == 1.2 Ratio == 0.75\n",
      "-72.2 - -72.4 == 0.2 Ratio == 0.125\n",
      "-72.1 - -72.2 == 0.1 Ratio == 0.0625\n",
      "-72.0 - -72.1 == 0.1 Ratio == 0.0625\n",
      "Creating ratio df for  F1 ,  SemEval 2007 Task 7 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-81.1 - -81.1 == -81.1 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SensEval 3 Task 1 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-71.1 - -64.3 == -71.1 Ratio == -10.4559\n",
      "-71.0 - -71.1 == 0.1 Ratio == 0.0147\n",
      "-64.3 - -71.0 == 6.7 Ratio == 0.9853\n",
      "Creating ratio df for  F1 ,  OntoNotes - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-64.21 - -64.21 == -64.21 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  Ubuntu Dialogue (Activity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  Ubuntu Dialogue (Entity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  Twitter Dialogue (Noun) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  SemEval-2010 Task 8 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-88.0 - -85.2 == -88.0 Ratio == -31.4286\n",
      "-85.2 - -88.0 == 2.8 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  SQuAD1.1 dev - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-64.7 - -64.7 == -64.7 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SQuAD1.1 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-73.743 - -67.748 == -73.743 Ratio == -12.3008\n",
      "-67.748 - -73.743 == 5.995 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  NewsQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-56.1 - -56.1 == -56.1 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  Natural Questions (long) - Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  Natural Questions (short) - Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  TriviaQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-52.85 - -46.9 == -52.85 Ratio == -8.8824\n",
      "-46.9 - -52.85 == 5.95 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  NYT-single - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-49.5 - -49.5 == -49.5 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  WebNLG - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-28.3 - -28.3 == -28.3 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  NYT - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-42.0 - -42.0 == -42.0 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  OntoNotes - Semantic Role Labeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-81.7 - -81.7 == -81.7 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  CoNLL 2005 - Predicate Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-96.4 - -96.4 == -96.4 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  COMPLEXQUESTIONS - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-53.6 - -30.1 == -53.6 Ratio == -2.2809\n",
      "-30.1 - -53.6 == 23.5 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  SCv1 - Sarcasm Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.69 - -0.69 == -0.69 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  Re-TACRED - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-79.4 - -79.4 == -79.4 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  TACRED - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-65.1 - -64.0 == -65.1 Ratio == -59.1818\n",
      "-64.0 - -65.1 == 1.1 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  Long-tail emerging entities - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-40.78 - -40.78 == -40.78 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SQuAD2.0 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-72.484 - -66.251 == -72.484 Ratio == -11.6291\n",
      "-71.439 - -72.484 == 1.045 Ratio == 0.1677\n",
      "-66.251 - -71.439 == 5.188 Ratio == 0.8323\n",
      "Creating ratio df for  F1 ,  SciCite - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-79.6 - -79.6 == -79.6 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ACL-ARC - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-53.0 - -53.0 == -53.0 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  CoNLL 2005 - Semantic Role Labeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-86.04 - -82.5 == -86.04 Ratio == -24.3051\n",
      "-82.5 - -86.04 == 3.54 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  WebQSP-WD - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.73 - -0.73 == -0.73 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  CoNLL 2012 - Predicate Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-97.2 - -97.2 == -97.2 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  CoNLL 2012 - Semantic Role Labeling (predicted predicates) benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL 2005 - Semantic Role Labeling (predicted predicates) benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  MSRA - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-93.18 - -92.74 == -93.18 Ratio == -211.7727\n",
      "-92.74 - -93.18 == 0.44 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  OntoNotes 4 - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-73.88 - -73.88 == -73.88 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  Weibo NER - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-58.79 - -53.08 == -58.79 Ratio == -10.296\n",
      "-53.08 - -58.79 == 5.71 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  Resume NER - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-94.46 - -94.46 == -94.46 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SemEval 2015 Task 13 - Word Sense Disambiguation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "-71.6 - -71.6 == -71.6 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  CoNLL 2000 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-90.34 - -90.34 == -90.34 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ACE 2005 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-72.2 - -72.2 == -72.2 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  GENIA - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-74.7 - -73.9 == -74.7 Ratio == -93.375\n",
      "-73.9 - -74.7 == 0.8 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.756 - -0.756 == -0.756 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SearchQA - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-64.5 - -63.6 == -64.5 Ratio == -71.6667\n",
      "-63.6 - -64.5 == 0.9 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  Ontonotes v5 (English) - Entity Typing benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL 2003 (German) Revised - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  GENIA - LAS - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-91.92 - -91.26 == -91.92 Ratio == -139.2727\n",
      "-91.26 - -91.92 == 0.66 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  GENIA - UAS - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-92.84 - -92.32 == -92.84 Ratio == -178.5385\n",
      "-92.46 - -92.84 == 0.38 Ratio == 0.7308\n",
      "-92.32 - -92.46 == 0.14 Ratio == 0.2692\n",
      "Creating ratio df for  F1 ,  SQuAD2.0 dev - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-74.8 - -74.0 == -74.8 Ratio == -93.5\n",
      "-74.0 - -74.8 == 0.8 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  PubMed 20k RCT - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-92.6 - -86.81 == -92.6 Ratio == -15.9931\n",
      "-86.81 - -92.6 == 5.79 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  BC5CDR - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-87.12 - -85.61 == -87.12 Ratio == -57.6954\n",
      "-85.61 - -87.12 == 1.51 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  SighanNER - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-90.64 - -90.64 == -90.64 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ACE 2004 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-73.3 - -73.3 == -73.3 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ACE 2004 - Nested Mention Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-73.1 - -73.1 == -73.1 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ACE 2005 - Nested Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-73.0 - -73.0 == -73.0 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  QuAC - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-64.1 - -64.1 == -64.1 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  NCBI-disease - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-86.37 - -86.37 == -86.37 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ReCoRD - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-56.065 - -56.065 == -56.065 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ATIS - Slot Filling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.952 - -0.952 == -0.952 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ChemProt - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-76.46 - -73.7 == -76.46 Ratio == -27.7029\n",
      "-73.7 - -76.46 == 2.76 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  JNLPBA - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-77.59 - -74.29 == -77.59 Ratio == -23.5121\n",
      "-75.77 - -77.59 == 1.82 Ratio == 0.5515\n",
      "-74.29 - -75.77 == 1.48 Ratio == 0.4485\n",
      "Creating ratio df for  F1 ,  Quora Question Pairs - Paraphrase Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-72.4 - -71.2 == -72.4 Ratio == -60.3333\n",
      "-71.2 - -72.4 == 1.2 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  Reuters-21578 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "-89.3 - -82.71 == -89.3 Ratio == -13.5508\n",
      "-88.9 - -89.3 == 0.4 Ratio == 0.0607\n",
      "-87.0 - -88.9 == 1.9 Ratio == 0.2883\n",
      "-82.71 - -87.0 == 4.29 Ratio == 0.651\n",
      "Creating ratio df for  F1 ,  SciERC - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-74.42 - -74.42 == -74.42 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  JNLPBA - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-76.09 - -76.09 == -76.09 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  Paper Field - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-65.71 - -64.02 == -65.71 Ratio == -38.8817\n",
      "-64.02 - -65.71 == 1.69 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  ScienceCite - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-84.43 - -84.43 == -84.43 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SciCite - Citation Intent Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-84.99 - -84.0 == -84.99 Ratio == -85.8485\n",
      "-84.0 - -84.99 == 0.99 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  WetLab - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-79.62 - -79.62 == -79.62 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  WLPC - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-79.5 - -79.5 == -79.5 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  WLPC - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-64.1 - -64.1 == -64.1 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.718 - -0.718 == -0.718 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  AAPD - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-72.9 - -72.9 == -72.9 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  MSRA Dev - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-95.0 - -95.0 == -95.0 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  FewRel - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-88.32 - -88.32 == -88.32 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  Open Entity - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-75.56 - -75.56 == -75.56 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  DocRED - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-50.12 - -42.33 == -50.12 Ratio == -6.4339\n",
      "-42.33 - -50.12 == 7.79 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  SemEval 2014 Task 4 Subtask 1+2 - Sentiment Analysis benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  ChnSentiCorp - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-95.8 - -95.8 == -95.8 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ATIS - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-95.8 - -0.952 == -95.8 Ratio == -1.01\n",
      "-0.952 - -95.8 == 94.848 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  NaturalQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-82.5 - -82.5 == -82.5 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  LINNAEUS - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-87.02 - -87.02 == -87.02 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  Species-800 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-82.44 - -82.44 == -82.44 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  CoNLL 2003 (German) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL 2002 (Dutch) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL 2002 (Spanish) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  Code-Switching English-Spanish NER - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-69.17 - -69.17 == -69.17 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ontontoes chinese v5 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-79.92 - -79.92 == -79.92 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  MSR - Chinese Word Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-98.35 - -97.89 == -98.35 Ratio == -213.8043\n",
      "-97.89 - -98.35 == 0.46 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  NYT29 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-71.6 - -67.3 == -71.6 Ratio == -16.6512\n",
      "-67.3 - -71.6 == 4.3 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  NYT24 - Relation Extraction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "-84.4 - -84.4 == -84.4 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  ASOS.com user intent - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-0.865 - -0.856 == -0.865 Ratio == -96.1111\n",
      "-0.856 - -0.865 == 0.009 Ratio == 1.0\n",
      "Creating ratio df for  F1 ,  _sem 2012 Shared Task: Sherlock Dataset - Negation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-91.59 - -91.59 == -91.59 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  BioScope : Full Papers - Negation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-94.4 - -94.4 == -94.4 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SFU Review Corpus - Negation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-91.25 - -91.25 == -91.25 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  BioScope : Abstracts - Negation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-95.74 - -95.74 == -95.74 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  BioScope : Full Papers - Speculation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-96.91 - -96.91 == -96.91 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  BioScope : Abstracts - Speculation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-97.87 - -97.87 == -97.87 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SFU Review Corpus - Speculation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-91 - -91 == -91 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-3b3f263d94a4>:177: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  ratio = round( gain / (max(sota[\"result\"] - sota.loc[sota.index[0], 'result'])  ) ,4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "-69.6 - -69.6 == -69.6 Ratio == -inf\n",
      "Creating ratio df for  F1 ,  SoSciSoCi - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.82 - -0.82 == -0.82 Ratio == -inf\n",
      "number of sota per dataset/metric:  145\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  SST-2 Binary classification - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-85.4 - -54.72 == -85.4 Ratio == -2.7836\n",
      "-82.9 - -85.4 == 2.5 Ratio == 0.0815\n",
      "-54.72 - -82.9 == 28.18 Ratio == 0.9185\n",
      "Creating ratio df for  Accuracy ,  MSRP - Paraphrase Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-72.75 - -71.5 == -72.75 Ratio == -58.2\n",
      "-71.5 - -72.75 == 1.25 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  MRPC - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-80.4 - -76.2 == -80.4 Ratio == -19.1429\n",
      "-76.2 - -80.4 == 4.2 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  SST-5 Fine-grained classification - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-44.4 - -41.6 == -44.4 Ratio == -15.8571\n",
      "-43.6 - -44.4 == 0.8 Ratio == 0.2857\n",
      "-41.6 - -43.6 == 2.0 Ratio == 0.7143\n",
      "Creating ratio df for  Accuracy ,  Reuters RCV1/RCV2 German-to-English - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-76.9 - -76.9 == -76.9 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Reuters RCV1/RCV2 English-to-German - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-86.2 - -86.2 == -86.2 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Cora - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-67.2 - -67.2 == -67.2 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Reverb - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-73 - -68 == -73 Ratio == -14.6\n",
      "-68 - -73 == 5 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  Reuters De-En - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-75 - -75 == -75 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Reuters En-De - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-86.5 - -86.5 == -86.5 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  ATIS - Semantic Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-84.2 - -84.2 == -84.2 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  IMDb - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "-92.33 - -44.5 == -92.33 Ratio == -1.9304\n",
      "-88.9 - -92.33 == 3.43 Ratio == 0.0717\n",
      "-88.3 - -88.9 == 0.6 Ratio == 0.0125\n",
      "-87.15 - -88.3 == 1.15 Ratio == 0.024\n",
      "-45.1 - -87.15 == 42.05 Ratio == 0.8792\n",
      "-44.5 - -45.1 == 0.6 Ratio == 0.0125\n",
      "Creating ratio df for  Accuracy ,  SUBJ - Subjectivity Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-95.5 - -90.8 == -95.5 Ratio == -20.3191\n",
      "-90.8 - -95.5 == 4.7 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  Penn Treebank - Part-Of-Speech Tagging benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-97.36 - -97.22 == -97.36 Ratio == -695.4286\n",
      "-97.22 - -97.36 == 0.14 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  20NEWS - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-1 - -1 == -1 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  VQA v1 test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-58.9 - -58.7 == -58.9 Ratio == -294.5\n",
      "-58.7 - -58.9 == 0.2 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  VQA v1 test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-58.6 - -58.6 == -58.6 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-92.85 - -92.85 == -92.85 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Switchboard corpus - Dialog Act Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-73.1 - -73.1 == -73.1 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Django - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-62.3 - -31.5 == -62.3 Ratio == -2.0227\n",
      "-31.5 - -62.3 == 30.8 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  MCTest-160 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-75.27 - -75.27 == -75.27 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MCTest-500 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-69.94 - -69.94 == -69.94 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Story Cloze Test - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-78.7 - -77.6 == -78.7 Ratio == -71.5455\n",
      "-77.6 - -78.7 == 1.1 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  CCGbank - Combinatory Categorical Grammar (CCG) Supertagging benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Ubuntu Dialogue (Tense) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Ubuntu Dialogue (Cmd) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Twitter Dialogue (Tense) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VQA v2 test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-64.7 - -63.18 == -64.7 Ratio == -42.5658\n",
      "-63.18 - -64.7 == 1.52 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-48.69 - -48.69 == -48.69 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  ReferIt - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-28.91 - -28.91 == -28.91 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Yahoo! Answers - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-72.3 - -72.3 == -72.3 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Sogou News - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-96.8 - -96.8 == -96.8 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Amazon Review Full - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-60.2 - -49.7 == -60.2 Ratio == -5.7333\n",
      "-49.7 - -60.2 == 10.5 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  Amazon Review Polarity - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-94.6 - -88.1 == -94.6 Ratio == -14.5538\n",
      "-88.1 - -94.6 == 6.5 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  MR - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "-78.26 - -75.9 == -78.26 Ratio == -33.161\n",
      "-76.2 - -78.26 == 2.06 Ratio == 0.8729\n",
      "-75.9 - -76.2 == 0.3 Ratio == 0.1271\n",
      "-75.9 - -75.9 == 0.0 Ratio == 0.0\n",
      "Creating ratio df for  Accuracy ,  Quora Question Pairs - Paraphrase Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-88.17 - -87.01 == -88.17 Ratio == -76.0086\n",
      "-87.01 - -88.17 == 1.16 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  MSVD-QA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.313 - -0.313 == -0.313 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MSRVTT-QA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.309 - -0.309 == -0.309 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  SARC (all-bal) - Sarcasm Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  SARC (pol-bal) - Sarcasm Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  RumourEval - Stance Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-0.784 - -0.78 == -0.784 Ratio == -196.0\n",
      "-0.78 - -0.784 == 0.004 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  XNLI Zero-Shot English-to-Spanish - Cross-Lingual Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-60.7 - -60.7 == -60.7 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  XNLI Zero-Shot English-to-French - Cross-Lingual Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-60.3 - -60.3 == -60.3 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  XNLI Zero-Shot English-to-German - Cross-Lingual Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-61.0 - -61.0 == -61.0 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-57.5 - -57.5 == -57.5 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MOSI - Multimodal Sentiment Analysis benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "-80.3 - -76.5 == -80.3 Ratio == -21.1316\n",
      "-77.1 - -80.3 == 3.2 Ratio == 0.8421\n",
      "-76.5 - -77.1 == 0.6 Ratio == 0.1579\n",
      "Creating ratio df for  Accuracy ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-56.32 - -56.32 == -56.32 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Ohsumed - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-36.2 - -36.2 == -36.2 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-49.74 - -49.74 == -49.74 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  ICSI Meeting Recorder Dialog Act (MRDA) corpus - Dialog Act Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  WOS-11967 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-86.07 - -86.07 == -86.07 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  WOS-5736 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-90.93 - -90.93 == -90.93 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  WOS-46985 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-76.58 - -76.58 == -76.58 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  LexNorm - Lexical Normalization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-87.63 - -83.94 == -87.63 Ratio == -23.748\n",
      "-83.94 - -87.63 == 3.69 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  CR - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-92.2 - -82.73 == -92.2 Ratio == -9.736\n",
      "-85.1 - -92.2 == 7.1 Ratio == 0.7497\n",
      "-82.73 - -85.1 == 2.37 Ratio == 0.2503\n",
      "Creating ratio df for  Accuracy ,  SciTail - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-83.3 - -83.3 == -83.3 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MPQA - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-88.14 - -88.14 == -88.14 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  20NEWS - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-87.91 - -76.18 == -87.91 Ratio == -7.4945\n",
      "-84.5 - -87.91 == 3.41 Ratio == 0.2907\n",
      "-76.18 - -84.5 == 8.32 Ratio == 0.7093\n",
      "Creating ratio df for  Accuracy ,  Geo - Semantic Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-88.2 - -87.7 == -88.2 Ratio == -176.4\n",
      "-87.7 - -88.2 == 0.5 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  Quora Question Pairs - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-83.03 - -72.1 == -83.03 Ratio == -7.5965\n",
      "-72.1 - -83.03 == 10.93 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Spanish - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-69.5 - -66.65 == -69.5 Ratio == -24.386\n",
      "-66.65 - -69.5 == 2.85 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-French - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-72.83 - -72.38 == -72.83 Ratio == -161.8444\n",
      "-72.38 - -72.83 == 0.45 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Chinese - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-74.73 - -71.93 == -74.73 Ratio == -26.6893\n",
      "-71.97 - -74.73 == 2.76 Ratio == 0.9857\n",
      "-71.93 - -71.97 == 0.04 Ratio == 0.0143\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot German-to-French - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-75.45 - -75.45 == -75.45 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-German - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-81.2 - -71.83 == -81.2 Ratio == -8.666\n",
      "-71.83 - -81.2 == 9.37 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Japanese - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-67.63 - -60.3 == -67.63 Ratio == -9.2265\n",
      "-60.3 - -67.63 == 7.33 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Italian - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-60.73 - -60.73 == -60.73 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Russian - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-60.8 - -60.8 == -60.8 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MemexQA - Memex Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-0.357 - -0.357 == -0.357 Ratio == -inf\n",
      "-0.357 - -0.357 == 0.0 Ratio == nan\n",
      "Creating ratio df for  Accuracy ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-3b3f263d94a4>:181: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ratio = round( gain / (max(sota[\"result\"] - sota.loc[sota.index[0], 'result'])  ) ,4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "-37.4 - -37.4 == -37.4 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  R8 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-96.7 - -96.7 == -96.7 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  V-SNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-86.41 - -86.41 == -86.41 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  CMU-MOSEI - Multimodal Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-76.9 - -76.9 == -76.9 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  LAMBADA - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-56.25 - -56.25 == -56.25 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  CLEVR - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-98.8 - -65.9 == -98.8 Ratio == -3.003\n",
      "-65.9 - -98.8 == 32.9 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  Query Wellformedness - Query Wellformedness benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-70.7 - -70.7 == -70.7 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  XNLI French - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-68.3 - -68.3 == -68.3 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  R52 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-93.56 - -93.56 == -93.56 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  spider - Semantic Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-19.7 - -19.7 == -19.7 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  WNLI - Natural Language Understanding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-65.1 - -65.1 == -65.1 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  PDP60 - Natural Language Understanding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-78.3 - -78.3 == -78.3 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Sogou News - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-97.25 - -97.0 == -97.25 Ratio == -389.0\n",
      "-97.0 - -97.25 == 0.25 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  HowmanyQA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-60.3 - -60.3 == -60.3 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  TallyQA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-71.8 - -71.8 == -71.8 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  CommonsenseQA - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-55.9 - -55.9 == -55.9 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Quora Question Pairs - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-88.01 - -88.01 == -88.01 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Automatic Misogynistic Identification - Hate Speech Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.704 - -0.704 == -0.704 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  ATIS - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-95.0 - -95.0 == -95.0 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Yelp-5 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "-73.28 - -67.6 == -73.28 Ratio == -12.9014\n",
      "-70.58 - -73.28 == 2.7 Ratio == 0.4754\n",
      "-68.7 - -70.58 == 1.88 Ratio == 0.331\n",
      "-67.6 - -68.7 == 1.1 Ratio == 0.1937\n",
      "Creating ratio df for  Accuracy ,  CoLA - Linguistic Acceptability Assessment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-68.4 - -49.1 == -68.4 Ratio == -3.544\n",
      "-52.3 - -68.4 == 16.1 Ratio == 0.8342\n",
      "-49.1 - -52.3 == 3.2 Ratio == 0.1658\n",
      "Creating ratio df for  Accuracy ,  TDIUC - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-88.2 - -87.0 == -88.2 Ratio == -73.5\n",
      "-87.0 - -88.2 == 1.2 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  GQA test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-46.55 - -46.55 == -46.55 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Twitter - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-74.71 - -72.83 == -74.71 Ratio == -39.7394\n",
      "-72.83 - -74.71 == 1.88 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  Recipe - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-59.06 - -59.06 == -59.06 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Amazon - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-94.31 - -94.31 == -94.31 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Classic - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-96.24 - -96.24 == -96.24 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Reuters-21578 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-97.17 - -97.17 == -97.17 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  BBCSport - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-95.73 - -95.73 == -95.73 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Twitter - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-72.6 - -72.6 == -72.6 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  CODAH - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-69.6 - -69.6 == -69.6 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Yelp-14 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-69.4 - -69.4 == -69.4 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  XNLI Chinese Dev - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-79.9 - -79.9 == -79.9 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  XNLI Chinese - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-78.4 - -78.4 == -78.4 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  Yelp-2 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-98.08 - -97.1 == -98.08 Ratio == -100.0816\n",
      "-97.1 - -98.08 == 0.98 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  FIGER - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-57.19 - -57.19 == -57.19 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  QNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-91.3 - -90.2 == -91.3 Ratio == -83.0\n",
      "-90.2 - -91.3 == 1.1 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  RTE - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-68.8 - -62.9 == -68.8 Ratio == -11.661\n",
      "-62.9 - -68.8 == 5.9 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  IMDb-M - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-52.8 - -52.8 == -52.8 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  RACE - Reading Comprehension benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-85.4 - -83.2 == -85.4 Ratio == -38.8182\n",
      "-83.2 - -85.4 == 2.2 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  WNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "-92.5 - -44.4 == -92.5 Ratio == -1.9231\n",
      "-89.0 - -92.5 == 3.5 Ratio == 0.0728\n",
      "-67.8 - -89.0 == 21.2 Ratio == 0.4407\n",
      "-44.4 - -67.8 == 23.4 Ratio == 0.4865\n",
      "Creating ratio df for  Accuracy ,  GQA test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-62.95 - -60.0 == -62.95 Ratio == -21.339\n",
      "-60.0 - -62.95 == 2.95 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  Helsinki Prosody Corpus - Prosody Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-81.8 - -80.8 == -81.8 Ratio == -81.8\n",
      "-80.8 - -81.8 == 1.0 Ratio == 1.0\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-AR) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (QA-R) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-AR) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-A) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  NLVR2 Dev - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-66.7 - -66.7 == -66.7 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MPQA - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-89.81 - -89.81 == -89.81 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  NLVR2 Test - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-76.2 - -76.2 == -76.2 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-A) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (QA-R) test - Visual Question Answering benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "Creating ratio df for  Accuracy ,  Financial PhraseBank - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-86 - -86 == -86 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  WikiSQL - Semantic Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-89 - -89 == -89 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  CoNLL-Aida - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-94.9 - -94.9 == -94.9 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  TAC-KBP 2010 - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-89.8 - -89.8 == -89.8 Ratio == -inf\n",
      "Creating ratio df for  Accuracy ,  MNIST - Handwritten Digit Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-96.95 - -96.95 == -96.95 Ratio == -inf\n",
      "number of sota per dataset/metric:  172\n",
      "####### PPL\n",
      "Creating ratio df for  PPL ,  One Billion Word - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "51.3 - 52.9 == 51.3 Ratio == 32.0625\n",
      "52.9 - 51.3 == 1.6 Ratio == 1.0\n",
      "Creating ratio df for  PPL ,  CNN / Daily Mail - Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "23.6 - 32.75 == 23.6 Ratio == 2.5792\n",
      "32.75 - 23.6 == 9.15 Ratio == 1.0\n",
      "Creating ratio df for  PPL ,  PTB - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "56 - 56 == 56 Ratio == inf\n",
      "number of sota per dataset/metric:  5\n",
      "####### %\\\\ Test\\\\ Accuracy\n",
      "Creating ratio df for  %\\\\ Test\\\\ Accuracy ,  SNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "86.8 - 91.9 == 86.8 Ratio == 17.0196\n",
      "88.1 - 86.8 == 1.3 Ratio == 0.2549\n",
      "88.6 - 88.1 == 0.5 Ratio == 0.098\n",
      "88.8 - 88.6 == 0.2 Ratio == 0.0392\n",
      "88.9 - 88.8 == 0.1 Ratio == 0.0196\n",
      "89.1 - 88.9 == 0.2 Ratio == 0.0392\n",
      "89.3 - 89.1 == 0.2 Ratio == 0.0392\n",
      "90.1 - 89.3 == 0.8 Ratio == 0.1569\n",
      "91.3 - 90.1 == 1.2 Ratio == 0.2353\n",
      "91.6 - 91.3 == 0.3 Ratio == 0.0588\n",
      "91.9 - 91.6 == 0.3 Ratio == 0.0588\n",
      "number of sota per dataset/metric:  11\n",
      "####### MRR\n",
      "Creating ratio df for  MRR ,  WikiQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "0.6058 - 0.784 == 0.6058 Ratio == 3.3996\n",
      "0.6281 - 0.6058 == 0.0223 Ratio == 0.1251\n",
      "0.6652 - 0.6281 == 0.0371 Ratio == 0.2082\n",
      "0.6988 - 0.6652 == 0.0336 Ratio == 0.1886\n",
      "0.7069 - 0.6988 == 0.0081 Ratio == 0.0455\n",
      "0.7226 - 0.7069 == 0.0157 Ratio == 0.0881\n",
      "0.7234 - 0.7226 == 0.0008 Ratio == 0.0045\n",
      "0.7265 - 0.7234 == 0.0031 Ratio == 0.0174\n",
      "0.727 - 0.7265 == 0.0005 Ratio == 0.0028\n",
      "0.784 - 0.727 == 0.057 Ratio == 0.3199\n",
      "Creating ratio df for  MRR ,  QASent - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "0.7514 - 0.8117 == 0.7514 Ratio == 12.461\n",
      "0.7846 - 0.7514 == 0.0332 Ratio == 0.5506\n",
      "0.8117 - 0.7846 == 0.0271 Ratio == 0.4494\n",
      "Creating ratio df for  MRR ,  TrecQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "0.785 - 0.928 == 0.785 Ratio == 5.4895\n",
      "0.8219 - 0.785 == 0.0369 Ratio == 0.258\n",
      "0.825 - 0.8219 == 0.0031 Ratio == 0.0217\n",
      "0.928 - 0.825 == 0.103 Ratio == 0.7203\n",
      "Creating ratio df for  MRR ,  YahooCQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "0.726 - 0.801 == 0.726 Ratio == 9.68\n",
      "0.731 - 0.726 == 0.005 Ratio == 0.0667\n",
      "0.801 - 0.731 == 0.07 Ratio == 0.9333\n",
      "Creating ratio df for  MRR ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "57.88 - 68.92 == 57.88 Ratio == 5.2428\n",
      "63.98 - 57.88 == 6.1 Ratio == 0.5525\n",
      "64.1 - 63.98 == 0.12 Ratio == 0.0109\n",
      "66.38 - 64.1 == 2.28 Ratio == 0.2065\n",
      "68.92 - 66.38 == 2.54 Ratio == 0.2301\n",
      "Creating ratio df for  MRR ,  Music domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "39.36 - 60.93 == 39.36 Ratio == 1.8248\n",
      "60.93 - 39.36 == 21.57 Ratio == 1.0\n",
      "Creating ratio df for  MRR ,  Medical domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "41.07 - 54.64 == 41.07 Ratio == 3.0265\n",
      "54.64 - 41.07 == 13.57 Ratio == 1.0\n",
      "Creating ratio df for  MRR ,  General - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "23.83 - 36.1 == 23.83 Ratio == 1.9421\n",
      "36.1 - 23.83 == 12.27 Ratio == 1.0\n",
      "Creating ratio df for  MRR ,  MS MARCO - Passage Re-Ranking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.359 - 0.368 == 0.359 Ratio == 39.8889\n",
      "0.368 - 0.359 == 0.009 Ratio == 1.0\n",
      "Creating ratio df for  MRR ,  Py150 - Type prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "98.7 - 98.7 == 98.7 Ratio == inf\n",
      "Creating ratio df for  MRR ,  Py150 - Value prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "73.6 - 73.6 == 73.6 Ratio == inf\n",
      "number of sota per dataset/metric:  35\n",
      "####### Accuracy\\\\ \\\\(2\\\\ classes\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(2\\\\ classes\\\\) ,  IMDb - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "92.58 - 96.8 == 92.58 Ratio == 21.9384\n",
      "95.17 - 92.58 == 2.59 Ratio == 0.6137\n",
      "95.63 - 95.17 == 0.46 Ratio == 0.109\n",
      "96.8 - 95.63 == 1.17 Ratio == 0.2773\n",
      "number of sota per dataset/metric:  4\n",
      "####### MAP\n",
      "Creating ratio df for  MAP ,  WikiQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-0.5976 - -0.511 == -0.5976 Ratio == -6.9007\n",
      "-0.511 - -0.5976 == 0.0866 Ratio == 1.0\n",
      "Creating ratio df for  MAP ,  QASent - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-0.6762 - -0.5213 == -0.6762 Ratio == -4.3654\n",
      "-0.5213 - -0.6762 == 0.1549 Ratio == 1.0\n",
      "Creating ratio df for  MAP ,  TrecQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.711 - -0.711 == -0.711 Ratio == -inf\n",
      "Creating ratio df for  MAP ,  SemEvalCQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-0.78 - -0.771 == -0.78 Ratio == -86.6667\n",
      "-0.771 - -0.78 == 0.009 Ratio == 1.0\n",
      "Creating ratio df for  MAP ,  General - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-10.6 - -1.36 == -10.6 Ratio == -1.1472\n",
      "-1.36 - -10.6 == 9.24 Ratio == 1.0\n",
      "Creating ratio df for  MAP ,  Music domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-12.99 - -1.95 == -12.99 Ratio == -1.1766\n",
      "-1.95 - -12.99 == 11.04 Ratio == 1.0\n",
      "Creating ratio df for  MAP ,  Medical domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-18.84 - -0.91 == -18.84 Ratio == -1.0508\n",
      "-0.91 - -18.84 == 17.93 Ratio == 1.0\n",
      "Creating ratio df for  MAP ,  TREC Robust04 - Ad-Hoc Information Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "-0.2811 - -0.2464 == -0.2811 Ratio == -8.1009\n",
      "-0.279 - -0.2811 == 0.0021 Ratio == 0.0605\n",
      "-0.258 - -0.279 == 0.021 Ratio == 0.6052\n",
      "-0.2499 - -0.258 == 0.0081 Ratio == 0.2334\n",
      "-0.2464 - -0.2499 == 0.0035 Ratio == 0.1009\n",
      "number of sota per dataset/metric:  18\n",
      "####### RE\\\\+\\\\ Micro\\\\ F1\n",
      "Creating ratio df for  RE\\\\+\\\\ Micro\\\\ F1 ,  ACE 2005 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "49.5 - 60.2 == 49.5 Ratio == 4.6262\n",
      "55.6 - 49.5 == 6.1 Ratio == 0.5701\n",
      "57.5 - 55.6 == 1.9 Ratio == 0.1776\n",
      "59.6 - 57.5 == 2.1 Ratio == 0.1963\n",
      "60.2 - 59.6 == 0.6 Ratio == 0.0561\n",
      "Creating ratio df for  RE\\\\+\\\\ Micro\\\\ F1 ,  ACE 2004 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "45.3 - 49.4 == 45.3 Ratio == 11.0488\n",
      "48.4 - 45.3 == 3.1 Ratio == 0.7561\n",
      "49.4 - 48.4 == 1.0 Ratio == 0.2439\n",
      "Creating ratio df for  RE\\\\+\\\\ Micro\\\\ F1 ,  CoNLL04 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "61.0 - 68.9 == 61.0 Ratio == 7.7215\n",
      "67.8 - 61.0 == 6.8 Ratio == 0.8608\n",
      "68.9 - 67.8 == 1.1 Ratio == 0.1392\n",
      "number of sota per dataset/metric:  11\n",
      "####### RE\\\\ Micro\\\\ F1\n",
      "Creating ratio df for  RE\\\\ Micro\\\\ F1 ,  ACE 2005 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "52.1 - 63.4 == 52.1 Ratio == 4.6106\n",
      "55.9 - 52.1 == 3.8 Ratio == 0.3363\n",
      "63.2 - 55.9 == 7.3 Ratio == 0.646\n",
      "63.4 - 63.2 == 0.2 Ratio == 0.0177\n",
      "Creating ratio df for  RE\\\\ Micro\\\\ F1 ,  ACE 2004 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "48.3 - 59.7 == 48.3 Ratio == 4.2368\n",
      "49.3 - 48.3 == 1.0 Ratio == 0.0877\n",
      "59.7 - 49.3 == 10.4 Ratio == 0.9123\n",
      "number of sota per dataset/metric:  7\n",
      "####### NER\\\\ Micro\\\\ F1\n",
      "Creating ratio df for  NER\\\\ Micro\\\\ F1 ,  ACE 2004 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "79.7 - 87.4 == 79.7 Ratio == 10.3506\n",
      "81.8 - 79.7 == 2.1 Ratio == 0.2727\n",
      "87.4 - 81.8 == 5.6 Ratio == 0.7273\n",
      "Creating ratio df for  NER\\\\ Micro\\\\ F1 ,  ACE 2005 - Relation Extraction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 5\n",
      "80.8 - 88.6 == 80.8 Ratio == 10.359\n",
      "83.4 - 80.8 == 2.6 Ratio == 0.3333\n",
      "83.6 - 83.4 == 0.2 Ratio == 0.0256\n",
      "88.4 - 83.6 == 4.8 Ratio == 0.6154\n",
      "88.6 - 88.4 == 0.2 Ratio == 0.0256\n",
      "Creating ratio df for  NER\\\\ Micro\\\\ F1 ,  CoNLL04 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "80.7 - 87.8 == 80.7 Ratio == 11.3662\n",
      "85.6 - 80.7 == 4.9 Ratio == 0.6901\n",
      "87.8 - 85.6 == 2.2 Ratio == 0.3099\n",
      "number of sota per dataset/metric:  11\n",
      "####### BLEU\\\\ score\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 English-French - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "34.54 - 45.6 == 34.54 Ratio == 3.123\n",
      "36.2 - 34.54 == 1.66 Ratio == 0.1501\n",
      "36.5 - 36.2 == 0.3 Ratio == 0.0271\n",
      "37.5 - 36.5 == 1.0 Ratio == 0.0904\n",
      "39.2 - 37.5 == 1.7 Ratio == 0.1537\n",
      "39.9 - 39.2 == 0.7 Ratio == 0.0633\n",
      "40.56 - 39.9 == 0.66 Ratio == 0.0597\n",
      "41.3 - 40.56 == 0.74 Ratio == 0.0669\n",
      "41.4 - 41.3 == 0.1 Ratio == 0.009\n",
      "41.5 - 41.4 == 0.1 Ratio == 0.009\n",
      "43.2 - 41.5 == 1.7 Ratio == 0.1537\n",
      "45.6 - 43.2 == 2.4 Ratio == 0.217\n",
      "Creating ratio df for  BLEU\\\\ score ,  IWSLT2015 German-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "28.53 - 35.18 == 28.53 Ratio == 4.2902\n",
      "29.98 - 28.53 == 1.45 Ratio == 0.218\n",
      "30.4 - 29.98 == 0.42 Ratio == 0.0632\n",
      "32.31 - 30.4 == 1.91 Ratio == 0.2872\n",
      "32.93 - 32.31 == 0.62 Ratio == 0.0932\n",
      "34.18 - 32.93 == 1.25 Ratio == 0.188\n",
      "35.18 - 34.18 == 1.0 Ratio == 0.1504\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "20.9 - 35.0 == 20.9 Ratio == 1.4823\n",
      "26.3 - 20.9 == 5.4 Ratio == 0.383\n",
      "26.4 - 26.3 == 0.1 Ratio == 0.0071\n",
      "28.4 - 26.4 == 2.0 Ratio == 0.1418\n",
      "28.9 - 28.4 == 0.5 Ratio == 0.0355\n",
      "29.2 - 28.9 == 0.3 Ratio == 0.0213\n",
      "29.3 - 29.2 == 0.1 Ratio == 0.0071\n",
      "35.0 - 29.3 == 5.7 Ratio == 0.4043\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2015 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "22.8 - 26.3 == 22.8 Ratio == 6.5143\n",
      "23.5 - 22.8 == 0.7 Ratio == 0.2\n",
      "26.3 - 23.5 == 2.8 Ratio == 0.8\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2015 English-Russian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "20.9 - 20.9 == 20.9 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 German-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "32.9 - 38.6 == 32.9 Ratio == 5.7719\n",
      "38.6 - 32.9 == 5.7 Ratio == 1.0\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 Romanian-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "33.3 - 35.3 == 33.3 Ratio == 16.65\n",
      "35.3 - 33.3 == 2.0 Ratio == 1.0\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 English-Czech - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "25.8 - 25.8 == 25.8 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 Czech-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "31.4 - 31.4 == 31.4 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 English-Romanian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "28.1 - 32.35 == 28.1 Ratio == 6.6118\n",
      "28.9 - 28.1 == 0.8 Ratio == 0.1882\n",
      "29.9 - 28.9 == 1.0 Ratio == 0.2353\n",
      "31.08 - 29.9 == 1.18 Ratio == 0.2776\n",
      "31.97 - 31.08 == 0.89 Ratio == 0.2094\n",
      "32.35 - 31.97 == 0.38 Ratio == 0.0894\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "28.4 - 40.68 == 28.4 Ratio == 2.3127\n",
      "34.2 - 28.4 == 5.8 Ratio == 0.4723\n",
      "40.68 - 34.2 == 6.48 Ratio == 0.5277\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 English-Russian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "26.0 - 26.0 == 26.0 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 Russian-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "28 - 28 == 28 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\ score ,  IWSLT2015 Thai-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "14.2 - 14.2 == 14.2 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\ score ,  IWSLT2014 German-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "28.53 - 35.7 == 28.53 Ratio == 3.9791\n",
      "34.44 - 28.53 == 5.91 Ratio == 0.8243\n",
      "35.2 - 34.44 == 0.76 Ratio == 0.106\n",
      "35.7 - 35.2 == 0.5 Ratio == 0.0697\n",
      "Creating ratio df for  BLEU\\\\ score ,  IWSLT2015 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "25.04 - 28.23 == 25.04 Ratio == 7.8495\n",
      "26.73 - 25.04 == 1.69 Ratio == 0.5298\n",
      "28.23 - 26.73 == 1.5 Ratio == 0.4702\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 German-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "23.2 - 28.29 == 23.2 Ratio == 4.558\n",
      "25.43 - 23.2 == 2.23 Ratio == 0.4381\n",
      "28.29 - 25.43 == 2.86 Ratio == 0.5619\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT 2017 English-Chinese - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "24.2 - 24.4 == 24.2 Ratio == 121.0\n",
      "24.4 - 24.2 == 0.2 Ratio == 1.0\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 French-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "25.87 - 25.87 == 25.87 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 English-Czech - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "27.6 - 28.2 == 27.6 Ratio == 46.0\n",
      "28.2 - 27.6 == 0.6 Ratio == 1.0\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2019 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "43.1 - 43.1 == 43.1 Ratio == inf\n",
      "number of sota per dataset/metric:  65\n",
      "####### Avg\\\\ F1\n",
      "Creating ratio df for  Avg\\\\ F1 ,  Persona-Chat - Dialog Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "16.18 - 19.77 == 16.18 Ratio == 4.507\n",
      "19.77 - 16.18 == 3.59 Ratio == 1.0\n",
      "Creating ratio df for  Avg\\\\ F1 ,  SARC (pol-unbal) - Sarcasm Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Avg\\\\ F1 ,  CoNLL 2012 - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "68.8 - 76.9 == 68.8 Ratio == 8.4938\n",
      "70.4 - 68.8 == 1.6 Ratio == 0.1975\n",
      "73.0 - 70.4 == 2.6 Ratio == 0.321\n",
      "76.61 - 73.0 == 3.61 Ratio == 0.4457\n",
      "76.9 - 76.61 == 0.29 Ratio == 0.0358\n",
      "Creating ratio df for  Avg\\\\ F1 ,  SemEval - Aspect Term Extraction and Sentiment Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "64.23 - 64.23 == 64.23 Ratio == inf\n",
      "number of sota per dataset/metric:  8\n",
      "####### Test\\\\ perplexity\n",
      "Creating ratio df for  Test\\\\ perplexity ,  Penn Treebank (Word Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Test\\\\ perplexity ,  20 Newsgroups - Topic modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "836 - 836 == 836 Ratio == inf\n",
      "Creating ratio df for  Test\\\\ perplexity ,  WikiText-2 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "87.7 - 99.3 == 87.7 Ratio == 7.5603\n",
      "99.3 - 87.7 == 11.6 Ratio == 1.0\n",
      "Creating ratio df for  Test\\\\ perplexity ,  WikiText-103 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "40.8 - 48.7 == 40.8 Ratio == 5.1646\n",
      "48.7 - 40.8 == 7.9 Ratio == 1.0\n",
      "number of sota per dataset/metric:  5\n",
      "####### Validation\\\\ perplexity\n",
      "Creating ratio df for  Validation\\\\ perplexity ,  Penn Treebank (Word Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Validation\\\\ perplexity ,  WikiText-2 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "92.3 - 92.3 == 92.3 Ratio == inf\n",
      "Creating ratio df for  Validation\\\\ perplexity ,  WikiText-103 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "32.0 - 36.0 == 32.0 Ratio == 8.0\n",
      "36.0 - 32.0 == 4.0 Ratio == 1.0\n",
      "Creating ratio df for  Validation\\\\ perplexity ,  One Billion Word - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "22.92 - 23.83 == 22.92 Ratio == 25.1868\n",
      "23.83 - 22.92 == 0.91 Ratio == 1.0\n",
      "number of sota per dataset/metric:  5\n",
      "####### BLEU\\\\-1\n",
      "Creating ratio df for  BLEU\\\\-1 ,  COCO Visual Question Answering (VQA) real images 1.0 open ended - Question Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  BLEU\\\\-1 ,  NarrativeQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "33.45 - 54.11 == 33.45 Ratio == 1.6191\n",
      "43.63 - 33.45 == 10.18 Ratio == 0.4927\n",
      "44.35 - 43.63 == 0.72 Ratio == 0.0348\n",
      "48.7 - 44.35 == 4.35 Ratio == 0.2106\n",
      "54.11 - 48.7 == 5.41 Ratio == 0.2619\n",
      "Creating ratio df for  BLEU\\\\-1 ,  MS MARCO - Question Answering benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "10.64 - 54.64 == 10.64 Ratio == 0.2418\n",
      "54.37 - 10.64 == 43.73 Ratio == 0.9939\n",
      "54.64 - 54.37 == 0.27 Ratio == 0.0061\n",
      "Creating ratio df for  BLEU\\\\-1 ,  quora - Paraphrase Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "22.9 - 45.7 == 22.9 Ratio == 1.0044\n",
      "45.7 - 22.9 == 22.8 Ratio == 1.0\n",
      "Creating ratio df for  BLEU\\\\-1 ,  Visual Question Generation - Question Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "36 - 36 == 36 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\-1 ,  DailyDialog - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "14.17 - 14.17 == 14.17 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\-1 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "64.2 - 64.2 == 64.2 Ratio == inf\n",
      "number of sota per dataset/metric:  13\n",
      "####### F1\\\\ score\n",
      "Creating ratio df for  F1\\\\ score ,  Penn Treebank - Constituency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "92.1 - 95.6 == 92.1 Ratio == 26.3143\n",
      "93.8 - 92.1 == 1.7 Ratio == 0.4857\n",
      "94.66 - 93.8 == 0.86 Ratio == 0.2457\n",
      "95.13 - 94.66 == 0.47 Ratio == 0.1343\n",
      "95.6 - 95.13 == 0.47 Ratio == 0.1343\n",
      "Creating ratio df for  F1\\\\ score ,  BUCC French-to-English - Cross-Lingual Bitext Mining benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "75.8 - 93.91 == 75.8 Ratio == 4.1855\n",
      "92.89 - 75.8 == 17.09 Ratio == 0.9437\n",
      "93.91 - 92.89 == 1.02 Ratio == 0.0563\n",
      "Creating ratio df for  F1\\\\ score ,  BUCC German-to-English - Cross-Lingual Bitext Mining benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "76.9 - 96.19 == 76.9 Ratio == 3.9865\n",
      "95.58 - 76.9 == 18.68 Ratio == 0.9684\n",
      "96.19 - 95.58 == 0.61 Ratio == 0.0316\n",
      "Creating ratio df for  F1\\\\ score ,  Penn Treebank - Chunking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "95.57 - 96.72 == 95.57 Ratio == 83.1043\n",
      "95.77 - 95.57 == 0.2 Ratio == 0.1739\n",
      "96.72 - 95.77 == 0.95 Ratio == 0.8261\n",
      "Creating ratio df for  F1\\\\ score ,  TimeBank - Temporal Information Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.511 - 0.511 == 0.511 Ratio == inf\n",
      "Creating ratio df for  F1\\\\ score ,  SemEval 2015 Task 12 - Extract Aspect benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.63 - 0.7 == 0.63 Ratio == 9.0\n",
      "0.7 - 0.63 == 0.07 Ratio == 1.0\n",
      "Creating ratio df for  F1\\\\ score ,  SemEval 2015 Task 12 - Extract aspect-polarity tuple benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.51 - 0.51 == 0.51 Ratio == inf\n",
      "Creating ratio df for  F1\\\\ score ,  BUCC Chinese-to-English - Cross-Lingual Bitext Mining benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "92.27 - 92.27 == 92.27 Ratio == inf\n",
      "Creating ratio df for  F1\\\\ score ,  BUCC Russian-to-English - Cross-Lingual Bitext Mining benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "93.3 - 93.3 == 93.3 Ratio == inf\n",
      "Creating ratio df for  F1\\\\ score ,  Financial PhraseBank - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "84 - 84 == 84 Ratio == inf\n",
      "Creating ratio df for  F1\\\\ score ,  CONLL 2003 German - Low Resource Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "65.24 - 65.24 == 65.24 Ratio == inf\n",
      "Creating ratio df for  F1\\\\ score ,  Conll 2003 Spanish - Low Resource Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "75.93 - 75.93 == 75.93 Ratio == inf\n",
      "Creating ratio df for  F1\\\\ score ,  CONLL 2003 Dutch - Low Resource Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "74.61 - 74.61 == 74.61 Ratio == inf\n",
      "Creating ratio df for  F1\\\\ score ,  Q2Q Arabic Benchmark - Question Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.94848 - 0.95924 == 0.94848 Ratio == 88.1487\n",
      "0.95924 - 0.94848 == 0.0108 Ratio == 1.0037\n",
      "number of sota per dataset/metric:  26\n",
      "####### Pearson\\\\ Correlation\n",
      "Creating ratio df for  Pearson\\\\ Correlation ,  SICK - Semantic Similarity Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.8676 - 0.8676 == 0.8676 Ratio == inf\n",
      "Creating ratio df for  Pearson\\\\ Correlation ,  STS Benchmark - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "0.782 - 0.925 == 0.782 Ratio == 5.4685\n",
      "0.832 - 0.782 == 0.05 Ratio == 0.3497\n",
      "0.925 - 0.832 == 0.093 Ratio == 0.6503\n",
      "number of sota per dataset/metric:  4\n",
      "####### Spearman\\\\ Correlation\n",
      "Creating ratio df for  Spearman\\\\ Correlation ,  SICK - Semantic Similarity Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.8083 - 0.8083 == 0.8083 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### MSE\n",
      "Creating ratio df for  MSE ,  SICK - Semantic Similarity Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.2532 - -0.2532 == -0.2532 Ratio == -inf\n",
      "Creating ratio df for  MSE ,  FiQA - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.07 - -0.07 == -0.07 Ratio == -inf\n",
      "number of sota per dataset/metric:  2\n",
      "####### P\\\\-at\\\\-1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  SemEvalCQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "0.753 - 0.809 == 0.753 Ratio == 13.4464\n",
      "0.755 - 0.753 == 0.002 Ratio == 0.0357\n",
      "0.809 - 0.755 == 0.054 Ratio == 0.9643\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  YahooCQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "0.56 - 0.683 == 0.56 Ratio == 4.5528\n",
      "0.568 - 0.56 == 0.008 Ratio == 0.065\n",
      "0.683 - 0.568 == 0.115 Ratio == 0.935\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  AI2 Kaggle Dataset - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "50.54 - 54.0 == 50.54 Ratio == 14.6069\n",
      "50.7 - 50.54 == 0.16 Ratio == 0.0462\n",
      "54.0 - 50.7 == 3.3 Ratio == 0.9538\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  en-fr - Word Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "82.3 - 82.3 == 82.3 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  fr-en - Word Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "82.1 - 82.1 == 82.1 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  en-es - Word Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "81.7 - 81.7 == 81.7 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  es-en - Word Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "83.3 - 83.3 == 83.3 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "93.2 - 93.2 == 93.2 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "84.48 - 84.48 == 84.48 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "54.38 - 54.38 == 54.38 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "84.18 - 84.18 == 84.18 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "74.95 - 80.2 == 74.95 Ratio == 14.2762\n",
      "80.2 - 74.95 == 5.25 Ratio == 1.0\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "94.87 - 94.87 == 94.87 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "97.05 - 97.05 == 97.05 Ratio == inf\n",
      "number of sota per dataset/metric:  21\n",
      "####### Mean\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Mean\\\\ Error\\\\ Rate ,  bAbi - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "7.5 - 28.7 == 7.5 Ratio == 0.3538\n",
      "28.7 - 7.5 == 21.2 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(trained\\\\ on\\\\ 10k\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(trained\\\\ on\\\\ 10k\\\\) ,  bAbi - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "93.4 - 99.7 == 93.4 Ratio == 14.8254\n",
      "99.7 - 93.4 == 6.3 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(trained\\\\ on\\\\ 1k\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(trained\\\\ on\\\\ 1k\\\\) ,  bAbi - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "86.1 - 90.1 == 86.1 Ratio == 21.525\n",
      "90.1 - 86.1 == 4.0 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Error\n",
      "Creating ratio df for  Error ,  TREC-6 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "4.0 - 9.6 == 4.0 Ratio == 0.7143\n",
      "5.4 - 4.0 == 1.4 Ratio == 0.25\n",
      "7.0 - 5.4 == 1.6 Ratio == 0.2857\n",
      "7.2 - 7.0 == 0.2 Ratio == 0.0357\n",
      "9.6 - 7.2 == 2.4 Ratio == 0.4286\n",
      "Creating ratio df for  Error ,  AG News - Text Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "9.51 - 14.0 == 9.51 Ratio == 2.118\n",
      "14.0 - 9.51 == 4.49 Ratio == 1.0\n",
      "Creating ratio df for  Error ,  Yelp Binary classification - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "4.88 - 4.88 == 4.88 Ratio == inf\n",
      "Creating ratio df for  Error ,  Yelp Fine-grained classification - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "37.95 - 46.8 == 37.95 Ratio == 4.2881\n",
      "46.8 - 37.95 == 8.85 Ratio == 1.0\n",
      "Creating ratio df for  Error ,  DBpedia - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "1.55 - 1.55 == 1.55 Ratio == inf\n",
      "Creating ratio df for  Error ,  TREC-50 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "2.8 - 2.8 == 2.8 Ratio == inf\n",
      "Creating ratio df for  Error ,  Amazon-2 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "2.11 - 3.9 == 2.11 Ratio == 1.1788\n",
      "3.9 - 2.11 == 1.79 Ratio == 1.0\n",
      "Creating ratio df for  Error ,  Amazon-5 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "31.67 - 35.9 == 31.67 Ratio == 7.487\n",
      "35.9 - 31.67 == 4.23 Ratio == 1.0\n",
      "number of sota per dataset/metric:  16\n",
      "####### Percentage\\\\ correct\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 2.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 1.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) abstract 1.0 multiple choice - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) abstract images 1.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 1.0 multiple choice - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual7W - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "62.2 - 72.53 == 62.2 Ratio == 6.0213\n",
      "72.53 - 62.2 == 10.33 Ratio == 1.0\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual Genome (subjects) - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual Genome (pairs) - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  2\n",
      "####### Average\n",
      "Creating ratio df for  Average ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-76.26 - -76.26 == -76.26 Ratio == -inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### DVD\n",
      "Creating ratio df for  DVD ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "75.4 - 81.0 == 75.4 Ratio == 13.4643\n",
      "76.57 - 75.4 == 1.17 Ratio == 0.2089\n",
      "78.14 - 76.57 == 1.57 Ratio == 0.2804\n",
      "81.0 - 78.14 == 2.86 Ratio == 0.5107\n",
      "number of sota per dataset/metric:  4\n",
      "####### Books\n",
      "Creating ratio df for  Books ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "71.43 - 81.4 == 71.43 Ratio == 7.1645\n",
      "73.4 - 71.43 == 1.97 Ratio == 0.1976\n",
      "74.86 - 73.4 == 1.46 Ratio == 0.1464\n",
      "81.4 - 74.86 == 6.54 Ratio == 0.656\n",
      "number of sota per dataset/metric:  4\n",
      "####### Electronics\n",
      "Creating ratio df for  Electronics ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "77.67 - 81.45 == 77.67 Ratio == 20.5476\n",
      "80.53 - 77.67 == 2.86 Ratio == 0.7566\n",
      "81.45 - 80.53 == 0.92 Ratio == 0.2434\n",
      "number of sota per dataset/metric:  3\n",
      "####### Kitchen\n",
      "Creating ratio df for  Kitchen ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "80.53 - 85.9 == 80.53 Ratio == 14.9963\n",
      "82.93 - 80.53 == 2.4 Ratio == 0.4469\n",
      "83.97 - 82.93 == 1.04 Ratio == 0.1937\n",
      "85.9 - 83.97 == 1.93 Ratio == 0.3594\n",
      "number of sota per dataset/metric:  4\n",
      "####### CNN\n",
      "Creating ratio df for  CNN ,  CNN / Daily Mail - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "63.8 - 78.6 == 63.8 Ratio == 4.3108\n",
      "69.4 - 63.8 == 5.6 Ratio == 0.3784\n",
      "75.4 - 69.4 == 6.0 Ratio == 0.4054\n",
      "77.9 - 75.4 == 2.5 Ratio == 0.1689\n",
      "78.6 - 77.9 == 0.7 Ratio == 0.0473\n",
      "number of sota per dataset/metric:  5\n",
      "####### Daily\\\\ Mail\n",
      "Creating ratio df for  Daily\\\\ Mail ,  CNN / Daily Mail - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "68.0 - 80.9 == 68.0 Ratio == 5.2713\n",
      "69.0 - 68.0 == 1.0 Ratio == 0.0775\n",
      "77.7 - 69.0 == 8.7 Ratio == 0.6744\n",
      "80.9 - 77.7 == 3.2 Ratio == 0.2481\n",
      "number of sota per dataset/metric:  4\n",
      "####### LAS\n",
      "Creating ratio df for  LAS ,  Penn Treebank - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "92.06 - 95.75 == 92.06 Ratio == 24.9485\n",
      "92.79 - 92.06 == 0.73 Ratio == 0.1978\n",
      "94.22 - 92.79 == 1.43 Ratio == 0.3875\n",
      "95.75 - 94.22 == 1.53 Ratio == 0.4146\n",
      "Creating ratio df for  LAS ,  CoNLL-2009 - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "85.38 - 85.38 == 85.38 Ratio == inf\n",
      "number of sota per dataset/metric:  5\n",
      "####### UAS\n",
      "Creating ratio df for  UAS ,  Penn Treebank - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "94.01 - 97.29 == 94.01 Ratio == 28.6616\n",
      "94.61 - 94.01 == 0.6 Ratio == 0.1829\n",
      "95.87 - 94.61 == 1.26 Ratio == 0.3841\n",
      "97.29 - 95.87 == 1.42 Ratio == 0.4329\n",
      "Creating ratio df for  UAS ,  CoNLL-2009 - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "88.9 - 88.9 == 88.9 Ratio == inf\n",
      "Creating ratio df for  UAS ,  WSJ10 - Dependency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "75.6 - 75.6 == 75.6 Ratio == inf\n",
      "number of sota per dataset/metric:  6\n",
      "####### POS\n",
      "Creating ratio df for  POS ,  Penn Treebank - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "97.3 - 97.97 == 97.3 Ratio == 145.2239\n",
      "97.44 - 97.3 == 0.14 Ratio == 0.209\n",
      "97.97 - 97.44 == 0.53 Ratio == 0.791\n",
      "number of sota per dataset/metric:  3\n",
      "####### R10\\\\-at\\\\-1\n",
      "Creating ratio df for  R10\\\\-at\\\\-1 ,  Ubuntu Dialogue (v1, Ranking) - Conversational Response Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### R10\\\\-at\\\\-2\n",
      "Creating ratio df for  R10\\\\-at\\\\-2 ,  Ubuntu Dialogue (v1, Ranking) - Conversational Response Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### R10\\\\-at\\\\-5\n",
      "Creating ratio df for  R10\\\\-at\\\\-5 ,  Ubuntu Dialogue (v1, Ranking) - Conversational Response Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### R2\\\\-at\\\\-1\n",
      "Creating ratio df for  R2\\\\-at\\\\-1 ,  Ubuntu Dialogue (v1, Ranking) - Conversational Response Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### %\\\\ Train\\\\ Accuracy\n",
      "Creating ratio df for  %\\\\ Train\\\\ Accuracy ,  SNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "99.7 - 99.7 == 99.7 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Parameters\n",
      "Creating ratio df for  Parameters ,  SNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "220000 - 339000000 == 220000 Ratio == 0.0006\n",
      "250000 - 220000 == 30000 Ratio == 0.0001\n",
      "15000000 - 250000 == 14750000 Ratio == 0.0435\n",
      "40000000 - 15000000 == 25000000 Ratio == 0.0738\n",
      "43000000 - 40000000 == 3000000 Ratio == 0.0089\n",
      "45000000 - 43000000 == 2000000 Ratio == 0.0059\n",
      "53300000 - 45000000 == 8300000 Ratio == 0.0245\n",
      "85000000 - 53300000 == 31700000 Ratio == 0.0936\n",
      "308000000 - 85000000 == 223000000 Ratio == 0.6582\n",
      "330000000 - 308000000 == 22000000 Ratio == 0.0649\n",
      "339000000 - 330000000 == 9000000 Ratio == 0.0266\n",
      "number of sota per dataset/metric:  11\n",
      "####### P\\\\-at\\\\-10%\n",
      "Creating ratio df for  P\\\\-at\\\\-10% ,  New York Times Corpus - Relationship extraction using distant supervision benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "61.3 - 70.9 == 61.3 Ratio == 6.3854\n",
      "70.9 - 61.3 == 9.6 Ratio == 1.0\n",
      "Creating ratio df for  P\\\\-at\\\\-10% ,  NYT Corpus - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "69.4 - 73.6 == 69.4 Ratio == 16.5238\n",
      "73.6 - 69.4 == 4.2 Ratio == 1.0\n",
      "number of sota per dataset/metric:  4\n",
      "####### P\\\\-at\\\\-30%\n",
      "Creating ratio df for  P\\\\-at\\\\-30% ,  New York Times Corpus - Relationship extraction using distant supervision benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "46.5 - 52.4 == 46.5 Ratio == 7.8814\n",
      "52.4 - 46.5 == 5.9 Ratio == 1.0\n",
      "Creating ratio df for  P\\\\-at\\\\-30% ,  NYT Corpus - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "51.8 - 59.5 == 51.8 Ratio == 6.7273\n",
      "59.5 - 51.8 == 7.7 Ratio == 1.0\n",
      "number of sota per dataset/metric:  4\n",
      "####### CR\n",
      "Creating ratio df for  CR ,  Google Dataset - Sentence Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.38 - 0.43 == 0.38 Ratio == 7.6\n",
      "0.43 - 0.38 == 0.05 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### ROUGE\\\\-1\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  DUC 2004 Task 1 - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "26.55 - 26.55 == 26.55 Ratio == inf\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  GigaWord - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "30.88 - 38.9 == 30.88 Ratio == 3.8504\n",
      "31.0 - 30.88 == 0.12 Ratio == 0.015\n",
      "36.4 - 31.0 == 5.4 Ratio == 0.6733\n",
      "37.57 - 36.4 == 1.17 Ratio == 0.1459\n",
      "38.73 - 37.57 == 1.16 Ratio == 0.1446\n",
      "38.9 - 38.73 == 0.17 Ratio == 0.0212\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  DUC 2004 Task 1 - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "28.18 - 32.85 == 28.18 Ratio == 6.0343\n",
      "28.61 - 28.18 == 0.43 Ratio == 0.0921\n",
      "28.97 - 28.61 == 0.36 Ratio == 0.0771\n",
      "29.33 - 28.97 == 0.36 Ratio == 0.0771\n",
      "32.85 - 29.33 == 3.52 Ratio == 0.7537\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  CNN / Daily Mail (Anonymized) - Text Summarization benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  CNN / Daily Mail - Abstractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "40.42 - 44.16 == 40.42 Ratio == 10.8075\n",
      "41.22 - 40.42 == 0.8 Ratio == 0.2139\n",
      "43.08 - 41.22 == 1.86 Ratio == 0.4973\n",
      "44.16 - 43.08 == 1.08 Ratio == 0.2888\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  CNN / Daily Mail - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "40.34 - 43.25 == 40.34 Ratio == 13.8625\n",
      "43.25 - 40.34 == 2.91 Ratio == 1.0\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  arXiv - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "32.06 - 32.06 == 32.06 Ratio == inf\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  Pubmed - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "35.86 - 35.86 == 35.86 Ratio == inf\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  Debatepedia - Query-Based Extractive Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "41.26 - 53.09 == 41.26 Ratio == 3.4877\n",
      "53.09 - 41.26 == 11.83 Ratio == 1.0\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  CNN / Daily Mail - Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "38.3 - 43.85 == 38.3 Ratio == 6.9009\n",
      "39.87 - 38.3 == 1.57 Ratio == 0.2829\n",
      "41.22 - 39.87 == 1.35 Ratio == 0.2432\n",
      "43.25 - 41.22 == 2.03 Ratio == 0.3658\n",
      "43.85 - 43.25 == 0.6 Ratio == 0.1081\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  Multi-News - Multi-Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "43.57 - 43.57 == 43.57 Ratio == inf\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  RASG - Reader-Aware Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "30.33 - 30.33 == 30.33 Ratio == inf\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  MTS - Timeline Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "39.78 - 39.78 == 39.78 Ratio == inf\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  X-Sum - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "38.81 - 45.14 == 38.81 Ratio == 6.1311\n",
      "45.14 - 38.81 == 6.33 Ratio == 1.0\n",
      "number of sota per dataset/metric:  32\n",
      "####### ROUGE\\\\-2\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  DUC 2004 Task 1 - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "7.06 - 7.06 == 7.06 Ratio == inf\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  DUC 2004 Task 1 - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "8.49 - 11.78 == 8.49 Ratio == 2.5805\n",
      "9.42 - 8.49 == 0.93 Ratio == 0.2827\n",
      "10.24 - 9.42 == 0.82 Ratio == 0.2492\n",
      "11.78 - 10.24 == 1.54 Ratio == 0.4681\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  CNN / Daily Mail (Anonymized) - Text Summarization benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  CNN / Daily Mail - Abstractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "17.62 - 21.28 == 17.62 Ratio == 4.8142\n",
      "18.68 - 17.62 == 1.06 Ratio == 0.2896\n",
      "20.43 - 18.68 == 1.75 Ratio == 0.4781\n",
      "21.28 - 20.43 == 0.85 Ratio == 0.2322\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  GigaWord - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "17.7 - 20.05 == 17.7 Ratio == 7.5319\n",
      "18.9 - 17.7 == 1.2 Ratio == 0.5106\n",
      "19.03 - 18.9 == 0.13 Ratio == 0.0553\n",
      "19.71 - 19.03 == 0.68 Ratio == 0.2894\n",
      "20.05 - 19.71 == 0.34 Ratio == 0.1447\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  CNN / Daily Mail - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "17.7 - 20.24 == 17.7 Ratio == 6.9685\n",
      "20.24 - 17.7 == 2.54 Ratio == 1.0\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  CNN / Daily Mail - Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "14.81 - 20.43 == 14.81 Ratio == 2.6352\n",
      "15.82 - 14.81 == 1.01 Ratio == 0.1797\n",
      "18.68 - 15.82 == 2.86 Ratio == 0.5089\n",
      "20.24 - 18.68 == 1.56 Ratio == 0.2776\n",
      "20.43 - 20.24 == 0.19 Ratio == 0.0338\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  Multi-News - Multi-Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "14.03 - 14.19 == 14.03 Ratio == 87.6875\n",
      "14.19 - 14.03 == 0.16 Ratio == 1.0\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  X-Sum - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "16.5 - 22.27 == 16.5 Ratio == 2.8596\n",
      "22.27 - 16.5 == 5.77 Ratio == 1.0\n",
      "number of sota per dataset/metric:  25\n",
      "####### ROUGE\\\\-L\n",
      "Creating ratio df for  ROUGE\\\\-L ,  DUC 2004 Task 1 - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "22.05 - 28.52 == 22.05 Ratio == 3.408\n",
      "23.81 - 22.05 == 1.76 Ratio == 0.272\n",
      "25.24 - 23.81 == 1.43 Ratio == 0.221\n",
      "28.52 - 25.24 == 3.28 Ratio == 0.507\n",
      "Creating ratio df for  ROUGE\\\\-L ,  DUC 2004 Task 1 - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "22.05 - 22.05 == 22.05 Ratio == inf\n",
      "Creating ratio df for  ROUGE\\\\-L ,  GigaWord - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "33.71 - 36.0 == 33.71 Ratio == 14.7205\n",
      "34.69 - 33.71 == 0.98 Ratio == 0.4279\n",
      "35.96 - 34.69 == 1.27 Ratio == 0.5546\n",
      "36.0 - 35.96 == 0.04 Ratio == 0.0175\n",
      "Creating ratio df for  ROUGE\\\\-L ,  CNN / Daily Mail (Anonymized) - Text Summarization benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  ROUGE\\\\-L ,  CNN / Daily Mail - Abstractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "36.67 - 40.9 == 36.67 Ratio == 8.669\n",
      "38.34 - 36.67 == 1.67 Ratio == 0.3948\n",
      "40.34 - 38.34 == 2.0 Ratio == 0.4728\n",
      "40.9 - 40.34 == 0.56 Ratio == 0.1324\n",
      "Creating ratio df for  ROUGE\\\\-L ,  CNN / Daily Mail - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "36.57 - 39.63 == 36.57 Ratio == 11.951\n",
      "39.63 - 36.57 == 3.06 Ratio == 1.0\n",
      "Creating ratio df for  ROUGE\\\\-L ,  CNN / Daily Mail - Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "35.49 - 40.34 == 35.49 Ratio == 7.3175\n",
      "36.9 - 35.49 == 1.41 Ratio == 0.2907\n",
      "38.34 - 36.9 == 1.44 Ratio == 0.2969\n",
      "39.63 - 38.34 == 1.29 Ratio == 0.266\n",
      "40.34 - 39.63 == 0.71 Ratio == 0.1464\n",
      "Creating ratio df for  ROUGE\\\\-L ,  E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "66.45 - 70.83 == 66.45 Ratio == 15.1712\n",
      "70.83 - 66.45 == 4.38 Ratio == 1.0\n",
      "Creating ratio df for  ROUGE\\\\-L ,  ACL Title and Abstract Dataset - Paper generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "20.3 - 20.3 == 20.3 Ratio == inf\n",
      "number of sota per dataset/metric:  23\n",
      "####### Restaurant\\\\ \\\\(Acc\\\\)\n",
      "Creating ratio df for  Restaurant\\\\ \\\\(Acc\\\\) ,  SemEval 2014 Task 4 Sub Task 2 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "75.63 - 90.18 == 75.63 Ratio == 5.1979\n",
      "80.95 - 75.63 == 5.32 Ratio == 0.3656\n",
      "81.34 - 80.95 == 0.39 Ratio == 0.0268\n",
      "81.6 - 81.34 == 0.26 Ratio == 0.0179\n",
      "82.23 - 81.6 == 0.63 Ratio == 0.0433\n",
      "84.46 - 82.23 == 2.23 Ratio == 0.1533\n",
      "84.95 - 84.46 == 0.49 Ratio == 0.0337\n",
      "87.89 - 84.95 == 2.94 Ratio == 0.2021\n",
      "90.18 - 87.89 == 2.29 Ratio == 0.1574\n",
      "Creating ratio df for  Restaurant\\\\ \\\\(Acc\\\\) ,  SemEval-2016 Task 5 Subtask 1 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "88 - 88 == 88 Ratio == inf\n",
      "Creating ratio df for  Restaurant\\\\ \\\\(Acc\\\\) ,  SemEval 2015 Task 12 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "80.6 - 81.7 == 80.6 Ratio == 73.2727\n",
      "81.7 - 80.6 == 1.1 Ratio == 1.0\n",
      "number of sota per dataset/metric:  12\n",
      "####### Laptop\\\\ \\\\(Acc\\\\)\n",
      "Creating ratio df for  Laptop\\\\ \\\\(Acc\\\\) ,  SemEval 2014 Task 4 Sub Task 2 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "68.13 - 82.29 == 68.13 Ratio == 4.8114\n",
      "72.21 - 68.13 == 4.08 Ratio == 0.2881\n",
      "74.49 - 72.21 == 2.28 Ratio == 0.161\n",
      "75.24 - 74.49 == 0.75 Ratio == 0.053\n",
      "76.01 - 75.24 == 0.77 Ratio == 0.0544\n",
      "77.27 - 76.01 == 1.26 Ratio == 0.089\n",
      "78.99 - 77.27 == 1.72 Ratio == 0.1215\n",
      "79.93 - 78.99 == 0.94 Ratio == 0.0664\n",
      "81.35 - 79.93 == 1.42 Ratio == 0.1003\n",
      "82.29 - 81.35 == 0.94 Ratio == 0.0664\n",
      "number of sota per dataset/metric:  10\n",
      "####### Mean\\\\ Acc\\\\ \\\\(Restaurant\\\\ \\\\+\\\\ Laptop\\\\)\n",
      "Creating ratio df for  Mean\\\\ Acc\\\\ \\\\(Restaurant\\\\ \\\\+\\\\ Laptop\\\\) ,  SemEval 2014 Task 4 Sub Task 2 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "71.88 - 86.24 == 71.88 Ratio == 5.0056\n",
      "76.58 - 71.88 == 4.7 Ratio == 0.3273\n",
      "77.36 - 76.58 == 0.78 Ratio == 0.0543\n",
      "78.29 - 77.36 == 0.93 Ratio == 0.0648\n",
      "78.35 - 78.29 == 0.06 Ratio == 0.0042\n",
      "78.4 - 78.35 == 0.05 Ratio == 0.0035\n",
      "79.75 - 78.4 == 1.35 Ratio == 0.094\n",
      "81.73 - 79.75 == 1.98 Ratio == 0.1379\n",
      "82.46 - 81.73 == 0.73 Ratio == 0.0508\n",
      "84.06 - 82.46 == 1.6 Ratio == 0.1114\n",
      "86.24 - 84.06 == 2.18 Ratio == 0.1518\n",
      "number of sota per dataset/metric:  11\n",
      "####### BLEU\n",
      "Creating ratio df for  BLEU ,  IWSLT2015 English-Vietnamese - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-26.4 - -26.4 == -26.4 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WikiBio - Table-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-34.7 - -34.7 == -34.7 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  RotoWire (Content Ordering) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  BLEU ,  RotoWire - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-14.19 - -14.19 == -14.19 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT 2017 Latvian-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-20.8 - -14.83 == -20.8 Ratio == -3.4841\n",
      "-14.83 - -20.8 == 5.97 Ratio == 1.0\n",
      "Creating ratio df for  BLEU ,  E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-64.22 - -56.57 == -64.22 Ratio == -8.3948\n",
      "-56.57 - -64.22 == 7.65 Ratio == 1.0\n",
      "Creating ratio df for  BLEU ,  WMT2016 German-English - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-25.2 - -25.2 == -25.2 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT2014 English-French - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-27.6 - -27.6 == -27.6 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT2016 English-German - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-20.2 - -20.0 == -20.2 Ratio == -101.0\n",
      "-20.0 - -20.2 == 0.2 Ratio == 1.0\n",
      "Creating ratio df for  BLEU ,  WMT2014 French-English - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-27.7 - -25.9 == -27.7 Ratio == -15.3889\n",
      "-25.9 - -27.7 == 1.8 Ratio == 1.0\n",
      "Creating ratio df for  BLEU ,  ACCURAT balanced test corpus for under resourced languages Russian-Estonian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-18.03 - -18.03 == -18.03 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  ACCURAT balanced test corpus for under resourced languages Estonian-Russian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-19.18 - -19.18 == -19.18 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  LDC2016E25 - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-22 - -22 == -22 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  LDC2015E86: - Graph-to-Sequence benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-33.6 - -23.95 == -33.6 Ratio == -3.4819\n",
      "-23.95 - -33.6 == 9.65 Ratio == 1.0\n",
      "Creating ratio df for  BLEU ,  Wikipedia Person and Animal Dataset - Table-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-23.2 - -23.2 == -23.2 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  Wikipedia Person and Animal Dataset - KB-to-Language Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-23.2 - -23.2 == -23.2 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT 2018 English-Estonian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-24.1 - -24.1 == -24.1 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT 2018 Estonian-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-29 - -29 == -29 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  CoNaLa - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-24.3 - -24.3 == -24.3 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  CoNaLa-Ext - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-18.85 - -18.85 == -18.85 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT 2018 Finnish-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-24.0 - -24.0 == -24.0 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT 2018 English-Finnish - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-17.4 - -17.4 == -17.4 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT 2017 English-Latvian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-22.89 - -22.89 == -22.89 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WebNLG - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-0.559 - -0.465 == -0.559 Ratio == -5.9468\n",
      "-0.465 - -0.559 == 0.094 Ratio == 1.0\n",
      "Creating ratio df for  BLEU ,  SR11Deep - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.666 - -0.666 == -0.666 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT2014 German-English - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-20.4 - -20.4 == -20.4 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT2014 English-German - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-17.0 - -17.0 == -17.0 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT2016 Romanian-English - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-31.8 - -31.8 == -31.8 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  JD Product Question Answer - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-2.0189 - -2.0189 == -2.0189 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT2016 Finnish-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-32.4 - -32.4 == -32.4 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT2019 Finnish-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-34.1 - -34.1 == -34.1 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WMT2017 Finnish-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-35.5 - -35.5 == -35.5 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  WebNLG Full - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-51.68 - -51.68 == -51.68 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  ViGGO - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-52.1 - -52.1 == -52.1 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  Cleaned E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-40.73 - -40.73 == -40.73 Ratio == -inf\n",
      "Creating ratio df for  BLEU ,  IWSLT2015 Chinese-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-19.84 - -19.84 == -19.84 Ratio == -inf\n",
      "number of sota per dataset/metric:  41\n",
      "####### Micro\\\\ Precision\n",
      "Creating ratio df for  Micro\\\\ Precision ,  TAC2010 - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "85.2 - 87.7 == 85.2 Ratio == 34.08\n",
      "87.7 - 85.2 == 2.5 Ratio == 1.0\n",
      "Creating ratio df for  Micro\\\\ Precision ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Micro\\\\ Precision ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "number of sota per dataset/metric:  2\n",
      "####### In\\\\-KB\\\\ Accuracy\n",
      "Creating ratio df for  In\\\\-KB\\\\ Accuracy ,  AIDA-CoNLL - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "93.1 - 95.0 == 93.1 Ratio == 49.0\n",
      "94.7 - 93.1 == 1.6 Ratio == 0.8421\n",
      "95.0 - 94.7 == 0.3 Ratio == 0.1579\n",
      "number of sota per dataset/metric:  3\n",
      "####### Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\)\n",
      "Creating ratio df for  Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\) ,  Text8 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "1.63 - 1.63 == 1.63 Ratio == inf\n",
      "Creating ratio df for  Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\) ,  Hutter Prize - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "1.31 - 1.31 == 1.31 Ratio == inf\n",
      "Creating ratio df for  Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\) ,  enwik8 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "1.27 - 1.34 == 1.27 Ratio == 18.1429\n",
      "1.32 - 1.27 == 0.05 Ratio == 0.7143\n",
      "1.34 - 1.32 == 0.02 Ratio == 0.2857\n",
      "Creating ratio df for  Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\) ,  Penn Treebank (Character Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\-CN\n",
      "Creating ratio df for  Accuracy\\\\-CN ,  Children\\'s Book Test - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "67.5 - 93.3 == 67.5 Ratio == 2.6163\n",
      "68.9 - 67.5 == 1.4 Ratio == 0.0543\n",
      "70.7 - 68.9 == 1.8 Ratio == 0.0698\n",
      "71.9 - 70.7 == 1.2 Ratio == 0.0465\n",
      "93.3 - 71.9 == 21.4 Ratio == 0.8295\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\-NE\n",
      "Creating ratio df for  Accuracy\\\\-NE ,  Children\\'s Book Test - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "71.0 - 89.05 == 71.0 Ratio == 3.9335\n",
      "74.9 - 71.0 == 3.9 Ratio == 0.2161\n",
      "89.05 - 74.9 == 14.15 Ratio == 0.7839\n",
      "number of sota per dataset/metric:  3\n",
      "####### Unigram\\\\ Acc\n",
      "Creating ratio df for  Unigram\\\\ Acc ,  SearchQA - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "41.3 - 62.2 == 41.3 Ratio == 1.9761\n",
      "46.8 - 41.3 == 5.5 Ratio == 0.2632\n",
      "49.4 - 46.8 == 2.6 Ratio == 0.1244\n",
      "62.2 - 49.4 == 12.8 Ratio == 0.6124\n",
      "number of sota per dataset/metric:  4\n",
      "####### N\\\\-gram\\\\ F1\n",
      "Creating ratio df for  N\\\\-gram\\\\ F1 ,  SearchQA - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "22.8 - 70.8 == 22.8 Ratio == 0.475\n",
      "56.6 - 22.8 == 33.8 Ratio == 0.7042\n",
      "59.5 - 56.6 == 2.9 Ratio == 0.0604\n",
      "70.8 - 59.5 == 11.3 Ratio == 0.2354\n",
      "number of sota per dataset/metric:  4\n",
      "####### ROUGE\n",
      "Creating ratio df for  ROUGE ,  WikiBio - Table-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-25.8 - -25.8 == -25.8 Ratio == -inf\n",
      "Creating ratio df for  ROUGE ,  Wikipedia Person and Animal Dataset - Table-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-23.4 - -23.4 == -23.4 Ratio == -inf\n",
      "Creating ratio df for  ROUGE ,  Wikipedia Person and Animal Dataset - KB-to-Language Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-42 - -42 == -42 Ratio == -inf\n",
      "Creating ratio df for  ROUGE ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-49 - -49 == -49 Ratio == -inf\n",
      "number of sota per dataset/metric:  4\n",
      "####### Number\\\\ of\\\\ params\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  Text8 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "16000000 - 1542000000 == 16000000 Ratio == 0.0105\n",
      "46000000 - 16000000 == 30000000 Ratio == 0.0197\n",
      "235000000 - 46000000 == 189000000 Ratio == 0.1239\n",
      "277000000 - 235000000 == 42000000 Ratio == 0.0275\n",
      "1542000000 - 277000000 == 1265000000 Ratio == 0.829\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  enwik8 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "46000000 - 1542000000 == 46000000 Ratio == 0.0307\n",
      "47000000 - 46000000 == 1000000 Ratio == 0.0007\n",
      "235000000 - 47000000 == 188000000 Ratio == 0.1257\n",
      "277000000 - 235000000 == 42000000 Ratio == 0.0281\n",
      "1542000000 - 277000000 == 1265000000 Ratio == 0.8456\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  Hutter Prize - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "46000000 - 277000000 == 46000000 Ratio == 0.1991\n",
      "47000000 - 46000000 == 1000000 Ratio == 0.0043\n",
      "235000000 - 47000000 == 188000000 Ratio == 0.8139\n",
      "277000000 - 235000000 == 42000000 Ratio == 0.1818\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  Penn Treebank (Character Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  WikiText-2 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "24000000 - 1542000000 == 24000000 Ratio == 0.0158\n",
      "33000000 - 24000000 == 9000000 Ratio == 0.0059\n",
      "34000000 - 33000000 == 1000000 Ratio == 0.0007\n",
      "35000000 - 34000000 == 1000000 Ratio == 0.0007\n",
      "185000000 - 35000000 == 150000000 Ratio == 0.0988\n",
      "1542000000 - 185000000 == 1357000000 Ratio == 0.8939\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  WikiText-103 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "151000000 - 8300000000 == 151000000 Ratio == 0.0185\n",
      "247000000 - 151000000 == 96000000 Ratio == 0.0118\n",
      "257000000 - 247000000 == 10000000 Ratio == 0.0012\n",
      "355000000 - 257000000 == 98000000 Ratio == 0.012\n",
      "1542000000 - 355000000 == 1187000000 Ratio == 0.1457\n",
      "8300000000 - 1542000000 == 6758000000 Ratio == 0.8293\n",
      "number of sota per dataset/metric:  26\n",
      "####### Avg\\\\ accuracy\n",
      "Creating ratio df for  Avg\\\\ accuracy ,  UD - Part-Of-Speech Tagging benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "96.4 - 96.88 == 96.4 Ratio == 200.8333\n",
      "96.65 - 96.4 == 0.25 Ratio == 0.5208\n",
      "96.88 - 96.65 == 0.23 Ratio == 0.4792\n",
      "number of sota per dataset/metric:  3\n",
      "####### R\\\\-at\\\\-1\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "43.51 - 55.16 == 43.51 Ratio == 3.7348\n",
      "48.53 - 43.51 == 5.02 Ratio == 0.4309\n",
      "50.29 - 48.53 == 1.76 Ratio == 0.1511\n",
      "50.92 - 50.29 == 0.63 Ratio == 0.0541\n",
      "54.76 - 50.92 == 3.84 Ratio == 0.3296\n",
      "55.16 - 54.76 == 0.4 Ratio == 0.0343\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "44.15 - 55.65 == 44.15 Ratio == 3.8391\n",
      "47.55 - 44.15 == 3.4 Ratio == 0.2957\n",
      "49.63 - 47.55 == 2.08 Ratio == 0.1809\n",
      "50.88 - 49.63 == 1.25 Ratio == 0.1087\n",
      "55.65 - 50.88 == 4.77 Ratio == 0.4148\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "69.69 - 71.33 == 69.69 Ratio == 42.4939\n",
      "71.33 - 69.69 == 1.64 Ratio == 1.0\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Advising Corpus - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "31 - 31 == 31 Ratio == inf\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Flickr30k Entities Dev - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "70.4 - 70.4 == 70.4 Ratio == inf\n",
      "number of sota per dataset/metric:  15\n",
      "####### R\\\\-at\\\\-10\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "83.96 - 92.95 == 83.96 Ratio == 9.3393\n",
      "87.43 - 83.96 == 3.47 Ratio == 0.386\n",
      "88.81 - 87.43 == 1.38 Ratio == 0.1535\n",
      "90.68 - 88.81 == 1.87 Ratio == 0.208\n",
      "92.95 - 90.68 == 2.27 Ratio == 0.2525\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "86.88 - 94.05 == 86.88 Ratio == 12.1172\n",
      "88.8 - 86.88 == 1.92 Ratio == 0.2678\n",
      "89.35 - 88.8 == 0.55 Ratio == 0.0767\n",
      "89.45 - 89.35 == 0.1 Ratio == 0.0139\n",
      "94.05 - 89.45 == 4.6 Ratio == 0.6416\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "86.35 - 86.51 == 86.35 Ratio == 539.6875\n",
      "86.51 - 86.35 == 0.16 Ratio == 1.0\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Advising Corpus - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "78.8 - 78.8 == 78.8 Ratio == inf\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Flickr30k Entities Dev - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "86.31 - 86.31 == 86.31 Ratio == inf\n",
      "number of sota per dataset/metric:  14\n",
      "####### R\\\\-at\\\\-5\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "74.49 - 86.26 == 74.49 Ratio == 6.3288\n",
      "78.66 - 74.49 == 4.17 Ratio == 0.3543\n",
      "80.71 - 78.66 == 2.05 Ratio == 0.1742\n",
      "83.03 - 80.71 == 2.32 Ratio == 0.1971\n",
      "86.26 - 83.03 == 3.23 Ratio == 0.2744\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 5\n",
      "76.88 - 86.73 == 76.88 Ratio == 7.8051\n",
      "78.1 - 76.88 == 1.22 Ratio == 0.1239\n",
      "79.75 - 78.1 == 1.65 Ratio == 0.1675\n",
      "80.63 - 79.75 == 0.88 Ratio == 0.0893\n",
      "86.73 - 80.63 == 6.1 Ratio == 0.6193\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "84.22 - 84.98 == 84.22 Ratio == 110.8158\n",
      "84.98 - 84.22 == 0.76 Ratio == 1.0\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Flickr30k Entities Dev - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "84.49 - 84.49 == 84.49 Ratio == inf\n",
      "number of sota per dataset/metric:  13\n",
      "####### Mean\\\\ Rank\n",
      "Creating ratio df for  Mean\\\\ Rank ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "5.84 - 5.84 == 5.84 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Precision\n",
      "Creating ratio df for  Precision ,  Ubuntu Dialogue (Activity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  Ubuntu Dialogue (Entity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  Twitter Dialogue (Noun) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  Rotowire (Content Selection) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  RotoWire (Relation Generation) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  Ontonotes v5 (English) - Entity Typing benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  CoNLL-2014 Shared Task - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-71.57 - -71.57 == -71.57 Ratio == -inf\n",
      "Creating ratio df for  Precision ,  FewRel - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-88.49 - -88.49 == -88.49 Ratio == -inf\n",
      "Creating ratio df for  Precision ,  Open Entity - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-78.42 - -78.42 == -78.42 Ratio == -inf\n",
      "Creating ratio df for  Precision ,  20NEWS - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-86.2 - -86.2 == -86.2 Ratio == -inf\n",
      "Creating ratio df for  Precision ,  SoSciSoCi - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.83 - -0.83 == -0.83 Ratio == -inf\n",
      "number of sota per dataset/metric:  5\n",
      "####### Recall\n",
      "Creating ratio df for  Recall ,  Ubuntu Dialogue (Activity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  Twitter Dialogue (Noun) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  Ubuntu Dialogue (Entity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  Rotowire (Content Selection) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  Ontonotes v5 (English) - Entity Typing benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  CoNLL-2014 Shared Task - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-38.65 - -38.65 == -38.65 Ratio == -inf\n",
      "Creating ratio df for  Recall ,  FewRel - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-88.44 - -88.44 == -88.44 Ratio == -inf\n",
      "Creating ratio df for  Recall ,  Open Entity - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-72.9 - -72.9 == -72.9 Ratio == -inf\n",
      "Creating ratio df for  Recall ,  20NEWS - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-86.18 - -86.18 == -86.18 Ratio == -inf\n",
      "Creating ratio df for  Recall ,  SoSciSoCi - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.82 - -0.82 == -0.82 Ratio == -inf\n",
      "number of sota per dataset/metric:  5\n",
      "####### EM\\\\ \\\\(Quasar\\\\-T\\\\)\n",
      "Creating ratio df for  EM\\\\ \\\\(Quasar\\\\-T\\\\) ,  Quasar - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "26.4 - 42.3 == 26.4 Ratio == 1.6604\n",
      "42.3 - 26.4 == 15.9 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### F1\\\\ \\\\(Quasar\\\\-T\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(Quasar\\\\-T\\\\) ,  Quasar - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "26.4 - 49.6 == 26.4 Ratio == 1.1379\n",
      "28.5 - 26.4 == 2.1 Ratio == 0.0905\n",
      "49.6 - 28.5 == 21.1 Ratio == 0.9095\n",
      "number of sota per dataset/metric:  3\n",
      "####### Joint\n",
      "Creating ratio df for  Joint ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "73.4 - 75.5 == 73.4 Ratio == 34.9524\n",
      "74.5 - 73.4 == 1.1 Ratio == 0.5238\n",
      "75.5 - 74.5 == 1.0 Ratio == 0.4762\n",
      "Creating ratio df for  Joint ,  Wizard-of-Oz - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "84.4 - 88.9 == 84.4 Ratio == 18.7556\n",
      "88.1 - 84.4 == 3.7 Ratio == 0.8222\n",
      "88.9 - 88.1 == 0.8 Ratio == 0.1778\n",
      "number of sota per dataset/metric:  6\n",
      "####### Area\n",
      "Creating ratio df for  Area ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "90 - 90 == 90 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Food\n",
      "Creating ratio df for  Food ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "84 - 84 == 84 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Price\n",
      "Creating ratio df for  Price ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "94 - 94 == 94 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Request\n",
      "Creating ratio df for  Request ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "96.5 - 97.5 == 96.5 Ratio == 96.5\n",
      "97.5 - 96.5 == 1.0 Ratio == 1.0\n",
      "Creating ratio df for  Request ,  Wizard-of-Oz - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "96.5 - 97.1 == 96.5 Ratio == 160.8333\n",
      "97.1 - 96.5 == 0.6 Ratio == 1.0\n",
      "number of sota per dataset/metric:  4\n",
      "####### Params\n",
      "Creating ratio df for  Params ,  Penn Treebank (Word Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "####### F0\\\\.5\n",
      "Creating ratio df for  F0\\\\.5 ,  CoNLL-2014 A1 - Grammatical Error Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "34.3 - 36.1 == 34.3 Ratio == 19.0556\n",
      "36.1 - 34.3 == 1.8 Ratio == 1.0\n",
      "Creating ratio df for  F0\\\\.5 ,  FCE - Grammatical Error Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "41.1 - 52.07 == 41.1 Ratio == 3.7466\n",
      "41.88 - 41.1 == 0.78 Ratio == 0.0711\n",
      "48.48 - 41.88 == 6.6 Ratio == 0.6016\n",
      "49.11 - 48.48 == 0.63 Ratio == 0.0574\n",
      "52.07 - 49.11 == 2.96 Ratio == 0.2698\n",
      "Creating ratio df for  F0\\\\.5 ,  CoNLL-2014 A2 - Grammatical Error Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "23.9 - 45.1 == 23.9 Ratio == 1.1274\n",
      "44.0 - 23.9 == 20.1 Ratio == 0.9481\n",
      "45.1 - 44.0 == 1.1 Ratio == 0.0519\n",
      "Creating ratio df for  F0\\\\.5 ,  CoNLL-2014 Shared Task - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "54.79 - 61.15 == 54.79 Ratio == 8.6148\n",
      "61.15 - 54.79 == 6.36 Ratio == 1.0\n",
      "Creating ratio df for  F0\\\\.5 ,  CoNLL-2014 Shared Task (10 annotations) - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F0\\\\.5 ,  Unrestricted - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "61.34 - 61.34 == 61.34 Ratio == inf\n",
      "Creating ratio df for  F0\\\\.5 ,  Restricted - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "56.52 - 56.52 == 56.52 Ratio == inf\n",
      "Creating ratio df for  F0\\\\.5 ,  JFLEG - Grammatical Error Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "52.52 - 52.52 == 52.52 Ratio == inf\n",
      "number of sota per dataset/metric:  15\n",
      "####### F1\\\\ Newswire\n",
      "Creating ratio df for  F1\\\\ Newswire ,  LDC2014T12: - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "0.7 - 0.75 == 0.7 Ratio == 14.0\n",
      "0.71 - 0.7 == 0.01 Ratio == 0.2\n",
      "0.73 - 0.71 == 0.02 Ratio == 0.4\n",
      "0.75 - 0.73 == 0.02 Ratio == 0.4\n",
      "Creating ratio df for  F1\\\\ Newswire ,  LDC2014T12 - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "70.0 - 73.3 == 70.0 Ratio == 21.2121\n",
      "71.0 - 70.0 == 1.0 Ratio == 0.303\n",
      "73.3 - 71.0 == 2.3 Ratio == 0.697\n",
      "number of sota per dataset/metric:  7\n",
      "####### EM\n",
      "Creating ratio df for  EM ,  SQuAD1.1 dev - Question Answering benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "-64.1 - -59.95 == -64.1 Ratio == -15.4458\n",
      "-62.5 - -64.1 == 1.6 Ratio == 0.3855\n",
      "-59.95 - -62.5 == 2.55 Ratio == 0.6145\n",
      "Creating ratio df for  EM ,  SQuAD1.1 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-54.505 - -54.505 == -54.505 Ratio == -inf\n",
      "Creating ratio df for  EM ,  SQuAD1.1 - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-66.2 - -65.5 == -66.2 Ratio == -94.5714\n",
      "-65.5 - -66.2 == 0.7 Ratio == 1.0\n",
      "Creating ratio df for  EM ,  NewsQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-43.7 - -43.7 == -43.7 Ratio == -inf\n",
      "Creating ratio df for  EM ,  Quasart-T - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-37.7 - -37.7 == -37.7 Ratio == -inf\n",
      "Creating ratio df for  EM ,  SearchQA - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-41.9 - -41.9 == -41.9 Ratio == -inf\n",
      "Creating ratio df for  EM ,  TriviaQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-46.94 - -43.16 == -46.94 Ratio == -12.418\n",
      "-43.16 - -46.94 == 3.78 Ratio == 1.0\n",
      "Creating ratio df for  EM ,  SQuAD2.0 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-70.3 - -63.372 == -70.3 Ratio == -10.1472\n",
      "-68.653 - -70.3 == 1.647 Ratio == 0.2377\n",
      "-63.372 - -68.653 == 5.281 Ratio == 0.7623\n",
      "Creating ratio df for  EM ,  SQuAD2.0 dev - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-72.3 - -70.3 == -72.3 Ratio == -36.15\n",
      "-70.3 - -72.3 == 2.0 Ratio == 1.0\n",
      "Creating ratio df for  EM ,  ReCoRD - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-54.04 - -54.04 == -54.04 Ratio == -inf\n",
      "Creating ratio df for  EM ,  DuReader - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-61.3 - -61.3 == -61.3 Ratio == -inf\n",
      "number of sota per dataset/metric:  18\n",
      "####### BLEU\\\\-4\n",
      "Creating ratio df for  BLEU\\\\-4 ,  EMNLP2017 WMT - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.4541 - 0.627 == 0.4541 Ratio == 2.6264\n",
      "0.627 - 0.4541 == 0.1729 Ratio == 1.0\n",
      "Creating ratio df for  BLEU\\\\-4 ,  COCO Captions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "0.521 - 0.778 == 0.521 Ratio == 2.0272\n",
      "0.557 - 0.521 == 0.036 Ratio == 0.1401\n",
      "0.778 - 0.557 == 0.221 Ratio == 0.8599\n",
      "Creating ratio df for  BLEU\\\\-4 ,  NarrativeQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "15.69 - 30.43 == 15.69 Ratio == 1.0645\n",
      "21.07 - 15.69 == 5.38 Ratio == 0.365\n",
      "22.49 - 21.07 == 1.42 Ratio == 0.0963\n",
      "27.61 - 22.49 == 5.12 Ratio == 0.3474\n",
      "30.43 - 27.61 == 2.82 Ratio == 0.1913\n",
      "Creating ratio df for  BLEU\\\\-4 ,  SQuAD1.1 - Question Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "13.27 - 22.78 == 13.27 Ratio == 1.3954\n",
      "13.91 - 13.27 == 0.64 Ratio == 0.0673\n",
      "22.78 - 13.91 == 8.87 Ratio == 0.9327\n",
      "Creating ratio df for  BLEU\\\\-4 ,  DailyDialog - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "2.84 - 2.84 == 2.84 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\-4 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "24.9 - 24.9 == 24.9 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\-4 ,  Flickr30k Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "30.1 - 30.1 == 30.1 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\-4 ,  COCO Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "36.5 - 36.5 == 36.5 Ratio == inf\n",
      "number of sota per dataset/metric:  17\n",
      "####### BLEU\\\\-2\n",
      "Creating ratio df for  BLEU\\\\-2 ,  Chinese Poems - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.738 - 0.812 == 0.738 Ratio == 9.973\n",
      "0.812 - 0.738 == 0.074 Ratio == 1.0\n",
      "Creating ratio df for  BLEU\\\\-2 ,  COCO Captions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "0.831 - 0.95 == 0.831 Ratio == 6.9832\n",
      "0.85 - 0.831 == 0.019 Ratio == 0.1597\n",
      "0.91 - 0.85 == 0.06 Ratio == 0.5042\n",
      "0.95 - 0.91 == 0.04 Ratio == 0.3361\n",
      "Creating ratio df for  BLEU\\\\-2 ,  EMNLP2017 WMT - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.859 - 0.956 == 0.859 Ratio == 8.8557\n",
      "0.956 - 0.859 == 0.097 Ratio == 1.0\n",
      "Creating ratio df for  BLEU\\\\-2 ,  DailyDialog - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "5.69 - 5.69 == 5.69 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\-2 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "46.3 - 46.3 == 46.3 Ratio == inf\n",
      "number of sota per dataset/metric:  10\n",
      "####### BLEU\\\\-3\n",
      "Creating ratio df for  BLEU\\\\-3 ,  COCO Captions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "0.642 - 0.88 == 0.642 Ratio == 2.6975\n",
      "0.672 - 0.642 == 0.03 Ratio == 0.1261\n",
      "0.713 - 0.672 == 0.041 Ratio == 0.1723\n",
      "0.88 - 0.713 == 0.167 Ratio == 0.7017\n",
      "Creating ratio df for  BLEU\\\\-3 ,  EMNLP2017 WMT - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.6015 - 0.819 == 0.6015 Ratio == 2.7655\n",
      "0.819 - 0.6015 == 0.2175 Ratio == 1.0\n",
      "Creating ratio df for  BLEU\\\\-3 ,  DailyDialog - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "3.78 - 3.78 == 3.78 Ratio == inf\n",
      "Creating ratio df for  BLEU\\\\-3 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "33.6 - 33.6 == 33.6 Ratio == inf\n",
      "number of sota per dataset/metric:  8\n",
      "####### BLEU\\\\-5\n",
      "Creating ratio df for  BLEU\\\\-5 ,  EMNLP2017 WMT - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "0.4498 - 0.498 == 0.4498 Ratio == 9.332\n",
      "0.463 - 0.4498 == 0.0132 Ratio == 0.2739\n",
      "0.498 - 0.463 == 0.035 Ratio == 0.7261\n",
      "Creating ratio df for  BLEU\\\\-5 ,  COCO Captions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "0.427 - 0.686 == 0.427 Ratio == 1.6486\n",
      "0.544 - 0.427 == 0.117 Ratio == 0.4517\n",
      "0.59 - 0.544 == 0.046 Ratio == 0.1776\n",
      "0.686 - 0.59 == 0.096 Ratio == 0.3707\n",
      "number of sota per dataset/metric:  7\n",
      "####### Inception\\\\ score\n",
      "Creating ratio df for  Inception\\\\ score ,  CUB - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "3.62 - 4.75 == 3.62 Ratio == 3.2035\n",
      "3.7 - 3.62 == 0.08 Ratio == 0.0708\n",
      "3.82 - 3.7 == 0.12 Ratio == 0.1062\n",
      "4.36 - 3.82 == 0.54 Ratio == 0.4779\n",
      "4.56 - 4.36 == 0.2 Ratio == 0.177\n",
      "4.75 - 4.56 == 0.19 Ratio == 0.1681\n",
      "Creating ratio df for  Inception\\\\ score ,  COCO - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "8.45 - 30.49 == 8.45 Ratio == 0.3834\n",
      "25.89 - 8.45 == 17.44 Ratio == 0.7913\n",
      "26.47 - 25.89 == 0.58 Ratio == 0.0263\n",
      "30.49 - 26.47 == 4.02 Ratio == 0.1824\n",
      "Creating ratio df for  Inception\\\\ score ,  Oxford 102 Flowers - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "3.2 - 3.26 == 3.2 Ratio == 53.3333\n",
      "3.26 - 3.2 == 0.06 Ratio == 1.0\n",
      "number of sota per dataset/metric:  12\n",
      "####### FID\n",
      "Creating ratio df for  FID ,  CUB - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-67.22 - -15.3 == -67.22 Ratio == -1.2947\n",
      "-15.3 - -67.22 == 51.92 Ratio == 1.0\n",
      "Creating ratio df for  FID ,  COCO - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-74.05 - -33.35 == -74.05 Ratio == -1.8194\n",
      "-33.35 - -74.05 == 40.7 Ratio == 1.0\n",
      "Creating ratio df for  FID ,  Oxford 102 Flowers - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-48.68 - -48.68 == -48.68 Ratio == -inf\n",
      "Creating ratio df for  FID ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "-125.98 - -116.32 == -125.98 Ratio == -13.0414\n",
      "-116.32 - -125.98 == 9.66 Ratio == 1.0\n",
      "number of sota per dataset/metric:  7\n",
      "####### Aspect\n",
      "Creating ratio df for  Aspect ,  Sentihood - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "69.3 - 87.9 == 69.3 Ratio == 3.7258\n",
      "78.18 - 69.3 == 8.88 Ratio == 0.4774\n",
      "86.4 - 78.18 == 8.22 Ratio == 0.4419\n",
      "87.9 - 86.4 == 1.5 Ratio == 0.0806\n",
      "number of sota per dataset/metric:  4\n",
      "####### Sentiment\n",
      "Creating ratio df for  Sentiment ,  Sentihood - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-81.9 - -81.9 == -81.9 Ratio == -inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### P\\\\-at\\\\-5\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Music domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "12.41 - 41.31 == 12.41 Ratio == 0.4294\n",
      "41.31 - 12.41 == 28.9 Ratio == 1.0\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  General - Hypernym Discovery benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "9.91 - 19.03 == 9.91 Ratio == 1.0866\n",
      "19.03 - 9.91 == 9.12 Ratio == 1.0\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Medical domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "20.71 - 36.77 == 20.71 Ratio == 1.2895\n",
      "21.43 - 20.71 == 0.72 Ratio == 0.0448\n",
      "36.77 - 21.43 == 15.34 Ratio == 0.9552\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "41.19 - 41.19 == 41.19 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "63.16 - 63.16 == 63.16 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "25.88 - 25.88 == 25.88 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "62.87 - 62.87 == 62.87 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "50.71 - 68.7 == 50.71 Ratio == 2.8188\n",
      "68.7 - 50.71 == 17.99 Ratio == 1.0\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "56.33 - 56.33 == 56.33 Ratio == inf\n",
      "number of sota per dataset/metric:  14\n",
      "####### F1\\\\ Full\n",
      "Creating ratio df for  F1\\\\ Full ,  LDC2014T12: - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "0.66 - 0.7 == 0.66 Ratio == 16.5\n",
      "0.68 - 0.66 == 0.02 Ratio == 0.5\n",
      "0.7 - 0.68 == 0.02 Ratio == 0.5\n",
      "Creating ratio df for  F1\\\\ Full ,  LDC2014T12 - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "66.0 - 70.2 == 66.0 Ratio == 15.7143\n",
      "68.4 - 66.0 == 2.4 Ratio == 0.5714\n",
      "70.2 - 68.4 == 1.8 Ratio == 0.4286\n",
      "number of sota per dataset/metric:  6\n",
      "####### Rouge\\\\-L\n",
      "Creating ratio df for  Rouge\\\\-L ,  NarrativeQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "36.74 - 59.87 == 36.74 Ratio == 1.5884\n",
      "44.16 - 36.74 == 7.42 Ratio == 0.3208\n",
      "46.67 - 44.16 == 2.51 Ratio == 0.1085\n",
      "54.74 - 46.67 == 8.07 Ratio == 0.3489\n",
      "59.87 - 54.74 == 5.13 Ratio == 0.2218\n",
      "Creating ratio df for  Rouge\\\\-L ,  MS MARCO - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "23.96 - 52.2 == 23.96 Ratio == 0.8484\n",
      "51.63 - 23.96 == 27.67 Ratio == 0.9798\n",
      "52.01 - 51.63 == 0.38 Ratio == 0.0135\n",
      "52.2 - 52.01 == 0.19 Ratio == 0.0067\n",
      "number of sota per dataset/metric:  9\n",
      "####### overall\n",
      "Creating ratio df for  overall ,  VQA v2 test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "25.98 - 72.5 == 25.98 Ratio == 0.5585\n",
      "62.27 - 25.98 == 36.29 Ratio == 0.7801\n",
      "67.4 - 62.27 == 5.13 Ratio == 0.1103\n",
      "70.34 - 67.4 == 2.94 Ratio == 0.0632\n",
      "70.4 - 70.34 == 0.06 Ratio == 0.0013\n",
      "70.9 - 70.4 == 0.5 Ratio == 0.0107\n",
      "71.0 - 70.9 == 0.1 Ratio == 0.0021\n",
      "72.5 - 71.0 == 1.5 Ratio == 0.0322\n",
      "Creating ratio df for  overall ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "54.72 - 55.4 == 54.72 Ratio == 80.4706\n",
      "55.4 - 54.72 == 0.68 Ratio == 1.0\n",
      "number of sota per dataset/metric:  10\n",
      "####### 1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-2\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-2 ,  Amazon-5 - Dialog Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "5 - 5 == 5 Ratio == inf\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-2 ,  Ubuntu Dialogue (v1, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-2 ,  Ubuntu Dialogue (v2, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  1\n",
      "####### Sequence\\\\ error\n",
      "Creating ratio df for  Sequence\\\\ error ,  FSNS - Test - Optical Character Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "27.54 - 27.54 == 27.54 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Perplexity\n",
      "Creating ratio df for  Perplexity ,  Yahoo Questions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "-63.9 - -59.7 == -63.9 Ratio == -15.2143\n",
      "-60.4 - -63.9 == 3.5 Ratio == 0.8333\n",
      "-59.7 - -60.4 == 0.7 Ratio == 0.1667\n",
      "Creating ratio df for  Perplexity ,  Android Repos - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-2.65 - -2.65 == -2.65 Ratio == -inf\n",
      "number of sota per dataset/metric:  4\n",
      "####### KL\n",
      "Creating ratio df for  KL ,  Yahoo Questions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "10.0 - 10.0 == 10.0 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### NLL\n",
      "Creating ratio df for  NLL ,  Yahoo Questions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "332.1 - 332.1 == 332.1 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Micro\\\\-F1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  WNED-WIKI - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "77.5 - 89.1 == 77.5 Ratio == 6.681\n",
      "89.1 - 77.5 == 11.6 Ratio == 1.0\n",
      "Creating ratio df for  Micro\\\\-F1 ,  MSNBC - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "93.7 - 96.3 == 93.7 Ratio == 36.0385\n",
      "94.1 - 93.7 == 0.4 Ratio == 0.1538\n",
      "96.3 - 94.1 == 2.2 Ratio == 0.8462\n",
      "Creating ratio df for  Micro\\\\-F1 ,  ACE2004 - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "88.5 - 91.9 == 88.5 Ratio == 26.0294\n",
      "91.5 - 88.5 == 3.0 Ratio == 0.8824\n",
      "91.9 - 91.5 == 0.4 Ratio == 0.1176\n",
      "Creating ratio df for  Micro\\\\-F1 ,  WNED-CWEB - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "77.9 - 78.9 == 77.9 Ratio == 77.9\n",
      "78.9 - 77.9 == 1.0 Ratio == 1.0\n",
      "Creating ratio df for  Micro\\\\-F1 ,  MSNBC - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "72.4 - 72.4 == 72.4 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\-F1 ,  OKE-2016 - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "58.4 - 58.4 == 58.4 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\-F1 ,  N3-Reuters-128 - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "54.6 - 54.6 == 54.6 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\-F1 ,  OKE-2015 - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "66.9 - 66.9 == 66.9 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\-F1 ,  Derczynski - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "42.3 - 42.3 == 42.3 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\-F1 ,  EC - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.7709 - 0.7765 == 0.7709 Ratio == 137.6607\n",
      "0.7765 - 0.7709 == 0.0056 Ratio == 1.0\n",
      "Creating ratio df for  Micro\\\\-F1 ,  AQUAINT - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "93.5 - 93.7 == 93.5 Ratio == 467.5\n",
      "93.7 - 93.5 == 0.2 Ratio == 1.0\n",
      "Creating ratio df for  Micro\\\\-F1 ,  DailyDialog - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "53.37 - 53.37 == 53.37 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\-F1 ,  Slashdot - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "56.8 - 56.8 == 56.8 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\-F1 ,  RCV1-v2 - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "88.5 - 88.5 == 88.5 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\-F1 ,  Reuters-21578 - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "89.9 - 89.9 == 89.9 Ratio == inf\n",
      "number of sota per dataset/metric:  23\n",
      "####### NDCG\\\\ \\\\(x\\\\ 100\\\\)\n",
      "Creating ratio df for  NDCG\\\\ \\\\(x\\\\ 100\\\\) ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "58.1 - 58.1 == 58.1 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### MRR\\\\ \\\\(x\\\\ 100\\\\)\n",
      "Creating ratio df for  MRR\\\\ \\\\(x\\\\ 100\\\\) ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "58.8 - 69.3 == 58.8 Ratio == 5.6\n",
      "61.5 - 58.8 == 2.7 Ratio == 0.2571\n",
      "63.2 - 61.5 == 1.7 Ratio == 0.1619\n",
      "64.22 - 63.2 == 1.02 Ratio == 0.0971\n",
      "69.3 - 64.22 == 5.08 Ratio == 0.4838\n",
      "number of sota per dataset/metric:  5\n",
      "####### Mean\n",
      "Creating ratio df for  Mean ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "-4.4 - -3.14 == -4.4 Ratio == -3.4921\n",
      "-4.4 - -4.4 == 0.0 Ratio == 0.0\n",
      "-4.3 - -4.4 == 0.1 Ratio == 0.0794\n",
      "-4.2 - -4.3 == 0.1 Ratio == 0.0794\n",
      "-3.14 - -4.2 == 1.06 Ratio == 0.8413\n",
      "number of sota per dataset/metric:  5\n",
      "####### Average\\\\ Recall\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Average\\\\ Recall ,  SemEval 2017 Task 4-A - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.685 - 0.685 == 0.685 Ratio == inf\n",
      "Creating ratio df for  Average\\\\ Recall ,  ArSAS - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.9 - 0.9 == 0.9 Ratio == inf\n",
      "Creating ratio df for  Average\\\\ Recall ,  ASTD - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.62 - 0.62 == 0.62 Ratio == inf\n",
      "number of sota per dataset/metric:  3\n",
      "####### F1\\\\-score\n",
      "Creating ratio df for  F1\\\\-score ,  SemEval - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.685 - 0.685 == 0.685 Ratio == inf\n",
      "Creating ratio df for  F1\\\\-score ,  GeNeVA (i-CLEVR) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1\\\\-score ,  GeNeVA (CoDraw) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1\\\\-score ,  200k Short Texts for Humor Detection - Humor Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.92 - 0.92 == 0.92 Ratio == inf\n",
      "number of sota per dataset/metric:  2\n",
      "####### SICK\\\\-E\n",
      "Creating ratio df for  SICK\\\\-E ,  SentEval - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "86.3 - 87.8 == 86.3 Ratio == 57.5333\n",
      "87.8 - 86.3 == 1.5 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### SICK\\\\-R\n",
      "Creating ratio df for  SICK\\\\-R ,  SentEval - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.884 - 0.888 == 0.884 Ratio == 221.0\n",
      "0.888 - 0.884 == 0.004 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### 14\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  100 sleep nights of 8 caregivers - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "10 - 10 == 10 Ratio == inf\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  100 sleep nights of 8 caregivers - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "10 - 10 == 10 Ratio == inf\n",
      "number of sota per dataset/metric:  2\n",
      "####### Average\\\\ Precision\n",
      "Creating ratio df for  Average\\\\ Precision ,  The ARRAU Corpus - Abstract Anaphora Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "43.83 - 43.83 == 43.83 Ratio == inf\n",
      "Creating ratio df for  Average\\\\ Precision ,  New York Times Corpus - Relationship extraction using distant supervision benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.39 - 0.39 == 0.39 Ratio == inf\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Valence\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Valence\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.189 - 0.192 == 0.189 Ratio == 63.0\n",
      "0.192 - 0.189 == 0.003 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Arousal\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Arousal\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.213 - 0.213 == 0.213 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(Expectancy\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Expectancy\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.19 - 0.195 == 0.19 Ratio == 38.0\n",
      "0.195 - 0.19 == 0.005 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Power\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Power\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "8.67 - 8.74 == 8.67 Ratio == 123.8571\n",
      "8.74 - 8.67 == 0.07 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Weighted\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "56.44 - 58.18 == 56.44 Ratio == 32.4368\n",
      "57.03 - 56.44 == 0.59 Ratio == 0.3391\n",
      "58.1 - 57.03 == 1.07 Ratio == 0.6149\n",
      "58.18 - 58.1 == 0.08 Ratio == 0.046\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "56.19 - 64.18 == 56.19 Ratio == 7.0325\n",
      "58.54 - 56.19 == 2.35 Ratio == 0.2941\n",
      "62.75 - 58.54 == 4.21 Ratio == 0.5269\n",
      "64.18 - 62.75 == 1.43 Ratio == 0.179\n",
      "number of sota per dataset/metric:  8\n",
      "####### UA\n",
      "Creating ratio df for  UA ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "0.741 - 0.765 == 0.741 Ratio == 30.875\n",
      "0.759 - 0.741 == 0.018 Ratio == 0.75\n",
      "0.765 - 0.759 == 0.006 Ratio == 0.25\n",
      "Creating ratio df for  UA ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.65 - 0.701 == 0.65 Ratio == 12.7451\n",
      "0.701 - 0.65 == 0.051 Ratio == 1.0\n",
      "number of sota per dataset/metric:  5\n",
      "####### Macro\\\\-F1\n",
      "Creating ratio df for  Macro\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "54.84 - 63.43 == 54.84 Ratio == 6.3842\n",
      "56.52 - 54.84 == 1.68 Ratio == 0.1956\n",
      "60.66 - 56.52 == 4.14 Ratio == 0.482\n",
      "63.43 - 60.66 == 2.77 Ratio == 0.3225\n",
      "Creating ratio df for  Macro\\\\-F1 ,  SemEval 2018 Task 1E-c - Emotion Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.561 - 0.561 == 0.561 Ratio == inf\n",
      "number of sota per dataset/metric:  5\n",
      "####### Weighted\\\\ Accuracy\n",
      "Creating ratio df for  Weighted\\\\ Accuracy ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "81.72 - 83.08 == 81.72 Ratio == 60.0882\n",
      "83.08 - 81.72 == 1.36 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Per\\\\-class\\\\ Accuracy\\\\ \\\\(Unrelated\\\\)\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy\\\\ \\\\(Unrelated\\\\) ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "97.9 - 98.04 == 97.9 Ratio == 699.2857\n",
      "98.04 - 97.9 == 0.14 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Per\\\\-class\\\\ Accuracy\\\\ \\\\(Agree\\\\)\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy\\\\ \\\\(Agree\\\\) ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "44.04 - 51.34 == 44.04 Ratio == 6.0329\n",
      "50.7 - 44.04 == 6.66 Ratio == 0.9123\n",
      "51.34 - 50.7 == 0.64 Ratio == 0.0877\n",
      "number of sota per dataset/metric:  3\n",
      "####### Per\\\\-class\\\\ Accuracy\\\\ \\\\(Disagree\\\\)\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy\\\\ \\\\(Disagree\\\\) ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "6.6 - 10.33 == 6.6 Ratio == 1.7694\n",
      "9.61 - 6.6 == 3.01 Ratio == 0.807\n",
      "10.33 - 9.61 == 0.72 Ratio == 0.193\n",
      "number of sota per dataset/metric:  3\n",
      "####### Per\\\\-class\\\\ Accuracy\\\\ \\\\(Discuss\\\\)\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy\\\\ \\\\(Discuss\\\\) ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "81.38 - 85.68 == 81.38 Ratio == 18.9256\n",
      "85.68 - 81.38 == 4.3 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Consistency\n",
      "Creating ratio df for  Consistency ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "78.71 - 93.1 == 78.71 Ratio == 5.4698\n",
      "89.59 - 78.71 == 10.88 Ratio == 0.7561\n",
      "93.1 - 89.59 == 3.51 Ratio == 0.2439\n",
      "number of sota per dataset/metric:  3\n",
      "####### Plausibility\n",
      "Creating ratio df for  Plausibility ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "84.57 - 85.21 == 84.57 Ratio == 132.1406\n",
      "85.21 - 84.57 == 0.64 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Validity\n",
      "Creating ratio df for  Validity ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "96.18 - 96.36 == 96.18 Ratio == 534.3333\n",
      "96.35 - 96.18 == 0.17 Ratio == 0.9444\n",
      "96.36 - 96.35 == 0.01 Ratio == 0.0556\n",
      "number of sota per dataset/metric:  3\n",
      "####### Distribution\n",
      "Creating ratio df for  Distribution ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "5.98 - 6.42 == 5.98 Ratio == 13.5909\n",
      "6.42 - 5.98 == 0.44 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### DLD\n",
      "Creating ratio df for  DLD ,  RotoWire (Content Ordering) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### count\n",
      "Creating ratio df for  count ,  RotoWire (Relation Generation) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### Binary\n",
      "Creating ratio df for  Binary ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "66.64 - 79.79 == 66.64 Ratio == 5.0677\n",
      "77.16 - 66.64 == 10.52 Ratio == 0.8\n",
      "79.79 - 77.16 == 2.63 Ratio == 0.2\n",
      "number of sota per dataset/metric:  3\n",
      "####### Open\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Open ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "34.83 - 47.64 == 34.83 Ratio == 2.719\n",
      "45.47 - 34.83 == 10.64 Ratio == 0.8306\n",
      "47.64 - 45.47 == 2.17 Ratio == 0.1694\n",
      "number of sota per dataset/metric:  3\n",
      "####### Execution\\\\ Accuracy\n",
      "Creating ratio df for  Execution\\\\ Accuracy ,  WikiSQL - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "35.9 - 89.2 == 35.9 Ratio == 0.6735\n",
      "59.4 - 35.9 == 23.5 Ratio == 0.4409\n",
      "68.0 - 59.4 == 8.6 Ratio == 0.1614\n",
      "74.6 - 68.0 == 6.6 Ratio == 0.1238\n",
      "82.6 - 74.6 == 8.0 Ratio == 0.1501\n",
      "89.2 - 82.6 == 6.6 Ratio == 0.1238\n",
      "number of sota per dataset/metric:  6\n",
      "####### Exact\\\\ Match\\\\ Accuracy\n",
      "Creating ratio df for  Exact\\\\ Match\\\\ Accuracy ,  WikiSQL - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "23.4 - 83.7 == 23.4 Ratio == 0.3881\n",
      "48.3 - 23.4 == 24.9 Ratio == 0.4129\n",
      "62.8 - 48.3 == 14.5 Ratio == 0.2405\n",
      "68.6 - 62.8 == 5.8 Ratio == 0.0962\n",
      "83.7 - 68.6 == 15.1 Ratio == 0.2504\n",
      "number of sota per dataset/metric:  5\n",
      "####### Error\\\\ rate\n",
      "Creating ratio df for  Error\\\\ rate ,  Wikipedia-Wikidata relations - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.159 - 0.159 == 0.159 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Senseval\\\\ 2\n",
      "Creating ratio df for  Senseval\\\\ 2 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "72.0 - 79.7 == 72.0 Ratio == 9.3506\n",
      "72.2 - 72.0 == 0.2 Ratio == 0.026\n",
      "75.15 - 72.2 == 2.95 Ratio == 0.3831\n",
      "79.7 - 75.15 == 4.55 Ratio == 0.5909\n",
      "number of sota per dataset/metric:  4\n",
      "####### Senseval\\\\ 3\n",
      "Creating ratio df for  Senseval\\\\ 3 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "69.4 - 77.8 == 69.4 Ratio == 8.2619\n",
      "69.6 - 69.4 == 0.2 Ratio == 0.0238\n",
      "70.5 - 69.6 == 0.9 Ratio == 0.1071\n",
      "77.8 - 70.5 == 7.3 Ratio == 0.869\n",
      "number of sota per dataset/metric:  4\n",
      "####### SemEval\\\\ 2013\n",
      "Creating ratio df for  SemEval\\\\ 2013 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "66.4 - 78.7 == 66.4 Ratio == 5.3984\n",
      "66.9 - 66.4 == 0.5 Ratio == 0.0407\n",
      "67.2 - 66.9 == 0.3 Ratio == 0.0244\n",
      "72.63 - 67.2 == 5.43 Ratio == 0.4415\n",
      "78.7 - 72.63 == 6.07 Ratio == 0.4935\n",
      "Creating ratio df for  SemEval\\\\ 2013 ,  Knowledge-based: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "65.3 - 65.3 == 65.3 Ratio == inf\n",
      "number of sota per dataset/metric:  6\n",
      "####### SemEval\\\\ 2015\n",
      "Creating ratio df for  SemEval\\\\ 2015 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "72.4 - 82.6 == 72.4 Ratio == 7.098\n",
      "72.6 - 72.4 == 0.2 Ratio == 0.0196\n",
      "74.46 - 72.6 == 1.86 Ratio == 0.1824\n",
      "82.6 - 74.46 == 8.14 Ratio == 0.798\n",
      "Creating ratio df for  SemEval\\\\ 2015 ,  Knowledge-based: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "69.6 - 69.6 == 69.6 Ratio == inf\n",
      "number of sota per dataset/metric:  5\n",
      "####### F1\\\\ \\\\(surface\\\\ form\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(surface\\\\ form\\\\) ,  Long-tail emerging entities - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "39.33 - 39.33 == 39.33 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### 1\\\\-of\\\\-100\\\\ Accuracy\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  20NEWS - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "5 - 5 == 5 Ratio == inf\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  PolyAI Reddit - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "19.3 - 71.8 == 19.3 Ratio == 0.3676\n",
      "47.7 - 19.3 == 28.4 Ratio == 0.541\n",
      "61.3 - 47.7 == 13.6 Ratio == 0.259\n",
      "71.8 - 61.3 == 10.5 Ratio == 0.2\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  DSTC7 Ubuntu - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "60.8 - 71.2 == 60.8 Ratio == 5.8462\n",
      "64.5 - 60.8 == 3.7 Ratio == 0.3558\n",
      "66.3 - 64.5 == 1.8 Ratio == 0.1731\n",
      "70.9 - 66.3 == 4.6 Ratio == 0.4423\n",
      "71.2 - 70.9 == 0.3 Ratio == 0.0288\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  PolyAI OpenSubtitles - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "30.6 - 30.6 == 30.6 Ratio == inf\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  PolyAI AmazonQA - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "71.3 - 84.3 == 71.3 Ratio == 5.4846\n",
      "84.3 - 71.3 == 13.0 Ratio == 1.0\n",
      "number of sota per dataset/metric:  13\n",
      "####### 1\\\\ in\\\\ 2\\\\ R\\\\-at\\\\-1\n",
      "Creating ratio df for  1\\\\ in\\\\ 2\\\\ R\\\\-at\\\\-1 ,  Ubuntu Dialogue (v1, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 2\\\\ R\\\\-at\\\\-1 ,  Ubuntu Dialogue (v2, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### 1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-1\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-1 ,  Ubuntu Dialogue (v1, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-1 ,  Ubuntu Dialogue (v2, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### 1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Ubuntu Dialogue (v1, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Ubuntu Dialogue (v2, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Visual Dialog v0.9 - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "80.1 - 80.1 == 80.1 Ratio == inf\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Visual Dialog  v0.9 - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "81 - 81 == 81 Ratio == inf\n",
      "number of sota per dataset/metric:  2\n",
      "####### Test\n",
      "Creating ratio df for  Test ,  WikiHop - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "42.9 - 70.6 == 42.9 Ratio == 1.5487\n",
      "59.3 - 42.9 == 16.4 Ratio == 0.5921\n",
      "65.4 - 59.3 == 6.1 Ratio == 0.2202\n",
      "70.6 - 65.4 == 5.2 Ratio == 0.1877\n",
      "Creating ratio df for  Test ,  SWAG - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "59.2 - 89.9 == 59.2 Ratio == 1.9283\n",
      "86.3 - 59.2 == 27.1 Ratio == 0.8827\n",
      "89.9 - 86.3 == 3.6 Ratio == 0.1173\n",
      "number of sota per dataset/metric:  7\n",
      "####### Holder\\\\ Binary\\\\ F1\n",
      "Creating ratio df for  Holder\\\\ Binary\\\\ F1 ,  MPQA - Fine-Grained Opinion Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "83.8 - 84.91 == 83.8 Ratio == 75.4955\n",
      "84.91 - 83.8 == 1.11 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Target\\\\ Binary\\\\ F1\n",
      "Creating ratio df for  Target\\\\ Binary\\\\ F1 ,  MPQA - Fine-Grained Opinion Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "72.06 - 73.29 == 72.06 Ratio == 58.5854\n",
      "73.29 - 72.06 == 1.23 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Mean\\\\ F1\\\\ \\\\(WSJ\\\\)\n",
      "Creating ratio df for  Mean\\\\ F1\\\\ \\\\(WSJ\\\\) ,  PTB - Constituency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "47.3 - 55.7 == 47.3 Ratio == 5.631\n",
      "47.9 - 47.3 == 0.6 Ratio == 0.0714\n",
      "48.1 - 47.9 == 0.2 Ratio == 0.0238\n",
      "55.7 - 48.1 == 7.6 Ratio == 0.9048\n",
      "number of sota per dataset/metric:  4\n",
      "####### Max\\\\ F1\\\\ \\\\(WSJ\\\\)\n",
      "Creating ratio df for  Max\\\\ F1\\\\ \\\\(WSJ\\\\) ,  PTB - Constituency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "47.9 - 60.1 == 47.9 Ratio == 3.9262\n",
      "49.4 - 47.9 == 1.5 Ratio == 0.123\n",
      "50.0 - 49.4 == 0.6 Ratio == 0.0492\n",
      "52.4 - 50.0 == 2.4 Ratio == 0.1967\n",
      "56.2 - 52.4 == 3.8 Ratio == 0.3115\n",
      "60.1 - 56.2 == 3.9 Ratio == 0.3197\n",
      "number of sota per dataset/metric:  6\n",
      "####### Exact\\\\ Span\\\\ F1\n",
      "Creating ratio df for  Exact\\\\ Span\\\\ F1 ,  CoNLL 2000 - Chunking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "95.25 - 96.72 == 95.25 Ratio == 64.7959\n",
      "96.72 - 95.25 == 1.47 Ratio == 1.0\n",
      "Creating ratio df for  Exact\\\\ Span\\\\ F1 ,  STM-corpus - Scientific Concept Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "65.5 - 66.4 == 65.5 Ratio == 72.7778\n",
      "66.4 - 65.5 == 0.9 Ratio == 1.0\n",
      "number of sota per dataset/metric:  4\n",
      "####### nDCG\\\\-at\\\\-20\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  TREC Robust04 - Ad-Hoc Information Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "0.431 - 0.5381 == 0.431 Ratio == 4.0243\n",
      "0.445 - 0.431 == 0.014 Ratio == 0.1307\n",
      "0.464 - 0.445 == 0.019 Ratio == 0.1774\n",
      "0.5381 - 0.464 == 0.0741 Ratio == 0.6919\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  ClueWeb09-B - Document Ranking benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "31.1 - 31.1 == 31.1 Ratio == inf\n",
      "number of sota per dataset/metric:  5\n",
      "####### P\\\\-at\\\\-20\n",
      "Creating ratio df for  P\\\\-at\\\\-20 ,  TREC Robust04 - Ad-Hoc Information Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "0.382 - 0.4667 == 0.382 Ratio == 4.51\n",
      "0.389 - 0.382 == 0.007 Ratio == 0.0826\n",
      "0.3948 - 0.389 == 0.0058 Ratio == 0.0685\n",
      "0.4064 - 0.3948 == 0.0116 Ratio == 0.137\n",
      "0.4287 - 0.4064 == 0.0223 Ratio == 0.2633\n",
      "0.4667 - 0.4287 == 0.038 Ratio == 0.4486\n",
      "number of sota per dataset/metric:  6\n",
      "####### LPIPS\n",
      "Creating ratio df for  LPIPS ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.512 - -0.512 == -0.512 Ratio == -inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Acc\n",
      "Creating ratio df for  Acc ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-13.0 - -13.0 == -13.0 Ratio == -inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Real\n",
      "Creating ratio df for  Real ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-11.9 - -11.9 == -11.9 Ratio == -inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### SOA\\\\-C\n",
      "Creating ratio df for  SOA\\\\-C ,  COCO - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "25.88 - 33.44 == 25.88 Ratio == 3.4233\n",
      "33.44 - 25.88 == 7.56 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### CIDEr\n",
      "Creating ratio df for  CIDEr ,  E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "2.2721 - 2.37 == 2.2721 Ratio == 23.2084\n",
      "2.37 - 2.2721 == 0.0979 Ratio == 1.0\n",
      "Creating ratio df for  CIDEr ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "77.6 - 77.6 == 77.6 Ratio == inf\n",
      "Creating ratio df for  CIDEr ,  COCO Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "116.9 - 116.9 == 116.9 Ratio == inf\n",
      "Creating ratio df for  CIDEr ,  Flickr30k Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "67.4 - 67.4 == 67.4 Ratio == inf\n",
      "number of sota per dataset/metric:  5\n",
      "####### NIST\n",
      "Creating ratio df for  NIST ,  E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "8.3453 - 8.73 == 8.3453 Ratio == 21.693\n",
      "8.5105 - 8.3453 == 0.1652 Ratio == 0.4294\n",
      "8.613 - 8.5105 == 0.1025 Ratio == 0.2664\n",
      "8.73 - 8.613 == 0.117 Ratio == 0.3041\n",
      "number of sota per dataset/metric:  4\n",
      "####### All\n",
      "Creating ratio df for  All ,  Knowledge-based: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "66.9 - 66.9 == 66.9 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### GLEU\n",
      "Creating ratio df for  GLEU ,  _Restricted_ - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "57.47 - 57.47 == 57.47 Ratio == inf\n",
      "Creating ratio df for  GLEU ,  Unrestricted - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "62.37 - 62.37 == 62.37 Ratio == inf\n",
      "Creating ratio df for  GLEU ,  JFLEG - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "61 - 61 == 61 Ratio == inf\n",
      "number of sota per dataset/metric:  3\n",
      "####### SemEval\\\\ 2007\n",
      "Creating ratio df for  SemEval\\\\ 2007 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "62.2 - 73.4 == 62.2 Ratio == 5.5536\n",
      "66.81 - 62.2 == 4.61 Ratio == 0.4116\n",
      "73.4 - 66.81 == 6.59 Ratio == 0.5884\n",
      "number of sota per dataset/metric:  3\n",
      "####### RACE\\\\-m\n",
      "Creating ratio df for  RACE\\\\-m ,  RACE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "60.2 - 85.45 == 60.2 Ratio == 2.3842\n",
      "62.9 - 60.2 == 2.7 Ratio == 0.1069\n",
      "85.45 - 62.9 == 22.55 Ratio == 0.8931\n",
      "number of sota per dataset/metric:  3\n",
      "####### RACE\\\\-h\n",
      "Creating ratio df for  RACE\\\\-h ,  RACE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "50.3 - 80.21 == 50.3 Ratio == 1.6817\n",
      "57.4 - 50.3 == 7.1 Ratio == 0.2374\n",
      "80.21 - 57.4 == 22.81 Ratio == 0.7626\n",
      "number of sota per dataset/metric:  3\n",
      "####### RACE\n",
      "Creating ratio df for  RACE ,  RACE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "53.3 - 81.75 == 53.3 Ratio == 1.8735\n",
      "59.0 - 53.3 == 5.7 Ratio == 0.2004\n",
      "81.75 - 59.0 == 22.75 Ratio == 0.7996\n",
      "number of sota per dataset/metric:  3\n",
      "####### Mismatched\n",
      "Creating ratio df for  Mismatched ,  MultiNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "71.3 - 90.2 == 71.3 Ratio == 3.7725\n",
      "72.1 - 71.3 == 0.8 Ratio == 0.0423\n",
      "81.4 - 72.1 == 9.3 Ratio == 0.4921\n",
      "86.0 - 81.4 == 4.6 Ratio == 0.2434\n",
      "90.2 - 86.0 == 4.2 Ratio == 0.2222\n",
      "number of sota per dataset/metric:  5\n",
      "####### Matched\n",
      "Creating ratio df for  Matched ,  MultiNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "71.4 - 91.3 == 71.4 Ratio == 3.5879\n",
      "72.2 - 71.4 == 0.8 Ratio == 0.0402\n",
      "82.1 - 72.2 == 9.9 Ratio == 0.4975\n",
      "86.7 - 82.1 == 4.6 Ratio == 0.2312\n",
      "90.8 - 86.7 == 4.1 Ratio == 0.206\n",
      "91.3 - 90.8 == 0.5 Ratio == 0.0251\n",
      "number of sota per dataset/metric:  6\n",
      "####### v2v\\\\ error\n",
      "Creating ratio df for  v2v\\\\ error ,  Expressive hands and faces dataset (EHF). - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### RE\\\\+\\\\ Macro\\\\ F1\n",
      "Creating ratio df for  RE\\\\+\\\\ Macro\\\\ F1 ,  ADE Corpus - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "74.58 - 77.19 == 74.58 Ratio == 28.5747\n",
      "75.52 - 74.58 == 0.94 Ratio == 0.3602\n",
      "77.19 - 75.52 == 1.67 Ratio == 0.6398\n",
      "Creating ratio df for  RE\\\\+\\\\ Macro\\\\ F1 ,  CoNLL04 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "62.04 - 64.4 == 62.04 Ratio == 26.2881\n",
      "64.4 - 62.04 == 2.36 Ratio == 1.0\n",
      "number of sota per dataset/metric:  5\n",
      "####### NER\\\\ Macro\\\\ F1\n",
      "Creating ratio df for  NER\\\\ Macro\\\\ F1 ,  ADE Corpus - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "86.4 - 87.02 == 86.4 Ratio == 139.3548\n",
      "86.73 - 86.4 == 0.33 Ratio == 0.5323\n",
      "87.02 - 86.73 == 0.29 Ratio == 0.4677\n",
      "Creating ratio df for  NER\\\\ Macro\\\\ F1 ,  CoNLL04 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "83.9 - 86.2 == 83.9 Ratio == 36.4783\n",
      "86.2 - 83.9 == 2.3 Ratio == 1.0\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(%\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  LOCAL DATASET - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "90.79 - 90.79 == 90.79 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Cross\\\\-Ent\n",
      "Creating ratio df for  Average\\\\ Cross\\\\-Ent ,  Event2Mind dev - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "4.44 - 4.44 == 4.44 Ratio == inf\n",
      "Creating ratio df for  Average\\\\ Cross\\\\-Ent ,  Event2Mind test - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "4.22 - 4.4 == 4.22 Ratio == 23.4444\n",
      "4.4 - 4.22 == 0.18 Ratio == 1.0\n",
      "number of sota per dataset/metric:  3\n",
      "####### AUC\n",
      "Creating ratio df for  AUC ,  SLAM 2018 - Language Acquisition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.821 - 0.821 == 0.821 Ratio == inf\n",
      "Creating ratio df for  AUC ,  New York Times Corpus - Relationship extraction using distant supervision benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.39 - 0.39 == 0.39 Ratio == inf\n",
      "number of sota per dataset/metric:  2\n",
      "####### Score\n",
      "Creating ratio df for  Score ,  Winograd Schema Challenge - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "63.7 - 70.7 == 63.7 Ratio == 9.1\n",
      "70.7 - 63.7 == 7.0 Ratio == 1.0\n",
      "Creating ratio df for  Score ,  VQA-CP - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "28.65 - 52.05 == 28.65 Ratio == 1.2244\n",
      "39.54 - 28.65 == 10.89 Ratio == 0.4654\n",
      "49.45 - 39.54 == 9.91 Ratio == 0.4235\n",
      "52.05 - 49.45 == 2.6 Ratio == 0.1111\n",
      "number of sota per dataset/metric:  6\n",
      "####### BEP\n",
      "Creating ratio df for  BEP ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "94.8 - 94.8 == 94.8 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### F\\\\-measure\n",
      "Creating ratio df for  F\\\\-measure ,  R8 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "91.0 - 91.7 == 91.0 Ratio == 130.0\n",
      "91.7 - 91.0 == 0.7 Ratio == 1.0\n",
      "Creating ratio df for  F\\\\-measure ,  20NEWS - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "83.9 - 86.2 == 83.9 Ratio == 36.4783\n",
      "86.2 - 83.9 == 2.3 Ratio == 1.0\n",
      "number of sota per dataset/metric:  4\n",
      "####### Macro\\\\ F1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Macro\\\\ F1 ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "84.2 - 84.2 == 84.2 Ratio == inf\n",
      "Creating ratio df for  Macro\\\\ F1 ,  FIGER - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "76.51 - 76.51 == 76.51 Ratio == inf\n",
      "Creating ratio df for  Macro\\\\ F1 ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Macro\\\\ F1 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "60.1 - 60.1 == 60.1 Ratio == inf\n",
      "Creating ratio df for  Macro\\\\ F1 ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  3\n",
      "####### Micro\\\\ F1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "85.7 - 85.7 == 85.7 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\ F1 ,  FIGER - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "73.39 - 73.39 == 73.39 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\ F1 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "73.2 - 73.2 == 73.2 Ratio == inf\n",
      "Creating ratio df for  Micro\\\\ F1 ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Micro\\\\ F1 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "83.3 - 88.5 == 83.3 Ratio == 16.0192\n",
      "88.5 - 83.3 == 5.2 Ratio == 1.0\n",
      "Creating ratio df for  Micro\\\\ F1 ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  5\n",
      "####### 10\\\\ fold\\\\ Cross\\\\ validation\n",
      "Creating ratio df for  10\\\\ fold\\\\ Cross\\\\ validation ,  2017_test set - Paraphrase Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "50 - 50 == 50 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\n",
      "Creating ratio df for  MAE ,  CMU-MOSEI - Multimodal Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-0.71 - -0.71 == -0.71 Ratio == -inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Dev\n",
      "Creating ratio df for  Dev ,  SWAG - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "59.1 - 86.6 == 59.1 Ratio == 2.1491\n",
      "81.6 - 59.1 == 22.5 Ratio == 0.8182\n",
      "86.6 - 81.6 == 5.0 Ratio == 0.1818\n",
      "number of sota per dataset/metric:  3\n",
      "####### In\\\\-domain\n",
      "Creating ratio df for  In\\\\-domain ,  CoQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "54.5 - 82.5 == 54.5 Ratio == 1.9464\n",
      "67.0 - 54.5 == 12.5 Ratio == 0.4464\n",
      "69.4 - 67.0 == 2.4 Ratio == 0.0857\n",
      "76.3 - 69.4 == 6.9 Ratio == 0.2464\n",
      "82.5 - 76.3 == 6.2 Ratio == 0.2214\n",
      "number of sota per dataset/metric:  5\n",
      "####### Overall\n",
      "Creating ratio df for  Overall ,  CoQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "52.6 - 81.1 == 52.6 Ratio == 1.8456\n",
      "65.1 - 52.6 == 12.5 Ratio == 0.4386\n",
      "67.8 - 65.1 == 2.7 Ratio == 0.0947\n",
      "75.0 - 67.8 == 7.2 Ratio == 0.2526\n",
      "81.1 - 75.0 == 6.1 Ratio == 0.214\n",
      "number of sota per dataset/metric:  5\n",
      "####### Out\\\\-of\\\\-domain\n",
      "Creating ratio df for  Out\\\\-of\\\\-domain ,  CoQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "47.9 - 77.6 == 47.9 Ratio == 1.6128\n",
      "60.4 - 47.9 == 12.5 Ratio == 0.4209\n",
      "63.8 - 60.4 == 3.4 Ratio == 0.1145\n",
      "71.8 - 63.8 == 8.0 Ratio == 0.2694\n",
      "77.6 - 71.8 == 5.8 Ratio == 0.1953\n",
      "number of sota per dataset/metric:  5\n",
      "####### F1\\\\-Score\n",
      "Creating ratio df for  F1\\\\-Score ,  CoQA - Generative Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "45.4 - 82.5 == 45.4 Ratio == 1.2237\n",
      "82.5 - 45.4 == 37.1 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Micro\\\\-F1\\\\ strong\n",
      "Creating ratio df for  Micro\\\\-F1\\\\ strong ,  AIDA-CoNLL - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "82.6 - 82.6 == 82.6 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Macro\\\\-F1\\\\ strong\n",
      "Creating ratio df for  Macro\\\\-F1\\\\ strong ,  AIDA-CoNLL - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "82.4 - 82.4 == 82.4 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### SacreBLEU\n",
      "Creating ratio df for  SacreBLEU ,  WMT2014 English-French - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "43.8 - 43.8 == 43.8 Ratio == inf\n",
      "Creating ratio df for  SacreBLEU ,  WMT2014 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "33.8 - 33.8 == 33.8 Ratio == inf\n",
      "Creating ratio df for  SacreBLEU ,  WMT2019 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "42.7 - 42.7 == 42.7 Ratio == inf\n",
      "number of sota per dataset/metric:  3\n",
      "####### Mean\\\\ F1\\\\ \\\\(WSJ10\\\\)\n",
      "Creating ratio df for  Mean\\\\ F1\\\\ \\\\(WSJ10\\\\) ,  PTB - Constituency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "60.2 - 67.7 == 60.2 Ratio == 8.0267\n",
      "65.1 - 60.2 == 4.9 Ratio == 0.6533\n",
      "67.7 - 65.1 == 2.6 Ratio == 0.3467\n",
      "number of sota per dataset/metric:  3\n",
      "####### Entity\\\\ F1\n",
      "Creating ratio df for  Entity\\\\ F1 ,  SciERC - Joint Entity and Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "64.2 - 67.5 == 64.2 Ratio == 19.4545\n",
      "65.2 - 64.2 == 1.0 Ratio == 0.303\n",
      "67.5 - 65.2 == 2.3 Ratio == 0.697\n",
      "number of sota per dataset/metric:  3\n",
      "####### Relation\\\\ F1\n",
      "Creating ratio df for  Relation\\\\ F1 ,  SciERC - Joint Entity and Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "39.3 - 48.4 == 39.3 Ratio == 4.3187\n",
      "41.6 - 39.3 == 2.3 Ratio == 0.2527\n",
      "48.4 - 41.6 == 6.8 Ratio == 0.7473\n",
      "number of sota per dataset/metric:  3\n",
      "####### ROUGE\\\\-SU4\n",
      "Creating ratio df for  ROUGE\\\\-SU4 ,  Multi-News - Multi-Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "17.37 - 17.37 == 17.37 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### HEQD\n",
      "Creating ratio df for  HEQD ,  QuAC - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "5.8 - 5.8 == 5.8 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### HEQQ\n",
      "Creating ratio df for  HEQQ ,  QuAC - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "59.6 - 59.6 == 59.6 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Max\\\\ F1\\\\ \\\\(WSJ10\\\\)\n",
      "Creating ratio df for  Max\\\\ F1\\\\ \\\\(WSJ10\\\\) ,  PTB - Constituency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "66.8 - 68.5 == 66.8 Ratio == 39.2941\n",
      "68.5 - 66.8 == 1.7 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### infNDCG\n",
      "Creating ratio df for  infNDCG ,  TREC-PM - Information Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "0.5545 - 0.5605 == 0.5545 Ratio == 92.4167\n",
      "0.5605 - 0.5545 == 0.006 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### rsim\n",
      "Creating ratio df for  rsim ,  GeNeVA (CoDraw) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  rsim ,  GeNeVA (i-CLEVR) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### Pointing\\\\ Game\\\\ Accuracy\n",
      "Creating ratio df for  Pointing\\\\ Game\\\\ Accuracy ,  Flickr30k - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "69.19 - 69.19 == 69.19 Ratio == inf\n",
      "Creating ratio df for  Pointing\\\\ Game\\\\ Accuracy ,  Visual Genome - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "55.16 - 55.16 == 55.16 Ratio == inf\n",
      "Creating ratio df for  Pointing\\\\ Game\\\\ Accuracy ,  ReferIt - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "62.76 - 62.76 == 62.76 Ratio == inf\n",
      "number of sota per dataset/metric:  3\n",
      "####### Slot\\\\ F1\\\\ Score\n",
      "Creating ratio df for  Slot\\\\ F1\\\\ Score ,  SNIPS - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "91.8 - 92.23 == 91.8 Ratio == 213.4884\n",
      "92.23 - 91.8 == 0.43 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### Intent\\\\ Accuracy\n",
      "Creating ratio df for  Intent\\\\ Accuracy ,  SNIPS - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "97.7 - 97.7 == 97.7 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### R@50\n",
      "Creating ratio df for  R@50 ,  Advising Corpus - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "97.8 - 97.8 == 97.8 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\ \\\\(Long\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(Long\\\\) ,  Natural Questions - Question Answering benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "66.2 - 66.2 == 66.2 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\ \\\\(Short\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(Short\\\\) ,  Natural Questions - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "52.1 - 52.1 == 52.1 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Bits\\\\ per\\\\ byte\n",
      "Creating ratio df for  Bits\\\\ per\\\\ byte ,  The Pile - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "1.2253 - 1.2253 == 1.2253 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### interest\\\\ \\\\(human\\\\)\n",
      "Creating ratio df for  interest\\\\ \\\\(human\\\\) ,  Reddit (multi-ref) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### relevance\\\\ \\\\(human\\\\)\n",
      "Creating ratio df for  relevance\\\\ \\\\(human\\\\) ,  Reddit (multi-ref) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(3\\\\-way\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(3\\\\-way\\\\) ,  SemEval 2014 Task 4 Subtask 4 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "89.9 - 89.9 == 89.9 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(4\\\\-way\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(4\\\\-way\\\\) ,  SemEval 2014 Task 4 Subtask 4 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "85.9 - 85.9 == 85.9 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Binary\\\\ Accuracy\n",
      "Creating ratio df for  Binary\\\\ Accuracy ,  SemEval 2014 Task 4 Subtask 4 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "95.6 - 95.6 == 95.6 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Laptop\\\\ \\\\(F1\\\\)\n",
      "Creating ratio df for  Laptop\\\\ \\\\(F1\\\\) ,  SemEval 2014 Task 4 Sub Task 1 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "84.26 - 84.26 == 84.26 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Restaurant\\\\ \\\\(F1\\\\)\n",
      "Creating ratio df for  Restaurant\\\\ \\\\(F1\\\\) ,  SemEval 2014 Task 4 Sub Task 1 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "77.97 - 77.97 == 77.97 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Phoneme\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Phoneme\\\\ Error\\\\ Rate ,  CMUDict 0.7b - Text-To-Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "4.6 - 4.6 == 4.6 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\)\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  CMUDict 0.7b - Text-To-Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "19.88 - 19.88 == 19.88 Ratio == inf\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  Tashkeela - Arabic Text Diacritization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.1119 - 0.1119 == 0.1119 Ratio == inf\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(10\\\\ classes\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(10\\\\ classes\\\\) ,  IMDb - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "53.7 - 53.7 == 53.7 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### mAP\n",
      "Creating ratio df for  mAP ,  TREC-PM - Passage Re-Ranking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-36.5 - -36.5 == -36.5 Ratio == -inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Diacritic\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Diacritic\\\\ Error\\\\ Rate ,  Tashkeela - Arabic Text Diacritization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.0373 - 0.0373 == 0.0373 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### JOINT\\\\-F1\n",
      "Creating ratio df for  JOINT\\\\-F1 ,  HotpotQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.5982 - 0.5982 == 0.5982 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Smatch\n",
      "Creating ratio df for  Smatch ,  LDC2017T10 - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "76.3 - 76.3 == 76.3 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Audio\\\\ Quality\\\\ MOS\n",
      "Creating ratio df for  Audio\\\\ Quality\\\\ MOS ,  LJSpeech - Text-To-Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "2.4 - 3.84 == 2.4 Ratio == 1.6667\n",
      "3.84 - 2.4 == 1.44 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### nDCG\\\\-at\\\\-5\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "54.65 - 54.65 == 54.65 Ratio == inf\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "83.7 - 83.7 == 83.7 Ratio == inf\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "87.57 - 87.57 == 87.57 Ratio == inf\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "67.82 - 67.82 == 67.82 Ratio == inf\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "59.28 - 82.3 == 59.28 Ratio == 2.5752\n",
      "82.3 - 59.28 == 23.02 Ratio == 1.0\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "93.11 - 93.11 == 93.11 Ratio == inf\n",
      "number of sota per dataset/metric:  7\n",
      "####### nDCG\\\\-at\\\\-3\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "80.11 - 80.11 == 80.11 Ratio == inf\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "89.13 - 89.13 == 89.13 Ratio == inf\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "51.7 - 51.7 == 51.7 Ratio == inf\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "75.64 - 75.64 == 75.64 Ratio == inf\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "64.89 - 71.11 == 64.89 Ratio == 10.4325\n",
      "71.11 - 64.89 == 6.22 Ratio == 1.0\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "92.47 - 92.47 == 92.47 Ratio == inf\n",
      "number of sota per dataset/metric:  7\n",
      "####### P\\\\-at\\\\-3\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "60.72 - 60.72 == 60.72 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "73.14 - 73.14 == 73.14 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "61.48 - 65.48 == 61.48 Ratio == 15.37\n",
      "65.48 - 61.48 == 4.0 Ratio == 1.0\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "79.16 - 79.16 == 79.16 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "34.6 - 34.6 == 34.6 Ratio == inf\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "81.27 - 81.27 == 81.27 Ratio == inf\n",
      "number of sota per dataset/metric:  7\n",
      "####### RP\\\\-at\\\\-5\n",
      "Creating ratio df for  RP\\\\-at\\\\-5 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "79.6 - 79.6 == 79.6 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### nDCG\\\\-at\\\\-1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-1 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "80.2 - 80.2 == 80.2 Ratio == inf\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-1 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "97.05 - 97.05 == 97.05 Ratio == inf\n",
      "number of sota per dataset/metric:  2\n",
      "####### Ign\\\\ F1\n",
      "Creating ratio df for  Ign\\\\ F1 ,  DocRED - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "43.6 - 54.42 == 43.6 Ratio == 4.0296\n",
      "43.93 - 43.6 == 0.33 Ratio == 0.0305\n",
      "44.73 - 43.93 == 0.8 Ratio == 0.0739\n",
      "54.42 - 44.73 == 9.69 Ratio == 0.8956\n",
      "number of sota per dataset/metric:  4\n",
      "####### Restaurant\\\\ 2014\\\\ \\\\(F1\\\\)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Restaurant\\\\ 2014\\\\ \\\\(F1\\\\) ,  SemEval - Aspect Term Extraction and Sentiment Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "70.72 - 70.72 == 70.72 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Laptop\\\\ 2014\\\\ \\\\(F1\\\\)\n",
      "Creating ratio df for  Laptop\\\\ 2014\\\\ \\\\(F1\\\\) ,  SemEval - Aspect Term Extraction and Sentiment Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "61.73 - 61.73 == 61.73 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Restaurant\\\\ 2015\\\\ \\\\(F1\\\\)\n",
      "Creating ratio df for  Restaurant\\\\ 2015\\\\ \\\\(F1\\\\) ,  SemEval - Aspect Term Extraction and Sentiment Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "60.22 - 60.22 == 60.22 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### A1\n",
      "Creating ratio df for  A1 ,  ANLI test - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "70.3 - 72.4 == 70.3 Ratio == 33.4762\n",
      "72.4 - 70.3 == 2.1 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### A2\n",
      "Creating ratio df for  A2 ,  ANLI test - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "50.9 - 50.9 == 50.9 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### A3\n",
      "Creating ratio df for  A3 ,  ANLI test - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "49.4 - 49.4 == 49.4 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### ERR\\\\-at\\\\-20\n",
      "Creating ratio df for  ERR\\\\-at\\\\-20 ,  ClueWeb09-B - Document Ranking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "20.28 - 20.28 == 20.28 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(High\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(High\\\\) ,  RACE - Reading Comprehension benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "84.0 - 90.0 == 84.0 Ratio == 14.0\n",
      "88.6 - 84.0 == 4.6 Ratio == 0.7667\n",
      "90.0 - 88.6 == 1.4 Ratio == 0.2333\n",
      "number of sota per dataset/metric:  3\n",
      "####### Accuracy\\\\ \\\\(Middle\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Middle\\\\) ,  RACE - Reading Comprehension benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "88.6 - 93.1 == 88.6 Ratio == 19.6889\n",
      "91.8 - 88.6 == 3.2 Ratio == 0.7111\n",
      "93.1 - 91.8 == 1.3 Ratio == 0.2889\n",
      "number of sota per dataset/metric:  3\n",
      "####### Macro\\\\ Recall\n",
      "Creating ratio df for  Macro\\\\ Recall ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Macro\\\\ Recall ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "####### Micro\\\\ Recall\n",
      "Creating ratio df for  Micro\\\\ Recall ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Micro\\\\ Recall ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "####### Macro\\\\ Precision\n",
      "Creating ratio df for  Macro\\\\ Precision ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Macro\\\\ Precision ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "####### Bias\\\\ \\\\(F/M\\\\)\n",
      "Creating ratio df for  Bias\\\\ \\\\(F/M\\\\) ,  GAP - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.97 - 0.97 == 0.97 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Overall\\\\ F1\n",
      "Creating ratio df for  Overall\\\\ F1 ,  GAP - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "92.5 - 92.5 == 92.5 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Masculine\\\\ F1\\\\ \\\\(M\\\\)\n",
      "Creating ratio df for  Masculine\\\\ F1\\\\ \\\\(M\\\\) ,  GAP - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "94 - 94 == 94 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Feminine\\\\ F1\\\\ \\\\(F\\\\)\n",
      "Creating ratio df for  Feminine\\\\ F1\\\\ \\\\(F\\\\) ,  GAP - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "91.1 - 91.1 == 91.1 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Dev\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Dev\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "67.4 - 67.4 == 67.4 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Test\\\\-P\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\-P\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "67 - 67 == 67 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Test\\\\-U\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\-U\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "67.3 - 67.3 == 67.3 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### number\n",
      "Creating ratio df for  number ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "24.76 - 24.76 == 24.76 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### unanswerable\n",
      "Creating ratio df for  unanswerable ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "82.26 - 82.26 == 82.26 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### yes/no\n",
      "Creating ratio df for  yes/no ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "74 - 74 == 74 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### other\n",
      "Creating ratio df for  other ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "39 - 39 == 39 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### ROUGE\\\\-3\n",
      "Creating ratio df for  ROUGE\\\\-3 ,  X-Sum - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "31.27 - 37.25 == 31.27 Ratio == 5.2291\n",
      "37.25 - 31.27 == 5.98 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### R\\\\^2\n",
      "Creating ratio df for  R\\\\^2 ,  FiQA - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.55 - 0.55 == 0.55 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Recall\\\\-at\\\\-10\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Visual Dialog  v0.9 - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "90.5 - 90.5 == 90.5 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### SPICE\n",
      "Creating ratio df for  SPICE ,  Flickr30k Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-17 - -17 == -17 Ratio == -inf\n",
      "Creating ratio df for  SPICE ,  COCO Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "-21.2 - -21.2 == -21.2 Ratio == -inf\n",
      "number of sota per dataset/metric:  2\n",
      "####### Weighted\\\\ Macro\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\ Macro\\\\-F1 ,  EmoryNLP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "34.39 - 34.39 == 34.39 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### Cased\\\\ sacreBLEU\n",
      "Creating ratio df for  Cased\\\\ sacreBLEU ,  IWSLT2017 French-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "38.6 - 38.6 == 38.6 Ratio == inf\n",
      "Creating ratio df for  Cased\\\\ sacreBLEU ,  IWSLT2017 English-French - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "39.83 - 39.83 == 39.83 Ratio == inf\n",
      "Creating ratio df for  Cased\\\\ sacreBLEU ,  IWSLT2017 English-Arabic - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "15.2 - 15.2 == 15.2 Ratio == inf\n",
      "Creating ratio df for  Cased\\\\ sacreBLEU ,  IWSLT2017 Arabic-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "33 - 33 == 33 Ratio == inf\n",
      "number of sota per dataset/metric:  4\n",
      "####### ICAT\\\\ Score\n",
      "Creating ratio df for  ICAT\\\\ Score ,  StereoSet - Bias Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "72.03 - 72.97 == 72.03 Ratio == 76.6277\n",
      "72.97 - 72.03 == 0.94 Ratio == 1.0\n",
      "number of sota per dataset/metric:  2\n",
      "####### PA\n",
      "Creating ratio df for  PA ,  SCDE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.299 - 0.299 == 0.299 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### DE\n",
      "Creating ratio df for  DE ,  SCDE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.661 - 0.661 == 0.661 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n",
      "####### BA\n",
      "Creating ratio df for  BA ,  SCDE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "0.717 - 0.717 == 0.717 Ratio == inf\n",
      "number of sota per dataset/metric:  1\n"
     ]
    }
   ],
   "source": [
    "#claculate ratio dataframe and save as csv\n",
    "get_ratio_df_all_per_global = get_ratio_df_per_ito(metricName_df, metricName_negative_list)\n",
    "csv_file_name=\"get_ratio_df_all_per_global_\"+selected_ito+\".AllPOL.csv\"\n",
    "csv_file_name=csv_file_name.replace(\"ito:\", \"\")\n",
    "get_ratio_df_all_per_global.to_csv(csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_count</th>\n",
       "      <th>task</th>\n",
       "      <th>ds</th>\n",
       "      <th>date</th>\n",
       "      <th>model_label</th>\n",
       "      <th>value</th>\n",
       "      <th>percent_of_max_sota</th>\n",
       "      <th>gain</th>\n",
       "      <th>ratio</th>\n",
       "      <th>max_sota</th>\n",
       "      <th>percent_of_max_metric</th>\n",
       "      <th>merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>Text Classification</td>\n",
       "      <td>R8</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>TextEnt-full</td>\n",
       "      <td>-96.7</td>\n",
       "      <td>100.00</td>\n",
       "      <td>-96.7</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-96.7</td>\n",
       "      <td>312.94</td>\n",
       "      <td>Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Text Classification</td>\n",
       "      <td>R8</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>TextEnt-full</td>\n",
       "      <td>91.0</td>\n",
       "      <td>99.24</td>\n",
       "      <td>91.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>91.7</td>\n",
       "      <td>0.99</td>\n",
       "      <td>F\\\\-measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Text Classification</td>\n",
       "      <td>R8</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>NABoE-full</td>\n",
       "      <td>91.7</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>F\\\\-measure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ds_count                 task  ds     date   model_label  value  \\\n",
       "104        1  Text Classification  R8  2018-06  TextEnt-full  -96.7   \n",
       "0          1  Text Classification  R8  2018-06  TextEnt-full   91.0   \n",
       "1          1  Text Classification  R8  2019-09    NABoE-full   91.7   \n",
       "\n",
       "     percent_of_max_sota   gain  ratio max_sota  percent_of_max_metric  \\\n",
       "104               100.00  -96.7   -inf    -96.7                 312.94   \n",
       "0                  99.24   91.0  130.0     91.7                   0.99   \n",
       "1                 100.00    0.7    1.0     91.7                   1.00   \n",
       "\n",
       "           merge  \n",
       "104     Accuracy  \n",
       "0    F\\\\-measure  \n",
       "1    F\\\\-measure  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ratio_df_all_per_global[get_ratio_df_all_per_global[\"ds\"]==\"R8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00101\n",
      "https://identifiers.org/ito:ITO_00113\n",
      "https://identifiers.org/ito:ITO_00115\n",
      "https://identifiers.org/ito:ITO_00126\n",
      "https://identifiers.org/ito:ITO_00131\n",
      "https://identifiers.org/ito:ITO_00137\n",
      "https://identifiers.org/ito:ITO_00141\n",
      "https://identifiers.org/ito:ITO_00145\n",
      "https://identifiers.org/ito:ITO_00310\n",
      "https://identifiers.org/ito:ITO_00485\n",
      "https://identifiers.org/ito:ITO_00491\n",
      "https://identifiers.org/ito:ITO_00528\n",
      "https://identifiers.org/ito:ITO_00600\n",
      "https://identifiers.org/ito:ITO_00873\n",
      "https://identifiers.org/ito:ITO_01532\n",
      "https://identifiers.org/ito:ITO_00506x\n"
     ]
    }
   ],
   "source": [
    "i=0 ###try the rest\n",
    "while i < len(top_level[\"top_level_class\"]):\n",
    "    print(top_level[\"top_level_class\"][i])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00101\n",
      "Number of metrics:  607\n",
      "####### AMrTRE\n",
      "Creating ratio df for  AMrTRE ,  CIMA-10k - BIRL: Benchmark on Image Registration methods with Landmark validations benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MMrTRE\n",
      "Creating ratio df for  MMrTRE ,  CIMA-10k - BIRL: Benchmark on Image Registration methods with Landmark validations benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ target\\\\ overlap\\\\ ratio\n",
      "Creating ratio df for  Mean\\\\ target\\\\ overlap\\\\ ratio ,  CUMC12 - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### RMSE\n",
      "Creating ratio df for  RMSE ,  Automatic Cardiac Diagnosis Challenge (ACDC) - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  RMSE ,  NYU-Depth V2 - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  CARPK - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  RMSE ,  Mid-Air Dataset - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  RMSE ,  KITTI Depth Completion - Depth Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  Make3D - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  VOID - Depth Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  KITTI Depth Completion Validation - Stereo-LiDAR Fusion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  10\n",
      "####### Hausdorff\\\\ Distance\\\\ \\\\(mm\\\\)\n",
      "Creating ratio df for  Hausdorff\\\\ Distance\\\\ \\\\(mm\\\\) ,  Automatic Cardiac Diagnosis Challenge (ACDC) - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Hausdorff\\\\ Distance\\\\ \\\\(mm\\\\) ,  Kumar - Multi-tissue Nucleus Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Hausdorff\\\\ Distance\\\\ \\\\(mm\\\\) ,  CRAG - Colorectal Gland Segmentation: benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### CPU\\\\ \\\\(sec\\\\)\n",
      "Creating ratio df for  CPU\\\\ \\\\(sec\\\\) ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Neg\\\\ Jacob\\\\ Det\n",
      "Creating ratio df for  Neg\\\\ Jacob\\\\ Det ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Grad\\\\ Det\\\\-Jac\n",
      "Creating ratio df for  Grad\\\\ Det\\\\-Jac ,  Automatic Cardiac Diagnosis Challenge (ACDC) - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Dice\n",
      "Creating ratio df for  Dice ,  Automatic Cardiac Diagnosis Challenge (ACDC) - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice ,  Kumar - Multi-tissue Nucleus Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice ,  RITE - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice ,  Anatomical Tracings of Lesions After Stroke (ATLAS)  - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice ,  CRAG - Colorectal Gland Segmentation: benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice ,  Cell17 - Nuclear Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Dice ,  Anatomical Tracings of Lesions After Stroke (ATLAS) - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice ,  2018 Data Science Bowl - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice ,  Osteoarthritis Initiative - Image Registration benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice ,  LIDC-IDRI - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice ,  LiTS2017 - Liver Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  13\n",
      "####### Dice\\\\ \\\\(Average\\\\)\n",
      "Creating ratio df for  Dice\\\\ \\\\(Average\\\\) ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Dice\\\\ \\\\(SE\\\\)\n",
      "Creating ratio df for  Dice\\\\ \\\\(SE\\\\) ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Mean\\\\ Reconstruction\\\\ Error\\\\ \\\\(mm\\\\)\n",
      "Creating ratio df for  Mean\\\\ Reconstruction\\\\ Error\\\\ \\\\(mm\\\\) ,  HumanEva-I - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ Reconstruction\\\\ Error\\\\ \\\\(mm\\\\) ,  NoW Benchmark - 3D Face Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ Reconstruction\\\\ Error\\\\ \\\\(mm\\\\) ,  Stirling-HQ (FG2018 3D face reconstruction challenge) - 3D Face Reconstruction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Mean\\\\ Reconstruction\\\\ Error\\\\ \\\\(mm\\\\) ,  Stirling-LQ (FG2018 3D face reconstruction challenge) - 3D Face Reconstruction benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  2\n",
      "####### MSE\\\\ \\\\(10%\\\\ missing\\\\)\n",
      "Creating ratio df for  MSE\\\\ \\\\(10%\\\\ missing\\\\) ,  KDD CUP Challenge 2018 - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(10%\\\\ missing\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(10%\\\\ missing\\\\) ,  UCI localization data - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(10%\\\\ of\\\\ data\\\\ as\\\\ GT\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(10%\\\\ of\\\\ data\\\\ as\\\\ GT\\\\) ,  PhysioNet Challenge 2012 - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(PM2\\\\.5\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(PM2\\\\.5\\\\) ,  Beijing Air Quality - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Percentage\\\\ error\n",
      "Creating ratio df for  Percentage\\\\ error ,  MNIST - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Percentage\\\\ error ,  SVHN - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Percentage\\\\ error ,  Fashion-MNIST - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Percentage\\\\ error ,  MultiMNIST - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Percentage\\\\ error ,  CIFAR-10, 40 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  17\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  GTSRB - Traffic Sign Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Extended Yale-B - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  UWA3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  coil-100 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Fashion-MNIST - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MNIST-full - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Coil-20 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CAD-120 - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  GPS - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ImageNet ReaL - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Accuracy ,  Office-Home - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Cambridge - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  UT - Human Interaction Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  MNIST - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  FER2013 - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ImageNet - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ImageNet-10 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  Imagenet-dog-15 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Tiny-ImageNet - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  CIFAR-100 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  STL-10 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MSR Daily Activity3D dataset - Multimodal Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Labeled Faces in the Wild - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  HMDBsmall-to-UCF - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Olympic-to-HMDBsmall - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  UCF-to-HMDBsmall - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  UCF-to-Olympic - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  VIVA Hand Gestures Dataset - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Florence 3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  UT-Kinect - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CUB-200-2011 - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  DogCentric - Activity Recognition In Videos benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  UCF-to-HMDBfull - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  CUB-200 - 0-Shot Learning - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CUB 200 50-way (0-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  BIT - Human Interaction Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  YouTube Faces DB - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  Oulu-CASIA - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SYNSIG-to-GTSRB - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  SVNH-to-MNIST - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MNIST-to-MNIST-M - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Synth Signs-to-GTSRB - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ImageCLEF-DA - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Synth Digits-to-SVHN - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  RVL-CDIP - Document Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  MegaFace - Face Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MegaFace - Disguised Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  JAFFE - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Syn2Real-C - Synthetic-to-Real Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  STL-10, 1000 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  CompCars - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10, 4000 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  ICDAR2013 - Scene Text Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SVT - Scene Text Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ICDAR 2003 - Scene Text Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SAT-4 - Satellite Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  SAT-6 - Satellite Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MMI - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  EV-Action - Multimodal Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  VQA v1 test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  VQA v1 test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  MegaFace - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  CACDVS - Age-Invariant Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  CAFR - Age-Invariant Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Collective Activity - Group Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  CMU-PIE - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  YouTube Faces DB - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  AVA - Aesthetics Quality Assessment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  TrackingNet - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Stanford Cars - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  DISFA - Smile Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SUN - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  AWA - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Kuzushiji-MNIST - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Trillion Pairs Dataset - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Trillion Pairs Dataset - Face Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  ModelNet10 - 3D Object Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ModelNet40 - 3D Object Recognition benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CUB Birds - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Stanford Dogs - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Stanford Cars - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Flowers-102 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  HMDBfull-to-UCF - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  VisDA2017 - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  VQA v2 test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Accuracy ,  ReferIt - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 5-Shot, 20-way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 5-Shot, 5-way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 1-Shot, 20-way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 1-Shot, 5-way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  SVHN, 1000 labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  Mini-ImageNet-CUB 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Meta-Dataset - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Stanford Cars 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Stanford Dogs 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Stanford Cars 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  SVHN, 250 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  cifar-100, 10000 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Gaming 3D (G3D) - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  SBU - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Static Facial Expressions in the Wild - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10, 250 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  Volleyball - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  FGVC Aircraft - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  SYSU 3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Cohn-Kanade - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ChaLearn val - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MNIST-to-USPS - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  SVHN-to-MNIST - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  Tiered ImageNet 5-way (5-shot) - Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Tiered ImageNet 10-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Tiered ImageNet 10-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 10-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 10-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 5-way (10-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  USPS - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  LineMOD - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  Volleyball - Group Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  ModelNet40 - 3D Object Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MSRVTT-QA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MSVD-QA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Kinetics-Skeleton dataset - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  FRGC - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CK+ - Face Verification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  EgoGesture - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Stanford Dogs - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Oxford 102 Flowers - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  NABirds - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  USPS-to-MNIST - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  NTU RGB+D 120 - One-Shot 3D Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  BUAA - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SmartWatch - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MGB - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  COCO-Stuff Labels-to-Photos - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  ADE20K Labels-to-Photos - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  ADE20K-Outdoor Labels-to-Photos - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 20-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 20-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "Creating ratio df for  Accuracy ,  TuSimple - Lane Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  STL-10 - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  IJB-B - Face Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  IJB-A - Face Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MovieQA - Video Story QA benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  PETA - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  PA-100K - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  RAP - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  SFEW - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  EMNIST-Balanced - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CUB 200 5-way 1-shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  CUB 200 5-way 5-shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  CIFAR-FS 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Clothing1M - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Food-101N - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Chalearn 2014 - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  IRD - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ICVL-4 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MNIST - Unsupervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  N-UCLA - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  ARL Polarimetric Thermal Face Dataset - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ARL Polarimetric Thermal Face Dataset - Multi-view Subspace Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ORL - Multi-view Subspace Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ChaLean test - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  NVGesture - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10 - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR100 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Caltech-256 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Caltech-256, 1024 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Caltech-101 - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Real-World Affective Faces - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  FC100 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  FC100 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Oxford-IIIT Pets - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Mini-ImageNet - 1-Shot Learning - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Noisy MNIST (Contrast) - Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Noisy MNIST (Motion) - Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Noisy Bangla Characters - Document Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  n-MNIST - Document Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Noisy Bangla Numeral - Document Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Chinese License Plates - License Plate Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Potsdam - Unsupervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  COCO-Stuff-15 - Unsupervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Potsdam-3 - Unsupervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  COCO-Stuff-3 - Unsupervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-20 - Unsupervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  STL-10 - Unsupervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10 - Unsupervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Pavia University - Classification Of Hyperspectral Images benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CLEVR - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  FERPlus - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  FG-NET - Age-Invariant Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CINIC-10 - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MNIST-test - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  TallyQA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  HowmanyQA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  BDD100K - Steering Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Birdsnap - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ChaLearn 2016 - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ChaLearn 2013 - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MSRC-12 - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Tiered ImageNet 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Tiered ImageNet 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  FC100 5-way (10-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Diving-48 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  LetterA-J - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  UTD-MHAD - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Occlusion LineMOD - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  LboroHAR - Multimodal Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  street2shop - topwear - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Northwestern University - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CapgMyo DB-c - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Ninapro DB-1 8 gestures - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Ninapro DB-1 12 gestures - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CapgMyo DB-b - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  FERG - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 1-Shot, 423 way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 5-Shot, 423 way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 1-Shot, 1000 way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 5-Shot, 1000 way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  TDIUC - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  GQA test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  DRIVE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  LUNA - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Stanford Dogs 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Office-Home - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  CIFAR-FS 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-ImageNet-CUB 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  miniSports - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  AWA1 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  aPY - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  AWA2 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  EMNIST-Letters - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SVHN - Sparse Representation-based Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SVHN, 2000 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SVHN, 4000 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10, 500 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10, 1000 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SVHN, 500 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10, 2000 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  STL-10, 5000 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CMU Multi-Modal Activity (CMU-MMAC) - Multimodal Activity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  MSR Action3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  UPenn Action - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  GQA test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  AgeDB-30 - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CFP-FP - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  DHG-28 - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  DHG-14 - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Montgomery County - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  UCF --> HMDB (full) - Domain Adaptation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  HMDB --> UCF (full) - Domain Adaptation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  BDD100K - Lane Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-AR) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (QA-R) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-A) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-AR) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  NLVR2 Dev - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  mini-ImageNet - 100-Way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  NLVR2 Test - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-A) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (QA-R) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Nurse Care Activity Recognition Challenge - Multimodal Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Flowers-102 - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  FER+ - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Food-101 - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Mini-ImageNet to CUB - 5 shot learning - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MNIST - Handwritten Digit Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  547\n",
      "####### Percentage\\\\ correct\n",
      "Creating ratio df for  Percentage\\\\ correct ,  CIFAR-10 - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  Percentage\\\\ correct ,  CIFAR-100 - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 13\n",
      "Creating ratio df for  Percentage\\\\ correct ,  STL-10 - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 2.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) abstract images 1.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) abstract 1.0 multiple choice - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 1.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 1.0 multiple choice - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual7W - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual Genome (subjects) - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual Genome (pairs) - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  cifar10, 250 Labels - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  38\n",
      "####### Classification\\\\ Error\n",
      "Creating ratio df for  Classification\\\\ Error ,  Hopkins155 - Motion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Classification\\\\ Error ,  RaFD - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Classification\\\\ Error ,  75 Superpixel MNIST - Superpixel Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Classification\\\\ Error ,  smallNORB - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Classification\\\\ Error ,  MTPV62 - Motion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### NMI\n",
      "Creating ratio df for  NMI ,  Fashion-MNIST - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  NMI ,  USPS - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  NMI ,  Coil-20 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  NMI ,  Extended Yale-B - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  NMI ,  MNIST-test - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  NMI ,  MNIST-full - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  NMI ,  coil-100 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  NMI ,  ImageNet-10 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  NMI ,  STL-10 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  NMI ,  Imagenet-dog-15 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  NMI ,  CIFAR-10 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  NMI ,  Tiny-ImageNet - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  NMI ,  CIFAR-100 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  NMI ,  CMU-PIE - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  NMI ,  YouTube Faces DB - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  NMI ,  FRGC - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  NMI ,  Stanford Cars - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  NMI ,  Stanford Dogs - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  NMI ,  UMist - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NMI ,  CUB Birds - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  NMI ,  LetterA-J - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  68\n",
      "####### Top\\\\ 1\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  ImageNet - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 20\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  ImageNet - Self-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  Moments in Time - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  iNaturalist - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  Something-Something V1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  Jester test - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  Jester val - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  iNaturalist - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  ImageNet - 10% labeled data - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  47\n",
      "####### Top\\\\ 5\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  ImageNet - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 20\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  ImageNet - 10% labeled data - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  Moments in Time - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  iNaturalist - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  Something-Something V1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  Jester val - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  ImageNet - 1% labeled data - Semi-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  ImageNet - Self-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  ObjectNet - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  ObjectNet (Bounding Box) - Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  39\n",
      "####### Number\\\\ of\\\\ params\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ImageNet - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### 3\\\\-fold\\\\ Accuracy\n",
      "Creating ratio df for  3\\\\-fold\\\\ Accuracy ,  UCF101 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  3\\\\-fold\\\\ Accuracy ,  UCF101 - Self-Supervised Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  12\n",
      "####### Top\\\\-1\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  CUB-200-2011 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  Something-Something V2 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  iNaturalist 2018 - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  Kinetics-600 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  Something-Something V1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  HMDB51 - Self-Supervised Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  MiniKinetics - Action Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  VTAB-1k - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  ObjectNet - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  EPIC-KITCHENS-55 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  EgoGesture - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  26\n",
      "####### Average\\\\ MPJPE\\\\ \\\\(mm\\\\)\n",
      "Creating ratio df for  Average\\\\ MPJPE\\\\ \\\\(mm\\\\) ,  Human3.6M - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ MPJPE\\\\ \\\\(mm\\\\) ,  Human3.6M - Monocular 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ MPJPE\\\\ \\\\(mm\\\\) ,  Total Capture - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ MPJPE\\\\ \\\\(mm\\\\) ,  Human3.6M - Weakly-supervised 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  7\n",
      "####### ARI\n",
      "Creating ratio df for  ARI ,  CIFAR-10 - Image Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  ARI ,  nuScenes-FB - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ARI ,  nuScenes-F - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### MAP\n",
      "Creating ratio df for  MAP ,  PASCAL VOC 2007 - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  MAP ,  Charades - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  MAP ,  PASCAL VOC 2007 - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MAP ,  PASCAL VOC 2012 - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  Charades - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  MAP ,  HICO-DET - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MAP ,  PASCAL VOC 2007 - Real-Time Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  Watercolor2k - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAP ,  COCO - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  Oxf105k - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  MAP ,  Visual Genome - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAP ,  Oxf5k - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  CUHK03 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  PASCAL VOC 2012 test - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  MAP ,  CUHK-SYSU - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  PeopleArt - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  ImageNet - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAP ,  CUHK03 labeled - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  MAP ,  CUHK03 detected - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  MAP ,  COCO - Real-Time Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  COCO minival - Real-Time Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  ImageNet VID - Video Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MAP ,  DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  CUHK03 (detected) - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  MAP ,  MAFA - Occluded Face Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAP ,  NYU Depth v2 - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  OCCLUSION - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  Comic2k - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  Clipart1k - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  Tsinghua-Tencent 100K - Traffic Sign Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAP ,  Bosch Small Traffic Lights - Traffic Sign Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAP ,  V-COCO - Human-Object Interaction Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MAP ,  IconArt - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  PeopleArt - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  CIFAR-10 - Quantization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  NUS-WIDE - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  117\n",
      "####### Error\\\\ rate\n",
      "Creating ratio df for  Error\\\\ rate ,  AFLW2000 - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Error\\\\ rate ,  Montalbano - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Average\\\\ accuracy\\\\ of\\\\ 3\\\\ splits\n",
      "Creating ratio df for  Average\\\\ accuracy\\\\ of\\\\ 3\\\\ splits ,  HMDB-51 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Average\\\\ accuracy\\\\ of\\\\ 3\\\\ splits ,  JHMDB (2D poses only) - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  7\n",
      "####### Rank\\\\-1\n",
      "Creating ratio df for  Rank\\\\-1 ,  Market-1501 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 15\n",
      "Creating ratio df for  Rank\\\\-1 ,  DukeMTMC-reID - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Rank\\\\-1 ,  CUHK03 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Rank\\\\-1 ,  CUHK-SYSU - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Rank\\\\-1 ,  MSMT17 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Rank\\\\-1 ,  CUHK03 detected - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Rank\\\\-1 ,  CUHK03 labeled - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Rank\\\\-1 ,  MARS - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Rank\\\\-1 ,  Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Rank\\\\-1 ,  DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Rank\\\\-1 ,  CUHK03 (detected) - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Rank\\\\-1 ,  PRID2011 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Rank\\\\-1 ,  MSMT17->DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-1 ,  UAV-Human - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-1 ,  DukeTracklet - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-1 ,  Market-1501->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-1 ,  DukeMTMC-reID->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-1 ,  iLIDS-VID - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-1 ,  DukeMTMC-reID->Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-1 ,  Market-1501->DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  83\n",
      "####### mAP\n",
      "Creating ratio df for  mAP ,  Market-1501 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 13\n",
      "Creating ratio df for  mAP ,  DukeMTMC-reID - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "Creating ratio df for  mAP ,  HICO - Human-Object Interaction Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mAP ,  Multi-THUMOS - Action Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  Par6k - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAP ,  Par106k - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAP ,  ActivityNet - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  MEXaction2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  MSMT17 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  UAV-Human - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  Charades - Action Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mAP ,  ActivityNet-1.3 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  THUMOSâ€™14 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  ActivityNet-1.2 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  MARS - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAP ,  HICO-DET - Human-Object Interaction Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  mAP ,  PoseTrack2017 - Pose Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAP ,  Duke to Market - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  Market to Duke - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  MSMT17->DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  Duke to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  Market to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  UAV-Human - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  Cityscapes-to-Foggy Cityscapes - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  ImageNet Detection - Zero-Shot Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  PoseTrack2018 - Pose Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  DOTA - Object Detection In Aerial Images benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  Ambiguious-HOI - Human-Object Interaction Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  DukeTracklet - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  MS-COCO - Zero-Shot Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  Market-1501->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  DukeMTMC-reID->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  AVA v2.2 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  ActEV - Activity Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  ScanNet - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  ScanNet(v2) - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  mAP ,  UCF101-24 - Action Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  DukeMTMC-reID->Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  Market-1501->DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  THUMOS\\'14 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  nuScenes - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  NYU-Depth V2 - Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  Con-Text - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  Bottles - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  120\n",
      "####### Video\\\\ hit\\\\-at\\\\-1\n",
      "Creating ratio df for  Video\\\\ hit\\\\-at\\\\-1 ,  Sports-1M - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Video\\\\ hit\\\\-at\\\\-1 ,  miniSports - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Video\\\\ hit\\\\-at\\\\-5\n",
      "Creating ratio df for  Video\\\\ hit\\\\-at\\\\-5 ,  Sports-1M - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Video\\\\ hit\\\\-at\\\\-5 ,  miniSports - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Clip\\\\ Hit\\\\-at\\\\-1\n",
      "Creating ratio df for  Clip\\\\ Hit\\\\-at\\\\-1 ,  Sports-1M - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Clip\\\\ Hit\\\\-at\\\\-1 ,  miniSports - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(CV\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\) ,  NTU RGB+D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\) ,  NTU RGB+D - Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(CS\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CS\\\\) ,  NTU RGB+D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CS\\\\) ,  NTU RGB+D - Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CS\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CS\\\\) ,  UTD-MHAD - Multimodal Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Average\\\\ Accuracy\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  VIRAT Ground 2.0 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Office-Caltech - Domain Adaptation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Office-31 - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Scan2CAD - 3D Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  ScanNet - Scene Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  BP4D - Facial Action Unit Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  UAV-Human - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  EGTEA - Egocentric Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  20\n",
      "####### Mean\\\\ IoU\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2012 test - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SkyScapes-Lane - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SkyScapes-Dense - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Mean\\\\ IoU ,  CamVid - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SUN-RGBD - Scene Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PhC-U373 - Cell Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  DIC-HeLa - Cell Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2011 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2012 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  NYU Depth v2 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  S3DIS - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Mean\\\\ IoU ,  ISIC 2017 - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  ShapeNet - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2007 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  LineMOD - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  LineMOD - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  CIHP - Human Part Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SUN-RGBD - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  Freiburg Forest - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  ScanNetV2 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SYNTHIA-CVPRâ€™16 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  MHP v2.0 - Human Part Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2012 val - Weakly-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2012 test - Weakly-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  S3DIS Area5 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  FSS-1000 - Few-Shot Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  ADE20K val - Scene Understanding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  55\n",
      "####### PCK\n",
      "Creating ratio df for  PCK ,  Leeds Sports Poses - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "number of sota per dataset/metric:  7\n",
      "####### AP\n",
      "Creating ratio df for  AP ,  WIDER Face (Hard) - Face Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  WIDER Face (Medium) - Face Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  PASCAL Face - Face Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  AP ,  FDDB - Face Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  AP ,  Annotated Faces in the Wild - Face Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  SKU-110K - Dense Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  KITTI Cars Moderate val - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  WIDER Face (Easy) - Face Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  MPII Multi-Person - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  KITTI Cars Hard - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  KITTI Cars Easy - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  KITTI Cars Moderate - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  COCO - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  KITTI Cars Hard val - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cars Easy val - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cars Easy val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Cars Moderate val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Cars Hard val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  COCO test-dev - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  AP ,  COCO test-dev - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  COCO test-challenge - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  WAF - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  Cityscapes test - Edge Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Cars Moderate - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cyclists Easy - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Pedestrians Hard - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Pedestrians Easy - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cars Hard - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Pedestrians Moderate - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cyclists Moderate - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cyclists Hard - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cars Easy - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Pedestrian Easy val - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Cars Easy - Birds Eye View Object Detection benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Pedestrian Moderate val - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Cyclist Moderate val - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Cyclist Easy val - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Cars Hard - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Cyclist Hard val - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Pedestrian Hard val - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Pedestrians Easy - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Cars Moderate - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  AP ,  KITTI Cyclists Easy - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  AP ,  KITTI Cyclists Hard - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  KITTI Cars Hard - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  AP ,  KITTI Pedestrians Hard - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  KITTI Pedestrians Moderate - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  KITTI Cyclists Moderate - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP ,  KITTI Cars Easy - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  AP ,  KITTI Cyclists Moderate - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Pedestrians Moderate - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Pedestrian Moderate val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cyclist Moderate val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cyclist Easy val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Pedestrian Hard val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  KITTI Cyclist Hard val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Pedestrian Easy val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  KITTI Cars Moderate - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  DensePose-COCO - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  OCHuman - Human Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  CrowdHuman (full body) - Object Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  COCO minival - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  nuScenes-FB - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  nuScenes-F - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Cyclists Easy - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Pedestrians Hard - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Cyclists Hard - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  KITTI Pedestrians Easy - Birds Eye View Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  181\n",
      "####### NME\n",
      "Creating ratio df for  NME ,  MAFL - Unsupervised Facial Landmark Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NME ,  300W - Facial Landmark Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NME ,  AFLW-PIFA (34 points) - Face Alignment benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  NME ,  AFLW-PIFA (21 points) - Face Alignment benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  NME ,  AFLW-MTFL - Unsupervised Facial Landmark Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  NME ,  300W - Unsupervised Facial Landmark Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  NME ,  AFLW (Zhang CVPR 2018 crops) - Unsupervised Facial Landmark Detection benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  6\n",
      "####### EER\n",
      "Creating ratio df for  EER ,  Replay-Attack - Face Anti-Spoofing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  EER ,  CASIA-MFSD - Face Anti-Spoofing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  EER ,  UBI-Fights - Abnormal Event Detection In Video benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  EER ,  UBI-Fights - Semi-supervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### mIoU\n",
      "Creating ratio df for  mIoU ,  GTAV-to-Cityscapes Labels - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mIoU ,  COCO-Stuff test - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  PASCAL Context - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  mIoU ,  CamVid - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  Cityscapes test - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  mIoU ,  Kvasir-Instrument - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  PASCAL-Part - Human Part Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  Cityscapes val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  Semantic3D - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  Cityscapes val - Video Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mIoU ,  YouTube - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mIoU ,  PASCAL VOC 2012 val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  ADE20K val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  mIoU ,  S3DIS Area5 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  SemanticKITTI - 3D Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  mIoU ,  NYU Depth v2 - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mIoU ,  SYNTHIA Fall-to-Winter - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mIoU ,  GTAV-to-Cityscapes Labels - Synthetic-to-Real Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  mIoU ,  LIP val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  COCO-Stuff Labels-to-Photos - Image-to-Image Translation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mIoU ,  ADE20K-Outdoor Labels-to-Photos - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mIoU ,  Cityscapes Labels-to-Photo - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mIoU ,  ADE20K Labels-to-Photos - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mIoU ,  S3DIS - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  2018 Data Science Bowl - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mIoU ,  SYNTHIA-to-Cityscapes - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mIoU ,  MICHE - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  CASIA - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  UBIRIS - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  ParisLille3D - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  S3DIS - 3D Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  Montgomery County - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  LUNA - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  DRIVE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  Mapillary val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  Cityscapes val - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  BDD - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  GTAV-to-Cityscapes Labels - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  YouTube - Unsupervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  COCO-Stuff - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  132\n",
      "####### Classification\\\\ Accuracy\n",
      "Creating ratio df for  Classification\\\\ Accuracy ,  SVNH-to-MNIST - Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Classification\\\\ Accuracy ,  Synth Objects-to-LINEMOD - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Classification\\\\ Accuracy ,  ModelNet40 - 3D Object Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### bits/dimension\n",
      "Creating ratio df for  bits/dimension ,  CIFAR-10 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  bits/dimension ,  MNIST - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Mean\\\\ PCK\n",
      "Creating ratio df for  Mean\\\\ PCK ,  Pascal3D+ - Keypoint Detection benchmarking , ds_count= 1\n",
      "null\n",
      "####### Validation\\\\ mIoU\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  ADE20K - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Pascal VOC 2012 2% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 12.5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 25% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 50% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Pascal VOC 2012 5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Pascal VOC 2012 12.5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  PASCAL Context 12.5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 2% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  PASCAL Context 25% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  23\n",
      "####### PCKh\\\\-0\\\\.5\n",
      "Creating ratio df for  PCKh\\\\-0\\\\.5 ,  MPII Human Pose - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "number of sota per dataset/metric:  11\n",
      "####### Accuracy\\\\ \\\\(RGB\\\\+pose\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(RGB\\\\+pose\\\\) ,  J-HMDB - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Reasonable\\\\ Miss\\\\ Rate\n",
      "Creating ratio df for  Reasonable\\\\ Miss\\\\ Rate ,  Caltech - Pedestrian Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Precision\n",
      "Creating ratio df for  Precision ,  ICDAR 2013 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Precision ,  CT-150 - Pancreas Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Precision ,  Anatomical Tracings of Lesions After Stroke (ATLAS)  - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  Montalbano - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  TrackingNet - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Precision ,  ICDAR 2015 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Precision ,  COCO-Text - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Precision ,  Anatomical Tracings of Lesions After Stroke (ATLAS) - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  MSRA-TD500 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Precision ,  Total-Text - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Precision ,  ICDAR 2017 MLT - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Precision ,  SCUT-CTW1500 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Precision ,  Mall - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  OTB-2015 - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  41\n",
      "####### Recall\n",
      "Creating ratio df for  Recall ,  ICDAR 2013 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Recall ,  Anatomical Tracings of Lesions After Stroke (ATLAS)  - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  CT-150 - Pancreas Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Recall ,  Montalbano - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall ,  CrossTask - Temporal Action Localization benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Recall ,  3DMatch Benchmark - Point Cloud Registration benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Recall ,  ICDAR 2015 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Recall ,  COCO-Text - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Recall ,  Anatomical Tracings of Lesions After Stroke (ATLAS) - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  MSRA-TD500 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Recall ,  Total-Text - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Recall ,  ICDAR 2017 MLT - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Recall ,  SCUT-CTW1500 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Recall ,  Pupil - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall ,  MS-COCO - Zero-Shot Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  46\n",
      "####### F\\\\-Measure\n",
      "Creating ratio df for  F\\\\-Measure ,  ICDAR 2013 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  F\\\\-Measure ,  SCUT-CTW1500 - Curved Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F\\\\-Measure ,  ICDAR 2015 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  F\\\\-Measure ,  COCO-Text - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F\\\\-Measure ,  MSRA-TD500 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F\\\\-Measure ,  Total-Text - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F\\\\-Measure ,  ICDAR 2017 MLT - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  F\\\\-Measure ,  SK-LARGE - Object Skeleton Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F\\\\-Measure ,  SCUT-CTW1500 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F\\\\-Measure ,  IC19-ReCTs - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  43\n",
      "####### Text\\\\-to\\\\-image\\\\ R@1\n",
      "Creating ratio df for  Text\\\\-to\\\\-image\\\\ R@1 ,  COCO 2014 - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Text\\\\-to\\\\-image\\\\ R@1 ,  Flickr30k - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Text\\\\-to\\\\-image\\\\ R@5\n",
      "Creating ratio df for  Text\\\\-to\\\\-image\\\\ R@5 ,  COCO 2014 - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Text\\\\-to\\\\-image\\\\ R@5 ,  Flickr30k - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Text\\\\-to\\\\-image\\\\ R@10\n",
      "Creating ratio df for  Text\\\\-to\\\\-image\\\\ R@10 ,  COCO 2014 - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Text\\\\-to\\\\-image\\\\ R@10 ,  Flickr30k - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### R\\\\-at\\\\-1\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Flickr30K 1K test - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Handbags - Sketch-Based Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Chairs - Sketch-Based Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Pix3D - 3D Shape Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  CUB-200-2011 - Metric Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  SOP - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  CARS196 - Metric Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  CARS196 - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Shoes - Sketch-Based Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  In-Shop - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  CUB-200-2011 - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Flickr30k Entities Dev - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  52\n",
      "####### R\\\\-at\\\\-10\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Flickr30K 1K test - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Handbags - Sketch-Based Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Chairs - Sketch-Based Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Shoes - Sketch-Based Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Flickr30k Entities Dev - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  26\n",
      "####### Recall\\\\-at\\\\-10\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  COCO (image as query) - Text-Image Retrieval benchmarking , ds_count= 1\n",
      "null\n",
      "####### Image\\\\-to\\\\-text\\\\ R\\\\-at\\\\-1\n",
      "Creating ratio df for  Image\\\\-to\\\\-text\\\\ R\\\\-at\\\\-1 ,  COCO 2014 - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Image\\\\-to\\\\-text\\\\ R\\\\-at\\\\-1 ,  Flickr30k - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Image\\\\-to\\\\-text\\\\ R\\\\-at\\\\-10\n",
      "Creating ratio df for  Image\\\\-to\\\\-text\\\\ R\\\\-at\\\\-10 ,  COCO 2014 - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Image\\\\-to\\\\-text\\\\ R\\\\-at\\\\-10 ,  Flickr30k - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Image\\\\-to\\\\-text\\\\ R\\\\-at\\\\-5\n",
      "Creating ratio df for  Image\\\\-to\\\\-text\\\\ R\\\\-at\\\\-5 ,  COCO 2014 - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Image\\\\-to\\\\-text\\\\ R\\\\-at\\\\-5 ,  Flickr30k - Cross-Modal Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Time\\\\ \\\\(ms\\\\)\n",
      "Creating ratio df for  Time\\\\ \\\\(ms\\\\) ,  CamVid - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Time\\\\ \\\\(ms\\\\) ,  Cityscapes test - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Mean\\\\ IoU\\\\ \\\\(class\\\\)\n",
      "Creating ratio df for  Mean\\\\ IoU\\\\ \\\\(class\\\\) ,  Cityscapes test - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  Mean\\\\ IoU\\\\ \\\\(class\\\\) ,  KITTI Semantic Segmentation - Semantic Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  13\n",
      "####### Frame\\\\ \\\\(fps\\\\)\n",
      "Creating ratio df for  Frame\\\\ \\\\(fps\\\\) ,  Cityscapes test - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Frame\\\\ \\\\(fps\\\\) ,  CamVid - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Frame\\\\ \\\\(fps\\\\) ,  MSCOCO - Real-time Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### PSNR\n",
      "Creating ratio df for  PSNR ,  Urban100 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  PSNR ,  Set5 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "Creating ratio df for  PSNR ,  FFHQ 1024 x 1024 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Manga109 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  PSNR ,  FFHQ 256 x 256 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  BSD100 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 13\n",
      "Creating ratio df for  PSNR ,  Vid4 - 4x upscaling - Video Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  PSNR ,  Set14 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 13\n",
      "Creating ratio df for  PSNR ,  Darmstadt Noise Dataset - Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma15 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Urban100 sigma15 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  VggFace2 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  Urban100 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  PSNR ,  Set14 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  PSNR ,  BSD100 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  PSNR ,  WebFace - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Set5 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  PSNR ,  Set5 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  BSD100 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  BSD200 sigma10 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  Live1 (Quality 10 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Set14 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  BSD200 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  BSD200 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  BSD200 sigma30 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  LIVE1 (Quality 20 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Urban100 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma25 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma15 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma35 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  LIVE1 (Quality 40 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  LIVE1 (Quality 30 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Classic5 (Quality 30 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Urban100 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Classic5 (Quality 20 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Classic5 (Quality 10 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Classic5 (Quality 40 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  FFHQ 512 x 512 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma50 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  Freiburg Forest Dataset - Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  EPFL NIR-VIS - Multimodal Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma35 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma5 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  NTU Hand Digit - Gesture-to-Gesture Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Senz3D - Gesture-to-Gesture Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  Vimeo90k - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  LIVE1 (Quality 20 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  LIVE1 (Quality 10 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma75 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  McMaster sigma75 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma15 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  McMaster sigma35 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma35 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  McMaster sigma50 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma75 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  McMaster sigma25 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma25 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  McMaster sigma15 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma35 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma25 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma15 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma50 - Color Image Denoising benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma15 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set12 sigma15 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma35 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma60 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma75 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set12 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  ICB (Quality 10 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Urban100 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  Set12 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  ICB (Quality 20 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  ICB (Quality 30 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  ICB (Quality 10 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  ICB (Quality 20 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Urban100 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set12 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  VggFace2 - Facial Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  WebFace - Facial Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Manga109 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  Manga109 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Sun80 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  CUFED5 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  KITTI 2015 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  KITTI 2012 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Middlebury - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  KITTI 2012 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  KITTI 2015 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Middlebury - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set14 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Set5 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  X4K1000FPS - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  UCF101 - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  DAVIS sigma40 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set8 sigma30 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set8 sigma40 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  DAVIS sigma50 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  DAVIS sigma10 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  Set8 sigma10 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  DAVIS sigma20 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  Set8 sigma50 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  DAVIS sigma30 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set8 sigma20 - Video Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Manga109 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  BSD100 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  Urban100 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  DIV2K val - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  DIV2K val - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set12 sigma30 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  CelebA Aligned - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  CelebA + AFLW Unaligned - Face Alignment benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Celeb-HQ 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  USR-248 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Urban100 - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Manga109 - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD100 - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  DIV2K val - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  DIV8K val - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  SOTS Indoor - Image Dehazing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  SOTS Outdoor - Image Dehazing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  cvusa - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Dayton (256Ã—256) - aerial-to-ground - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR ,  Middlebury - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  269\n",
      "####### Average\\\\ PSNR\n",
      "Creating ratio df for  Average\\\\ PSNR ,  Xiph HD - 4x upscaling - Video Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ PSNR ,  Ultra Video Group HD - 4x upscaling - Video Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ PSNR ,  REDS - Deblurring benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ PSNR ,  LOL - Low-Light Image Enhancement benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### SSIM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  SSIM ,  Set5 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  SSIM ,  FFHQ 256 x 256 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  SSIM ,  FFHQ 1024 x 1024 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  SSIM ,  Vid4 - 4x upscaling - Video Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  SSIM ,  Manga109 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  SSIM ,  Urban100 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  SSIM ,  BSD100 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  SSIM ,  Set14 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  SSIM ,  BSD100 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  SSIM ,  Set14 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  SSIM ,  Set5 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  SSIM ,  Set5 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  BSD100 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  BSD200 sigma10 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  BSD200 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  BSD200 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Set14 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  BSD200 sigma30 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  FFHQ 512 x 512 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  SSIM ,  Dayton (256Ã—256) - ground-to-aerial - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  Dayton (64x64) - ground-to-aerial - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  Dayton (64Ã—64) - aerial-to-ground - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  Ego2Top - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  SSIM ,  Dayton (256Ã—256) - aerial-to-ground - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  cvusa - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  SSIM ,  Deep-Fashion - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  LIVE1 (Quality 20 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  LIVE1 (Quality 10 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  LIVE1 (Quality 20 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  Live1 (Quality 10 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  CUHK - Face Sketch Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  Human3.6M - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  ICB (Quality 20 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  ICB (Quality 10 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  ICB (Quality 20 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  ICB (Quality 30 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  ICB (Quality 10 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  ShapeNet Chair - Novel View Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  ShapeNet Car - Novel View Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  KITTI Novel View Synthesis - Novel View Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Synthia Novel View Synthesis - Novel View Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Urban100 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  CUFS - Face Sketch Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  CUFSF - Face Sketch Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Manga109 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  SSIM ,  Manga109 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  X4K1000FPS - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  UCF101 - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Vimeo90k - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Urban100 - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  SSIM ,  Urban100 - 3x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  Market-1501 - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Set5 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  Manga109 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  Set14 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  BSD100 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  Urban100 - 8x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SSIM ,  DIV2K val - 2x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  DIV2K val - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  CelebA Aligned - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  CelebA + AFLW Unaligned - Face Alignment benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM ,  Celeb-HQ 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  USR-248 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Urban100 - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  DIV2K val - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  BSD100 - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  DIV8K val - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Manga109 - 16x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  SOTS Indoor - Image Dehazing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  SOTS Outdoor - Image Dehazing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Middlebury - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  126\n",
      "####### FID\n",
      "Creating ratio df for  FID ,  FFHQ 256 x 256 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  FID ,  FFHQ 1024 x 1024 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  FID ,  CUB 128 x 128 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  Stanford Dogs - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  Stanford Cars - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  FFHQ 512 x 512 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  CUB - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Edge-to-Shoes - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Edge-to-Handbags - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients - Fundus to Angiography Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CAT 256x256 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CIFAR-10 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  FID ,  LSUN Bedroom 64 x 64 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  Cityscapes Labels-to-Photo - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  COCO-Stuff Labels-to-Photos - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  ADE20K-Outdoor Labels-to-Photos - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  ADE20K Labels-to-Photos - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  FFHQ 512 x 512 - 16x upscaling - Face Hallucination benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  COCO - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  LSUN Bedroom 256 x 256 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Oxford 102 Flowers - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  CelebA-HQ 256x256 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  LSUN Churches 256 x 256 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CelebA-HQ 1024x1024 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  FFHQ - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  LSUN Cat 256 x 256 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  CIFAR-10 - Conditional Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  ImageNet 128x128 - Conditional Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  STL-10 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  Visual Genome 64x64 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  COCO-Stuff 64x64 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CelebA-HQ - Multimodal Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  AFHQ - Multimodal Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  ImageNet 128x128 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  FID ,  ImageNet 256x256 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CelebA-HQ 128x128 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CelebA-HQ 64x64 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  TrailerFaces - Video Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  VoxCeleb2 - 8-shot learning - Talking Head Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  VoxCeleb1 - 32-shot learning - Talking Head Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  VoxCeleb1 - 1-shot learning - Talking Head Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  VoxCeleb1 - 8-shot learning - Talking Head Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  VoxCeleb2 - 32-shot learning - Talking Head Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  VoxCeleb2 - 1-shot learning - Talking Head Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CelebA 256x256 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Fashion-MNIST - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  MNIST - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  Kinetics-600 48 frames, 64x64 - Video Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Kinetics-600 12 frames, 64x64 - Video Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Kinetics-600 12 frames, 128x128 - Video Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  COCO-Stuff 128x128 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  Visual Genome 128x128 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Stacked MNIST - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CelebA 128 x 128 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Edge-to-Clothes - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Deep-Fashion - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Street Scene - Video-to-Video Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  YouTube Dancing - Video-to-Video Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CIFAR-100 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  ImageNet 32x32 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  ADE-Indoor Labels-to-Photo - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Cityscapes-5K 256x512 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  Cityscapes-25K 256x512 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  ADE-Indoor - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  LSUN Horse 256 x 256 - Image Generation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  LSUN Car 512 x 384 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  AFHQ - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  CelebA-HQ - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  Deep-Fashion - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  96\n",
      "####### MOVIE\n",
      "Creating ratio df for  MOVIE ,  Vid4 - 4x upscaling - Video Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MS\\\\-SSIM\n",
      "Creating ratio df for  MS\\\\-SSIM ,  FFHQ 256 x 256 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MS\\\\-SSIM ,  FFHQ 1024 x 1024 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MS\\\\-SSIM ,  FFHQ 512 x 512 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MS\\\\-SSIM ,  CelebA + AFLW Unaligned - Face Alignment benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MS\\\\-SSIM ,  CelebA Aligned - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### TAR\\\\ at\\\\ FAR=0\\\\.01\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.01 ,  IJB-C - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.01 ,  IJB-A - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.01 ,  BUAA-VisNir - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.01 ,  Oulu-CASIA NIR-VIS - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.01 ,  IJB-B - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.01 ,  IIIT-D Viewed Sketch - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  16\n",
      "####### Permuted\\\\ Accuracy\n",
      "Creating ratio df for  Permuted\\\\ Accuracy ,  Sequential MNIST - Sequential Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Unpermuted\\\\ Accuracy\n",
      "Creating ratio df for  Unpermuted\\\\ Accuracy ,  Sequential MNIST - Sequential Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Unpermuted\\\\ Accuracy ,  Sequential CIFAR-10 - Sequential Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  6\n",
      "####### F1\n",
      "Creating ratio df for  F1 ,  Caltech Lanes Washington - Lane Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  Caltech Lanes Cordova - Lane Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  Sydney Urban Objects - 3D Point Cloud Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  BP4D - Facial Action Unit Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  MICHE - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  CASIA - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  UBIRIS - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  BSDS500 - Edge Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Rebar Head - Head Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  16\n",
      "####### MOTA\n",
      "Creating ratio df for  MOTA ,  MOT16 - Multi-Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MOTA ,  KITTI Tracking test - Multiple Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MOTA ,  Multi-Person PoseTrack - Pose Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MOTA ,  PoseTrack2017 - Pose Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  MOTA ,  KITTI - 3D Multi-Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MOTA ,  PoseTrack2018 - Pose Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MOTA ,  MOT17 - Multi-Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MOTA ,  MOT16 - Online Multi-Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MOTA ,  2D MOT 2015 - Online Multi-Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MOTA ,  MOT17 - Online Multi-Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MOTA ,  2D MOT 2015 - Multi-Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MOTA ,  MOT15 - Online Multi-Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  25\n",
      "####### R\\\\-at\\\\-5\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Flickr30K 1K test - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Flickr30k Entities Dev - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  19\n",
      "####### Dice\\\\ Score\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2013 leaderboard - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2013 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  CT-150 - Pancreas Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  TCIA Pancreas-CT Dataset - Pancreas Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2015 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  ISLES-2015 - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  PROMISE 2012 - Volumetric Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  TCIA Pancreas-CT - 3D Medical Imaging Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2017 val - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2014 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  iSEG 2017 Challenge - Infant Brain MRI Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  iSEG 2017 Challenge - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice\\\\ Score ,  BUS 2017 Dataset B - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  ISIC 2018 - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS 2018 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  T1-weighted MRI - Brain Image Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS 2018 val - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  HSVM - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  CHAOS MRI Dataset - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  Brain MRI segmentation - Brain Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  Lung Nodule  - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  29\n",
      "####### Warping\\\\ Error\n",
      "Creating ratio df for  Warping\\\\ Error ,  ISBI 2012 EM Segmentation - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### DSC\n",
      "Creating ratio df for  DSC ,  Kvasir-Instrument - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mean\\\\ Dice\n",
      "Creating ratio df for  mean\\\\ Dice ,  Kvasir-SEG - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mean\\\\ Dice ,  CVC-ClinicDB - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Average\\\\ MAE\n",
      "Creating ratio df for  Average\\\\ MAE ,  Kvasir-SEG - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ MAE ,  SOC - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  3\n",
      "####### S\\\\-Measure\n",
      "Creating ratio df for  S\\\\-Measure ,  Kvasir-SEG - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  S\\\\-Measure ,  SOC - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  S\\\\-Measure ,  DUTS-TE - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  S\\\\-Measure ,  COD - Camouflaged Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  S\\\\-Measure ,  CAMO - Camouflaged Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### max\\\\ E\\\\-Measure\n",
      "Creating ratio df for  max\\\\ E\\\\-Measure ,  Kvasir-SEG - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AUC\n",
      "Creating ratio df for  AUC ,  Kaggle Skin Lesion Segmentation - Skin Cancer Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC ,  DRIVE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AUC ,  STARE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  LUNA - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC ,  CHASE_DB1 - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  AUC ,  SNEMI3D - Electron Microscopy Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  PCam - Breast Tumour Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  OTB-50 - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC ,  OTB-2013 - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AUC ,  OTB-2015 - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC ,  MPI-INF-3DHP - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC ,  UBI-Fights - Abnormal Event Detection In Video benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  UCSD - Abnormal Event Detection In Video benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  UBI-Fights - Semi-supervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  HRF - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  LaSOT - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  KITTI Horizon - Horizon Line Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  41\n",
      "####### IoU\n",
      "Creating ratio df for  IoU ,  Anatomical Tracings of Lesions After Stroke (ATLAS)  - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  IoU ,  Anatomical Tracings of Lesions After Stroke (ATLAS) - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  IoU ,  Pix3D - 3D Shape Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IoU ,  LiTS2017 - Liver Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IoU ,  LIDC-IDRI - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IoU ,  PH2 - Skin Cancer Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IoU ,  Cell - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IoU ,  EM - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### F1\\\\ score\n",
      "Creating ratio df for  F1\\\\ score ,  STARE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  LUNA - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  DRIVE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  CHASE_DB1 - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1\\\\ score ,  Kaggle Skin Lesion Segmentation - Skin Cancer Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  CULane - Lane Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  TuSimple - Lane Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\ score ,  HRF - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  DRIVE - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  22\n",
      "####### F1\\\\-score\n",
      "Creating ratio df for  F1\\\\-score ,  CRAG - Colorectal Gland Segmentation: benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score ,  Cell17 - Nuclear Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\-score ,  TvSum - Unsupervised Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score ,  SumMe - Unsupervised Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score ,  GeNeVA (i-CLEVR) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1\\\\-score ,  GeNeVA (CoDraw) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  9\n",
      "####### Jaccard\\\\ Index\n",
      "Creating ratio df for  Jaccard\\\\ Index ,  RITE - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### text\\\\-to\\\\-video\\\\ Median\\\\ Rank\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Median\\\\ Rank ,  YouCook2 - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Median\\\\ Rank ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Median\\\\ Rank ,  LSMDC - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Median\\\\ Rank ,  MSR-VTT-1kA - Video Retrieval benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Median\\\\ Rank ,  MSVD - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Median\\\\ Rank ,  DiDeMo - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Median\\\\ Rank ,  ActivityNet - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-1 ,  YouCook2 - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-1 ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-1 ,  LSMDC - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-1 ,  MSR-VTT-1kA - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-1 ,  MSVD - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-1 ,  DiDeMo - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-1 ,  ActivityNet - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  17\n",
      "####### text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-5\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-5 ,  YouCook2 - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-5 ,  LSMDC - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-5 ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-5 ,  MSR-VTT-1kA - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-5 ,  DiDeMo - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-5 ,  MSVD - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-5 ,  ActivityNet - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  14\n",
      "####### text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-10\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-10 ,  YouCook2 - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-10 ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-10 ,  LSMDC - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-10 ,  MSR-VTT-1kA - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-10 ,  MSVD - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-10 ,  DiDeMo - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-10 ,  ActivityNet - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  17\n",
      "####### MAE\n",
      "Creating ratio df for  MAE ,  CARPK - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  UCF-QNRF - Crowd Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  AFLW2000 - Head Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  DUTS-TE - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  ChaLearn 2015 - Age Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  MORPH Album2 - Age Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  Pointing\\'04 - Head Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  BJUT-3D - Head Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  AFLW - Head Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  QM9 - Formation Energy benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  ShanghaiTech B - Crowd Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  UCF CC 50 - Crowd Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  ShanghaiTech A - Crowd Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  DUT-OMRON - Saliency Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  KITTI Depth Completion - Depth Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  Human3.6M - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  SCUT-FBP - Facial Beauty Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  FGNET - Age Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAE ,  MORPH - Age Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  SOD - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  PASCAL-S - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  Materials Project - Formation Energy benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  Filtered NTU RGB+D - Pose Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MAE ,  Comma.ai - Steering Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  Udacity - Steering Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  HKU-IS - Saliency Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  PASCAL-S - Saliency Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  ECSSD - Saliency Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  DUTS-test - Saliency Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  COD - Camouflaged Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  DUT-OMRON - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  ECSSD - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  DUTS-test - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  HKU-IS - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  VOID - Depth Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  OQMD v1.2 - Formation Energy benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAE ,  DUTS-TE - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  ECSSD - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  CAMO - Camouflaged Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  CACD - Age Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  Gaming 3D (G3D) - Pose Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  52\n",
      "####### FPS\n",
      "Creating ratio df for  FPS ,  PASCAL VOC 2007 - Real-Time Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FPS ,  COCO - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FPS ,  COCO - Real-Time Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  FPS ,  CrowdPose - Multi-Person Pose Estimation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FPS ,  K2HPD - 3D Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FPS ,  ICVL Hands - Hand Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FPS ,  NYU Hands - Hand Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  12\n",
      "####### AP75\n",
      "Creating ratio df for  AP75 ,  SKU-110K - Dense Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP75 ,  COCO test-dev - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  AP75 ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  AP75 ,  COCO test-dev - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP75 ,  COCO test-dev - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  AP75 ,  COCO minival - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  AP75 ,  COCO test-challenge - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP75 ,  COCO test-dev - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP75 ,  YouTube-VIS validation - Video Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP75 ,  MSCOCO - Real-time Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP75 ,  nuScenes-FB - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP75 ,  nuScenes-F - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  49\n",
      "####### Jaccard\\\\ \\\\(Mean\\\\)\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Mean\\\\) ,  Montalbano - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Mean\\\\) ,  DAVIS 2016 - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Mean\\\\) ,  DAVIS 2017 (test-dev) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Mean\\\\) ,  DAVIS 2017 (val) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Mean\\\\) ,  DAVIS 2016 - Unsupervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Mean\\\\) ,  FBMS - Unsupervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### AUC\\\\-at\\\\-0\\\\.1\\\\ \\\\(all\\\\)\n",
      "Creating ratio df for  AUC\\\\-at\\\\-0\\\\.1\\\\ \\\\(all\\\\) ,  WFLW - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "number of sota per dataset/metric:  7\n",
      "####### FR\\\\-at\\\\-0\\\\.1\\\\(%,\\\\ all\\\\)\n",
      "Creating ratio df for  FR\\\\-at\\\\-0\\\\.1\\\\(%,\\\\ all\\\\) ,  WFLW - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ME\\\\ \\\\(%,\\\\ all\\\\)\n",
      "Creating ratio df for  ME\\\\ \\\\(%,\\\\ all\\\\) ,  WFLW - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Viewpoint\\\\ I\\\\ AEPE\n",
      "Creating ratio df for  Viewpoint\\\\ I\\\\ AEPE ,  HPatches - Dense Pixel Correspondence Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Viewpoint\\\\ II\\\\ AEPE\n",
      "Creating ratio df for  Viewpoint\\\\ II\\\\ AEPE ,  HPatches - Dense Pixel Correspondence Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Viewpoint\\\\ III\\\\ AEPE\n",
      "Creating ratio df for  Viewpoint\\\\ III\\\\ AEPE ,  HPatches - Dense Pixel Correspondence Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Viewpoint\\\\ IV\\\\ AEPE\n",
      "Creating ratio df for  Viewpoint\\\\ IV\\\\ AEPE ,  HPatches - Dense Pixel Correspondence Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Viewpoint\\\\ V\\\\ AEPE\n",
      "Creating ratio df for  Viewpoint\\\\ V\\\\ AEPE ,  HPatches - Dense Pixel Correspondence Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAR,\\\\ walking,\\\\ 400ms\n",
      "Creating ratio df for  MAR,\\\\ walking,\\\\ 400ms ,  Human3.6M - Human Pose Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAR,\\\\ walking,\\\\ 1,000ms\n",
      "Creating ratio df for  MAR,\\\\ walking,\\\\ 1,000ms ,  Human3.6M - Human Pose Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### SSIM\\\\ \\\\(sRGB\\\\)\n",
      "Creating ratio df for  SSIM\\\\ \\\\(sRGB\\\\) ,  Darmstadt Noise Dataset - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  SSIM\\\\ \\\\(sRGB\\\\) ,  RealBlur-R (trained on GoPro) - Deblurring benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM\\\\ \\\\(sRGB\\\\) ,  HIDE (trained on GOPRO) - Deblurring benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM\\\\ \\\\(sRGB\\\\) ,  RealBlur-J (trained on GoPro) - Deblurring benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SSIM\\\\ \\\\(sRGB\\\\) ,  DND - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM\\\\ \\\\(sRGB\\\\) ,  SIDD - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### PSNR\\\\ \\\\(sRGB\\\\)\n",
      "Creating ratio df for  PSNR\\\\ \\\\(sRGB\\\\) ,  Darmstadt Noise Dataset - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR\\\\ \\\\(sRGB\\\\) ,  RealBlur-R (trained on GoPro) - Deblurring benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\ \\\\(sRGB\\\\) ,  RealBlur-J (trained on GoPro) - Deblurring benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\ \\\\(sRGB\\\\) ,  HIDE (trained on GOPRO) - Deblurring benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\ \\\\(sRGB\\\\) ,  SIDD - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR\\\\ \\\\(sRGB\\\\) ,  DND - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### mAP\\\\-at\\\\-0\\\\.25\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.25 ,  SUN-RGBD val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.25 ,  SUN-RGBD - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.25 ,  ScanNetV2 - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.25 ,  ScanNetV1 - 3D Semantic Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  12\n",
      "####### AP50\n",
      "Creating ratio df for  AP50 ,  COCO test-dev - Weakly Supervised Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP50 ,  COCO test-dev - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  AP50 ,  COCO test-dev - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  AP50 ,  Flowers-102 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP50 ,  CUB-200-2011 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP50 ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  AP50 ,  COCO test-dev - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  AP50 ,  COCO test-dev - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AP50 ,  COCO minival - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP50 ,  COCO test-challenge - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  AP50 ,  MSCOCO - Real-time Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP50 ,  nuScenes-FB - 3D Object Detection benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP50 ,  nuScenes-F - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  47\n",
      "####### MOS\n",
      "Creating ratio df for  MOS ,  Set5 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MOS ,  BSD100 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MOS ,  Set14 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MOS ,  CelebA + AFLW Unaligned - Face Alignment benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MOS ,  CelebA Aligned - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### Inception\\\\ score\n",
      "Creating ratio df for  Inception\\\\ score ,  CIFAR-10 - Conditional Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Inception\\\\ score ,  CIFAR-10 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Inception\\\\ score ,  CUB 128 x 128 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Inception\\\\ score ,  Stanford Cars - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Inception\\\\ score ,  Stanford Dogs - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Inception\\\\ score ,  CUB - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Inception\\\\ score ,  ImageNet 128x128 - Conditional Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Inception\\\\ score ,  COCO - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Inception\\\\ score ,  Oxford 102 Flowers - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Inception\\\\ score ,  STL-10 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  40\n",
      "####### \\\\#\\\\ of\\\\ clusters\\\\ \\\\(k\\\\)\n",
      "Creating ratio df for  \\\\#\\\\ of\\\\ clusters\\\\ \\\\(k\\\\) ,  SVHN - Unsupervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Acc\n",
      "Creating ratio df for  Acc ,  SVHN - Unsupervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Acc ,  OCT2017 - Retinal OCT Disease Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Acc ,  Srinivasan2014 - Retinal OCT Disease Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Acc ,  GTEA - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Acc ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Acc ,  50 Salads - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Acc ,  Breakfast - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  20\n",
      "####### HTER\n",
      "Creating ratio df for  HTER ,  Replay-Attack - Face Anti-Spoofing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Equal\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Equal\\\\ Error\\\\ Rate ,  MSU-MFSD - Face Anti-Spoofing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AOP\n",
      "Creating ratio df for  AOP ,  WAF - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Global\\\\ Accuracy\n",
      "Creating ratio df for  Global\\\\ Accuracy ,  CamVid - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP\\\\-at\\\\-0\\\\.5\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  MPII Multi-Person - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  THUMOS 2014 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  NYU Depth v2 - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  ActivityNet-1.3 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  Cityscapes to Foggy Cityscapes - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  ActivityNet-1.2 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  ScanNetV2 - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  SIM10K to BDD100K - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  SceneNN - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  SUN-RGBD val - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  India Driving Dataset - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  BDD100K - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  THUMOSâ€™14 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  40\n",
      "####### mAP\\\\-at\\\\-0\\\\.1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.1 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### mAP\\\\-at\\\\-0\\\\.2\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.2 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### mAP\\\\-at\\\\-0\\\\.3\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.3 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "number of sota per dataset/metric:  7\n",
      "####### mAP\\\\-at\\\\-0\\\\.4\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.4 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "number of sota per dataset/metric:  8\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.5\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.5 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.5 ,  ActivityNet-1.3 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.5 ,  ActivityNet-1.2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  14\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.1\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.1 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.1 ,  ActivityNet-1.2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.2\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.2 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.3\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.3 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.3 ,  ActivityNet-1.2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.4\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.4 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "number of sota per dataset/metric:  9\n",
      "####### MAE\\\\ \\\\(trained\\\\ with\\\\ other\\\\ data\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(trained\\\\ with\\\\ other\\\\ data\\\\) ,  BIWI - Head Pose Estimation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ NME\n",
      "Creating ratio df for  Mean\\\\ NME ,  AFLW2000-3D - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ NME ,  Florence - 3D Face Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ NME ,  AFLW2000-3D - 3D Face Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ NME ,  AFLW-Full - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ NME ,  AFLW-LFPA - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ NME ,  AFLW-Full - Facial Landmark Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ NME ,  AFLW-Front - Facial Landmark Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ NME ,  AFLW - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ NME ,  300W (Full) - Facial Landmark Detection benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  10\n",
      "####### Frames\\\\ Needed\n",
      "Creating ratio df for  Frames\\\\ Needed ,  Human3.6M - Monocular 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Orientation\\\\ Similarity\n",
      "Creating ratio df for  Average\\\\ Orientation\\\\ Similarity ,  KITTI Cars Hard - Vehicle Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Sensitivity\n",
      "Creating ratio df for  Sensitivity ,  OCT2017 - Retinal OCT Disease Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Normalized\\\\ Precision\n",
      "Creating ratio df for  Normalized\\\\ Precision ,  TrackingNet - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### box\\\\ AP\n",
      "Creating ratio df for  box\\\\ AP ,  COCO test-dev - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 14\n",
      "Creating ratio df for  box\\\\ AP ,  COCO minival - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  box\\\\ AP ,  Pix3D S1 - 3D Shape Modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  box\\\\ AP ,  Pix3D S2 - 3D Shape Modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  23\n",
      "####### Backpack\n",
      "Creating ratio df for  Backpack ,  UAV-Human - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### LCC\n",
      "Creating ratio df for  LCC ,  UAV-Human - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### LCS\n",
      "Creating ratio df for  LCS ,  UAV-Human - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### UCC\n",
      "Creating ratio df for  UCC ,  UAV-Human - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### UCS\n",
      "Creating ratio df for  UCS ,  UAV-Human - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Gender\n",
      "Creating ratio df for  Gender ,  UAV-Human - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Hat\n",
      "Creating ratio df for  Hat ,  UAV-Human - Pedestrian Attribute Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Top\\\\-1\\\\ accuracy\\\\ %\n",
      "Creating ratio df for  Top\\\\-1\\\\ accuracy\\\\ % ,  ImageNet-A - Domain Generalization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Top\\\\-1\\\\ accuracy\\\\ % ,  MIT-States - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ accuracy\\\\ % ,  UT-Zappos - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Top\\\\-1\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  ImageNet-R - Domain Generalization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  ILSVRC 2015 - Weakly-Supervised Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  Oxford-IIIT Pets - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  Caltech-101 - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  FGVC Aircraft - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  Oxford 102 Flowers - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  CUB-200-2011 - Weakly-Supervised Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  ImageNet - Image Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### Top\\\\-1\\\\ Localization\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\-1\\\\ Localization\\\\ Accuracy ,  Tiny ImageNet - Weakly-Supervised Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Top\\\\-5\\\\ Error\n",
      "Creating ratio df for  Top\\\\-5\\\\ Error ,  ILSVRC 2016 - Weakly-Supervised Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Top\\\\-5\\\\ Error ,  CUB-200-2011 - Weakly-Supervised Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### AP\\\\ 0\\\\.5\n",
      "Creating ratio df for  AP\\\\ 0\\\\.5 ,  PASCAL-Part - Multi-Human Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP\\\\ 0\\\\.5 ,  MHP v2.0 - Multi-Human Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP\\\\ 0\\\\.5 ,  MHP v1.0 - Multi-Human Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP\\\\ 0\\\\.5 ,  COCO - One-Shot Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP\\\\ 0\\\\.5 ,  COCO - One-Shot Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### R1\n",
      "Creating ratio df for  R1 ,  BioEye - Person Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### nats\n",
      "Creating ratio df for  nats ,  Binarized MNIST - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### bpd\n",
      "Creating ratio df for  bpd ,  ImageNet 32x32 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  bpd ,  CelebA 256x256 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.2\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.2 ,  FLIC Wrists - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.2 ,  FLIC Elbows - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.2 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  7\n",
      "####### Mean\\\\ PCK\\\\-at\\\\-0\\\\.2\n",
      "Creating ratio df for  Mean\\\\ PCK\\\\-at\\\\-0\\\\.2 ,  J-HMDB - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ PCK\\\\-at\\\\-0\\\\.2 ,  UPenn Action - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### F1@50%\n",
      "Creating ratio df for  F1@50% ,  GTEA - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1@50% ,  50 Salads - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1@50% ,  Breakfast - Action Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  9\n",
      "####### F1@25%\n",
      "Creating ratio df for  F1@25% ,  GTEA - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1@25% ,  Breakfast - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1@25% ,  50 Salads - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  9\n",
      "####### F1@10%\n",
      "Creating ratio df for  F1@10% ,  GTEA - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1@10% ,  50 Salads - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1@10% ,  Breakfast - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  9\n",
      "####### F\\\\-measure\n",
      "Creating ratio df for  F\\\\-measure ,  DUTS-TE - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F\\\\-measure ,  PASCAL-S - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F\\\\-measure ,  DUTS-test - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F\\\\-measure ,  DUT-OMRON - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F\\\\-measure ,  ECSSD - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F\\\\-measure ,  HKU-IS - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F\\\\-measure ,  SOD - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  15\n",
      "####### Mean\\\\ mAP\n",
      "Creating ratio df for  Mean\\\\ mAP ,  ITOP front-view - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Mean\\\\ mAP ,  ITOP top-view - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ mAP ,  Multi-Person PoseTrack - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ mAP ,  PoseTrack2017 - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Mean\\\\ mAP ,  INRIA Holidays - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ mAP ,  PoseTrack2018 - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ mAP ,  ActivityNet-1.2 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ mAP ,  COCO 2017 - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  14\n",
      "####### Hausdorff\n",
      "Creating ratio df for  Hausdorff ,  Cell17 - Nuclear Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 3DIoU\n",
      "Creating ratio df for  3DIoU ,  Data3Dâˆ’R2N2 - 3D Object Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  3DIoU ,  Data3Dâˆ’R2N2 - 3D Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  3DIoU ,  ScanNet - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  3DIoU ,  Stanford 2D-3D - 3D Room Layouts From A Single RGB Panorama benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  3DIoU ,  Realtor360 - 3D Room Layouts From A Single RGB Panorama benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  3DIoU ,  PanoContext - 3D Room Layouts From A Single RGB Panorama benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  3DIoU ,  ShapeNet - Single-View 3D Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  3DIoU ,  ScanNet - Scene Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  20\n",
      "####### Avg\\\\ F1\n",
      "Creating ratio df for  Avg\\\\ F1 ,  Data3Dâˆ’R2N2 - 3D Object Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Avg\\\\ F1 ,  BP4D - Action Unit Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### AUC\\\\ \\\\(horizon\\\\ error\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(horizon\\\\ error\\\\) ,  Horizon Lines in the Wild - Horizon Line Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC\\\\ \\\\(horizon\\\\ error\\\\) ,  Eurasian Cities Dataset - Horizon Line Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC\\\\ \\\\(horizon\\\\ error\\\\) ,  York Urban Dataset - Horizon Line Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  6\n",
      "####### mask\\\\ AP\n",
      "Creating ratio df for  mask\\\\ AP ,  COCO test-dev - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mask\\\\ AP ,  COCO minival - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mask\\\\ AP ,  MSCOCO - Real-time Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mask\\\\ AP ,  Pix3D S2 - 3D Shape Modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mask\\\\ AP ,  Pix3D S1 - 3D Shape Modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mask\\\\ AP ,  LVIS v1.0 - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  16\n",
      "####### Accuracy\\\\ \\\\(Cross\\\\-Subject\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Subject\\\\) ,  NTU RGB+D 120 - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Subject\\\\) ,  NTU RGB+D 120 - Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(Cross\\\\-Setup\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Setup\\\\) ,  NTU RGB+D 120 - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Setup\\\\) ,  NTU RGB+D 120 - Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(CV\\\\ I\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\ I\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Accuracy\\\\ \\\\(CV\\\\ II\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\ II\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(AV\\\\ I\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(AV\\\\ I\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(AV\\\\ II\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(AV\\\\ II\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mRMSE\n",
      "Creating ratio df for  mRMSE ,  COCO count-test - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mRMSE ,  Pascal VOC 2007 count-test - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### mRMSE\\\\-nz\n",
      "Creating ratio df for  mRMSE\\\\-nz ,  Pascal VOC 2007 count-test - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mRMSE\\\\-nz ,  COCO count-test - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### Overall\\\\ Accuracy\n",
      "Creating ratio df for  Overall\\\\ Accuracy ,  ModelNet40 - 3D Point Cloud Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Overall\\\\ Accuracy ,  Photo-Art-50 - Depiction Invariant Object Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Overall\\\\ Accuracy ,  Pavia University - Hyperspectral Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Overall\\\\ Accuracy ,  Indian Pines - Hyperspectral Image Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Overall\\\\ Accuracy ,  ScanObjectNN - 3D Point Cloud Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Overall\\\\ Accuracy ,  Salinas Scene - Hyperspectral Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Overall\\\\ Accuracy ,  RAF-DB - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  16\n",
      "####### m\\\\-reIRMSE\n",
      "Creating ratio df for  m\\\\-reIRMSE ,  COCO count-test - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### m\\\\-reIRMSE\\\\-nz\n",
      "Creating ratio df for  m\\\\-reIRMSE\\\\-nz ,  COCO count-test - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  m\\\\-reIRMSE\\\\-nz ,  Pascal VOC 2007 count-test - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### m\\\\-relRMSE\n",
      "Creating ratio df for  m\\\\-relRMSE ,  Pascal VOC 2007 count-test - Object Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Score\n",
      "Creating ratio df for  Score ,  Hopper - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Ant + Gathering - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Full Humanoid - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Acrobot (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Inverted Pendulum (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Acrobot - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Score ,  Inverted Pendulum (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Inverted Pendulum - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Acrobot (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Mountain Car (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Swimmer - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Ant - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Double Inverted Pendulum - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Inverted Pendulum (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Half-Cheetah - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  2D Walker - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Mountain Car - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Score ,  Acrobot (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Simple Humanoid - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Mountain Car (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Mountain Car (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Lunar Lander (OpenAI Gym) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Cart Pole (OpenAI Gym) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  VQA-CP - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  14\n",
      "####### Frame\\\\-mAP\n",
      "Creating ratio df for  Frame\\\\-mAP ,  J-HMDB-21 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Frame\\\\-mAP ,  UCF101-24 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  8\n",
      "####### Average\\\\ Score\n",
      "Creating ratio df for  Average\\\\ Score ,  ViZDoom Basic Scenario - Playing Game of Doom benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MRR\n",
      "Creating ratio df for  MRR ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Mean\\\\ Rank\n",
      "Creating ratio df for  Mean\\\\ Rank ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ Rank ,  Meta-Dataset Rank - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  3\n",
      "####### J\\\\&F\n",
      "Creating ratio df for  J\\\\&F ,  DAVIS 2016 - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  J\\\\&F ,  DAVIS 2017 (test-dev) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  J\\\\&F ,  DAVIS 2017 (val) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  J\\\\&F ,  DAVIS 2016 - Unsupervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  6\n",
      "####### F\\\\-measure\\\\ \\\\(Decay\\\\)\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Decay\\\\) ,  DAVIS 2016 - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Decay\\\\) ,  DAVIS 2017 (test-dev) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Decay\\\\) ,  DAVIS 2017 (val) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Decay\\\\) ,  DAVIS 2016 - Unsupervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### User\\\\ Study\\\\ Score\n",
      "Creating ratio df for  User\\\\ Study\\\\ Score ,  DICM - Low-Light Image Enhancement benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  User\\\\ Study\\\\ Score ,  MEF - Low-Light Image Enhancement benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  User\\\\ Study\\\\ Score ,  VV - Low-Light Image Enhancement benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  User\\\\ Study\\\\ Score ,  NPE - Low-Light Image Enhancement benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  User\\\\ Study\\\\ Score ,  LIME - Low-Light Image Enhancement benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  10\n",
      "####### F\\\\-measure\\\\ \\\\(Mean\\\\)\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Mean\\\\) ,  DAVIS 2016 - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Mean\\\\) ,  DAVIS 2017 (test-dev) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Mean\\\\) ,  DAVIS 2017 (val) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Mean\\\\) ,  DAVIS 2016 - Unsupervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  8\n",
      "####### F\\\\-measure\\\\ \\\\(Recall\\\\)\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Recall\\\\) ,  DAVIS 2016 - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Recall\\\\) ,  DAVIS 2017 (test-dev) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Recall\\\\) ,  DAVIS 2017 (val) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(Recall\\\\) ,  DAVIS 2016 - Unsupervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  7\n",
      "####### Jaccard\\\\ \\\\(Decay\\\\)\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Decay\\\\) ,  DAVIS 2016 - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Decay\\\\) ,  DAVIS 2017 (test-dev) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Decay\\\\) ,  DAVIS 2017 (val) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Decay\\\\) ,  DAVIS 2016 - Unsupervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Jaccard\\\\ \\\\(Recall\\\\)\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Recall\\\\) ,  DAVIS 2016 - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Recall\\\\) ,  DAVIS 2017 (test-dev) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Recall\\\\) ,  DAVIS 2017 (val) - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Recall\\\\) ,  DAVIS 2016 - Unsupervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  7\n",
      "####### Class\\\\ IOU\n",
      "Creating ratio df for  Class\\\\ IOU ,  Cityscapes Labels-to-Photo - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Class\\\\ IOU ,  Cityscapes Photo-to-Labels - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Class\\\\ IOU ,  Aerial-to-Map - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Per\\\\-class\\\\ Accuracy\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy ,  Cityscapes Labels-to-Photo - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy ,  Cityscapes Photo-to-Labels - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy ,  Aerial-to-Map - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Per\\\\-pixel\\\\ Accuracy\n",
      "Creating ratio df for  Per\\\\-pixel\\\\ Accuracy ,  Cityscapes Photo-to-Labels - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Per\\\\-pixel\\\\ Accuracy ,  Cityscapes Labels-to-Photo - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Per\\\\-pixel\\\\ Accuracy ,  Aerial-to-Map - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Per\\\\-pixel\\\\ Accuracy ,  GTAV-to-Cityscapes Labels - Synthetic-to-Real Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Per\\\\-pixel\\\\ Accuracy ,  SYNTHIA Fall-to-Winter - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  13\n",
      "####### MSE\\\\ \\\\(10\\\\^2,\\\\ 50%\\\\ missing\\\\)\n",
      "Creating ratio df for  MSE\\\\ \\\\(10\\\\^2,\\\\ 50%\\\\ missing\\\\) ,  MuJoCo - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Bits\\\\ per\\\\ dim\n",
      "Creating ratio df for  Bits\\\\ per\\\\ dim ,  ImageNet 64x64 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Instance\\\\ Average\\\\ IoU\n",
      "Creating ratio df for  Instance\\\\ Average\\\\ IoU ,  ShapeNet-Part - 3D Part Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Accuracy\\\\ \\\\(10\\\\-fold\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(10\\\\-fold\\\\) ,  Oulu-CASIA - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(10\\\\-fold\\\\) ,  CK+ - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  2\n",
      "####### Recall\\\\-at\\\\-50\n",
      "Creating ratio df for  Recall\\\\-at\\\\-50 ,  VRD - Scene Graph Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Recall\\\\-at\\\\-50 ,  Visual Genome - Scene Graph Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  6\n",
      "####### Vid\\\\ acc@1\n",
      "Creating ratio df for  Vid\\\\ acc@1 ,  Kinetics-400 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "number of sota per dataset/metric:  8\n",
      "####### Vid\\\\ acc@5\n",
      "Creating ratio df for  Vid\\\\ acc@5 ,  Kinetics-400 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "number of sota per dataset/metric:  7\n",
      "####### Mean\\\\ Angle\\\\ Error\n",
      "Creating ratio df for  Mean\\\\ Angle\\\\ Error ,  Synth Objects-to-LINEMOD - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Inception\\\\ Score\n",
      "Creating ratio df for  Inception\\\\ Score ,  UCF-101 16 frames, Unconditional, Single GPU - Video Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Inception\\\\ Score ,  Visual Genome 64x64 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Inception\\\\ Score ,  COCO-Stuff 64x64 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Inception\\\\ Score ,  Kinetics-600 12 frames, 64x64 - Video Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Inception\\\\ Score ,  Kinetics-600 48 frames, 64x64 - Video Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Inception\\\\ Score ,  COCO-Stuff 128x128 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Inception\\\\ Score ,  Visual Genome 128x128 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Inception\\\\ Score ,  UCF-101 16 frames, 64x64, Unconditional - Video Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  16\n",
      "####### Abs\\\\ Rel\n",
      "Creating ratio df for  Abs\\\\ Rel ,  Mid-Air Dataset - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Abs\\\\ Rel ,  Make3D - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### SQ\\\\ Rel\n",
      "Creating ratio df for  SQ\\\\ Rel ,  Mid-Air Dataset - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### RMSE\\\\ log\n",
      "Creating ratio df for  RMSE\\\\ log ,  Mid-Air Dataset - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### absolute\\\\ relative\\\\ error\n",
      "Creating ratio df for  absolute\\\\ relative\\\\ error ,  KITTI Eigen split unsupervised - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  absolute\\\\ relative\\\\ error ,  KITTI Eigen split - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  4\n",
      "####### NIQE\n",
      "Creating ratio df for  NIQE ,  FFHQ 512 x 512 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  NIQE ,  PIRM-test - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NIQE ,  FFHQ 512 x 512 - 16x upscaling - Face Hallucination benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  6\n",
      "####### LLE\n",
      "Creating ratio df for  LLE ,  FFHQ 512 x 512 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### FED\n",
      "Creating ratio df for  FED ,  FFHQ 512 x 512 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### LPIPS\n",
      "Creating ratio df for  LPIPS ,  FFHQ 512 x 512 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  LPIPS ,  Edge-to-Handbags - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  LPIPS ,  Edge-to-Shoes - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  LPIPS ,  FFHQ 512 x 512 - 16x upscaling - Face Hallucination benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  LPIPS ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  LPIPS ,  Deep-Fashion - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  LPIPS ,  Edge-to-Clothes - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  LPIPS ,  CelebA-HQ - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  LPIPS ,  AFHQ - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### video\\\\-to\\\\-text\\\\ R\\\\-at\\\\-5\n",
      "Creating ratio df for  video\\\\-to\\\\-text\\\\ R\\\\-at\\\\-5 ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Hit\\\\-at\\\\-1\n",
      "Creating ratio df for  Hit\\\\-at\\\\-1 ,  YouTube-8M - Video Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Hit\\\\-at\\\\-5\n",
      "Creating ratio df for  Hit\\\\-at\\\\-5 ,  YouTube-8M - Video Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PERR\n",
      "Creating ratio df for  PERR ,  YouTube-8M - Video Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### CVGTCE\n",
      "Creating ratio df for  CVGTCE ,  3DFAW - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GTE\n",
      "Creating ratio df for  GTE ,  3DFAW - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### R\\\\-at\\\\-16\n",
      "Creating ratio df for  R\\\\-at\\\\-16 ,  Pix3D - 3D Shape Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### R\\\\-at\\\\-2\n",
      "Creating ratio df for  R\\\\-at\\\\-2 ,  Pix3D - 3D Shape Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### R\\\\-at\\\\-32\n",
      "Creating ratio df for  R\\\\-at\\\\-32 ,  Pix3D - 3D Shape Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### R\\\\-at\\\\-4\n",
      "Creating ratio df for  R\\\\-at\\\\-4 ,  Pix3D - 3D Shape Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### R\\\\-at\\\\-8\n",
      "Creating ratio df for  R\\\\-at\\\\-8 ,  Pix3D - 3D Shape Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Average\\\\ End\\\\-Point\\\\ Error\n",
      "Creating ratio df for  Average\\\\ End\\\\-Point\\\\ Error ,  Sintel-clean - Optical Flow Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ End\\\\-Point\\\\ Error ,  Sintel-final - Optical Flow Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ End\\\\-Point\\\\ Error ,  KITTI 2012 - Optical Flow Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### Balanced\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Balanced\\\\ Error\\\\ Rate ,  UCF - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Balanced\\\\ Error\\\\ Rate ,  SBU - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Balanced\\\\ Error\\\\ Rate ,  ISTD - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Speed\\\\ \\\\ \\\\(FPS\\\\)\n",
      "Creating ratio df for  Speed\\\\ \\\\ \\\\(FPS\\\\) ,  YouTube-VOS - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Speed\\\\ \\\\ \\\\(FPS\\\\) ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Overall\n",
      "Creating ratio df for  Overall ,  YouTube-VOS - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F\\\\-Measure\\\\ \\\\(Seen\\\\)\n",
      "Creating ratio df for  F\\\\-Measure\\\\ \\\\(Seen\\\\) ,  YouTube-VOS - One-shot visual object segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F\\\\-Measure\\\\ \\\\(Seen\\\\) ,  YouTube-VOS - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F\\\\-Measure\\\\ \\\\(Seen\\\\) ,  YouTube-VOS - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### F\\\\-Measure\\\\ \\\\(Unseen\\\\)\n",
      "Creating ratio df for  F\\\\-Measure\\\\ \\\\(Unseen\\\\) ,  YouTube-VOS - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F\\\\-Measure\\\\ \\\\(Unseen\\\\) ,  YouTube-VOS - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F\\\\-Measure\\\\ \\\\(Unseen\\\\) ,  YouTube-VOS - One-shot visual object segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### APL\n",
      "Creating ratio df for  APL ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  APL ,  COCO test-dev - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  APL ,  COCO test-dev - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  APL ,  COCO test-dev - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  APL ,  COCO minival - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  APL ,  COCO test-challenge - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  APL ,  COCO test-dev - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  APL ,  MSCOCO - Real-time Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  40\n",
      "####### Jaccard\\\\ \\\\(Seen\\\\)\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Seen\\\\) ,  YouTube-VOS - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Seen\\\\) ,  YouTube-VOS - One-shot visual object segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Seen\\\\) ,  YouTube-VOS - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  6\n",
      "####### Jaccard\\\\ \\\\(Unseen\\\\)\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Unseen\\\\) ,  YouTube-VOS - Semi-Supervised Video Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Unseen\\\\) ,  YouTube-VOS - One-shot visual object segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Unseen\\\\) ,  YouTube-VOS - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### APM\n",
      "Creating ratio df for  APM ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  APM ,  COCO test-dev - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  APM ,  COCO test-dev - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  APM ,  COCO test-dev - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  APM ,  COCO minival - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  APM ,  COCO test-dev - Object Detection benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  APM ,  MSCOCO - Real-time Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  41\n",
      "####### Test\\\\ AP\n",
      "Creating ratio df for  Test\\\\ AP ,  COCO - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### O\\\\ \\\\(Average\\\\ of\\\\ Measures\\\\)\n",
      "Creating ratio df for  O\\\\ \\\\(Average\\\\ of\\\\ Measures\\\\) ,  YouTube-VOS - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR\n",
      "Creating ratio df for  AR ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  AR ,  COCO test-dev - Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  AR ,  COCO test-challenge - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  AR ,  nuScenes-F - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AR ,  nuScenes-FB - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AR ,  COCO test-dev - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  21\n",
      "####### AR50\n",
      "Creating ratio df for  AR50 ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AR50 ,  COCO test-challenge - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  AR50 ,  COCO test-dev - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  10\n",
      "####### AR75\n",
      "Creating ratio df for  AR75 ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AR75 ,  COCO test-challenge - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  9\n",
      "####### ARL\n",
      "Creating ratio df for  ARL ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  ARL ,  COCO test-challenge - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  9\n",
      "####### ARM\n",
      "Creating ratio df for  ARM ,  COCO test-dev - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  ARM ,  COCO test-challenge - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  10\n",
      "####### Median\\\\ Relighting\\\\ Error\n",
      "Creating ratio df for  Median\\\\ Relighting\\\\ Error ,  SUN360 - Outdoor Light Source Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### APS\n",
      "Creating ratio df for  APS ,  COCO test-dev - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  APS ,  COCO minival - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  APS ,  COCO test-dev - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  APS ,  MSCOCO - Real-time Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  27\n",
      "####### MOTP\n",
      "Creating ratio df for  MOTP ,  Multi-Person PoseTrack - Pose Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MOTP ,  KITTI - 3D Multi-Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Validation\\\\ AP\n",
      "Creating ratio df for  Validation\\\\ AP ,  COCO - Keypoint Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Average\\\\ Precision\n",
      "Creating ratio df for  Average\\\\ Precision ,  Cityscapes test - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Average\\\\ Precision ,  iSAID - Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ Precision ,  EGTEA - Long-tail Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Precision ,  iSAID - Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### Expected\\\\ Average\\\\ Overlap\\\\ \\\\(EAO\\\\)\n",
      "Creating ratio df for  Expected\\\\ Average\\\\ Overlap\\\\ \\\\(EAO\\\\) ,  VOT2017/18 - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Expected\\\\ Average\\\\ Overlap\\\\ \\\\(EAO\\\\) ,  VOT2016 - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Expected\\\\ Average\\\\ Overlap\\\\ \\\\(EAO\\\\) ,  VOT2017 - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Expected\\\\ Average\\\\ Overlap\\\\ \\\\(EAO\\\\) ,  VOT2019 - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  12\n",
      "####### Class\\\\ Average\\\\ IoU\n",
      "Creating ratio df for  Class\\\\ Average\\\\ IoU ,  ShapeNet-Part - 3D Part Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### overall\n",
      "Creating ratio df for  overall ,  VQA v2 test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  overall ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  10\n",
      "####### mAcc\n",
      "Creating ratio df for  mAcc ,  S3DIS Area5 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAcc ,  S3DIS - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAcc ,  S3DIS - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAcc ,  S3DIS - 3D Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  12\n",
      "####### oAcc\n",
      "Creating ratio df for  oAcc ,  S3DIS - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  oAcc ,  S3DIS Area5 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  oAcc ,  Semantic3D - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  7\n",
      "####### Mean\\\\ Accuracy\n",
      "Creating ratio df for  Mean\\\\ Accuracy ,  ModelNet40 - 3D Point Cloud Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ Accuracy ,  Barrettâ€™s Esophagus - Medical Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  3\n",
      "####### Test\\\\ Score\n",
      "Creating ratio df for  Test\\\\ Score ,  ADE20K - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Speed\\\\(ms/f\\\\)\n",
      "Creating ratio df for  Speed\\\\(ms/f\\\\) ,  NYU Depth v2 - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.1\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.1 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### PCK\\\\-at\\\\-0\\\\.3\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.3 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.4\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.4 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.5\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.5 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mIoU\\\\ \\\\(13\\\\ classes\\\\)\n",
      "Creating ratio df for  mIoU\\\\ \\\\(13\\\\ classes\\\\) ,  SYNTHIA-to-Cityscapes - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "number of sota per dataset/metric:  7\n",
      "####### Test\\\\ error\n",
      "Creating ratio df for  Test\\\\ error ,  Rotated MNIST - Rotated MNIST benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ 3D\\\\ Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Average\\\\ 3D\\\\ Error ,  Florence - 3D Face Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ 3D\\\\ Error ,  ICVL Hands - Hand Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ 3D\\\\ Error ,  MSRA Hands - Hand Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ 3D\\\\ Error ,  NYU Hands - Hand Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ 3D\\\\ Error ,  HANDS 2017 - Hand Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ 3D\\\\ Error ,  HANDS 2019 - Hand Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### Number\\\\ of\\\\ Views\n",
      "Creating ratio df for  Number\\\\ of\\\\ Views ,  Human3.6M - Weakly-supervised 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Number\\\\ of\\\\ Frames\\\\ Per\\\\ View\n",
      "Creating ratio df for  Number\\\\ of\\\\ Frames\\\\ Per\\\\ View ,  Human3.6M - Weakly-supervised 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Sequence\\\\ error\n",
      "Creating ratio df for  Sequence\\\\ error ,  FSNS - Test - Optical Character Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Small\\\\ MR\\\\^\\\\-2\n",
      "Creating ratio df for  Small\\\\ MR\\\\^\\\\-2 ,  CityPersons - Pedestrian Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Medium\\\\ MR\\\\^\\\\-2\n",
      "Creating ratio df for  Medium\\\\ MR\\\\^\\\\-2 ,  CityPersons - Pedestrian Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Large\\\\ MR\\\\^\\\\-2\n",
      "Creating ratio df for  Large\\\\ MR\\\\^\\\\-2 ,  CityPersons - Pedestrian Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Reasonable\\\\ MR\\\\^\\\\-2\n",
      "Creating ratio df for  Reasonable\\\\ MR\\\\^\\\\-2 ,  CityPersons - Pedestrian Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Diversity\n",
      "Creating ratio df for  Diversity ,  Edge-to-Shoes - Multimodal Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Diversity ,  Edge-to-Handbags - Multimodal Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  6\n",
      "####### IS\n",
      "Creating ratio df for  IS ,  Cats-and-Dogs - Multimodal Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  IS ,  Deep-Fashion - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  IS ,  NTU Hand Digit - Gesture-to-Gesture Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  IS ,  Senz3D - Gesture-to-Gesture Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  IS ,  ImageNet 128x128 - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IS ,  Market-1501 - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  13\n",
      "####### Quality\n",
      "Creating ratio df for  Quality ,  Edge-to-Handbags - Multimodal Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Quality ,  Edge-to-Shoes - Multimodal Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### CIS\n",
      "Creating ratio df for  CIS ,  Cats-and-Dogs - Multimodal Unsupervised Image-To-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.7\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.7 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.7 ,  ActivityNet-1.2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.6\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.6 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### bpsp\n",
      "Creating ratio df for  bpsp ,  ImageNet32 - Image Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### inference\\\\ time\\\\ \\\\(ms\\\\)\n",
      "Creating ratio df for  inference\\\\ time\\\\ \\\\(ms\\\\) ,  COCO - Real-Time Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### APbb75\n",
      "Creating ratio df for  APbb75 ,  COCO minival - Real-Time Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PQth\n",
      "Creating ratio df for  PQth ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  PQth ,  COCO test-dev - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  7\n",
      "####### mAP\\\\ at\\\\-0\\\\.5:0\\\\.95\n",
      "Creating ratio df for  mAP\\\\ at\\\\-0\\\\.5:0\\\\.95 ,  CrowdPose - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP\\\\ at\\\\-0\\\\.5:0\\\\.95 ,  DFG traffic-sign dataset - Traffic Sign Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### AUC0\\\\.07\n",
      "Creating ratio df for  AUC0\\\\.07 ,  LS3D-W Balanced - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC0\\\\.07 ,  300-VW (C) - Face Alignment benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  1\n",
      "####### Rank\\\\-5\n",
      "Creating ratio df for  Rank\\\\-5 ,  CUHK03 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-5 ,  MARS - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Rank\\\\-5 ,  Market-1501 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Rank\\\\-5 ,  DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Rank\\\\-5 ,  Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Rank\\\\-5 ,  PRID2011 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Rank\\\\-5 ,  MSMT17->DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-5 ,  UAV-Human - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-5 ,  DukeTracklet - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-5 ,  iLIDS-VID - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-5 ,  Market-1501->DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-5 ,  Market-1501->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-5 ,  DukeMTMC-reID->Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-5 ,  DukeMTMC-reID->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-5 ,  DukeMTMC-reID - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  36\n",
      "####### runtime\\\\ \\\\(ms\\\\)\n",
      "Creating ratio df for  runtime\\\\ \\\\(ms\\\\) ,  ImageNet VID - Video Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Recall\n",
      "Creating ratio df for  Average\\\\ Recall ,  PASCAL VOC 2012, 60 proposals per image - Object Proposal Generation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ Recall ,  EGTEA - Long-tail Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Recall ,  ScanNet - Scene Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Recall ,  3DMatch Benchmark - 3D Feature Matching benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Video\\\\-mAP\\\\ 0\\\\.2\n",
      "Creating ratio df for  Video\\\\-mAP\\\\ 0\\\\.2 ,  UCF101-24 - Action Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Video\\\\-mAP\\\\ 0\\\\.1\n",
      "Creating ratio df for  Video\\\\-mAP\\\\ 0\\\\.1 ,  UCF101-24 - Action Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Mean\\\\ ADD\n",
      "Creating ratio df for  Mean\\\\ ADD ,  LineMOD - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Mean\\\\ ADD ,  YCB-Video - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ ADD ,  YCB-Video - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Mean\\\\ ADD ,  LineMOD - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Mean\\\\ ADD ,  Occlusion LineMOD - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  14\n",
      "####### Accuracy\\\\ \\\\(ADD\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(ADD\\\\) ,  LineMOD - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(ADD\\\\) ,  YCB-Video - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(ADD\\\\) ,  LineMOD - 6D Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  7\n",
      "####### RMS\n",
      "Creating ratio df for  RMS ,  NYU-Depth V2 - Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PQ\n",
      "Creating ratio df for  PQ ,  Cityscapes test - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PQ ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PQ ,  COCO test-dev - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PQ ,  Mapillary val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PQ ,  KITTI Panoptic Segmentation - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PQ ,  Indian Driving Dataset - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PQ ,  COCO panoptic - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  21\n",
      "####### PCK3D\\\\ \\\\(CA\\\\)\n",
      "Creating ratio df for  PCK3D\\\\ \\\\(CA\\\\) ,  Geometric Pose Affordance  - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### PCK3D\\\\ \\\\(CS\\\\)\n",
      "Creating ratio df for  PCK3D\\\\ \\\\(CS\\\\) ,  Geometric Pose Affordance  - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MPJPE\\\\ \\\\(CS\\\\)\n",
      "Creating ratio df for  MPJPE\\\\ \\\\(CS\\\\) ,  Geometric Pose Affordance  - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MPJPE\\\\ \\\\(CA\\\\)\n",
      "Creating ratio df for  MPJPE\\\\ \\\\(CA\\\\) ,  Geometric Pose Affordance  - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NDCG\\\\ \\\\(x\\\\ 100\\\\)\n",
      "Creating ratio df for  NDCG\\\\ \\\\(x\\\\ 100\\\\) ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MRR\\\\ \\\\(x\\\\ 100\\\\)\n",
      "Creating ratio df for  MRR\\\\ \\\\(x\\\\ 100\\\\) ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Mean\n",
      "Creating ratio df for  Mean ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Time\\\\ Per\\\\ Frame\\\\ \\\\(ms\\\\)\n",
      "Creating ratio df for  Time\\\\ Per\\\\ Frame\\\\ \\\\(ms\\\\) ,  HICO-DET - Human-Object Interaction Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CV\\\\)\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CV\\\\) ,  PKU-MMD - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CS\\\\)\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CS\\\\) ,  PKU-MMD - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Blur\\\\ Segmentation\\\\ Accuracy\n",
      "Creating ratio df for  Blur\\\\ Segmentation\\\\ Accuracy ,  CUHK - Blur Detection Dataset - Defocus Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 3DPCK\n",
      "Creating ratio df for  3DPCK ,  MPI-INF-3DHP - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  3DPCK ,  MuPoTS-3D - 3D Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  3DPCK ,  MuPoTS-3D - 3D Multi-Person Pose Estimation (root-relative) benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  3DPCK ,  MuPoTS-3D - 3D Multi-Person Pose Estimation (absolute) benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  3\n",
      "####### MJPE\n",
      "Creating ratio df for  MJPE ,  MPI-INF-3DHP - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### CS\n",
      "Creating ratio df for  CS ,  Toyota Smarthome dataset - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### CV1\n",
      "Creating ratio df for  CV1 ,  Toyota Smarthome dataset - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### CV2\n",
      "Creating ratio df for  CV2 ,  Toyota Smarthome dataset - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mAP\\\\ \\\\(Val\\\\)\n",
      "Creating ratio df for  mAP\\\\ \\\\(Val\\\\) ,  AVA v2.1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Video\\\\-mAP\\\\ 0\\\\.5\n",
      "Creating ratio df for  Video\\\\-mAP\\\\ 0\\\\.5 ,  J-HMDB-21 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Video\\\\-mAP\\\\ 0\\\\.5 ,  UCF101-24 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### AMT\n",
      "Creating ratio df for  AMT ,  NTU Hand Digit - Gesture-to-Gesture Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AMT ,  Senz3D - Gesture-to-Gesture Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  8\n",
      "####### Maximum\\\\ F\\\\-measure\n",
      "Creating ratio df for  Maximum\\\\ F\\\\-measure ,  Cityscapes test - Edge Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Maximum\\\\ F\\\\-measure ,  SBD - Edge Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Rank\\\\-10\n",
      "Creating ratio df for  Rank\\\\-10 ,  Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Rank\\\\-10 ,  DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Rank\\\\-10 ,  MSMT17->DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-10 ,  CUHK03 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-10 ,  Market-1501->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-10 ,  DukeMTMC-reID->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-10 ,  Market-1501 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-10 ,  MARS - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-10 ,  DukeMTMC-reID->Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-10 ,  Market-1501->DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-10 ,  DukeMTMC-reID - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-10 ,  iLIDS-VID - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  19\n",
      "####### AUC0\\\\.08\\\\ private\n",
      "Creating ratio df for  AUC0\\\\.08\\\\ private ,  300W - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC0\\\\.08\\\\ private ,  300-VW (C) - Facial Landmark Detection benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  3\n",
      "####### Fullset\\\\ \\\\(public\\\\)\n",
      "Creating ratio df for  Fullset\\\\ \\\\(public\\\\) ,  300W - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Failure\\\\ private\n",
      "Creating ratio df for  Failure\\\\ private ,  300W - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ Error\\\\ Rate\\\\ private\n",
      "Creating ratio df for  Mean\\\\ Error\\\\ Rate\\\\ private ,  300W - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Top\\\\-5\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\-5\\\\ Accuracy ,  Something-Something V2 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Top\\\\-5\\\\ Accuracy ,  ImageNet (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Top\\\\-5\\\\ Accuracy ,  Kinetics-600 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Top\\\\-5\\\\ Accuracy ,  EgoGesture - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### mean\\\\ E\\\\-Measure\n",
      "Creating ratio df for  mean\\\\ E\\\\-Measure ,  SOC - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mean\\\\ E\\\\-Measure ,  DUTS-TE - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  5\n",
      "####### MAE\\\\ \\\\(Valence\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Valence\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Arousal\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Arousal\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(Expectancy\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Expectancy\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Power\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Power\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MPJPE\n",
      "Creating ratio df for  MPJPE ,  MuPoTS-3D - 3D Multi-Person Pose Estimation (root-relative) benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MPJPE ,  Surreal - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MPJPE ,  3DPW - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MPJPE ,  CHALL H80K - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MPJPE ,  MuPoTS-3D - 3D Multi-Person Pose Estimation (absolute) benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MPJPE ,  3D Poses in the Wild Challenge - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MPJPE ,  Total Capture - 3D Absolute Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Weighted\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  8\n",
      "####### UA\n",
      "Creating ratio df for  UA ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  UA ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Macro\\\\-F1\n",
      "Creating ratio df for  Macro\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Bounding\\\\ Box\\\\ AP\n",
      "Creating ratio df for  Bounding\\\\ Box\\\\ AP ,  AVA - Image Cropping benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AUC\\\\ \\\\(val\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(val\\\\) ,  ActivityNet-1.3 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### AUC\\\\ \\\\(test\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(test\\\\) ,  ActivityNet-1.3 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AR@100\n",
      "Creating ratio df for  AR@100 ,  ActivityNet-1.3 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AR@100 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Consistency\n",
      "Creating ratio df for  Consistency ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Consistency ,  ImageNet - Classification Consistency benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Plausibility\n",
      "Creating ratio df for  Plausibility ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Validity\n",
      "Creating ratio df for  Validity ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Distribution\n",
      "Creating ratio df for  Distribution ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Binary\n",
      "Creating ratio df for  Binary ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Open\n",
      "Creating ratio df for  Open ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### MSE\n",
      "Creating ratio df for  MSE ,  ShanghaiTech A - Crowd Counting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSE ,  Human3.6M - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MSE ,  Filtered NTU RGB+D - Pose Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MSE ,  Senz3D - Gesture-to-Gesture Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSE ,  NTU Hand Digit - Gesture-to-Gesture Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSE ,  KITTI Horizon - Horizon Line Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSE ,  Composition-1K - Image Matting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSE ,  Gaming 3D (G3D) - Pose Prediction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "number of sota per dataset/metric:  7\n",
      "####### Log\\\\-Spectral\\\\ Distance\n",
      "Creating ratio df for  Log\\\\-Spectral\\\\ Distance ,  Piano - Audio Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Log\\\\-Spectral\\\\ Distance ,  VCTK Multi-Speaker - Audio Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Log\\\\-Spectral\\\\ Distance ,  Voice Bank corpus (VCTK) - Audio Super-Resolution benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  2\n",
      "####### Interpolation\\\\ Error\n",
      "Creating ratio df for  Interpolation\\\\ Error ,  Middlebury - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PSNR\\\\-B\n",
      "Creating ratio df for  PSNR\\\\-B ,  LIVE1 (Quality 10 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\-B ,  LIVE1 (Quality 20 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\-B ,  LIVE1 (Quality 20 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\-B ,  Live1 (Quality 10 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\-B ,  ICB (Quality 10 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\-B ,  ICB (Quality 20 Grayscale) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\-B ,  ICB (Quality 10 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\-B ,  ICB (Quality 20 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PSNR\\\\-B ,  ICB (Quality 30 Color) - JPEG Artifact Correction benchmarking , ds_count= 1\n",
      "null\n",
      "####### TAR\\\\ at\\\\ FAR=0\\\\.001\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.001 ,  BUAA-VisNir - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.001 ,  CASIA NIR-VIS 2.0 - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.001 ,  Oulu-CASIA NIR-VIS - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.001 ,  IJB-B - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.001 ,  IJB-A - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.001 ,  IJB-C - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  14\n",
      "####### F\\\\-measure\\\\ \\\\(%\\\\)\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(%\\\\) ,  ActionNet-VE - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(%\\\\) ,  SHREC15 - Point Cloud Super Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(8\\\\ emotion\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(8\\\\ emotion\\\\) ,  AffectNet - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mean\\\\ F\\\\-Measure\n",
      "Creating ratio df for  mean\\\\ F\\\\-Measure ,  DUTS-TE - RGB Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Runtime\\\\ \\\\[ms\\\\]\n",
      "Creating ratio df for  Runtime\\\\ \\\\[ms\\\\] ,  KITTI Depth Completion - Depth Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Mean\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Mean\\\\ Error\\\\ Rate ,  300W - Facial Landmark Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ Error\\\\ Rate ,  COFW - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ Error\\\\ Rate ,  IBUG - Face Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Decidability\n",
      "Creating ratio df for  Decidability ,  UBI-Fights - Abnormal Event Detection In Video benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Decidability ,  UBI-Fights - Semi-supervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### F1\\\\-score\\\\ \\\\(Canonical\\\\)\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(Canonical\\\\) ,  TvSum - Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(Canonical\\\\) ,  SumMe - Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(Canonical\\\\) ,  SumMe - Supervised Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(Canonical\\\\) ,  TvSum - Supervised Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  8\n",
      "####### F1\\\\-score\\\\ \\\\(Augmented\\\\)\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(Augmented\\\\) ,  TvSum - Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(Augmented\\\\) ,  SumMe - Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(Augmented\\\\) ,  SumMe - Supervised Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(Augmented\\\\) ,  TvSum - Supervised Video Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### H\\\\-Mean\n",
      "Creating ratio df for  H\\\\-Mean ,  MSRA-TD500 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  H\\\\-Mean ,  SCUT-CTW1500 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  H\\\\-Mean ,  ICDAR 2015 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  H\\\\-Mean ,  ICDAR 2013 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  H\\\\-Mean ,  ICDAR 2017 MLT - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  H\\\\-Mean ,  Total-Text - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  H\\\\-Mean ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### Rank\\\\-20\n",
      "Creating ratio df for  Rank\\\\-20 ,  PRID2011 - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Rank\\\\-20 ,  DukeTracklet - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-20 ,  MARS - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-20 ,  iLIDS-VID - Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Rank\\\\-20 ,  Market-1501->DukeMTMC-reID - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Rank\\\\-20 ,  DukeMTMC-reID->Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\)\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  RWTH-PHOENIX-Weather 2014 - Sign Language Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(trained\\\\ with\\\\ BIWI\\\\ data\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(trained\\\\ with\\\\ BIWI\\\\ data\\\\) ,  BIWI - Head Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### TAR\\\\ at\\\\ FAR=0\\\\.1\n",
      "Creating ratio df for  TAR\\\\ at\\\\ FAR=0\\\\.1 ,  IJB-A - Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### FSIM\n",
      "Creating ratio df for  FSIM ,  CUHK - Face Sketch Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FSIM ,  CUFSF - Face Sketch Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FSIM ,  CUFS - Face Sketch Synthesis benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### 10%\n",
      "Creating ratio df for  10% ,  J-HMBD Early Action - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  10% ,  2019_test set - Face Anonymization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### ADDS\\\\ AUC\n",
      "Creating ratio df for  ADDS\\\\ AUC ,  YCB-Video - 6D Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Mean\\\\ ADD\\\\-S\n",
      "Creating ratio df for  Mean\\\\ ADD\\\\-S ,  YCB-Video - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ ADD\\\\-S ,  YCB-Video - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### fwIOU\n",
      "Creating ratio df for  fwIOU ,  SYNTHIA Fall-to-Winter - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  fwIOU ,  GTAV-to-Cityscapes Labels - Synthetic-to-Real Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### rank\\\\-10\n",
      "Creating ratio df for  rank\\\\-10 ,  Duke to Market - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-10 ,  Market to Duke - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-10 ,  Market to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-10 ,  Duke to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  12\n",
      "####### rank\\\\-1\n",
      "Creating ratio df for  rank\\\\-1 ,  Duke to Market - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-1 ,  Market to Duke - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-1 ,  Duke to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-1 ,  Market to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  12\n",
      "####### rank\\\\-5\n",
      "Creating ratio df for  rank\\\\-5 ,  Duke to Market - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-5 ,  Market to Duke - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-5 ,  Market to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  rank\\\\-5 ,  Duke to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  10\n",
      "####### Heavy\\\\ MR\\\\^\\\\-2\n",
      "Creating ratio df for  Heavy\\\\ MR\\\\^\\\\-2 ,  CityPersons - Pedestrian Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Partial\\\\ MR\\\\^\\\\-2\n",
      "Creating ratio df for  Partial\\\\ MR\\\\^\\\\-2 ,  CityPersons - Pedestrian Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Bare\\\\ MR\\\\^\\\\-2\n",
      "Creating ratio df for  Bare\\\\ MR\\\\^\\\\-2 ,  CityPersons - Pedestrian Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Val\n",
      "Creating ratio df for  Val ,  Jester - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mAP\\\\-at\\\\-0\\\\.50\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.50 ,  ScanNetV2 - 3D Semantic Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.50 ,  DFG traffic-sign dataset - Traffic Sign Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.50 ,  Swedish traffic-sign dataset (STSD) - Traffic Sign Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  6\n",
      "####### IoU\\\\-2D\n",
      "Creating ratio df for  IoU\\\\-2D ,  Tejani - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### IoU\\\\-3D\n",
      "Creating ratio df for  IoU\\\\-3D ,  Tejani - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### VSS\\\\-2D\n",
      "Creating ratio df for  VSS\\\\-2D ,  Tejani - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### VSS\\\\-3D\n",
      "Creating ratio df for  VSS\\\\-3D ,  Tejani - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Real\n",
      "Creating ratio df for  Real ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Real ,  FaceForensics - DeepFake Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### SOA\\\\-C\n",
      "Creating ratio df for  SOA\\\\-C ,  COCO - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Kernel\\\\ Inception\\\\ Distance\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients - Fundus to Angiography Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  anime-to-selfie - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  selfie-to-anime - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  vangogh2photo - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  portrait2photo - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  horse2zebra - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  photo2portrait - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  zebra2horse - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  dog2cat - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  photo2vangogh - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Kernel\\\\ Inception\\\\ Distance ,  cat2dog - Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### BER\n",
      "Creating ratio df for  BER ,  SBU - Shadow Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP@0\\\\.1:0\\\\.7\n",
      "Creating ratio df for  mAP@0\\\\.1:0\\\\.7 ,  THUMOS 2014 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### acceleration\\\\ error\n",
      "Creating ratio df for  acceleration\\\\ error ,  3DPW - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PA\\\\-MPJPE\n",
      "Creating ratio df for  PA\\\\-MPJPE ,  3DPW - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Retrieval\\\\ Top10\\\\ Recall\n",
      "Creating ratio df for  Retrieval\\\\ Top10\\\\ Recall ,  Deep-Fashion - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### L2\\\\ Loss\\\\ \\\\(10\\\\^\\\\-4\\\\)\n",
      "Creating ratio df for  L2\\\\ Loss\\\\ \\\\(10\\\\^\\\\-4\\\\) ,  PEMS-SF - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### PQst\n",
      "Creating ratio df for  PQst ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PQst ,  COCO test-dev - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  4\n",
      "####### Top\\\\-1\\\\ \\\\(%\\\\)\n",
      "Creating ratio df for  Top\\\\-1\\\\ \\\\(%\\\\) ,  Moments in Time Dataset - Multimodal Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Top\\\\-1\\\\ \\\\(%\\\\) ,  DukeMTMC-reID->Market-1501 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ \\\\(%\\\\) ,  Market-1501->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ \\\\(%\\\\) ,  DukeMTMC-reID->MSMT17 - Unsupervised Person Re-Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Top\\\\-5\\\\ \\\\(%\\\\)\n",
      "Creating ratio df for  Top\\\\-5\\\\ \\\\(%\\\\) ,  Moments in Time Dataset - Multimodal Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Path\\\\ Length\n",
      "Creating ratio df for  Path\\\\ Length ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Step\\\\ Change\\\\ \\\\(10\\\\^âˆ’3\\\\)\n",
      "Creating ratio df for  Step\\\\ Change\\\\ \\\\(10\\\\^âˆ’3\\\\) ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Path\\\\ Difference\n",
      "Creating ratio df for  Path\\\\ Difference ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Player\\\\ Distance\n",
      "Creating ratio df for  Player\\\\ Distance ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### OOB\\\\ Rate\\\\ \\\\(10\\\\^âˆ’3\\\\)\n",
      "Creating ratio df for  OOB\\\\ Rate\\\\ \\\\(10\\\\^âˆ’3\\\\) ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### rect\\\\ mask\\\\ l1\\\\ error\n",
      "Creating ratio df for  rect\\\\ mask\\\\ l1\\\\ error ,  Places2 val - Image Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### rect\\\\ mask\\\\ l2\\\\ err\n",
      "Creating ratio df for  rect\\\\ mask\\\\ l2\\\\ err ,  Places2 val - Image Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### free\\\\-form\\\\ mask\\\\ l1\\\\ err\n",
      "Creating ratio df for  free\\\\-form\\\\ mask\\\\ l1\\\\ err ,  Places2 val - Image Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### free\\\\-form\\\\ mask\\\\ l2\\\\ err\n",
      "Creating ratio df for  free\\\\-form\\\\ mask\\\\ l2\\\\ err ,  Places2 val - Image Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 14\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  2017_test set - 3D Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  100 sleep nights of 8 caregivers - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  SHREC 2017 - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  SHREC 2017 track on 3D Hand Gesture Recognition - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### AR1\n",
      "Creating ratio df for  AR1 ,  YouTube-VIS validation - Video Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR10\n",
      "Creating ratio df for  AR10 ,  YouTube-VIS validation - Video Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Pearson\\\\ Correlation\n",
      "Creating ratio df for  Pearson\\\\ Correlation ,  ECCV HotOrNot - Facial Beauty Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### IoU\\\\ \\\\[32\\\\ distractors\\\\]\n",
      "Creating ratio df for  IoU\\\\ \\\\[32\\\\ distractors\\\\] ,  Cluttered Omniglot - One-Shot Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### IoU\\\\ \\\\[4\\\\ distractors\\\\]\n",
      "Creating ratio df for  IoU\\\\ \\\\[4\\\\ distractors\\\\] ,  Cluttered Omniglot - One-Shot Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### IoU\\\\ \\\\[256\\\\ distractors\\\\]\n",
      "Creating ratio df for  IoU\\\\ \\\\[256\\\\ distractors\\\\] ,  Cluttered Omniglot - One-Shot Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ ADI\n",
      "Creating ratio df for  Mean\\\\ ADI ,  YCB-Video - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ ADI ,  YCB-Video - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### CIDEr\n",
      "Creating ratio df for  CIDEr ,  YouCook2 - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  CIDEr ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  CIDEr ,  COCO Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  CIDEr ,  Flickr30k Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  CIDEr ,  VATEX - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  CIDEr ,  MSR-VTT - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  CIDEr ,  MSVD - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### ROUGE\\\\-L\n",
      "Creating ratio df for  ROUGE\\\\-L ,  YouCook2 - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  ROUGE\\\\-L ,  VATEX - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-L ,  MSR-VTT - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-L ,  MSVD - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### BLEU\\\\-4\n",
      "Creating ratio df for  BLEU\\\\-4 ,  YouCook2 - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  RWTH-PHOENIX-Weather 2014 T - Sign Language Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  Flickr30k Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  COCO Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  VATEX - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  MSR-VTT - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  MSVD - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  ActivityNet Captions - Dense Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### BLEU\\\\-3\n",
      "Creating ratio df for  BLEU\\\\-3 ,  YouCook2 - Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\-3 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-3 ,  ActivityNet Captions - Dense Video Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Error\n",
      "Creating ratio df for  Error ,  KT3DMoSeg - Motion Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Error ,  Kuzushiji-MNIST - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### CD\n",
      "Creating ratio df for  CD ,  Pix3D - 3D Shape Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### EMD\n",
      "Creating ratio df for  EMD ,  Pix3D - 3D Shape Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### v2v\\\\ error\n",
      "Creating ratio df for  v2v\\\\ error ,  Expressive hands and faces dataset (EHF). - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### mAP\\\\ \\\\(at\\\\-0\\\\.1,\\\\ Through\\\\-wall\\\\)\n",
      "Creating ratio df for  mAP\\\\ \\\\(at\\\\-0\\\\.1,\\\\ Through\\\\-wall\\\\) ,  RF-MMD - RF-based Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP\\\\ \\\\(at\\\\-0\\\\.1,\\\\ Through\\\\-wall\\\\) ,  3DMatch Benchmark - Low-Light Image Enhancement benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.75\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.75 ,  ActivityNet-1.3 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.95\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.95 ,  ActivityNet-1.3 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### GAR\\\\ at\\\\-0\\\\.1%\\\\ FAR\n",
      "Creating ratio df for  GAR\\\\ at\\\\-0\\\\.1%\\\\ FAR ,  Disguised Faces in the Wild - Disguised Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GAR\\\\ at\\\\-1%\\\\ FAR\n",
      "Creating ratio df for  GAR\\\\ at\\\\-1%\\\\ FAR ,  Disguised Faces in the Wild - Disguised Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GAR\\\\ at\\\\-10%\\\\ FAR\n",
      "Creating ratio df for  GAR\\\\ at\\\\-10%\\\\ FAR ,  Disguised Faces in the Wild - Disguised Face Verification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(7\\\\ emotion\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(7\\\\ emotion\\\\) ,  AffectNet - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mMR\n",
      "Creating ratio df for  mMR ,  CrowdHuman (full body) - Object Detection benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(median\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(median\\\\) ,  LUMC - Pulmonary Arteryâ€“Vein Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(median\\\\) ,  SunYs - Pulmonary Arteryâ€“Vein Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  5\n",
      "####### Angular\\\\ Error\n",
      "Creating ratio df for  Angular\\\\ Error ,  EYEDIAP (floating target) - Gaze Estimation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Angular\\\\ Error ,  EYEDIAP (screen target) - Gaze Estimation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Angular\\\\ Error ,  MPII Gaze - Gaze Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Angular\\\\ Error ,  UT Multi-view - Gaze Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Angular\\\\ Error ,  RT-GENE - Gaze Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Edit\n",
      "Creating ratio df for  Edit ,  GTEA - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Edit ,  Breakfast - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Edit ,  50 Salads - Action Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  8\n",
      "####### Top\\\\ 1\\\\ Accuracy\\\\ \\\\(kNN,\\\\ k=20\\\\)\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy\\\\ \\\\(kNN,\\\\ k=20\\\\) ,  ImageNet - Self-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Sq\\\\ Rel\n",
      "Creating ratio df for  Sq\\\\ Rel ,  Make3D - Monocular Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR@1000\n",
      "Creating ratio df for  AR@1000 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR@200\n",
      "Creating ratio df for  AR@200 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR@50\n",
      "Creating ratio df for  AR@50 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR@500\n",
      "Creating ratio df for  AR@500 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### text\\\\-to\\\\-video\\\\ Mean\\\\ Rank\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Mean\\\\ Rank ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Mean\\\\ Rank ,  MSR-VTT-1kA - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Mean\\\\ Rank ,  MSVD - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Mean\\\\ Rank ,  DiDeMo - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ Mean\\\\ Rank ,  ActivityNet - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### video\\\\-to\\\\-text\\\\ Mean\\\\ Rank\n",
      "Creating ratio df for  video\\\\-to\\\\-text\\\\ Mean\\\\ Rank ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### video\\\\-to\\\\-text\\\\ Median\\\\ Rank\n",
      "Creating ratio df for  video\\\\-to\\\\-text\\\\ Median\\\\ Rank ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### video\\\\-to\\\\-text\\\\ R\\\\-at\\\\-1\n",
      "Creating ratio df for  video\\\\-to\\\\-text\\\\ R\\\\-at\\\\-1 ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### video\\\\-to\\\\-text\\\\ R\\\\-at\\\\-10\n",
      "Creating ratio df for  video\\\\-to\\\\-text\\\\ R\\\\-at\\\\-10 ,  MSR-VTT - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mse\\\\ \\\\(10\\\\^\\\\-3\\\\)\n",
      "Creating ratio df for  mse\\\\ \\\\(10\\\\^\\\\-3\\\\) ,  PhysioNet Challenge 2012 - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### F\\\\-Score\n",
      "Creating ratio df for  F\\\\-Score ,  Plant - Object Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GFLOPs\n",
      "Creating ratio df for  GFLOPs ,  Chinese License Plates - License Plate Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Average\\\\ Class\\\\ Accuracy\n",
      "Creating ratio df for  Average\\\\ Class\\\\ Accuracy ,  CT Lesion Stroke Dataset - Stroke Classification from CT data benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(%\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  Office-Caltech-10 - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  Office-Home - Partial Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Chamfer\\\\ Distance\n",
      "Creating ratio df for  Chamfer\\\\ Distance ,  Completion3D - Point Cloud Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Chamfer\\\\ Distance ,  ShapeNet - Point Cloud Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### F\\\\-Score@1%\n",
      "Creating ratio df for  F\\\\-Score@1% ,  ShapeNet - Point Cloud Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Normalized\\\\ cPSNR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Normalized\\\\ cPSNR ,  PROBA-V - Multi-Frame Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP\\\\ \\\\(at\\\\-0\\\\.1,\\\\ Visible\\\\)\n",
      "Creating ratio df for  mAP\\\\ \\\\(at\\\\-0\\\\.1,\\\\ Visible\\\\) ,  RF-MMD - RF-based Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Rank\\\\-1\\\\ Recognition\\\\ Rate\n",
      "Creating ratio df for  Rank\\\\-1\\\\ Recognition\\\\ Rate ,  MORPH Album2 - Age-Invariant Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Fl\\\\-all\n",
      "Creating ratio df for  Fl\\\\-all ,  KITTI 2015 - Optical Flow Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### GPU\\\\ sec\n",
      "Creating ratio df for  GPU\\\\ sec ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### MIoU\\\\ \\\\(13\\\\ classes\\\\)\n",
      "Creating ratio df for  MIoU\\\\ \\\\(13\\\\ classes\\\\) ,  SYNTHIA-to-Cityscapes - Synthetic-to-Real Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### three\\\\ pixel\\\\ error\n",
      "Creating ratio df for  three\\\\ pixel\\\\ error ,  KITTI2015 - Stereo Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  three\\\\ pixel\\\\ error ,  KITTI2012 - Stereo Depth Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Return\n",
      "Creating ratio df for  Return ,  DeepMind Walker Walk (Images) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Return ,  DeepMind Cheetah Run (Images) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Return ,  DeepMind Cup Catch (Images) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "####### Success\\\\ Rate\\\\ 0\\\\.5\n",
      "Creating ratio df for  Success\\\\ Rate\\\\ 0\\\\.5 ,  GOT-10k - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Overlap\n",
      "Creating ratio df for  Average\\\\ Overlap ,  GOT-10k - Visual Object Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Time\\\\ Per\\\\ Frame\\\\(ms\\\\)\n",
      "Creating ratio df for  Time\\\\ Per\\\\ Frame\\\\(ms\\\\) ,  V-COCO - Human-Object Interaction Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### TIoU\n",
      "Creating ratio df for  TIoU ,  SCUT-CTW1500 - Scene Text Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### rsim\n",
      "Creating ratio df for  rsim ,  GeNeVA (i-CLEVR) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  rsim ,  GeNeVA (CoDraw) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### spl\n",
      "Creating ratio df for  spl ,  Room2Room - Vision-Language Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  spl ,  Gibson PointGoal Navigation - PointGoal Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Actions\\\\ Top\\\\-1\\\\ \\\\(S2\\\\)\n",
      "Creating ratio df for  Actions\\\\ Top\\\\-1\\\\ \\\\(S2\\\\) ,  EPIC-KITCHENS-55 - Egocentric Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Pointing\\\\ Game\\\\ Accuracy\n",
      "Creating ratio df for  Pointing\\\\ Game\\\\ Accuracy ,  Flickr30k - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Pointing\\\\ Game\\\\ Accuracy ,  ReferIt - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Pointing\\\\ Game\\\\ Accuracy ,  Visual Genome - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### mean\\\\ Corruption\\\\ Error\\\\ \\\\(mCE\\\\)\n",
      "Creating ratio df for  mean\\\\ Corruption\\\\ Error\\\\ \\\\(mCE\\\\) ,  ImageNet-C - Domain Generalization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AP\\\\ Easy\n",
      "Creating ratio df for  AP\\\\ Easy ,  CrowdPose - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AP\\\\ Medium\n",
      "Creating ratio df for  AP\\\\ Medium ,  CrowdPose - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### AP\\\\ Hard\n",
      "Creating ratio df for  AP\\\\ Hard ,  CrowdPose - Multi-Person Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### GFlops\n",
      "Creating ratio df for  GFlops ,  AVA v2.1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Params\\\\ \\\\(M\\\\)\n",
      "Creating ratio df for  Params\\\\ \\\\(M\\\\) ,  AVA v2.1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ AP\\\\ at\\\\ 0\\\\.5\n",
      "Creating ratio df for  Mean\\\\ AP\\\\ at\\\\ 0\\\\.5 ,  ScanNet(v2) - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "####### AUROC\n",
      "Creating ratio df for  AUROC ,  CIFAR-10 vs CIFAR-100 - Out-of-Distribution Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUROC ,  CIFAR-10 - Out-of-Distribution Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### AUPR\n",
      "Creating ratio df for  AUPR ,  CIFAR-10 vs CIFAR-100 - Out-of-Distribution Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### FPR95\n",
      "Creating ratio df for  FPR95 ,  CIFAR-10 - Out-of-Distribution Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FPR95 ,  CIFAR-100 - Out-of-Distribution Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Actions\\\\ Top\\\\-1\\\\ \\\\(S1\\\\)\n",
      "Creating ratio df for  Actions\\\\ Top\\\\-1\\\\ \\\\(S1\\\\) ,  EPIC-KITCHENS-55 - Egocentric Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### FID\\\\-50k\n",
      "Creating ratio df for  FID\\\\-50k ,  LSUN Bedroom - Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ AUC\n",
      "Creating ratio df for  Mean\\\\ AUC ,  YCB-Video - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mAP\\\\ 10,\\\\ 10cm\n",
      "Creating ratio df for  mAP\\\\ 10,\\\\ 10cm ,  CAMERA25 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\ 10,\\\\ 10cm ,  REAL275 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP\\\\ 10,\\\\ 5cm\n",
      "Creating ratio df for  mAP\\\\ 10,\\\\ 5cm ,  REAL275 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\ 10,\\\\ 5cm ,  CAMERA25 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP\\\\ 3DIou\\\\-at\\\\-25\n",
      "Creating ratio df for  mAP\\\\ 3DIou\\\\-at\\\\-25 ,  REAL275 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\ 3DIou\\\\-at\\\\-25 ,  CAMERA25 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP\\\\ 3DIou\\\\-at\\\\-50\n",
      "Creating ratio df for  mAP\\\\ 3DIou\\\\-at\\\\-50 ,  REAL275 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\ 3DIou\\\\-at\\\\-50 ,  CAMERA25 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP\\\\ 5,\\\\ 5cm\n",
      "Creating ratio df for  mAP\\\\ 5,\\\\ 5cm ,  REAL275 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\ 5,\\\\ 5cm ,  CAMERA25 - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### 28\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  28\\\\ gestures\\\\ accuracy ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  28\\\\ gestures\\\\ accuracy ,  SHREC 2017 - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Pixel\\\\ Accuracy\n",
      "Creating ratio df for  Pixel\\\\ Accuracy ,  ADE20K val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### FSF\n",
      "Creating ratio df for  FSF ,  FaceForensics - DeepFake Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Total\\\\ Accuracy\n",
      "Creating ratio df for  Total\\\\ Accuracy ,  FaceForensics - DeepFake Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### DF\n",
      "Creating ratio df for  DF ,  FaceForensics - DeepFake Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### FS\n",
      "Creating ratio df for  FS ,  FaceForensics - DeepFake Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NT\n",
      "Creating ratio df for  NT ,  FaceForensics - DeepFake Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ Recall\n",
      "Creating ratio df for  Mean\\\\ Recall ,  T-LESS - 6D Pose Estimation using RGBD benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ Recall ,  T-LESS - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### ADE\\\\-8/12\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  ActEV - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  ETH/UCY - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  ActEV - Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  Hotel BIWI Walking Pedestrians dataset - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### FDE\\\\-8/12\n",
      "Creating ratio df for  FDE\\\\-8/12 ,  ActEV - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### iMAE\n",
      "Creating ratio df for  iMAE ,  KITTI Depth Completion - Depth Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  iMAE ,  VOID - Depth Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### iRMSE\n",
      "Creating ratio df for  iRMSE ,  KITTI Depth Completion - Depth Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  iRMSE ,  VOID - Depth Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### mRec\n",
      "Creating ratio df for  mRec ,  S3DIS - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  mRec ,  ScanNet(v2) - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  6\n",
      "####### mPrec\n",
      "Creating ratio df for  mPrec ,  S3DIS - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### 4\n",
      "Creating ratio df for  4 ,  4 - 4D Spatio Temporal Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### VInfo\n",
      "Creating ratio df for  VInfo ,  ISBI 2012 EM Segmentation - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### VRand\n",
      "Creating ratio df for  VRand ,  ISBI 2012 EM Segmentation - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MMD\n",
      "Creating ratio df for  MMD ,  Edge-to-Handbags - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MMD ,  Edge-to-Shoes - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### HP\n",
      "Creating ratio df for  HP ,  Edge-to-Handbags - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  HP ,  Edge-to-Shoes - Image Reconstruction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### NDS\n",
      "Creating ratio df for  NDS ,  nuScenes - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Micro\\\\-F1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  EC - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Micro\\\\-F1 ,  DailyDialog - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### tOF\n",
      "Creating ratio df for  tOF ,  X4K1000FPS - Video Frame Interpolation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Object\\\\ Top\\\\ 5\\\\ Accuracy\n",
      "Creating ratio df for  Object\\\\ Top\\\\ 5\\\\ Accuracy ,  YouCook2 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Object\\\\ Top\\\\-1\\\\ Accuracy\n",
      "Creating ratio df for  Object\\\\ Top\\\\-1\\\\ Accuracy ,  YouCook2 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Verb\\\\ Top\\\\-1\\\\ Accuracy\n",
      "Creating ratio df for  Verb\\\\ Top\\\\-1\\\\ Accuracy ,  YouCook2 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Verb\\\\ Top\\\\-5\\\\ Accuracy\n",
      "Creating ratio df for  Verb\\\\ Top\\\\-5\\\\ Accuracy ,  YouCook2 - Action Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mIOU\n",
      "Creating ratio df for  mIOU ,  Paris-Lille-3D - LIDAR Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### PCKh\n",
      "Creating ratio df for  PCKh ,  Deep-Fashion - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PCKh ,  Market-1501 - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### mask\\\\-SSIM\n",
      "Creating ratio df for  mask\\\\-SSIM ,  Market-1501 - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### DS\n",
      "Creating ratio df for  DS ,  Market-1501 - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  DS ,  Deep-Fashion - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### mask\\\\-IS\n",
      "Creating ratio df for  mask\\\\-IS ,  Market-1501 - Pose Transfer benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### E\\\\-Measure\n",
      "Creating ratio df for  E\\\\-Measure ,  COD - Camouflaged Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  E\\\\-Measure ,  CAMO - Camouflaged Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Weighted\\\\ F\\\\-Measure\n",
      "Creating ratio df for  Weighted\\\\ F\\\\-Measure ,  COD - Camouflaged Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Weighted\\\\ F\\\\-Measure ,  CAMO - Camouflaged Object Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### AVD\n",
      "Creating ratio df for  AVD ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### VS\n",
      "Creating ratio df for  VS ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  VS ,  HSVM - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  VS ,  CHAOS MRI Dataset - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  VS ,  BRATS 2018 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### FDE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\)\n",
      "Creating ratio df for  FDE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\) ,  Stanford Drone - Trajectory Prediction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ADE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\)\n",
      "Creating ratio df for  ADE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\) ,  Stanford Drone - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ARm\n",
      "Creating ratio df for  ARm ,  nuScenes-FB - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ARm ,  nuScenes-F - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### ARs\n",
      "Creating ratio df for  ARs ,  nuScenes-F - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ARs ,  nuScenes-FB - 3D Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### coverage\n",
      "Creating ratio df for  coverage ,  Human Righst Archive (HRA) - Displaced People Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### ROUGE\n",
      "Creating ratio df for  ROUGE ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### BLEU\\\\-1\n",
      "Creating ratio df for  BLEU\\\\-1 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### BLEU\\\\-2\n",
      "Creating ratio df for  BLEU\\\\-2 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AP\\\\-at\\\\-0\\\\.7\n",
      "Creating ratio df for  AP\\\\-at\\\\-0\\\\.7 ,  PreSIL to KITTI - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MACE\n",
      "Creating ratio df for  MACE ,  COCO 2014 - Homography Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Test\\\\ Error\n",
      "Creating ratio df for  Test\\\\ Error ,  CMU Mocap-2 - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Test\\\\ Error ,  CMU Mocap-1 - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### 40\\\\-50%\\\\ Mask\\\\ PSNR\n",
      "Creating ratio df for  40\\\\-50%\\\\ Mask\\\\ PSNR ,  Paris StreetView - Image Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 10\\\\-20%\\\\ Mask\\\\ PSNR\n",
      "Creating ratio df for  10\\\\-20%\\\\ Mask\\\\ PSNR ,  Paris StreetView - Image Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 20\\\\-30%\\\\ Mask\\\\ PSNR\n",
      "Creating ratio df for  20\\\\-30%\\\\ Mask\\\\ PSNR ,  Paris StreetView - Image Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 30\\\\-40%\\\\ Mask\\\\ PSNR\n",
      "Creating ratio df for  30\\\\-40%\\\\ Mask\\\\ PSNR ,  Paris StreetView - Image Inpainting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### FwÎ²\n",
      "Creating ratio df for  FwÎ² ,  DUTS-TE - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FwÎ² ,  ECSSD - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Sm\n",
      "Creating ratio df for  Sm ,  DUTS-TE - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Sm ,  ECSSD - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### relaxFbÎ²\n",
      "Creating ratio df for  relaxFbÎ² ,  ECSSD - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  relaxFbÎ² ,  DUTS-TE - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### \\\\{max\\\\}FÎ²\n",
      "Creating ratio df for  \\\\{max\\\\}FÎ² ,  DUTS-TE - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  \\\\{max\\\\}FÎ² ,  ECSSD - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Model\\\\ Size\\\\ \\\\(MB\\\\)\n",
      "Creating ratio df for  Model\\\\ Size\\\\ \\\\(MB\\\\) ,  ECSSD - Salient Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Total\\\\ Variation\\\\ of\\\\ Information\n",
      "Creating ratio df for  Total\\\\ Variation\\\\ of\\\\ Information ,  SNEMI3D - Electron Microscopy Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### VI\\\\ Split\n",
      "Creating ratio df for  VI\\\\ Split ,  SNEMI3D - Electron Microscopy Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### VI\\\\ Merge\n",
      "Creating ratio df for  VI\\\\ Merge ,  SNEMI3D - Electron Microscopy Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Number\\\\ of\\\\ Params\n",
      "Creating ratio df for  Number\\\\ of\\\\ Params ,  ImageNet - Self-Supervised Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mesh\\\\ AP\n",
      "Creating ratio df for  mesh\\\\ AP ,  Pix3D S1 - 3D Shape Modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mesh\\\\ AP ,  Pix3D S2 - 3D Shape Modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Average\\\\ Per\\\\-Class\\\\ Accuracy\n",
      "Creating ratio df for  Average\\\\ Per\\\\-Class\\\\ Accuracy ,  CUB-200 - 0-Shot Learning - Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MSD\n",
      "Creating ratio df for  MSD ,  HSVM - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSD ,  CHAOS MRI Dataset - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSD ,  BRATS 2018 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Params\n",
      "Creating ratio df for  Params ,  ImageNet ReaL - Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MMD\\\\-CD\n",
      "Creating ratio df for  MMD\\\\-CD ,  ShapeNet Airplane - Point Cloud Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MMD\\\\-CD ,  ShapeNet Car - Point Cloud Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MMD\\\\-CD ,  ShapeNet Chair - Point Cloud Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### 1\\\\-NNA\\\\-CD\n",
      "Creating ratio df for  1\\\\-NNA\\\\-CD ,  ShapeNet Airplane - Point Cloud Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  1\\\\-NNA\\\\-CD ,  ShapeNet Car - Point Cloud Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  1\\\\-NNA\\\\-CD ,  ShapeNet Chair - Point Cloud Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Accuracy\\\\(on\\\\ validation\\\\ set\\\\)\n",
      "Creating ratio df for  Accuracy\\\\(on\\\\ validation\\\\ set\\\\) ,  Acted Facial Expressions In The Wild (AFEW) - Facial Expression Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### FVD\\\\ score\n",
      "Creating ratio df for  FVD\\\\ score ,  BAIR Robot Pushing - Video Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mPC\\\\ \\\\[AP50\\\\]\n",
      "Creating ratio df for  mPC\\\\ \\\\[AP50\\\\] ,  PASCAL VOC 2007 - Robust Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mPC\\\\ \\\\[AP\\\\]\n",
      "Creating ratio df for  mPC\\\\ \\\\[AP\\\\] ,  Cityscapes test - Robust Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mPC\\\\ \\\\[AP\\\\] ,  COCO - Robust Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### rPC\\\\ \\\\[%\\\\]\n",
      "Creating ratio df for  rPC\\\\ \\\\[%\\\\] ,  PASCAL VOC 2007 - Robust Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  rPC\\\\ \\\\[%\\\\] ,  Cityscapes test - Robust Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  rPC\\\\ \\\\[%\\\\] ,  COCO - Robust Object Detection benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### NI\n",
      "Creating ratio df for  NI ,  mtrl-auto-uav - Autonomous Flight (Dense Forest) benchmarking , ds_count= 1\n",
      "null\n",
      "####### ATV\n",
      "Creating ratio df for  ATV ,  KITTI Horizon - Horizon Line Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### No\\\\.\\\\ parameters\n",
      "Creating ratio df for  No\\\\.\\\\ parameters ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  No\\\\.\\\\ parameters ,  JHMDB (2D poses only) - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  1\n",
      "####### MPJAE\n",
      "Creating ratio df for  MPJAE ,  3D Poses in the Wild Challenge - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MRPE\n",
      "Creating ratio df for  MRPE ,  Human3.6M - 3D Absolute Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-50\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-50 ,  ActivityNet - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-50 ,  MSVD - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  text\\\\-to\\\\-video\\\\ R\\\\-at\\\\-50 ,  DiDeMo - Video Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### SAD\n",
      "Creating ratio df for  SAD ,  Composition-1K - Image Matting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SAD ,  Semantic Image Matting Dataset - Semantic Image Matting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Grad\n",
      "Creating ratio df for  Grad ,  Composition-1K - Image Matting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Grad ,  Semantic Image Matting Dataset - Semantic Image Matting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### MSE\\\\(10\\\\^3\\\\)\n",
      "Creating ratio df for  MSE\\\\(10\\\\^3\\\\) ,  Semantic Image Matting Dataset - Semantic Image Matting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Conn\n",
      "Creating ratio df for  Conn ,  Composition-1K - Image Matting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Conn ,  Semantic Image Matting Dataset - Semantic Image Matting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(Dev\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Dev\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Test\\\\-P\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\-P\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Test\\\\-U\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\-U\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### SceneFID\n",
      "Creating ratio df for  SceneFID ,  COCO-Stuff 128x128 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  SceneFID ,  Visual Genome 128x128 - Layout-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### number\n",
      "Creating ratio df for  number ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### unanswerable\n",
      "Creating ratio df for  unanswerable ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Recall\\\\ \\\\(VSD\\\\)\n",
      "Creating ratio df for  Recall\\\\ \\\\(VSD\\\\) ,  T-LESS - 6D Pose Estimation using RGB benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### yes/no\n",
      "Creating ratio df for  yes/no ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### other\n",
      "Creating ratio df for  other ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Recall\\\\-at\\\\-20\n",
      "Creating ratio df for  Recall\\\\-at\\\\-20 ,  DeepFashion - Image Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PDJ@5mm\n",
      "Creating ratio df for  PDJ@5mm ,  K2HPD - Hand Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\-Score\n",
      "Creating ratio df for  F1\\\\-Score ,  ISIC 2018 - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ODS\n",
      "Creating ratio df for  ODS ,  BIPED - Edge Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ODS ,  CID - Edge Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Train\\\\ F\\\\-measure\n",
      "Creating ratio df for  Train\\\\ F\\\\-measure ,  Nurse Care Activity Recognition Challenge - Multimodal Activity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### UIQM\n",
      "Creating ratio df for  UIQM ,  USR-248 - 4x upscaling - Image Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GAR\\\\ at\\\\-1%\\\\ FAR\\\\ Obfuscation\n",
      "Creating ratio df for  GAR\\\\ at\\\\-1%\\\\ FAR\\\\ Obfuscation ,  Disguised Faces in the Wild - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GAR\\\\ at\\\\-1%\\\\ FAR\\\\ Overall\n",
      "Creating ratio df for  GAR\\\\ at\\\\-1%\\\\ FAR\\\\ Overall ,  Disguised Faces in the Wild - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GAR\\\\ at\\\\-0\\\\.1%\\\\ FAR\\\\ Impersonation\n",
      "Creating ratio df for  GAR\\\\ at\\\\-0\\\\.1%\\\\ FAR\\\\ Impersonation ,  Disguised Faces in the Wild - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GAR\\\\ at\\\\-0\\\\.1%\\\\ FAR\\\\ Obfuscation\n",
      "Creating ratio df for  GAR\\\\ at\\\\-0\\\\.1%\\\\ FAR\\\\ Obfuscation ,  Disguised Faces in the Wild - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GAR\\\\ at\\\\-0\\\\.1%\\\\ FAR\\\\ Overall\n",
      "Creating ratio df for  GAR\\\\ at\\\\-0\\\\.1%\\\\ FAR\\\\ Overall ,  Disguised Faces in the Wild - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GAR\\\\ at\\\\-1%\\\\ FAR\\\\ Impersonation\n",
      "Creating ratio df for  GAR\\\\ at\\\\-1%\\\\ FAR\\\\ Impersonation ,  Disguised Faces in the Wild - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 16x16\\\\ Accuracy\n",
      "Creating ratio df for  16x16\\\\ Accuracy ,  CMU-MPIE - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 24x24\\\\ Accuracy\n",
      "Creating ratio df for  24x24\\\\ Accuracy ,  CMU-MPIE - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 32x32\\\\ Accuracy\n",
      "Creating ratio df for  32x32\\\\ Accuracy ,  CMU-MPIE - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 48x48\\\\ Accuracy\n",
      "Creating ratio df for  48x48\\\\ Accuracy ,  CMU-MPIE - Heterogeneous Face Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### SPICE\n",
      "Creating ratio df for  SPICE ,  Flickr30k Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SPICE ,  COCO Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Weighted\\\\ Macro\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\ Macro\\\\-F1 ,  EmoryNLP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ADE\n",
      "Creating ratio df for  ADE ,  Citywalks - Multiple Object Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AIOU\n",
      "Creating ratio df for  AIOU ,  Citywalks - Multiple Object Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MPVPE\n",
      "Creating ratio df for  MPVPE ,  3DPW - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Real\\\\ World\\\\ Accuracy\n",
      "Creating ratio df for  Real\\\\ World\\\\ Accuracy ,  GesturePod - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### IOU25\n",
      "Creating ratio df for  IOU25 ,  NOCS-REAL275 - 6D Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 5Â°5\\\\ cm\n",
      "Creating ratio df for  5Â°5\\\\ cm ,  NOCS-REAL275 - 6D Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Rerr\n",
      "Creating ratio df for  Rerr ,  NOCS-REAL275 - 6D Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Terr\n",
      "Creating ratio df for  Terr ,  NOCS-REAL275 - 6D Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MIoU\\\\ \\\\(16\\\\ classes\\\\)\n",
      "Creating ratio df for  MIoU\\\\ \\\\(16\\\\ classes\\\\) ,  SYNTHIA-to-Cityscapes - Synthetic-to-Real Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP@0\\\\.1:0\\\\.5\n",
      "Creating ratio df for  mAP@0\\\\.1:0\\\\.5 ,  THUMOS 2014 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Acc\\\\-at\\\\-0\\\\.5m,\\\\ 2Â°\n",
      "Creating ratio df for  Acc\\\\-at\\\\-0\\\\.5m,\\\\ 2Â° ,  Aachen Day-Night benchmark - Camera Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Acc\\\\-at\\\\-1m,\\\\ 5Â°\n",
      "Creating ratio df for  Acc\\\\-at\\\\-1m,\\\\ 5Â° ,  Aachen Day-Night benchmark - Camera Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Acc\\\\-at\\\\-5m,\\\\ 10Â°\n",
      "Creating ratio df for  Acc\\\\-at\\\\-5m,\\\\ 10Â° ,  Aachen Day-Night benchmark - Camera Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Category\\\\ mIoU\n",
      "Creating ratio df for  Category\\\\ mIoU ,  Cityscapes test - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mCov\n",
      "Creating ratio df for  mCov ,  S3DIS - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mWCov\n",
      "Creating ratio df for  mWCov ,  S3DIS - 3D Instance Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### KL\n",
      "Creating ratio df for  KL ,  Dayton (256Ã—256) - aerial-to-ground - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  KL ,  cvusa - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### SD\n",
      "Creating ratio df for  SD ,  cvusa - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SD ,  Dayton (256Ã—256) - aerial-to-ground - Cross-View Image-to-Image Translation benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  1\n",
      "####### Recall\\\\-at\\\\-1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-1 ,  SOP - Fine-Grained Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 1/4\n",
      "Creating ratio df for  1/4 ,  SUTD-TrafficQA - Video Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 1/2\n",
      "Creating ratio df for  1/2 ,  SUTD-TrafficQA - Video Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mean\\\\ Recall\\\\ @20\n",
      "Creating ratio df for  mean\\\\ Recall\\\\ @20 ,  Visual Genome - Scene Graph Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ODRMSE\n",
      "Creating ratio df for  ODRMSE ,  ultracold fermions Technion system, pixelfly - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Test\\\\ AUC\\\\ top\\\\ 1\n",
      "Creating ratio df for  Test\\\\ AUC\\\\ top\\\\ 1 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Test\\\\ AUC\\\\ top\\\\ 2\n",
      "Creating ratio df for  Test\\\\ AUC\\\\ top\\\\ 2 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Test\\\\ AUC\\\\ top\\\\ 3\n",
      "Creating ratio df for  Test\\\\ AUC\\\\ top\\\\ 3 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Val\\\\ AUC\\\\ top\\\\ 1\n",
      "Creating ratio df for  Val\\\\ AUC\\\\ top\\\\ 1 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Val\\\\ AUC\\\\ top\\\\ 2\n",
      "Creating ratio df for  Val\\\\ AUC\\\\ top\\\\ 2 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Val\\\\ AUC\\\\ top\\\\ 3\n",
      "Creating ratio df for  Val\\\\ AUC\\\\ top\\\\ 3 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Top\\\\-2\\\\ accuracy\\\\ %\n",
      "Creating ratio df for  Top\\\\-2\\\\ accuracy\\\\ % ,  UT-Zappos - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-2\\\\ accuracy\\\\ % ,  MIT-States - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Top\\\\-3\\\\ accuracy\\\\ %\n",
      "Creating ratio df for  Top\\\\-3\\\\ accuracy\\\\ % ,  UT-Zappos - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-3\\\\ accuracy\\\\ % ,  MIT-States - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Seen\\\\ accuracy\n",
      "Creating ratio df for  Seen\\\\ accuracy ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Unseen\\\\ accuracy\n",
      "Creating ratio df for  Unseen\\\\ accuracy ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PCK3D\n",
      "Creating ratio df for  PCK3D ,  Surreal - 3D Human Pose Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Human Pose Estimation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Human Pose Estimation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-09",
          "2018-06",
          "2019-09",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "3D Human Pose Estimation",
          "3D Human Pose Estimation",
          "3D Human Pose Estimation",
          "3D Human Pose Estimation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Instance Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Instance Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-04",
          "2019-06",
          "2020-03",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "3D Instance Segmentation",
          "3D Instance Segmentation",
          "3D Instance Segmentation",
          "3D Instance Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Object Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Object Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-06",
          "2017-11",
          "2017-12",
          "2018-02",
          "2018-12",
          "2019-03",
          "2019-04",
          "2019-07",
          "2020-01",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Object Reconstruction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Object Reconstruction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2018-02",
          "2019-01"
         ],
         "xaxis": "x",
         "y": [
          "3D Object Reconstruction",
          "3D Object Reconstruction",
          "3D Object Reconstruction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Part Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Part Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2017-06",
          "2017-11",
          "2018-01",
          "2019-04",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Point Cloud Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Point Cloud Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-04",
          "2017-06",
          "2018-01",
          "2018-03",
          "2018-12",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "3D Point Cloud Classification",
          "3D Point Cloud Classification",
          "3D Point Cloud Classification",
          "3D Point Cloud Classification",
          "3D Point Cloud Classification",
          "3D Point Cloud Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Reconstruction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Reconstruction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-12",
          "2018-08"
         ],
         "xaxis": "x",
         "y": [
          "3D Reconstruction",
          "3D Reconstruction",
          "3D Reconstruction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Room Layouts From A Single RGB Panorama",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Room Layouts From A Single RGB Panorama",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-01"
         ],
         "xaxis": "x",
         "y": [
          "3D Room Layouts From A Single RGB Panorama",
          "3D Room Layouts From A Single RGB Panorama"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Semantic Instance Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Semantic Instance Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-11",
          "2018-12",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "3D Semantic Instance Segmentation",
          "3D Semantic Instance Segmentation",
          "3D Semantic Instance Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Semantic Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Semantic Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2017-06",
          "2017-10",
          "2018-07",
          "2018-09",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Shape Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Shape Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-10",
          "2018-04"
         ],
         "xaxis": "x",
         "y": [
          "3D Shape Classification",
          "3D Shape Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "6D Pose Estimation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "6D Pose Estimation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-01",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "6D Pose Estimation",
          "6D Pose Estimation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "6D Pose Estimation using RGB",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "6D Pose Estimation using RGB",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-03",
          "2019-02",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "6D Pose Estimation using RGB",
          "6D Pose Estimation using RGB",
          "6D Pose Estimation using RGB"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Action Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Action Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-06",
          "2016-12",
          "2017-11",
          "2017-12",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2018-12",
          "2019-05",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Action Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Action Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2017-12",
          "2018-03",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Action Detection",
          "Action Detection",
          "Action Detection",
          "Action Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Action Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Action Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2012-12",
          "2014-12",
          "2015-03",
          "2015-05",
          "2015-12",
          "2016-01",
          "2016-04",
          "2016-08",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-11",
          "2018-01",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2019-01",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Action Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Action Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2018-06",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "Action Segmentation",
          "Action Segmentation",
          "Action Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Activity Recognition In Videos",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Activity Recognition In Videos",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-12",
          "2015-05",
          "2016-05"
         ],
         "xaxis": "x",
         "y": [
          "Activity Recognition In Videos",
          "Activity Recognition In Videos",
          "Activity Recognition In Videos"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Aesthetics Quality Assessment",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Aesthetics Quality Assessment",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-04",
          "2017-04",
          "2018-10"
         ],
         "xaxis": "x",
         "y": [
          "Aesthetics Quality Assessment",
          "Aesthetics Quality Assessment",
          "Aesthetics Quality Assessment"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Age-Invariant Face Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Age-Invariant Face Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-03",
          "2018-09"
         ],
         "xaxis": "x",
         "y": [
          "Age-Invariant Face Recognition",
          "Age-Invariant Face Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Birds Eye View Object Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Birds Eye View Object Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-12",
          "2016-08",
          "2017-12",
          "2018-12",
          "2019-07",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Color Image Denoising",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Color Image Denoising",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-04",
          "2018-02",
          "2018-07",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Color Image Denoising",
          "Color Image Denoising",
          "Color Image Denoising",
          "Color Image Denoising"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Conditional Image Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Conditional Image Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-06",
          "2016-10",
          "2016-12",
          "2017-03",
          "2017-09",
          "2018-05",
          "2018-09"
         ],
         "xaxis": "x",
         "y": [
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Cross-Modal Retrieval",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Cross-Modal Retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-12",
          "2018-03"
         ],
         "xaxis": "x",
         "y": [
          "Cross-Modal Retrieval",
          "Cross-Modal Retrieval"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Cross-View Image-to-Image Translation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Cross-View Image-to-Image Translation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2018-03",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Cross-View Image-to-Image Translation",
          "Cross-View Image-to-Image Translation",
          "Cross-View Image-to-Image Translation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Curved Text Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Curved Text Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-05",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Curved Text Detection",
          "Curved Text Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Denoising",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Denoising",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-05",
          "2018-07",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Denoising",
          "Denoising",
          "Denoising"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Dense Object Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Dense Object Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-06",
          "2016-12",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Dense Object Detection",
          "Dense Object Detection",
          "Dense Object Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Document Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Document Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-04",
          "2018-01",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Document Image Classification",
          "Document Image Classification",
          "Document Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Domain Adaptation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Domain Adaptation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-05",
          "2016-08",
          "2017-04",
          "2017-05",
          "2017-11",
          "2017-12",
          "2018-07",
          "2018-11",
          "2019-01",
          "2019-03",
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Domain Generalization",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Domain Generalization",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08",
          "2017-10",
          "2019-03",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Domain Generalization",
          "Domain Generalization",
          "Domain Generalization",
          "Domain Generalization"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Egocentric Activity Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Egocentric Activity Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-05",
          "2019-08",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Egocentric Activity Recognition",
          "Egocentric Activity Recognition",
          "Egocentric Activity Recognition",
          "Egocentric Activity Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Electron Microscopy Image Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Electron Microscopy Image Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-06",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Electron Microscopy Image Segmentation",
          "Electron Microscopy Image Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Emotion Recognition in Conversation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Emotion Recognition in Conversation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-06",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-08",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Face Alignment",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Face Alignment",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-07",
          "2017-11",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "Face Alignment",
          "Face Alignment",
          "Face Alignment",
          "Face Alignment",
          "Face Alignment",
          "Face Alignment",
          "Face Alignment"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Face Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Face Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2017-08",
          "2017-09",
          "2018-09",
          "2018-10"
         ],
         "xaxis": "x",
         "y": [
          "Face Detection",
          "Face Detection",
          "Face Detection",
          "Face Detection",
          "Face Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Face Identification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Face Identification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-11",
          "2016-04",
          "2017-04",
          "2018-01",
          "2018-03",
          "2018-12"
         ],
         "xaxis": "x",
         "y": [
          "Face Identification",
          "Face Identification",
          "Face Identification",
          "Face Identification",
          "Face Identification",
          "Face Identification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Face Verification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Face Verification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-06",
          "2015-02",
          "2015-03",
          "2015-08",
          "2015-11",
          "2016-03",
          "2016-04",
          "2017-03",
          "2017-04",
          "2017-12",
          "2018-01",
          "2018-03",
          "2018-09",
          "2018-12",
          "2019-03",
          "2019-04",
          "2019-08",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Facial Expression Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Facial Expression Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08",
          "2018-05",
          "2019-02",
          "2019-05",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Facial Expression Recognition",
          "Facial Expression Recognition",
          "Facial Expression Recognition",
          "Facial Expression Recognition",
          "Facial Expression Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Few-Shot Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Few-Shot Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2013-06",
          "2016-03",
          "2017-03",
          "2017-11",
          "2018-06",
          "2018-10",
          "2019-03",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Fine-Grained Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Fine-Grained Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-12",
          "2018-01",
          "2018-06",
          "2018-11",
          "2019-01",
          "2019-06",
          "2019-10",
          "2019-12",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Formation Energy",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Formation Energy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Formation Energy",
          "Formation Energy"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Gesture-to-Gesture Translation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Gesture-to-Gesture Translation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-07",
          "2017-12",
          "2018-08"
         ],
         "xaxis": "x",
         "y": [
          "Gesture-to-Gesture Translation",
          "Gesture-to-Gesture Translation",
          "Gesture-to-Gesture Translation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Grayscale Image Denoising",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Grayscale Image Denoising",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-08",
          "2017-04",
          "2018-05",
          "2018-06",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Group Activity Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Group Activity Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Group Activity Recognition",
          "Group Activity Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Hand Gesture Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Hand Gesture Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-12",
          "2019-01"
         ],
         "xaxis": "x",
         "y": [
          "Hand Gesture Recognition",
          "Hand Gesture Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Hand Pose Estimation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Hand Pose Estimation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-07",
          "2017-12"
         ],
         "xaxis": "x",
         "y": [
          "Hand Pose Estimation",
          "Hand Pose Estimation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Horizon Line Estimation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Horizon Line Estimation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-08",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Horizon Line Estimation",
          "Horizon Line Estimation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Human Interaction Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Human Interaction Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-06",
          "2018-11"
         ],
         "xaxis": "x",
         "y": [
          "Human Interaction Recognition",
          "Human Interaction Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Human Part Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Human Part Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08",
          "2018-05",
          "2018-09",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Human Part Segmentation",
          "Human Part Segmentation",
          "Human Part Segmentation",
          "Human Part Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Human-Object Interaction Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Human-Object Interaction Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-04",
          "2017-04",
          "2018-07",
          "2018-08",
          "2018-11",
          "2019-04",
          "2019-12",
          "2020-03",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Hyperspectral Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Hyperspectral Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-07",
          "2019-02"
         ],
         "xaxis": "x",
         "y": [
          "Hyperspectral Image Classification",
          "Hyperspectral Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2012-02",
          "2012-12",
          "2013-01",
          "2013-02",
          "2013-11",
          "2013-12",
          "2014-04",
          "2014-06",
          "2014-09",
          "2014-12",
          "2015-02",
          "2015-06",
          "2015-11",
          "2015-12",
          "2016-02",
          "2016-03",
          "2016-05",
          "2016-08",
          "2016-10",
          "2016-11",
          "2017-07",
          "2017-08",
          "2017-09",
          "2017-10",
          "2017-12",
          "2018-02",
          "2018-05",
          "2018-07",
          "2018-11",
          "2019-01",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-10",
          "2019-12",
          "2020-01"
         ],
         "xaxis": "x",
         "y": [
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Image Clustering",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Image Clustering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2013-12",
          "2015-11",
          "2016-04",
          "2017-03",
          "2017-04",
          "2017-09",
          "2017-10",
          "2018-04",
          "2018-07",
          "2018-10",
          "2018-11",
          "2018-12",
          "2019-01",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Image Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Image Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-05",
          "2017-02",
          "2017-03",
          "2017-09",
          "2017-10",
          "2018-02",
          "2018-09",
          "2018-11",
          "2018-12",
          "2019-03"
         ],
         "xaxis": "x",
         "y": [
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Image Retrieval",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Image Retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-12",
          "2015-04",
          "2015-11",
          "2016-04",
          "2016-08",
          "2016-11",
          "2016-12",
          "2017-12",
          "2018-01",
          "2018-03",
          "2018-04",
          "2018-11",
          "2019-02",
          "2019-03",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Image Super-Resolution",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Image Super-Resolution",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-08",
          "2015-11",
          "2016-03",
          "2016-08",
          "2016-09",
          "2016-11",
          "2016-12",
          "2017-07",
          "2017-10",
          "2018-02",
          "2018-03",
          "2018-04",
          "2018-05",
          "2018-07",
          "2018-09",
          "2018-11",
          "2019-03",
          "2019-04",
          "2019-06",
          "2019-07"
         ],
         "xaxis": "x",
         "y": [
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Image-to-Image Translation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Image-to-Image Translation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-12",
          "2016-06",
          "2017-11",
          "2018-04",
          "2018-11",
          "2019-03",
          "2019-04",
          "2019-05",
          "2019-08",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Instance Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Instance Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-03",
          "2017-04",
          "2017-12",
          "2019-02",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-11",
          "2020-01"
         ],
         "xaxis": "x",
         "y": [
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Keypoint Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Keypoint Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-08",
          "2016-12",
          "2017-03",
          "2017-11",
          "2018-04",
          "2018-12",
          "2019-01",
          "2019-02"
         ],
         "xaxis": "x",
         "y": [
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Lane Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Lane Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-10",
          "2017-12",
          "2018-06",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Lane Detection",
          "Lane Detection",
          "Lane Detection",
          "Lane Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Layout-to-Image Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Layout-to-Image Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Layout-to-Image Generation",
          "Layout-to-Image Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Lesion Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Lesion Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-10",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "Lesion Segmentation",
          "Lesion Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Low-Light Image Enhancement",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Low-Light Image Enhancement",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-06",
          "2020-01"
         ],
         "xaxis": "x",
         "y": [
          "Low-Light Image Enhancement",
          "Low-Light Image Enhancement"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Lung Nodule Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Lung Nodule Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-11",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Lung Nodule Segmentation",
          "Lung Nodule Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Medical Image Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Medical Image Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-11",
          "2018-07"
         ],
         "xaxis": "x",
         "y": [
          "Medical Image Segmentation",
          "Medical Image Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Metric Learning",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Metric Learning",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-06",
          "2018-04",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Metric Learning",
          "Metric Learning",
          "Metric Learning",
          "Metric Learning"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Monocular Depth Estimation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Monocular Depth Estimation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-09",
          "2018-03",
          "2018-05"
         ],
         "xaxis": "x",
         "y": [
          "Monocular Depth Estimation",
          "Monocular Depth Estimation",
          "Monocular Depth Estimation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multi-Human Parsing",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multi-Human Parsing",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-05",
          "2017-09",
          "2018-04"
         ],
         "xaxis": "x",
         "y": [
          "Multi-Human Parsing",
          "Multi-Human Parsing",
          "Multi-Human Parsing"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multi-Object Tracking",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multi-Object Tracking",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-04",
          "2018-11",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "Multi-Object Tracking",
          "Multi-Object Tracking",
          "Multi-Object Tracking"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multi-Person Pose Estimation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multi-Person Pose Estimation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-05",
          "2016-08",
          "2016-12",
          "2017-01",
          "2017-11",
          "2018-03",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multi-tissue Nucleus Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multi-tissue Nucleus Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-05",
          "2017-03"
         ],
         "xaxis": "x",
         "y": [
          "Multi-tissue Nucleus Segmentation",
          "Multi-tissue Nucleus Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multimodal Activity Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multimodal Activity Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-11",
          "2016-03",
          "2016-08",
          "2017-04",
          "2018-01",
          "2019-01"
         ],
         "xaxis": "x",
         "y": [
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multimodal Unsupervised Image-To-Image Translation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multimodal Unsupervised Image-To-Image Translation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-03",
          "2017-11",
          "2018-04",
          "2018-08"
         ],
         "xaxis": "x",
         "y": [
          "Multimodal Unsupervised Image-To-Image Translation",
          "Multimodal Unsupervised Image-To-Image Translation",
          "Multimodal Unsupervised Image-To-Image Translation",
          "Multimodal Unsupervised Image-To-Image Translation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multiple Object Tracking",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multiple Object Tracking",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-02",
          "2018-11",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Multiple Object Tracking",
          "Multiple Object Tracking",
          "Multiple Object Tracking"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multivariate Time Series Imputation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multivariate Time Series Imputation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-06",
          "2018-12"
         ],
         "xaxis": "x",
         "y": [
          "Multivariate Time Series Imputation",
          "Multivariate Time Series Imputation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Nuclear Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Nuclear Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-03",
          "2018-09"
         ],
         "xaxis": "x",
         "y": [
          "Nuclear Segmentation",
          "Nuclear Segmentation",
          "Nuclear Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Object Counting",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Object Counting",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-06",
          "2016-04"
         ],
         "xaxis": "x",
         "y": [
          "Object Counting",
          "Object Counting"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Object Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Object Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-06",
          "2015-12",
          "2017-03",
          "2017-07",
          "2017-08",
          "2017-11",
          "2017-12",
          "2018-03",
          "2018-05",
          "2018-11",
          "2018-12",
          "2019-01",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-10",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Pancreas Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Pancreas Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-09",
          "2018-04"
         ],
         "xaxis": "x",
         "y": [
          "Pancreas Segmentation",
          "Pancreas Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Panoptic Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Panoptic Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-12",
          "2019-01",
          "2019-05",
          "2019-09",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Pedestrian Attribute Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Pedestrian Attribute Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-08",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Pedestrian Attribute Recognition",
          "Pedestrian Attribute Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Pedestrian Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Pedestrian Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-12",
          "2018-07"
         ],
         "xaxis": "x",
         "y": [
          "Pedestrian Detection",
          "Pedestrian Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Person Re-Identification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Person Re-Identification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-06",
          "2016-03",
          "2016-07",
          "2016-10",
          "2016-11",
          "2017-01",
          "2017-03",
          "2017-07",
          "2017-08",
          "2017-09",
          "2017-10",
          "2017-11",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2018-12",
          "2019-03",
          "2019-05",
          "2019-08",
          "2019-10",
          "2019-11",
          "2019-12",
          "2020-01"
         ],
         "xaxis": "x",
         "y": [
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Pose Estimation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Pose Estimation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-11",
          "2016-03",
          "2016-09",
          "2016-12",
          "2017-01",
          "2017-02",
          "2017-04",
          "2017-05",
          "2017-07",
          "2017-08",
          "2017-11",
          "2017-12",
          "2018-03",
          "2018-04",
          "2018-05",
          "2018-11",
          "2018-12",
          "2019-01",
          "2019-02",
          "2019-10",
          "2020-01",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Pose Tracking",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Pose Tracking",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-12",
          "2018-02",
          "2019-02",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Pose Tracking",
          "Pose Tracking",
          "Pose Tracking",
          "Pose Tracking"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "RGB Salient Object Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "RGB Salient Object Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-06",
          "2017-04",
          "2017-08",
          "2017-10",
          "2018-06",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "RGB Salient Object Detection",
          "RGB Salient Object Detection",
          "RGB Salient Object Detection",
          "RGB Salient Object Detection",
          "RGB Salient Object Detection",
          "RGB Salient Object Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Real-Time Object Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Real-Time Object Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-05",
          "2017-08",
          "2019-04",
          "2019-09",
          "2019-11",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Real-Time Object Detection",
          "Real-Time Object Detection",
          "Real-Time Object Detection",
          "Real-Time Object Detection",
          "Real-Time Object Detection",
          "Real-Time Object Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Real-Time Semantic Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Real-Time Semantic Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-02",
          "2015-11",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2018-08",
          "2018-11",
          "2019-03",
          "2019-09",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Retinal Vessel Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Retinal Vessel Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-11",
          "2018-02",
          "2018-06",
          "2018-10",
          "2019-07",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Satellite Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Satellite Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-12",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Satellite Image Classification",
          "Satellite Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Scene Graph Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Scene Graph Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-07",
          "2018-06",
          "2018-08"
         ],
         "xaxis": "x",
         "y": [
          "Scene Graph Generation",
          "Scene Graph Generation",
          "Scene Graph Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Scene Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Scene Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-03",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Scene Segmentation",
          "Scene Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Scene Text Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Scene Text Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-04",
          "2016-04",
          "2017-03",
          "2017-04",
          "2017-07",
          "2017-08",
          "2017-09",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-06",
          "2018-07",
          "2018-11",
          "2019-03",
          "2019-04",
          "2019-10",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Self-Supervised Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Self-Supervised Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2019-01",
          "2019-06",
          "2019-07",
          "2019-11",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Semantic Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Semantic Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-02",
          "2015-03",
          "2015-04",
          "2015-09",
          "2015-11",
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-02",
          "2017-03",
          "2017-04",
          "2017-06",
          "2017-10",
          "2017-11",
          "2017-12",
          "2018-02",
          "2018-03",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-09",
          "2018-12",
          "2019-03",
          "2019-04",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-10",
          "2019-11",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Semi-Supervised Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Semi-Supervised Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-10",
          "2016-11",
          "2017-03",
          "2017-04",
          "2018-06",
          "2018-07",
          "2019-05",
          "2019-09",
          "2019-11",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Semi-Supervised Video Object Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Semi-Supervised Video Object Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-06",
          "2018-02",
          "2018-03",
          "2018-04",
          "2018-06",
          "2019-02",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Sequential Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Sequential Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-11",
          "2016-03",
          "2017-10",
          "2018-03",
          "2018-10"
         ],
         "xaxis": "x",
         "y": [
          "Sequential Image Classification",
          "Sequential Image Classification",
          "Sequential Image Classification",
          "Sequential Image Classification",
          "Sequential Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Skeleton Based Action Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Skeleton Based Action Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2012-07",
          "2013-02",
          "2016-04",
          "2016-06",
          "2016-09",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-11",
          "2018-12",
          "2019-04",
          "2019-07",
          "2019-09",
          "2019-11",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Skin Cancer Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Skin Cancer Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-11",
          "2018-02"
         ],
         "xaxis": "x",
         "y": [
          "Skin Cancer Segmentation",
          "Skin Cancer Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Synthetic-to-Real Translation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Synthetic-to-Real Translation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-07",
          "2018-08",
          "2018-10",
          "2019-04",
          "2019-09",
          "2019-10",
          "2019-11",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Temporal Action Localization",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Temporal Action Localization",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-06",
          "2016-01",
          "2016-09",
          "2017-03",
          "2017-05",
          "2018-04",
          "2018-06",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Temporal Action Proposal Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Temporal Action Proposal Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-07"
         ],
         "xaxis": "x",
         "y": [
          "Temporal Action Proposal Generation",
          "Temporal Action Proposal Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Text-to-Image Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Text-to-Image Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2017-10",
          "2019-03",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Text-to-Image Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Unsupervised Domain Adaptation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Unsupervised Domain Adaptation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-02",
          "2015-05",
          "2017-11",
          "2018-11",
          "2018-12",
          "2019-11",
          "2020-01"
         ],
         "xaxis": "x",
         "y": [
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Unsupervised Image-To-Image Translation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Unsupervised Image-To-Image Translation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-03",
          "2017-11"
         ],
         "xaxis": "x",
         "y": [
          "Unsupervised Image-To-Image Translation",
          "Unsupervised Image-To-Image Translation",
          "Unsupervised Image-To-Image Translation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Unsupervised Person Re-Identification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Unsupervised Person Re-Identification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-05",
          "2017-11"
         ],
         "xaxis": "x",
         "y": [
          "Unsupervised Person Re-Identification",
          "Unsupervised Person Re-Identification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Video Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Video Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-09",
          "2016-11",
          "2017-07",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Video Generation",
          "Video Generation",
          "Video Generation",
          "Video Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Video Object Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Video Object Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-07",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "Video Object Detection",
          "Video Object Detection",
          "Video Object Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Video Prediction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Video Prediction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Video Prediction",
          "Video Prediction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Video Retrieval",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Video Retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-09",
          "2016-12",
          "2017-07",
          "2018-04",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "Video Retrieval",
          "Video Retrieval",
          "Video Retrieval",
          "Video Retrieval",
          "Video Retrieval"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Video Semantic Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Video Semantic Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Video Semantic Segmentation",
          "Video Semantic Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Video Super-Resolution",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Video Super-Resolution",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-09",
          "2016-11",
          "2017-04",
          "2018-01",
          "2018-06",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Video Super-Resolution",
          "Video Super-Resolution",
          "Video Super-Resolution",
          "Video Super-Resolution",
          "Video Super-Resolution",
          "Video Super-Resolution"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Visual Dialog",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Visual Dialog",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-09",
          "2017-11",
          "2018-09",
          "2019-02",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Visual Object Tracking",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Visual Object Tracking",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-04",
          "2017-06",
          "2017-10",
          "2018-02",
          "2018-03",
          "2018-06",
          "2018-12",
          "2019-06",
          "2019-07"
         ],
         "xaxis": "x",
         "y": [
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Visual Question Answering",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Visual Question Answering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Weakly Supervised Action Localization",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Weakly Supervised Action Localization",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Weakly Supervised Object Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Weakly Supervised Object Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-03",
          "2015-05",
          "2015-11",
          "2016-03",
          "2016-09",
          "2016-11",
          "2017-04",
          "2017-06",
          "2017-07",
          "2017-08",
          "2017-11",
          "2018-02",
          "2018-04",
          "2018-06",
          "2018-07",
          "2018-11",
          "2019-10",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Weakly-supervised 3D Human Pose Estimation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Weakly-supervised 3D Human Pose Estimation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-01",
          "2017-04",
          "2019-03"
         ],
         "xaxis": "x",
         "y": [
          "Weakly-supervised 3D Human Pose Estimation",
          "Weakly-supervised 3D Human Pose Estimation",
          "Weakly-supervised 3D Human Pose Estimation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "3D Human Pose Estimation<BR>task: 3D Human Pose Estimation<BR>date: 2017-09<BR>ratio: 0.07",
          "3D Human Pose Estimation<BR>task: 3D Human Pose Estimation<BR>date: 2018-06<BR>ratio: 0.25",
          "3D Human Pose Estimation<BR>task: 3D Human Pose Estimation<BR>date: 2019-09<BR>ratio: 0.45",
          "3D Human Pose Estimation<BR>task: 3D Human Pose Estimation<BR>date: 2020-02<BR>ratio: 0.0",
          "3D Instance Segmentation<BR>task: 3D Instance Segmentation<BR>date: 2019-04<BR>ratio: 0.26",
          "3D Instance Segmentation<BR>task: 3D Instance Segmentation<BR>date: 2019-06<BR>ratio: 0.01",
          "3D Instance Segmentation<BR>task: 3D Instance Segmentation<BR>date: 2020-03<BR>ratio: 0.24",
          "3D Instance Segmentation<BR>task: 3D Instance Segmentation<BR>date: 2020-04<BR>ratio: 0.07",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2016-06<BR>ratio: 0.09",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2017-11<BR>ratio: 0.48",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2017-12<BR>ratio: 0.03",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2018-02<BR>ratio: 0.03",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2018-12<BR>ratio: 0.09",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2019-03<BR>ratio: 0.15",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2019-04<BR>ratio: 0.4",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2019-07<BR>ratio: 0.04",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2020-01<BR>ratio: 0.15",
          "3D Object Detection<BR>task: 3D Object Detection<BR>date: 2020-03<BR>ratio: 0.21",
          "3D Object Reconstruction<BR>task: 3D Object Reconstruction<BR>date: 2016-12<BR>ratio: 0.15",
          "3D Object Reconstruction<BR>task: 3D Object Reconstruction<BR>date: 2018-02<BR>ratio: 0.26",
          "3D Object Reconstruction<BR>task: 3D Object Reconstruction<BR>date: 2019-01<BR>ratio: 0.01",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2016-12<BR>ratio: 0.32",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2017-06<BR>ratio: 0.01",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2017-11<BR>ratio: 0.01",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2018-01<BR>ratio: 0.01",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2019-04<BR>ratio: 0.01",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2019-09<BR>ratio: 0.0",
          "3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2017-04<BR>ratio: 0.02",
          "3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2017-06<BR>ratio: 0.06",
          "3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2018-01<BR>ratio: 0.01",
          "3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2018-03<BR>ratio: 0.01",
          "3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2018-12<BR>ratio: 0.0",
          "3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2019-04<BR>ratio: 0.0",
          "3D Reconstruction<BR>task: 3D Reconstruction<BR>date: 2016-03<BR>ratio: 0.32",
          "3D Reconstruction<BR>task: 3D Reconstruction<BR>date: 2016-12<BR>ratio: 0.16",
          "3D Reconstruction<BR>task: 3D Reconstruction<BR>date: 2018-08<BR>ratio: 0.0",
          "3D Room Layouts From A Single RGB Panorama<BR>task: 3D Room Layouts From A Single RGB Panorama<BR>date: 2018-11<BR>ratio: 0.09",
          "3D Room Layouts From A Single RGB Panorama<BR>task: 3D Room Layouts From A Single RGB Panorama<BR>date: 2019-01<BR>ratio: 0.03",
          "3D Semantic Instance Segmentation<BR>task: 3D Semantic Instance Segmentation<BR>date: 2017-11<BR>ratio: 0.23",
          "3D Semantic Instance Segmentation<BR>task: 3D Semantic Instance Segmentation<BR>date: 2018-12<BR>ratio: 0.39",
          "3D Semantic Instance Segmentation<BR>task: 3D Semantic Instance Segmentation<BR>date: 2020-03<BR>ratio: 0.37",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.25",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2017-06<BR>ratio: 0.09",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2017-10<BR>ratio: 0.16",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2018-07<BR>ratio: 0.11",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2018-09<BR>ratio: 0.06",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2019-04<BR>ratio: 0.32",
          "3D Shape Classification<BR>task: 3D Shape Classification<BR>date: 2016-10<BR>ratio: 0.16",
          "3D Shape Classification<BR>task: 3D Shape Classification<BR>date: 2018-04<BR>ratio: 0.14",
          "6D Pose Estimation<BR>task: 6D Pose Estimation<BR>date: 2019-01<BR>ratio: 0.47",
          "6D Pose Estimation<BR>task: 6D Pose Estimation<BR>date: 2019-11<BR>ratio: 0.04",
          "6D Pose Estimation using RGB<BR>task: 6D Pose Estimation using RGB<BR>date: 2018-03<BR>ratio: 0.48",
          "6D Pose Estimation using RGB<BR>task: 6D Pose Estimation using RGB<BR>date: 2019-02<BR>ratio: 0.38",
          "6D Pose Estimation using RGB<BR>task: 6D Pose Estimation using RGB<BR>date: 2019-09<BR>ratio: 0.0",
          "Action Classification<BR>task: Action Classification<BR>date: 2014-06<BR>ratio: 0.41",
          "Action Classification<BR>task: Action Classification<BR>date: 2016-12<BR>ratio: 0.08",
          "Action Classification<BR>task: Action Classification<BR>date: 2017-11<BR>ratio: 0.02",
          "Action Classification<BR>task: Action Classification<BR>date: 2017-12<BR>ratio: 0.47",
          "Action Classification<BR>task: Action Classification<BR>date: 2018-06<BR>ratio: 0.17",
          "Action Classification<BR>task: Action Classification<BR>date: 2018-07<BR>ratio: 0.05",
          "Action Classification<BR>task: Action Classification<BR>date: 2018-10<BR>ratio: 0.0",
          "Action Classification<BR>task: Action Classification<BR>date: 2018-11<BR>ratio: 0.07",
          "Action Classification<BR>task: Action Classification<BR>date: 2018-12<BR>ratio: 0.1",
          "Action Classification<BR>task: Action Classification<BR>date: 2019-05<BR>ratio: 0.0",
          "Action Classification<BR>task: Action Classification<BR>date: 2019-06<BR>ratio: 0.03",
          "Action Detection<BR>task: Action Detection<BR>date: 2016-12<BR>ratio: 0.43",
          "Action Detection<BR>task: Action Detection<BR>date: 2017-12<BR>ratio: 0.24",
          "Action Detection<BR>task: Action Detection<BR>date: 2018-03<BR>ratio: 0.17",
          "Action Detection<BR>task: Action Detection<BR>date: 2019-04<BR>ratio: 0.37",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2012-12<BR>ratio: 0.45",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2014-12<BR>ratio: 0.04",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2015-03<BR>ratio: 0.07",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2015-05<BR>ratio: 0.06",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2015-12<BR>ratio: 0.5",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2016-01<BR>ratio: 0.04",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2016-04<BR>ratio: 0.01",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2016-08<BR>ratio: 0.03",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2017-03<BR>ratio: 0.08",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2017-04<BR>ratio: 0.1",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2017-05<BR>ratio: 0.27",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2017-11<BR>ratio: 0.26",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-01<BR>ratio: 0.46",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-06<BR>ratio: 0.1",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-07<BR>ratio: 0.01",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-10<BR>ratio: 0.0",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-11<BR>ratio: 0.06",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-01<BR>ratio: 0.11",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-04<BR>ratio: 0.14",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-06<BR>ratio: 0.01",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-07<BR>ratio: 0.03",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-08<BR>ratio: 0.03",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-12<BR>ratio: 0.03",
          "Action Segmentation<BR>task: Action Segmentation<BR>date: 2016-11<BR>ratio: 0.14",
          "Action Segmentation<BR>task: Action Segmentation<BR>date: 2018-06<BR>ratio: 0.23",
          "Action Segmentation<BR>task: Action Segmentation<BR>date: 2020-03<BR>ratio: 0.1",
          "Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2014-12<BR>ratio: 0.16",
          "Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2015-05<BR>ratio: 0.04",
          "Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2016-05<BR>ratio: 0.06",
          "Aesthetics Quality Assessment<BR>task: Aesthetics Quality Assessment<BR>date: 2016-04<BR>ratio: 0.04",
          "Aesthetics Quality Assessment<BR>task: Aesthetics Quality Assessment<BR>date: 2017-04<BR>ratio: 0.04",
          "Aesthetics Quality Assessment<BR>task: Aesthetics Quality Assessment<BR>date: 2018-10<BR>ratio: 0.01",
          "Age-Invariant Face Recognition<BR>task: Age-Invariant Face Recognition<BR>date: 2017-03<BR>ratio: 0.01",
          "Age-Invariant Face Recognition<BR>task: Age-Invariant Face Recognition<BR>date: 2018-09<BR>ratio: 0.28",
          "Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2015-12<BR>ratio: 0.11",
          "Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2016-08<BR>ratio: 0.27",
          "Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2017-12<BR>ratio: 0.48",
          "Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2018-12<BR>ratio: 0.02",
          "Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2019-07<BR>ratio: 0.46",
          "Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2019-10<BR>ratio: 0.0",
          "Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2017-04<BR>ratio: 0.38",
          "Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2018-02<BR>ratio: 0.01",
          "Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2018-07<BR>ratio: 0.06",
          "Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2019-04<BR>ratio: 0.01",
          "Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2016-06<BR>ratio: 0.16",
          "Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2016-10<BR>ratio: 0.12",
          "Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2016-12<BR>ratio: 0.03",
          "Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2017-03<BR>ratio: 0.01",
          "Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2017-09<BR>ratio: 0.02",
          "Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2018-05<BR>ratio: 0.13",
          "Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2018-09<BR>ratio: 0.31",
          "Cross-Modal Retrieval<BR>task: Cross-Modal Retrieval<BR>date: 2017-12<BR>ratio: 0.49",
          "Cross-Modal Retrieval<BR>task: Cross-Modal Retrieval<BR>date: 2018-03<BR>ratio: 0.11",
          "Cross-View Image-to-Image Translation<BR>task: Cross-View Image-to-Image Translation<BR>date: 2016-12<BR>ratio: 0.0",
          "Cross-View Image-to-Image Translation<BR>task: Cross-View Image-to-Image Translation<BR>date: 2018-03<BR>ratio: 0.06",
          "Cross-View Image-to-Image Translation<BR>task: Cross-View Image-to-Image Translation<BR>date: 2019-04<BR>ratio: 0.34",
          "Curved Text Detection<BR>task: Curved Text Detection<BR>date: 2015-05<BR>ratio: 0.43",
          "Curved Text Detection<BR>task: Curved Text Detection<BR>date: 2019-04<BR>ratio: 0.15",
          "Denoising<BR>task: Denoising<BR>date: 2017-05<BR>ratio: 0.1",
          "Denoising<BR>task: Denoising<BR>date: 2018-07<BR>ratio: 0.01",
          "Denoising<BR>task: Denoising<BR>date: 2019-04<BR>ratio: 0.01",
          "Dense Object Detection<BR>task: Dense Object Detection<BR>date: 2015-06<BR>ratio: 0.06",
          "Dense Object Detection<BR>task: Dense Object Detection<BR>date: 2016-12<BR>ratio: 0.09",
          "Dense Object Detection<BR>task: Dense Object Detection<BR>date: 2019-04<BR>ratio: 0.18",
          "Document Image Classification<BR>task: Document Image Classification<BR>date: 2017-04<BR>ratio: 0.01",
          "Document Image Classification<BR>task: Document Image Classification<BR>date: 2018-01<BR>ratio: 0.01",
          "Document Image Classification<BR>task: Document Image Classification<BR>date: 2019-08<BR>ratio: 0.05",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2015-05<BR>ratio: 0.02",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2016-08<BR>ratio: 0.37",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-04<BR>ratio: 0.11",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-05<BR>ratio: 0.42",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-11<BR>ratio: 0.01",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-12<BR>ratio: 0.04",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2018-07<BR>ratio: 0.03",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2018-11<BR>ratio: 0.26",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-01<BR>ratio: 0.09",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-03<BR>ratio: 0.09",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-05<BR>ratio: 0.02",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-06<BR>ratio: 0.29",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-08<BR>ratio: 0.12",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-09<BR>ratio: 0.0",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-11<BR>ratio: 0.01",
          "Domain Generalization<BR>task: Domain Generalization<BR>date: 2017-08<BR>ratio: 0.03",
          "Domain Generalization<BR>task: Domain Generalization<BR>date: 2017-10<BR>ratio: 0.3",
          "Domain Generalization<BR>task: Domain Generalization<BR>date: 2019-03<BR>ratio: 0.1",
          "Domain Generalization<BR>task: Domain Generalization<BR>date: 2019-05<BR>ratio: 0.1",
          "Egocentric Activity Recognition<BR>task: Egocentric Activity Recognition<BR>date: 2018-11<BR>ratio: 0.34",
          "Egocentric Activity Recognition<BR>task: Egocentric Activity Recognition<BR>date: 2019-05<BR>ratio: 0.17",
          "Egocentric Activity Recognition<BR>task: Egocentric Activity Recognition<BR>date: 2019-08<BR>ratio: 0.06",
          "Egocentric Activity Recognition<BR>task: Egocentric Activity Recognition<BR>date: 2020-02<BR>ratio: 0.01",
          "Electron Microscopy Image Segmentation<BR>task: Electron Microscopy Image Segmentation<BR>date: 2019-06<BR>ratio: 0.48",
          "Electron Microscopy Image Segmentation<BR>task: Electron Microscopy Image Segmentation<BR>date: 2019-08<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-06<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-10<BR>ratio: 0.04",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-11<BR>ratio: 0.05",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-04<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-08<BR>ratio: 0.03",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-09<BR>ratio: 0.0",
          "Face Alignment<BR>task: Face Alignment<BR>date: 2017-07<BR>ratio: 0.17",
          "Face Alignment<BR>task: Face Alignment<BR>date: 2017-11<BR>ratio: 0.17",
          "Face Alignment<BR>task: Face Alignment<BR>date: 2018-03<BR>ratio: 0.19",
          "Face Alignment<BR>task: Face Alignment<BR>date: 2018-05<BR>ratio: 0.24",
          "Face Alignment<BR>task: Face Alignment<BR>date: 2019-02<BR>ratio: 0.0",
          "Face Alignment<BR>task: Face Alignment<BR>date: 2019-04<BR>ratio: 0.0",
          "Face Alignment<BR>task: Face Alignment<BR>date: 2019-06<BR>ratio: 0.0",
          "Face Detection<BR>task: Face Detection<BR>date: 2016-03<BR>ratio: 0.03",
          "Face Detection<BR>task: Face Detection<BR>date: 2017-08<BR>ratio: 0.03",
          "Face Detection<BR>task: Face Detection<BR>date: 2017-09<BR>ratio: 0.0",
          "Face Detection<BR>task: Face Detection<BR>date: 2018-09<BR>ratio: 0.0",
          "Face Detection<BR>task: Face Detection<BR>date: 2018-10<BR>ratio: 0.0",
          "Face Identification<BR>task: Face Identification<BR>date: 2015-11<BR>ratio: 0.03",
          "Face Identification<BR>task: Face Identification<BR>date: 2016-04<BR>ratio: 0.5",
          "Face Identification<BR>task: Face Identification<BR>date: 2017-04<BR>ratio: 0.06",
          "Face Identification<BR>task: Face Identification<BR>date: 2018-01<BR>ratio: 0.23",
          "Face Identification<BR>task: Face Identification<BR>date: 2018-03<BR>ratio: 0.03",
          "Face Identification<BR>task: Face Identification<BR>date: 2018-12<BR>ratio: 0.16",
          "Face Verification<BR>task: Face Verification<BR>date: 2014-06<BR>ratio: 0.01",
          "Face Verification<BR>task: Face Verification<BR>date: 2015-02<BR>ratio: 0.0",
          "Face Verification<BR>task: Face Verification<BR>date: 2015-03<BR>ratio: 0.23",
          "Face Verification<BR>task: Face Verification<BR>date: 2015-08<BR>ratio: 0.11",
          "Face Verification<BR>task: Face Verification<BR>date: 2015-11<BR>ratio: 0.43",
          "Face Verification<BR>task: Face Verification<BR>date: 2016-03<BR>ratio: 0.05",
          "Face Verification<BR>task: Face Verification<BR>date: 2016-04<BR>ratio: 0.47",
          "Face Verification<BR>task: Face Verification<BR>date: 2017-03<BR>ratio: 0.03",
          "Face Verification<BR>task: Face Verification<BR>date: 2017-04<BR>ratio: 0.04",
          "Face Verification<BR>task: Face Verification<BR>date: 2017-12<BR>ratio: 0.01",
          "Face Verification<BR>task: Face Verification<BR>date: 2018-01<BR>ratio: 0.09",
          "Face Verification<BR>task: Face Verification<BR>date: 2018-03<BR>ratio: 0.0",
          "Face Verification<BR>task: Face Verification<BR>date: 2018-09<BR>ratio: 0.12",
          "Face Verification<BR>task: Face Verification<BR>date: 2018-12<BR>ratio: 0.15",
          "Face Verification<BR>task: Face Verification<BR>date: 2019-03<BR>ratio: 0.02",
          "Face Verification<BR>task: Face Verification<BR>date: 2019-04<BR>ratio: 0.02",
          "Face Verification<BR>task: Face Verification<BR>date: 2019-08<BR>ratio: 0.0",
          "Face Verification<BR>task: Face Verification<BR>date: 2019-10<BR>ratio: 0.03",
          "Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2017-08<BR>ratio: 0.48",
          "Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2018-05<BR>ratio: 0.06",
          "Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2019-02<BR>ratio: 0.02",
          "Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2019-05<BR>ratio: 0.03",
          "Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2019-11<BR>ratio: 0.06",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2013-06<BR>ratio: 0.32",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2016-03<BR>ratio: 0.08",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2017-03<BR>ratio: 0.01",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2017-11<BR>ratio: 0.25",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2018-06<BR>ratio: 0.49",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2018-10<BR>ratio: 0.0",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-03<BR>ratio: 0.19",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-04<BR>ratio: 0.12",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-05<BR>ratio: 0.01",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-06<BR>ratio: 0.05",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-07<BR>ratio: 0.1",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-08<BR>ratio: 0.02",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2016-11<BR>ratio: 0.35",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2017-12<BR>ratio: 0.01",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2018-01<BR>ratio: 0.03",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2018-06<BR>ratio: 0.0",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2018-11<BR>ratio: 0.5",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2019-01<BR>ratio: 0.02",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2019-06<BR>ratio: 0.02",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2019-10<BR>ratio: 0.01",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2019-12<BR>ratio: 0.03",
          "Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2020-02<BR>ratio: 0.01",
          "Formation Energy<BR>task: Formation Energy<BR>date: 2018-11<BR>ratio: 0.22",
          "Formation Energy<BR>task: Formation Energy<BR>date: 2019-05<BR>ratio: 0.33",
          "Gesture-to-Gesture Translation<BR>task: Gesture-to-Gesture Translation<BR>date: 2017-07<BR>ratio: 0.03",
          "Gesture-to-Gesture Translation<BR>task: Gesture-to-Gesture Translation<BR>date: 2017-12<BR>ratio: 0.08",
          "Gesture-to-Gesture Translation<BR>task: Gesture-to-Gesture Translation<BR>date: 2018-08<BR>ratio: 0.42",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2016-08<BR>ratio: 0.33",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2017-04<BR>ratio: 0.5",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2018-05<BR>ratio: 0.18",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2018-06<BR>ratio: 0.01",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2019-10<BR>ratio: 0.16",
          "Group Activity Recognition<BR>task: Group Activity Recognition<BR>date: 2018-11<BR>ratio: 0.04",
          "Group Activity Recognition<BR>task: Group Activity Recognition<BR>date: 2019-04<BR>ratio: 0.07",
          "Hand Gesture Recognition<BR>task: Hand Gesture Recognition<BR>date: 2018-12<BR>ratio: 0.02",
          "Hand Gesture Recognition<BR>task: Hand Gesture Recognition<BR>date: 2019-01<BR>ratio: 0.03",
          "Hand Pose Estimation<BR>task: Hand Pose Estimation<BR>date: 2017-07<BR>ratio: 0.19",
          "Hand Pose Estimation<BR>task: Hand Pose Estimation<BR>date: 2017-12<BR>ratio: 0.02",
          "Horizon Line Estimation<BR>task: Horizon Line Estimation<BR>date: 2016-08<BR>ratio: 0.08",
          "Horizon Line Estimation<BR>task: Horizon Line Estimation<BR>date: 2019-05<BR>ratio: 0.05",
          "Human Interaction Recognition<BR>task: Human Interaction Recognition<BR>date: 2017-06<BR>ratio: 0.08",
          "Human Interaction Recognition<BR>task: Human Interaction Recognition<BR>date: 2018-11<BR>ratio: 0.02",
          "Human Part Segmentation<BR>task: Human Part Segmentation<BR>date: 2017-08<BR>ratio: 0.1",
          "Human Part Segmentation<BR>task: Human Part Segmentation<BR>date: 2018-05<BR>ratio: 0.04",
          "Human Part Segmentation<BR>task: Human Part Segmentation<BR>date: 2018-09<BR>ratio: 0.05",
          "Human Part Segmentation<BR>task: Human Part Segmentation<BR>date: 2019-10<BR>ratio: 0.04",
          "Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2016-04<BR>ratio: 0.16",
          "Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2017-04<BR>ratio: 0.36",
          "Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2018-07<BR>ratio: 0.08",
          "Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2018-08<BR>ratio: 0.41",
          "Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2018-11<BR>ratio: 0.32",
          "Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2019-04<BR>ratio: 0.15",
          "Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2019-12<BR>ratio: 0.18",
          "Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2020-03<BR>ratio: 0.05",
          "Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2020-04<BR>ratio: 0.03",
          "Hyperspectral Image Classification<BR>task: Hyperspectral Image Classification<BR>date: 2018-07<BR>ratio: 0.02",
          "Hyperspectral Image Classification<BR>task: Hyperspectral Image Classification<BR>date: 2019-02<BR>ratio: 0.03",
          "Image Classification<BR>task: Image Classification<BR>date: 2012-02<BR>ratio: 0.47",
          "Image Classification<BR>task: Image Classification<BR>date: 2012-12<BR>ratio: 0.47",
          "Image Classification<BR>task: Image Classification<BR>date: 2013-01<BR>ratio: 0.33",
          "Image Classification<BR>task: Image Classification<BR>date: 2013-02<BR>ratio: 0.04",
          "Image Classification<BR>task: Image Classification<BR>date: 2013-11<BR>ratio: 0.01",
          "Image Classification<BR>task: Image Classification<BR>date: 2013-12<BR>ratio: 0.12",
          "Image Classification<BR>task: Image Classification<BR>date: 2014-04<BR>ratio: 0.02",
          "Image Classification<BR>task: Image Classification<BR>date: 2014-06<BR>ratio: 0.19",
          "Image Classification<BR>task: Image Classification<BR>date: 2014-09<BR>ratio: 0.04",
          "Image Classification<BR>task: Image Classification<BR>date: 2014-12<BR>ratio: 0.03",
          "Image Classification<BR>task: Image Classification<BR>date: 2015-02<BR>ratio: 0.0",
          "Image Classification<BR>task: Image Classification<BR>date: 2015-06<BR>ratio: 0.41",
          "Image Classification<BR>task: Image Classification<BR>date: 2015-11<BR>ratio: 0.16",
          "Image Classification<BR>task: Image Classification<BR>date: 2015-12<BR>ratio: 0.02",
          "Image Classification<BR>task: Image Classification<BR>date: 2016-02<BR>ratio: 0.01",
          "Image Classification<BR>task: Image Classification<BR>date: 2016-03<BR>ratio: 0.34",
          "Image Classification<BR>task: Image Classification<BR>date: 2016-05<BR>ratio: 0.04",
          "Image Classification<BR>task: Image Classification<BR>date: 2016-08<BR>ratio: 0.01",
          "Image Classification<BR>task: Image Classification<BR>date: 2016-10<BR>ratio: 0.0",
          "Image Classification<BR>task: Image Classification<BR>date: 2016-11<BR>ratio: 0.02",
          "Image Classification<BR>task: Image Classification<BR>date: 2017-07<BR>ratio: 0.24",
          "Image Classification<BR>task: Image Classification<BR>date: 2017-08<BR>ratio: 0.21",
          "Image Classification<BR>task: Image Classification<BR>date: 2017-09<BR>ratio: 0.01",
          "Image Classification<BR>task: Image Classification<BR>date: 2017-10<BR>ratio: 0.01",
          "Image Classification<BR>task: Image Classification<BR>date: 2017-12<BR>ratio: 0.0",
          "Image Classification<BR>task: Image Classification<BR>date: 2018-02<BR>ratio: 0.12",
          "Image Classification<BR>task: Image Classification<BR>date: 2018-05<BR>ratio: 0.16",
          "Image Classification<BR>task: Image Classification<BR>date: 2018-07<BR>ratio: 0.02",
          "Image Classification<BR>task: Image Classification<BR>date: 2018-11<BR>ratio: 0.01",
          "Image Classification<BR>task: Image Classification<BR>date: 2019-01<BR>ratio: 0.36",
          "Image Classification<BR>task: Image Classification<BR>date: 2019-04<BR>ratio: 0.15",
          "Image Classification<BR>task: Image Classification<BR>date: 2019-05<BR>ratio: 0.04",
          "Image Classification<BR>task: Image Classification<BR>date: 2019-06<BR>ratio: 0.17",
          "Image Classification<BR>task: Image Classification<BR>date: 2019-08<BR>ratio: 0.17",
          "Image Classification<BR>task: Image Classification<BR>date: 2019-10<BR>ratio: 0.18",
          "Image Classification<BR>task: Image Classification<BR>date: 2019-12<BR>ratio: 0.22",
          "Image Classification<BR>task: Image Classification<BR>date: 2020-01<BR>ratio: 0.0",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2013-12<BR>ratio: 0.44",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2015-11<BR>ratio: 0.19",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2016-04<BR>ratio: 0.38",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2017-03<BR>ratio: 0.25",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2017-04<BR>ratio: 0.14",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2017-09<BR>ratio: 0.2",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2017-10<BR>ratio: 0.22",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2018-04<BR>ratio: 0.26",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2018-07<BR>ratio: 0.2",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2018-10<BR>ratio: 0.24",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2018-11<BR>ratio: 0.24",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2018-12<BR>ratio: 0.21",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2019-01<BR>ratio: 0.0",
          "Image Clustering<BR>task: Image Clustering<BR>date: 2019-04<BR>ratio: 0.17",
          "Image Generation<BR>task: Image Generation<BR>date: 2016-05<BR>ratio: 0.09",
          "Image Generation<BR>task: Image Generation<BR>date: 2017-02<BR>ratio: 0.02",
          "Image Generation<BR>task: Image Generation<BR>date: 2017-03<BR>ratio: 0.37",
          "Image Generation<BR>task: Image Generation<BR>date: 2017-09<BR>ratio: 0.42",
          "Image Generation<BR>task: Image Generation<BR>date: 2017-10<BR>ratio: 0.33",
          "Image Generation<BR>task: Image Generation<BR>date: 2018-02<BR>ratio: 0.38",
          "Image Generation<BR>task: Image Generation<BR>date: 2018-09<BR>ratio: 0.31",
          "Image Generation<BR>task: Image Generation<BR>date: 2018-11<BR>ratio: 0.42",
          "Image Generation<BR>task: Image Generation<BR>date: 2018-12<BR>ratio: 0.02",
          "Image Generation<BR>task: Image Generation<BR>date: 2019-03<BR>ratio: 0.23",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2014-12<BR>ratio: 0.44",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2015-04<BR>ratio: 0.39",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2015-11<BR>ratio: 0.29",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2016-04<BR>ratio: 0.32",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2016-08<BR>ratio: 0.12",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2016-11<BR>ratio: 0.27",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2016-12<BR>ratio: 0.01",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2017-12<BR>ratio: 0.02",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2018-01<BR>ratio: 0.06",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2018-03<BR>ratio: 0.05",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2018-04<BR>ratio: 0.48",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2018-11<BR>ratio: 0.14",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2019-02<BR>ratio: 0.5",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2019-03<BR>ratio: 0.08",
          "Image Retrieval<BR>task: Image Retrieval<BR>date: 2019-09<BR>ratio: 0.07",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2015-08<BR>ratio: 0.01",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2015-11<BR>ratio: 0.41",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-03<BR>ratio: 0.01",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-08<BR>ratio: 0.11",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-09<BR>ratio: 0.32",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-11<BR>ratio: 0.01",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-12<BR>ratio: 0.03",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2017-07<BR>ratio: 0.17",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2017-10<BR>ratio: 0.15",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-02<BR>ratio: 0.0",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-03<BR>ratio: 0.0",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-04<BR>ratio: 0.03",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-05<BR>ratio: 0.01",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-07<BR>ratio: 0.01",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-09<BR>ratio: 0.02",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-11<BR>ratio: 0.0",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2019-03<BR>ratio: 0.42",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2019-04<BR>ratio: 0.23",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2019-06<BR>ratio: 0.16",
          "Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2019-07<BR>ratio: 0.28",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2015-12<BR>ratio: 0.01",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2016-06<BR>ratio: 0.19",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2017-11<BR>ratio: 0.26",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2018-04<BR>ratio: 0.04",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2018-11<BR>ratio: 0.21",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-03<BR>ratio: 0.19",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-04<BR>ratio: 0.03",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-05<BR>ratio: 0.19",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-08<BR>ratio: 0.04",
          "Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-10<BR>ratio: 0.06",
          "Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2017-03<BR>ratio: 0.3",
          "Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2017-04<BR>ratio: 0.1",
          "Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2017-12<BR>ratio: 0.02",
          "Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-02<BR>ratio: 0.02",
          "Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-06<BR>ratio: 0.11",
          "Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-08<BR>ratio: 0.08",
          "Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-09<BR>ratio: 0.03",
          "Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-11<BR>ratio: 0.08",
          "Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2020-01<BR>ratio: 0.0",
          "Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2016-08<BR>ratio: 0.03",
          "Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2016-12<BR>ratio: 0.33",
          "Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2017-03<BR>ratio: 0.03",
          "Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2017-11<BR>ratio: 0.04",
          "Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2018-04<BR>ratio: 0.02",
          "Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2018-12<BR>ratio: 0.06",
          "Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2019-01<BR>ratio: 0.08",
          "Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2019-02<BR>ratio: 0.01",
          "Lane Detection<BR>task: Lane Detection<BR>date: 2017-10<BR>ratio: 0.0",
          "Lane Detection<BR>task: Lane Detection<BR>date: 2017-12<BR>ratio: 0.5",
          "Lane Detection<BR>task: Lane Detection<BR>date: 2018-06<BR>ratio: 0.0",
          "Lane Detection<BR>task: Lane Detection<BR>date: 2019-08<BR>ratio: 0.5",
          "Layout-to-Image Generation<BR>task: Layout-to-Image Generation<BR>date: 2018-11<BR>ratio: 0.19",
          "Layout-to-Image Generation<BR>task: Layout-to-Image Generation<BR>date: 2019-09<BR>ratio: 0.32",
          "Lesion Segmentation<BR>task: Lesion Segmentation<BR>date: 2018-10<BR>ratio: 0.47",
          "Lesion Segmentation<BR>task: Lesion Segmentation<BR>date: 2020-03<BR>ratio: 0.0",
          "Low-Light Image Enhancement<BR>task: Low-Light Image Enhancement<BR>date: 2019-06<BR>ratio: 0.03",
          "Low-Light Image Enhancement<BR>task: Low-Light Image Enhancement<BR>date: 2020-01<BR>ratio: 0.11",
          "Lung Nodule Segmentation<BR>task: Lung Nodule Segmentation<BR>date: 2017-11<BR>ratio: 0.0",
          "Lung Nodule Segmentation<BR>task: Lung Nodule Segmentation<BR>date: 2019-08<BR>ratio: 0.5",
          "Medical Image Segmentation<BR>task: Medical Image Segmentation<BR>date: 2015-11<BR>ratio: 0.2",
          "Medical Image Segmentation<BR>task: Medical Image Segmentation<BR>date: 2018-07<BR>ratio: 0.4",
          "Metric Learning<BR>task: Metric Learning<BR>date: 2016-11<BR>ratio: 0.04",
          "Metric Learning<BR>task: Metric Learning<BR>date: 2017-06<BR>ratio: 0.47",
          "Metric Learning<BR>task: Metric Learning<BR>date: 2018-04<BR>ratio: 0.06",
          "Metric Learning<BR>task: Metric Learning<BR>date: 2019-08<BR>ratio: 0.04",
          "Monocular Depth Estimation<BR>task: Monocular Depth Estimation<BR>date: 2016-09<BR>ratio: 0.34",
          "Monocular Depth Estimation<BR>task: Monocular Depth Estimation<BR>date: 2018-03<BR>ratio: 0.5",
          "Monocular Depth Estimation<BR>task: Monocular Depth Estimation<BR>date: 2018-05<BR>ratio: 0.0",
          "Multi-Human Parsing<BR>task: Multi-Human Parsing<BR>date: 2017-05<BR>ratio: 0.12",
          "Multi-Human Parsing<BR>task: Multi-Human Parsing<BR>date: 2017-09<BR>ratio: 0.03",
          "Multi-Human Parsing<BR>task: Multi-Human Parsing<BR>date: 2018-04<BR>ratio: 0.23",
          "Multi-Object Tracking<BR>task: Multi-Object Tracking<BR>date: 2018-04<BR>ratio: 0.03",
          "Multi-Object Tracking<BR>task: Multi-Object Tracking<BR>date: 2018-11<BR>ratio: 0.02",
          "Multi-Object Tracking<BR>task: Multi-Object Tracking<BR>date: 2019-06<BR>ratio: 0.38",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2016-05<BR>ratio: 0.37",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2016-08<BR>ratio: 0.03",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2016-12<BR>ratio: 0.06",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2017-01<BR>ratio: 0.03",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2017-11<BR>ratio: 0.0",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2018-03<BR>ratio: 0.05",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2019-06<BR>ratio: 0.41",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2019-07<BR>ratio: 0.0",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2019-08<BR>ratio: 0.06",
          "Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2019-10<BR>ratio: 0.0",
          "Multi-tissue Nucleus Segmentation<BR>task: Multi-tissue Nucleus Segmentation<BR>date: 2015-05<BR>ratio: 0.33",
          "Multi-tissue Nucleus Segmentation<BR>task: Multi-tissue Nucleus Segmentation<BR>date: 2017-03<BR>ratio: 0.06",
          "Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2015-11<BR>ratio: 0.5",
          "Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2016-03<BR>ratio: 0.03",
          "Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2016-08<BR>ratio: 0.42",
          "Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2017-04<BR>ratio: 0.08",
          "Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2018-01<BR>ratio: 0.25",
          "Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2019-01<BR>ratio: 0.5",
          "Multimodal Unsupervised Image-To-Image Translation<BR>task: Multimodal Unsupervised Image-To-Image Translation<BR>date: 2017-03<BR>ratio: 0.45",
          "Multimodal Unsupervised Image-To-Image Translation<BR>task: Multimodal Unsupervised Image-To-Image Translation<BR>date: 2017-11<BR>ratio: 0.49",
          "Multimodal Unsupervised Image-To-Image Translation<BR>task: Multimodal Unsupervised Image-To-Image Translation<BR>date: 2018-04<BR>ratio: 0.35",
          "Multimodal Unsupervised Image-To-Image Translation<BR>task: Multimodal Unsupervised Image-To-Image Translation<BR>date: 2018-08<BR>ratio: 0.48",
          "Multiple Object Tracking<BR>task: Multiple Object Tracking<BR>date: 2018-02<BR>ratio: 0.07",
          "Multiple Object Tracking<BR>task: Multiple Object Tracking<BR>date: 2018-11<BR>ratio: 0.0",
          "Multiple Object Tracking<BR>task: Multiple Object Tracking<BR>date: 2019-09<BR>ratio: 0.0",
          "Multivariate Time Series Imputation<BR>task: Multivariate Time Series Imputation<BR>date: 2016-06<BR>ratio: 0.12",
          "Multivariate Time Series Imputation<BR>task: Multivariate Time Series Imputation<BR>date: 2018-12<BR>ratio: 0.25",
          "Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2016-11<BR>ratio: 0.0",
          "Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2017-03<BR>ratio: 0.13",
          "Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2018-09<BR>ratio: 0.0",
          "Object Counting<BR>task: Object Counting<BR>date: 2015-06<BR>ratio: 0.34",
          "Object Counting<BR>task: Object Counting<BR>date: 2016-04<BR>ratio: 0.48",
          "Object Detection<BR>task: Object Detection<BR>date: 2015-06<BR>ratio: 0.09",
          "Object Detection<BR>task: Object Detection<BR>date: 2015-12<BR>ratio: 0.42",
          "Object Detection<BR>task: Object Detection<BR>date: 2017-03<BR>ratio: 0.27",
          "Object Detection<BR>task: Object Detection<BR>date: 2017-07<BR>ratio: 0.27",
          "Object Detection<BR>task: Object Detection<BR>date: 2017-08<BR>ratio: 0.02",
          "Object Detection<BR>task: Object Detection<BR>date: 2017-11<BR>ratio: 0.05",
          "Object Detection<BR>task: Object Detection<BR>date: 2017-12<BR>ratio: 0.04",
          "Object Detection<BR>task: Object Detection<BR>date: 2018-03<BR>ratio: 0.04",
          "Object Detection<BR>task: Object Detection<BR>date: 2018-05<BR>ratio: 0.04",
          "Object Detection<BR>task: Object Detection<BR>date: 2018-11<BR>ratio: 0.06",
          "Object Detection<BR>task: Object Detection<BR>date: 2018-12<BR>ratio: 0.16",
          "Object Detection<BR>task: Object Detection<BR>date: 2019-01<BR>ratio: 0.03",
          "Object Detection<BR>task: Object Detection<BR>date: 2019-06<BR>ratio: 0.06",
          "Object Detection<BR>task: Object Detection<BR>date: 2019-08<BR>ratio: 0.03",
          "Object Detection<BR>task: Object Detection<BR>date: 2019-09<BR>ratio: 0.18",
          "Object Detection<BR>task: Object Detection<BR>date: 2019-10<BR>ratio: 0.02",
          "Object Detection<BR>task: Object Detection<BR>date: 2019-11<BR>ratio: 0.01",
          "Pancreas Segmentation<BR>task: Pancreas Segmentation<BR>date: 2017-09<BR>ratio: 0.11",
          "Pancreas Segmentation<BR>task: Pancreas Segmentation<BR>date: 2018-04<BR>ratio: 0.0",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2018-12<BR>ratio: 0.17",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-01<BR>ratio: 0.26",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-05<BR>ratio: 0.04",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-09<BR>ratio: 0.28",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-11<BR>ratio: 0.04",
          "Pedestrian Attribute Recognition<BR>task: Pedestrian Attribute Recognition<BR>date: 2016-08<BR>ratio: 0.05",
          "Pedestrian Attribute Recognition<BR>task: Pedestrian Attribute Recognition<BR>date: 2019-10<BR>ratio: 0.05",
          "Pedestrian Detection<BR>task: Pedestrian Detection<BR>date: 2014-12<BR>ratio: 0.16",
          "Pedestrian Detection<BR>task: Pedestrian Detection<BR>date: 2018-07<BR>ratio: 0.07",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2014-06<BR>ratio: 0.3",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2016-03<BR>ratio: 0.1",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2016-07<BR>ratio: 0.04",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2016-10<BR>ratio: 0.43",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2016-11<BR>ratio: 0.25",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-01<BR>ratio: 0.16",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-03<BR>ratio: 0.23",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-07<BR>ratio: 0.08",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-08<BR>ratio: 0.03",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-09<BR>ratio: 0.38",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-10<BR>ratio: 0.04",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-11<BR>ratio: 0.34",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-02<BR>ratio: 0.01",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-04<BR>ratio: 0.25",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-05<BR>ratio: 0.0",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-06<BR>ratio: 0.06",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-07<BR>ratio: 0.02",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-10<BR>ratio: 0.1",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-11<BR>ratio: 0.01",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-12<BR>ratio: 0.21",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-03<BR>ratio: 0.45",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-05<BR>ratio: 0.28",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-08<BR>ratio: 0.24",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-10<BR>ratio: 0.28",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-11<BR>ratio: 0.03",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-12<BR>ratio: 0.04",
          "Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2020-01<BR>ratio: 0.03",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2015-11<BR>ratio: 0.0",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2016-03<BR>ratio: 0.37",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2016-09<BR>ratio: 0.0",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2016-12<BR>ratio: 0.3",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-01<BR>ratio: 0.04",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-02<BR>ratio: 0.01",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-04<BR>ratio: 0.0",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-05<BR>ratio: 0.01",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-07<BR>ratio: 0.08",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-08<BR>ratio: 0.0",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-11<BR>ratio: 0.04",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-12<BR>ratio: 0.5",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-03<BR>ratio: 0.0",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-04<BR>ratio: 0.01",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-05<BR>ratio: 0.01",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-11<BR>ratio: 0.09",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-12<BR>ratio: 0.01",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2019-01<BR>ratio: 0.14",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2019-02<BR>ratio: 0.01",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2019-10<BR>ratio: 0.0",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2020-01<BR>ratio: 0.02",
          "Pose Estimation<BR>task: Pose Estimation<BR>date: 2020-02<BR>ratio: 0.0",
          "Pose Tracking<BR>task: Pose Tracking<BR>date: 2017-12<BR>ratio: 0.03",
          "Pose Tracking<BR>task: Pose Tracking<BR>date: 2018-02<BR>ratio: 0.05",
          "Pose Tracking<BR>task: Pose Tracking<BR>date: 2019-02<BR>ratio: 0.01",
          "Pose Tracking<BR>task: Pose Tracking<BR>date: 2019-05<BR>ratio: 0.0",
          "RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2016-06<BR>ratio: 0.0",
          "RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2017-04<BR>ratio: 0.0",
          "RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2017-08<BR>ratio: 0.47",
          "RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2017-10<BR>ratio: 0.15",
          "RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2018-06<BR>ratio: 0.38",
          "RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2019-06<BR>ratio: 0.0",
          "Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2016-05<BR>ratio: 0.09",
          "Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2017-08<BR>ratio: 0.01",
          "Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2019-04<BR>ratio: 0.09",
          "Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2019-09<BR>ratio: 0.11",
          "Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2019-11<BR>ratio: 0.04",
          "Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2020-04<BR>ratio: 0.3",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2015-02<BR>ratio: 0.01",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2015-11<BR>ratio: 0.06",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-06<BR>ratio: 0.39",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-11<BR>ratio: 0.06",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.26",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2017-04<BR>ratio: 0.18",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2018-08<BR>ratio: 0.12",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2018-11<BR>ratio: 0.0",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2019-03<BR>ratio: 0.01",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2019-09<BR>ratio: 0.01",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.25",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2017-11<BR>ratio: 0.0",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-02<BR>ratio: 0.0",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-06<BR>ratio: 0.33",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-10<BR>ratio: 0.0",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2019-07<BR>ratio: 0.5",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2019-12<BR>ratio: 0.0",
          "Satellite Image Classification<BR>task: Satellite Image Classification<BR>date: 2015-12<BR>ratio: 0.01",
          "Satellite Image Classification<BR>task: Satellite Image Classification<BR>date: 2019-11<BR>ratio: 0.03",
          "Scene Graph Generation<BR>task: Scene Graph Generation<BR>date: 2017-07<BR>ratio: 0.34",
          "Scene Graph Generation<BR>task: Scene Graph Generation<BR>date: 2018-06<BR>ratio: 0.01",
          "Scene Graph Generation<BR>task: Scene Graph Generation<BR>date: 2018-08<BR>ratio: 0.02",
          "Scene Segmentation<BR>task: Scene Segmentation<BR>date: 2018-03<BR>ratio: 0.2",
          "Scene Segmentation<BR>task: Scene Segmentation<BR>date: 2019-08<BR>ratio: 0.04",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2015-04<BR>ratio: 0.03",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2016-04<BR>ratio: 0.33",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-03<BR>ratio: 0.43",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-04<BR>ratio: 0.18",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-07<BR>ratio: 0.05",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-08<BR>ratio: 0.02",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-09<BR>ratio: 0.28",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-01<BR>ratio: 0.38",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-02<BR>ratio: 0.05",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-04<BR>ratio: 0.06",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-06<BR>ratio: 0.27",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-07<BR>ratio: 0.02",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-11<BR>ratio: 0.12",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2019-03<BR>ratio: 0.05",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2019-04<BR>ratio: 0.35",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2019-10<BR>ratio: 0.02",
          "Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2019-11<BR>ratio: 0.03",
          "Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2016-03<BR>ratio: 0.5",
          "Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2019-01<BR>ratio: 0.04",
          "Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2019-06<BR>ratio: 0.39",
          "Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2019-07<BR>ratio: 0.03",
          "Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2019-11<BR>ratio: 0.01",
          "Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2020-03<BR>ratio: 0.07",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-02<BR>ratio: 0.03",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-03<BR>ratio: 0.02",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-04<BR>ratio: 0.08",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-09<BR>ratio: 0.21",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-11<BR>ratio: 0.36",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-03<BR>ratio: 0.38",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-05<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-06<BR>ratio: 0.47",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-11<BR>ratio: 0.25",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.44",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-02<BR>ratio: 0.42",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-03<BR>ratio: 0.4",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-04<BR>ratio: 0.06",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-06<BR>ratio: 0.21",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-10<BR>ratio: 0.09",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-11<BR>ratio: 0.34",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-12<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-02<BR>ratio: 0.04",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-03<BR>ratio: 0.03",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-04<BR>ratio: 0.06",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-06<BR>ratio: 0.05",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-08<BR>ratio: 0.5",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-09<BR>ratio: 0.04",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-12<BR>ratio: 0.05",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-03<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-04<BR>ratio: 0.13",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-06<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-08<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-09<BR>ratio: 0.02",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-10<BR>ratio: 0.28",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-11<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.04",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2016-10<BR>ratio: 0.15",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2016-11<BR>ratio: 0.04",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2017-03<BR>ratio: 0.25",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2017-04<BR>ratio: 0.27",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2018-06<BR>ratio: 0.31",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2018-07<BR>ratio: 0.21",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2019-05<BR>ratio: 0.24",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2019-09<BR>ratio: 0.09",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2019-11<BR>ratio: 0.11",
          "Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2019-12<BR>ratio: 0.0",
          "Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2016-11<BR>ratio: 0.49",
          "Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2017-06<BR>ratio: 0.05",
          "Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2018-02<BR>ratio: 0.49",
          "Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2018-03<BR>ratio: 0.0",
          "Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2018-04<BR>ratio: 0.01",
          "Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2018-06<BR>ratio: 0.0",
          "Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2019-02<BR>ratio: 0.0",
          "Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2019-08<BR>ratio: 0.01",
          "Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2015-11<BR>ratio: 0.03",
          "Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2016-03<BR>ratio: 0.04",
          "Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2017-10<BR>ratio: 0.0",
          "Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2018-03<BR>ratio: 0.43",
          "Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2018-10<BR>ratio: 0.15",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2012-07<BR>ratio: 0.22",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2013-02<BR>ratio: 0.04",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-04<BR>ratio: 0.47",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-06<BR>ratio: 0.49",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-09<BR>ratio: 0.1",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-11<BR>ratio: 0.16",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-03<BR>ratio: 0.03",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-04<BR>ratio: 0.39",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-05<BR>ratio: 0.09",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-08<BR>ratio: 0.36",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-01<BR>ratio: 0.34",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-02<BR>ratio: 0.36",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-04<BR>ratio: 0.05",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-05<BR>ratio: 0.14",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-06<BR>ratio: 0.06",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-11<BR>ratio: 0.01",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-12<BR>ratio: 0.05",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-04<BR>ratio: 0.07",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-07<BR>ratio: 0.34",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-09<BR>ratio: 0.0",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-11<BR>ratio: 0.01",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-12<BR>ratio: 0.02",
          "Skin Cancer Segmentation<BR>task: Skin Cancer Segmentation<BR>date: 2017-11<BR>ratio: 0.0",
          "Skin Cancer Segmentation<BR>task: Skin Cancer Segmentation<BR>date: 2018-02<BR>ratio: 0.0",
          "Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2017-07<BR>ratio: 0.04",
          "Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2018-08<BR>ratio: 0.07",
          "Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2018-10<BR>ratio: 0.04",
          "Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-04<BR>ratio: 0.03",
          "Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-09<BR>ratio: 0.01",
          "Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-10<BR>ratio: 0.36",
          "Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-11<BR>ratio: 0.06",
          "Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-12<BR>ratio: 0.03",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2015-06<BR>ratio: 0.4",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2016-01<BR>ratio: 0.03",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2016-09<BR>ratio: 0.37",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2017-03<BR>ratio: 0.19",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2017-05<BR>ratio: 0.23",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2018-04<BR>ratio: 0.26",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2018-06<BR>ratio: 0.3",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-04<BR>ratio: 0.08",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-06<BR>ratio: 0.06",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-07<BR>ratio: 0.07",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-09<BR>ratio: 0.1",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-11<BR>ratio: 0.03",
          "Temporal Action Proposal Generation<BR>task: Temporal Action Proposal Generation<BR>date: 2018-11<BR>ratio: 0.01",
          "Temporal Action Proposal Generation<BR>task: Temporal Action Proposal Generation<BR>date: 2019-07<BR>ratio: 0.01",
          "Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2016-12<BR>ratio: 0.43",
          "Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2017-10<BR>ratio: 0.34",
          "Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2019-03<BR>ratio: 0.03",
          "Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2019-04<BR>ratio: 0.14",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2015-02<BR>ratio: 0.25",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2015-05<BR>ratio: 0.03",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2017-11<BR>ratio: 0.44",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2018-11<BR>ratio: 0.36",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2018-12<BR>ratio: 0.25",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2019-11<BR>ratio: 0.04",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2020-01<BR>ratio: 0.23",
          "Unsupervised Image-To-Image Translation<BR>task: Unsupervised Image-To-Image Translation<BR>date: 2016-11<BR>ratio: 0.12",
          "Unsupervised Image-To-Image Translation<BR>task: Unsupervised Image-To-Image Translation<BR>date: 2017-03<BR>ratio: 0.44",
          "Unsupervised Image-To-Image Translation<BR>task: Unsupervised Image-To-Image Translation<BR>date: 2017-11<BR>ratio: 0.32",
          "Unsupervised Person Re-Identification<BR>task: Unsupervised Person Re-Identification<BR>date: 2017-05<BR>ratio: 0.49",
          "Unsupervised Person Re-Identification<BR>task: Unsupervised Person Re-Identification<BR>date: 2017-11<BR>ratio: 0.45",
          "Video Generation<BR>task: Video Generation<BR>date: 2016-09<BR>ratio: 0.36",
          "Video Generation<BR>task: Video Generation<BR>date: 2016-11<BR>ratio: 0.16",
          "Video Generation<BR>task: Video Generation<BR>date: 2017-07<BR>ratio: 0.03",
          "Video Generation<BR>task: Video Generation<BR>date: 2019-12<BR>ratio: 0.46",
          "Video Object Detection<BR>task: Video Object Detection<BR>date: 2018-11<BR>ratio: 0.04",
          "Video Object Detection<BR>task: Video Object Detection<BR>date: 2019-07<BR>ratio: 0.01",
          "Video Object Detection<BR>task: Video Object Detection<BR>date: 2020-03<BR>ratio: 0.01",
          "Video Prediction<BR>task: Video Prediction<BR>date: 2018-11<BR>ratio: 0.0",
          "Video Prediction<BR>task: Video Prediction<BR>date: 2019-05<BR>ratio: 0.5",
          "Video Retrieval<BR>task: Video Retrieval<BR>date: 2016-09<BR>ratio: 0.5",
          "Video Retrieval<BR>task: Video Retrieval<BR>date: 2016-12<BR>ratio: 0.07",
          "Video Retrieval<BR>task: Video Retrieval<BR>date: 2017-07<BR>ratio: 0.12",
          "Video Retrieval<BR>task: Video Retrieval<BR>date: 2018-04<BR>ratio: 0.24",
          "Video Retrieval<BR>task: Video Retrieval<BR>date: 2019-06<BR>ratio: 0.28",
          "Video Semantic Segmentation<BR>task: Video Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.06",
          "Video Semantic Segmentation<BR>task: Video Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.0",
          "Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2016-09<BR>ratio: 0.01",
          "Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2016-11<BR>ratio: 0.09",
          "Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2017-04<BR>ratio: 0.01",
          "Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2018-01<BR>ratio: 0.01",
          "Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2018-06<BR>ratio: 0.01",
          "Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2019-05<BR>ratio: 0.0",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2017-09<BR>ratio: 0.06",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2017-11<BR>ratio: 0.04",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2018-09<BR>ratio: 0.02",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2019-02<BR>ratio: 0.02",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2019-04<BR>ratio: 0.05",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2016-11<BR>ratio: 0.45",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2017-04<BR>ratio: 0.41",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2017-06<BR>ratio: 0.4",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2017-10<BR>ratio: 0.0",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2018-02<BR>ratio: 0.1",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2018-03<BR>ratio: 0.0",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2018-06<BR>ratio: 0.0",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2018-12<BR>ratio: 0.04",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2019-06<BR>ratio: 0.0",
          "Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2019-07<BR>ratio: 0.18",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-03<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-05<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-06<BR>ratio: 0.45",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-11<BR>ratio: 0.07",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-12<BR>ratio: 0.43",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-04<BR>ratio: 0.35",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-05<BR>ratio: 0.05",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-08<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-03<BR>ratio: 0.0",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-05<BR>ratio: 0.0",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-02<BR>ratio: 0.36",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-04<BR>ratio: 0.33",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-05<BR>ratio: 0.19",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-06<BR>ratio: 0.01",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-07<BR>ratio: 0.14",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-08<BR>ratio: 0.22",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-09<BR>ratio: 0.05",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2020-02<BR>ratio: 0.0",
          "Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-05<BR>ratio: 0.13",
          "Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-06<BR>ratio: 0.01",
          "Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-08<BR>ratio: 0.38",
          "Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-11<BR>ratio: 0.35",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2014-03<BR>ratio: 0.42",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2015-05<BR>ratio: 0.25",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2015-11<BR>ratio: 0.47",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2016-03<BR>ratio: 0.08",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2016-09<BR>ratio: 0.35",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2016-11<BR>ratio: 0.25",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-04<BR>ratio: 0.08",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-06<BR>ratio: 0.15",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-07<BR>ratio: 0.01",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-08<BR>ratio: 0.09",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-11<BR>ratio: 0.1",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-02<BR>ratio: 0.08",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-04<BR>ratio: 0.0",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-06<BR>ratio: 0.06",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-07<BR>ratio: 0.11",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-11<BR>ratio: 0.03",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2019-10<BR>ratio: 0.02",
          "Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2019-11<BR>ratio: 0.02",
          "Weakly-supervised 3D Human Pose Estimation<BR>task: Weakly-supervised 3D Human Pose Estimation<BR>date: 2017-01<BR>ratio: 0.42",
          "Weakly-supervised 3D Human Pose Estimation<BR>task: Weakly-supervised 3D Human Pose Estimation<BR>date: 2017-04<BR>ratio: 0.25",
          "Weakly-supervised 3D Human Pose Estimation<BR>task: Weakly-supervised 3D Human Pose Estimation<BR>date: 2019-03<BR>ratio: 0.5"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.07,
           0.25,
           0.45,
           0,
           0.26,
           0.01,
           0.24,
           0.07,
           0.09,
           0.48,
           0.03,
           0.03,
           0.09,
           0.15,
           0.4,
           0.04,
           0.15,
           0.21,
           0.15,
           0.26,
           0.01,
           0.32,
           0.01,
           0.01,
           0.01,
           0.01,
           0,
           0.02,
           0.06,
           0.01,
           0.01,
           0,
           0,
           0.32,
           0.16,
           0,
           0.09,
           0.03,
           0.23,
           0.39,
           0.37,
           0.25,
           0.09,
           0.16,
           0.11,
           0.06,
           0.32,
           0.16,
           0.14,
           0.47,
           0.04,
           0.48,
           0.38,
           0,
           0.41,
           0.08,
           0.02,
           0.47,
           0.17,
           0.05,
           0,
           0.07,
           0.1,
           0,
           0.03,
           0.43,
           0.24,
           0.17,
           0.37,
           0.45,
           0.04,
           0.07,
           0.06,
           0.5,
           0.04,
           0.01,
           0.03,
           0.08,
           0.1,
           0.27,
           0.26,
           0.46,
           0.1,
           0.01,
           0,
           0.06,
           0.11,
           0.14,
           0.01,
           0.03,
           0.03,
           0.03,
           0.14,
           0.23,
           0.1,
           0.16,
           0.04,
           0.06,
           0.04,
           0.04,
           0.01,
           0.01,
           0.28,
           0.11,
           0.27,
           0.48,
           0.02,
           0.46,
           0,
           0.38,
           0.01,
           0.06,
           0.01,
           0.16,
           0.12,
           0.03,
           0.01,
           0.02,
           0.13,
           0.31,
           0.49,
           0.11,
           0,
           0.06,
           0.34,
           0.43,
           0.15,
           0.1,
           0.01,
           0.01,
           0.06,
           0.09,
           0.18,
           0.01,
           0.01,
           0.05,
           0.02,
           0.37,
           0.11,
           0.42,
           0.01,
           0.04,
           0.03,
           0.26,
           0.09,
           0.09,
           0.02,
           0.29,
           0.12,
           0,
           0.01,
           0.03,
           0.3,
           0.1,
           0.1,
           0.34,
           0.17,
           0.06,
           0.01,
           0.48,
           0,
           0,
           0.04,
           0.05,
           0,
           0.03,
           0,
           0.17,
           0.17,
           0.19,
           0.24,
           0,
           0,
           0,
           0.03,
           0.03,
           0,
           0,
           0,
           0.03,
           0.5,
           0.06,
           0.23,
           0.03,
           0.16,
           0.01,
           0,
           0.23,
           0.11,
           0.43,
           0.05,
           0.47,
           0.03,
           0.04,
           0.01,
           0.09,
           0,
           0.12,
           0.15,
           0.02,
           0.02,
           0,
           0.03,
           0.48,
           0.06,
           0.02,
           0.03,
           0.06,
           0.32,
           0.08,
           0.01,
           0.25,
           0.49,
           0,
           0.19,
           0.12,
           0.01,
           0.05,
           0.1,
           0.02,
           0.35,
           0.01,
           0.03,
           0,
           0.5,
           0.02,
           0.02,
           0.01,
           0.03,
           0.01,
           0.22,
           0.33,
           0.03,
           0.08,
           0.42,
           0.33,
           0.5,
           0.18,
           0.01,
           0.16,
           0.04,
           0.07,
           0.02,
           0.03,
           0.19,
           0.02,
           0.08,
           0.05,
           0.08,
           0.02,
           0.1,
           0.04,
           0.05,
           0.04,
           0.16,
           0.36,
           0.08,
           0.41,
           0.32,
           0.15,
           0.18,
           0.05,
           0.03,
           0.02,
           0.03,
           0.47,
           0.47,
           0.33,
           0.04,
           0.01,
           0.12,
           0.02,
           0.19,
           0.04,
           0.03,
           0,
           0.41,
           0.16,
           0.02,
           0.01,
           0.34,
           0.04,
           0.01,
           0,
           0.02,
           0.24,
           0.21,
           0.01,
           0.01,
           0,
           0.12,
           0.16,
           0.02,
           0.01,
           0.36,
           0.15,
           0.04,
           0.17,
           0.17,
           0.18,
           0.22,
           0,
           0.44,
           0.19,
           0.38,
           0.25,
           0.14,
           0.2,
           0.22,
           0.26,
           0.2,
           0.24,
           0.24,
           0.21,
           0,
           0.17,
           0.09,
           0.02,
           0.37,
           0.42,
           0.33,
           0.38,
           0.31,
           0.42,
           0.02,
           0.23,
           0.44,
           0.39,
           0.29,
           0.32,
           0.12,
           0.27,
           0.01,
           0.02,
           0.06,
           0.05,
           0.48,
           0.14,
           0.5,
           0.08,
           0.07,
           0.01,
           0.41,
           0.01,
           0.11,
           0.32,
           0.01,
           0.03,
           0.17,
           0.15,
           0,
           0,
           0.03,
           0.01,
           0.01,
           0.02,
           0,
           0.42,
           0.23,
           0.16,
           0.28,
           0.01,
           0.19,
           0.26,
           0.04,
           0.21,
           0.19,
           0.03,
           0.19,
           0.04,
           0.06,
           0.3,
           0.1,
           0.02,
           0.02,
           0.11,
           0.08,
           0.03,
           0.08,
           0,
           0.03,
           0.33,
           0.03,
           0.04,
           0.02,
           0.06,
           0.08,
           0.01,
           0,
           0.5,
           0,
           0.5,
           0.19,
           0.32,
           0.47,
           0,
           0.03,
           0.11,
           0,
           0.5,
           0.2,
           0.4,
           0.04,
           0.47,
           0.06,
           0.04,
           0.34,
           0.5,
           0,
           0.12,
           0.03,
           0.23,
           0.03,
           0.02,
           0.38,
           0.37,
           0.03,
           0.06,
           0.03,
           0,
           0.05,
           0.41,
           0,
           0.06,
           0,
           0.33,
           0.06,
           0.5,
           0.03,
           0.42,
           0.08,
           0.25,
           0.5,
           0.45,
           0.49,
           0.35,
           0.48,
           0.07,
           0,
           0,
           0.12,
           0.25,
           0,
           0.13,
           0,
           0.34,
           0.48,
           0.09,
           0.42,
           0.27,
           0.27,
           0.02,
           0.05,
           0.04,
           0.04,
           0.04,
           0.06,
           0.16,
           0.03,
           0.06,
           0.03,
           0.18,
           0.02,
           0.01,
           0.11,
           0,
           0.17,
           0.26,
           0.04,
           0.28,
           0.04,
           0.05,
           0.05,
           0.16,
           0.07,
           0.3,
           0.1,
           0.04,
           0.43,
           0.25,
           0.16,
           0.23,
           0.08,
           0.03,
           0.38,
           0.04,
           0.34,
           0.01,
           0.25,
           0,
           0.06,
           0.02,
           0.1,
           0.01,
           0.21,
           0.45,
           0.28,
           0.24,
           0.28,
           0.03,
           0.04,
           0.03,
           0,
           0.37,
           0,
           0.3,
           0.04,
           0.01,
           0,
           0.01,
           0.08,
           0,
           0.04,
           0.5,
           0,
           0.01,
           0.01,
           0.09,
           0.01,
           0.14,
           0.01,
           0,
           0.02,
           0,
           0.03,
           0.05,
           0.01,
           0,
           0,
           0,
           0.47,
           0.15,
           0.38,
           0,
           0.09,
           0.01,
           0.09,
           0.11,
           0.04,
           0.3,
           0.01,
           0.06,
           0.39,
           0.06,
           0.26,
           0.18,
           0.12,
           0,
           0.01,
           0.01,
           0.25,
           0,
           0,
           0.33,
           0,
           0.5,
           0,
           0.01,
           0.03,
           0.34,
           0.01,
           0.02,
           0.2,
           0.04,
           0.03,
           0.33,
           0.43,
           0.18,
           0.05,
           0.02,
           0.28,
           0.38,
           0.05,
           0.06,
           0.27,
           0.02,
           0.12,
           0.05,
           0.35,
           0.02,
           0.03,
           0.5,
           0.04,
           0.39,
           0.03,
           0.01,
           0.07,
           0.03,
           0.02,
           0.08,
           0.21,
           0.36,
           0.38,
           0.01,
           0.47,
           0.25,
           0.44,
           0.42,
           0.4,
           0.06,
           0.21,
           0.09,
           0.34,
           0.01,
           0.04,
           0.03,
           0.06,
           0.05,
           0.5,
           0.04,
           0.05,
           0.01,
           0.13,
           0.01,
           0.01,
           0.02,
           0.28,
           0.01,
           0.04,
           0.15,
           0.04,
           0.25,
           0.27,
           0.31,
           0.21,
           0.24,
           0.09,
           0.11,
           0,
           0.49,
           0.05,
           0.49,
           0,
           0.01,
           0,
           0,
           0.01,
           0.03,
           0.04,
           0,
           0.43,
           0.15,
           0.22,
           0.04,
           0.47,
           0.49,
           0.1,
           0.16,
           0.03,
           0.39,
           0.09,
           0.36,
           0.34,
           0.36,
           0.05,
           0.14,
           0.06,
           0.01,
           0.05,
           0.07,
           0.34,
           0,
           0.01,
           0.02,
           0,
           0,
           0.04,
           0.07,
           0.04,
           0.03,
           0.01,
           0.36,
           0.06,
           0.03,
           0.4,
           0.03,
           0.37,
           0.19,
           0.23,
           0.26,
           0.3,
           0.08,
           0.06,
           0.07,
           0.1,
           0.03,
           0.01,
           0.01,
           0.43,
           0.34,
           0.03,
           0.14,
           0.25,
           0.03,
           0.44,
           0.36,
           0.25,
           0.04,
           0.23,
           0.12,
           0.44,
           0.32,
           0.49,
           0.45,
           0.36,
           0.16,
           0.03,
           0.46,
           0.04,
           0.01,
           0.01,
           0,
           0.5,
           0.5,
           0.07,
           0.12,
           0.24,
           0.28,
           0.06,
           0,
           0.01,
           0.09,
           0.01,
           0.01,
           0.01,
           0,
           0.06,
           0.04,
           0.02,
           0.02,
           0.05,
           0.45,
           0.41,
           0.4,
           0,
           0.1,
           0,
           0,
           0.04,
           0,
           0.18,
           0.03,
           0.03,
           0.45,
           0.07,
           0.43,
           0.35,
           0.05,
           0.03,
           0,
           0,
           0.36,
           0.33,
           0.19,
           0.01,
           0.14,
           0.22,
           0.05,
           0,
           0.13,
           0.01,
           0.38,
           0.35,
           0.42,
           0.25,
           0.47,
           0.08,
           0.35,
           0.25,
           0.08,
           0.15,
           0.01,
           0.09,
           0.1,
           0.08,
           0,
           0.06,
           0.11,
           0.03,
           0.02,
           0.02,
           0.42,
           0.25,
           0.5
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2017-09",
          "2018-06",
          "2019-09",
          "2020-02",
          "2019-04",
          "2019-06",
          "2020-03",
          "2020-04",
          "2016-06",
          "2017-11",
          "2017-12",
          "2018-02",
          "2018-12",
          "2019-03",
          "2019-04",
          "2019-07",
          "2020-01",
          "2020-03",
          "2016-12",
          "2018-02",
          "2019-01",
          "2016-12",
          "2017-06",
          "2017-11",
          "2018-01",
          "2019-04",
          "2019-09",
          "2017-04",
          "2017-06",
          "2018-01",
          "2018-03",
          "2018-12",
          "2019-04",
          "2016-03",
          "2016-12",
          "2018-08",
          "2018-11",
          "2019-01",
          "2017-11",
          "2018-12",
          "2020-03",
          "2016-12",
          "2017-06",
          "2017-10",
          "2018-07",
          "2018-09",
          "2019-04",
          "2016-10",
          "2018-04",
          "2019-01",
          "2019-11",
          "2018-03",
          "2019-02",
          "2019-09",
          "2014-06",
          "2016-12",
          "2017-11",
          "2017-12",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2018-12",
          "2019-05",
          "2019-06",
          "2016-12",
          "2017-12",
          "2018-03",
          "2019-04",
          "2012-12",
          "2014-12",
          "2015-03",
          "2015-05",
          "2015-12",
          "2016-01",
          "2016-04",
          "2016-08",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-11",
          "2018-01",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2019-01",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-12",
          "2016-11",
          "2018-06",
          "2020-03",
          "2014-12",
          "2015-05",
          "2016-05",
          "2016-04",
          "2017-04",
          "2018-10",
          "2017-03",
          "2018-09",
          "2015-12",
          "2016-08",
          "2017-12",
          "2018-12",
          "2019-07",
          "2019-10",
          "2017-04",
          "2018-02",
          "2018-07",
          "2019-04",
          "2016-06",
          "2016-10",
          "2016-12",
          "2017-03",
          "2017-09",
          "2018-05",
          "2018-09",
          "2017-12",
          "2018-03",
          "2016-12",
          "2018-03",
          "2019-04",
          "2015-05",
          "2019-04",
          "2017-05",
          "2018-07",
          "2019-04",
          "2015-06",
          "2016-12",
          "2019-04",
          "2017-04",
          "2018-01",
          "2019-08",
          "2015-05",
          "2016-08",
          "2017-04",
          "2017-05",
          "2017-11",
          "2017-12",
          "2018-07",
          "2018-11",
          "2019-01",
          "2019-03",
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-11",
          "2017-08",
          "2017-10",
          "2019-03",
          "2019-05",
          "2018-11",
          "2019-05",
          "2019-08",
          "2020-02",
          "2019-06",
          "2019-08",
          "2018-06",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-08",
          "2019-09",
          "2017-07",
          "2017-11",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-06",
          "2016-03",
          "2017-08",
          "2017-09",
          "2018-09",
          "2018-10",
          "2015-11",
          "2016-04",
          "2017-04",
          "2018-01",
          "2018-03",
          "2018-12",
          "2014-06",
          "2015-02",
          "2015-03",
          "2015-08",
          "2015-11",
          "2016-03",
          "2016-04",
          "2017-03",
          "2017-04",
          "2017-12",
          "2018-01",
          "2018-03",
          "2018-09",
          "2018-12",
          "2019-03",
          "2019-04",
          "2019-08",
          "2019-10",
          "2017-08",
          "2018-05",
          "2019-02",
          "2019-05",
          "2019-11",
          "2013-06",
          "2016-03",
          "2017-03",
          "2017-11",
          "2018-06",
          "2018-10",
          "2019-03",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2016-11",
          "2017-12",
          "2018-01",
          "2018-06",
          "2018-11",
          "2019-01",
          "2019-06",
          "2019-10",
          "2019-12",
          "2020-02",
          "2018-11",
          "2019-05",
          "2017-07",
          "2017-12",
          "2018-08",
          "2016-08",
          "2017-04",
          "2018-05",
          "2018-06",
          "2019-10",
          "2018-11",
          "2019-04",
          "2018-12",
          "2019-01",
          "2017-07",
          "2017-12",
          "2016-08",
          "2019-05",
          "2017-06",
          "2018-11",
          "2017-08",
          "2018-05",
          "2018-09",
          "2019-10",
          "2016-04",
          "2017-04",
          "2018-07",
          "2018-08",
          "2018-11",
          "2019-04",
          "2019-12",
          "2020-03",
          "2020-04",
          "2018-07",
          "2019-02",
          "2012-02",
          "2012-12",
          "2013-01",
          "2013-02",
          "2013-11",
          "2013-12",
          "2014-04",
          "2014-06",
          "2014-09",
          "2014-12",
          "2015-02",
          "2015-06",
          "2015-11",
          "2015-12",
          "2016-02",
          "2016-03",
          "2016-05",
          "2016-08",
          "2016-10",
          "2016-11",
          "2017-07",
          "2017-08",
          "2017-09",
          "2017-10",
          "2017-12",
          "2018-02",
          "2018-05",
          "2018-07",
          "2018-11",
          "2019-01",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-10",
          "2019-12",
          "2020-01",
          "2013-12",
          "2015-11",
          "2016-04",
          "2017-03",
          "2017-04",
          "2017-09",
          "2017-10",
          "2018-04",
          "2018-07",
          "2018-10",
          "2018-11",
          "2018-12",
          "2019-01",
          "2019-04",
          "2016-05",
          "2017-02",
          "2017-03",
          "2017-09",
          "2017-10",
          "2018-02",
          "2018-09",
          "2018-11",
          "2018-12",
          "2019-03",
          "2014-12",
          "2015-04",
          "2015-11",
          "2016-04",
          "2016-08",
          "2016-11",
          "2016-12",
          "2017-12",
          "2018-01",
          "2018-03",
          "2018-04",
          "2018-11",
          "2019-02",
          "2019-03",
          "2019-09",
          "2015-08",
          "2015-11",
          "2016-03",
          "2016-08",
          "2016-09",
          "2016-11",
          "2016-12",
          "2017-07",
          "2017-10",
          "2018-02",
          "2018-03",
          "2018-04",
          "2018-05",
          "2018-07",
          "2018-09",
          "2018-11",
          "2019-03",
          "2019-04",
          "2019-06",
          "2019-07",
          "2015-12",
          "2016-06",
          "2017-11",
          "2018-04",
          "2018-11",
          "2019-03",
          "2019-04",
          "2019-05",
          "2019-08",
          "2019-10",
          "2017-03",
          "2017-04",
          "2017-12",
          "2019-02",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-11",
          "2020-01",
          "2016-08",
          "2016-12",
          "2017-03",
          "2017-11",
          "2018-04",
          "2018-12",
          "2019-01",
          "2019-02",
          "2017-10",
          "2017-12",
          "2018-06",
          "2019-08",
          "2018-11",
          "2019-09",
          "2018-10",
          "2020-03",
          "2019-06",
          "2020-01",
          "2017-11",
          "2019-08",
          "2015-11",
          "2018-07",
          "2016-11",
          "2017-06",
          "2018-04",
          "2019-08",
          "2016-09",
          "2018-03",
          "2018-05",
          "2017-05",
          "2017-09",
          "2018-04",
          "2018-04",
          "2018-11",
          "2019-06",
          "2016-05",
          "2016-08",
          "2016-12",
          "2017-01",
          "2017-11",
          "2018-03",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-10",
          "2015-05",
          "2017-03",
          "2015-11",
          "2016-03",
          "2016-08",
          "2017-04",
          "2018-01",
          "2019-01",
          "2017-03",
          "2017-11",
          "2018-04",
          "2018-08",
          "2018-02",
          "2018-11",
          "2019-09",
          "2016-06",
          "2018-12",
          "2016-11",
          "2017-03",
          "2018-09",
          "2015-06",
          "2016-04",
          "2015-06",
          "2015-12",
          "2017-03",
          "2017-07",
          "2017-08",
          "2017-11",
          "2017-12",
          "2018-03",
          "2018-05",
          "2018-11",
          "2018-12",
          "2019-01",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-10",
          "2019-11",
          "2017-09",
          "2018-04",
          "2018-12",
          "2019-01",
          "2019-05",
          "2019-09",
          "2019-11",
          "2016-08",
          "2019-10",
          "2014-12",
          "2018-07",
          "2014-06",
          "2016-03",
          "2016-07",
          "2016-10",
          "2016-11",
          "2017-01",
          "2017-03",
          "2017-07",
          "2017-08",
          "2017-09",
          "2017-10",
          "2017-11",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2018-12",
          "2019-03",
          "2019-05",
          "2019-08",
          "2019-10",
          "2019-11",
          "2019-12",
          "2020-01",
          "2015-11",
          "2016-03",
          "2016-09",
          "2016-12",
          "2017-01",
          "2017-02",
          "2017-04",
          "2017-05",
          "2017-07",
          "2017-08",
          "2017-11",
          "2017-12",
          "2018-03",
          "2018-04",
          "2018-05",
          "2018-11",
          "2018-12",
          "2019-01",
          "2019-02",
          "2019-10",
          "2020-01",
          "2020-02",
          "2017-12",
          "2018-02",
          "2019-02",
          "2019-05",
          "2016-06",
          "2017-04",
          "2017-08",
          "2017-10",
          "2018-06",
          "2019-06",
          "2016-05",
          "2017-08",
          "2019-04",
          "2019-09",
          "2019-11",
          "2020-04",
          "2015-02",
          "2015-11",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2018-08",
          "2018-11",
          "2019-03",
          "2019-09",
          "2020-04",
          "2017-11",
          "2018-02",
          "2018-06",
          "2018-10",
          "2019-07",
          "2019-12",
          "2015-12",
          "2019-11",
          "2017-07",
          "2018-06",
          "2018-08",
          "2018-03",
          "2019-08",
          "2015-04",
          "2016-04",
          "2017-03",
          "2017-04",
          "2017-07",
          "2017-08",
          "2017-09",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-06",
          "2018-07",
          "2018-11",
          "2019-03",
          "2019-04",
          "2019-10",
          "2019-11",
          "2016-03",
          "2019-01",
          "2019-06",
          "2019-07",
          "2019-11",
          "2020-03",
          "2015-02",
          "2015-03",
          "2015-04",
          "2015-09",
          "2015-11",
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-02",
          "2017-03",
          "2017-04",
          "2017-06",
          "2017-10",
          "2017-11",
          "2017-12",
          "2018-02",
          "2018-03",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-09",
          "2018-12",
          "2019-03",
          "2019-04",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-10",
          "2019-11",
          "2020-04",
          "2016-10",
          "2016-11",
          "2017-03",
          "2017-04",
          "2018-06",
          "2018-07",
          "2019-05",
          "2019-09",
          "2019-11",
          "2019-12",
          "2016-11",
          "2017-06",
          "2018-02",
          "2018-03",
          "2018-04",
          "2018-06",
          "2019-02",
          "2019-08",
          "2015-11",
          "2016-03",
          "2017-10",
          "2018-03",
          "2018-10",
          "2012-07",
          "2013-02",
          "2016-04",
          "2016-06",
          "2016-09",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-11",
          "2018-12",
          "2019-04",
          "2019-07",
          "2019-09",
          "2019-11",
          "2019-12",
          "2017-11",
          "2018-02",
          "2017-07",
          "2018-08",
          "2018-10",
          "2019-04",
          "2019-09",
          "2019-10",
          "2019-11",
          "2019-12",
          "2015-06",
          "2016-01",
          "2016-09",
          "2017-03",
          "2017-05",
          "2018-04",
          "2018-06",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11",
          "2018-11",
          "2019-07",
          "2016-12",
          "2017-10",
          "2019-03",
          "2019-04",
          "2015-02",
          "2015-05",
          "2017-11",
          "2018-11",
          "2018-12",
          "2019-11",
          "2020-01",
          "2016-11",
          "2017-03",
          "2017-11",
          "2017-05",
          "2017-11",
          "2016-09",
          "2016-11",
          "2017-07",
          "2019-12",
          "2018-11",
          "2019-07",
          "2020-03",
          "2018-11",
          "2019-05",
          "2016-09",
          "2016-12",
          "2017-07",
          "2018-04",
          "2019-06",
          "2016-12",
          "2020-04",
          "2016-09",
          "2016-11",
          "2017-04",
          "2018-01",
          "2018-06",
          "2019-05",
          "2017-09",
          "2017-11",
          "2018-09",
          "2019-02",
          "2019-04",
          "2016-11",
          "2017-04",
          "2017-06",
          "2017-10",
          "2018-02",
          "2018-03",
          "2018-06",
          "2018-12",
          "2019-06",
          "2019-07",
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09",
          "2020-02",
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-11",
          "2014-03",
          "2015-05",
          "2015-11",
          "2016-03",
          "2016-09",
          "2016-11",
          "2017-04",
          "2017-06",
          "2017-07",
          "2017-08",
          "2017-11",
          "2018-02",
          "2018-04",
          "2018-06",
          "2018-07",
          "2018-11",
          "2019-10",
          "2019-11",
          "2017-01",
          "2017-04",
          "2019-03"
         ],
         "y": [
          "3D Human Pose Estimation",
          "3D Human Pose Estimation",
          "3D Human Pose Estimation",
          "3D Human Pose Estimation",
          "3D Instance Segmentation",
          "3D Instance Segmentation",
          "3D Instance Segmentation",
          "3D Instance Segmentation",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Detection",
          "3D Object Reconstruction",
          "3D Object Reconstruction",
          "3D Object Reconstruction",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Point Cloud Classification",
          "3D Point Cloud Classification",
          "3D Point Cloud Classification",
          "3D Point Cloud Classification",
          "3D Point Cloud Classification",
          "3D Point Cloud Classification",
          "3D Reconstruction",
          "3D Reconstruction",
          "3D Reconstruction",
          "3D Room Layouts From A Single RGB Panorama",
          "3D Room Layouts From A Single RGB Panorama",
          "3D Semantic Instance Segmentation",
          "3D Semantic Instance Segmentation",
          "3D Semantic Instance Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Shape Classification",
          "3D Shape Classification",
          "6D Pose Estimation",
          "6D Pose Estimation",
          "6D Pose Estimation using RGB",
          "6D Pose Estimation using RGB",
          "6D Pose Estimation using RGB",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Classification",
          "Action Detection",
          "Action Detection",
          "Action Detection",
          "Action Detection",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Segmentation",
          "Action Segmentation",
          "Action Segmentation",
          "Activity Recognition In Videos",
          "Activity Recognition In Videos",
          "Activity Recognition In Videos",
          "Aesthetics Quality Assessment",
          "Aesthetics Quality Assessment",
          "Aesthetics Quality Assessment",
          "Age-Invariant Face Recognition",
          "Age-Invariant Face Recognition",
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection",
          "Birds Eye View Object Detection",
          "Color Image Denoising",
          "Color Image Denoising",
          "Color Image Denoising",
          "Color Image Denoising",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Conditional Image Generation",
          "Cross-Modal Retrieval",
          "Cross-Modal Retrieval",
          "Cross-View Image-to-Image Translation",
          "Cross-View Image-to-Image Translation",
          "Cross-View Image-to-Image Translation",
          "Curved Text Detection",
          "Curved Text Detection",
          "Denoising",
          "Denoising",
          "Denoising",
          "Dense Object Detection",
          "Dense Object Detection",
          "Dense Object Detection",
          "Document Image Classification",
          "Document Image Classification",
          "Document Image Classification",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Generalization",
          "Domain Generalization",
          "Domain Generalization",
          "Domain Generalization",
          "Egocentric Activity Recognition",
          "Egocentric Activity Recognition",
          "Egocentric Activity Recognition",
          "Egocentric Activity Recognition",
          "Electron Microscopy Image Segmentation",
          "Electron Microscopy Image Segmentation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Face Alignment",
          "Face Alignment",
          "Face Alignment",
          "Face Alignment",
          "Face Alignment",
          "Face Alignment",
          "Face Alignment",
          "Face Detection",
          "Face Detection",
          "Face Detection",
          "Face Detection",
          "Face Detection",
          "Face Identification",
          "Face Identification",
          "Face Identification",
          "Face Identification",
          "Face Identification",
          "Face Identification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Face Verification",
          "Facial Expression Recognition",
          "Facial Expression Recognition",
          "Facial Expression Recognition",
          "Facial Expression Recognition",
          "Facial Expression Recognition",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Fine-Grained Image Classification",
          "Formation Energy",
          "Formation Energy",
          "Gesture-to-Gesture Translation",
          "Gesture-to-Gesture Translation",
          "Gesture-to-Gesture Translation",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Group Activity Recognition",
          "Group Activity Recognition",
          "Hand Gesture Recognition",
          "Hand Gesture Recognition",
          "Hand Pose Estimation",
          "Hand Pose Estimation",
          "Horizon Line Estimation",
          "Horizon Line Estimation",
          "Human Interaction Recognition",
          "Human Interaction Recognition",
          "Human Part Segmentation",
          "Human Part Segmentation",
          "Human Part Segmentation",
          "Human Part Segmentation",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Human-Object Interaction Detection",
          "Hyperspectral Image Classification",
          "Hyperspectral Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Classification",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Clustering",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Generation",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Retrieval",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image Super-Resolution",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Image-to-Image Translation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Instance Segmentation",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Keypoint Detection",
          "Lane Detection",
          "Lane Detection",
          "Lane Detection",
          "Lane Detection",
          "Layout-to-Image Generation",
          "Layout-to-Image Generation",
          "Lesion Segmentation",
          "Lesion Segmentation",
          "Low-Light Image Enhancement",
          "Low-Light Image Enhancement",
          "Lung Nodule Segmentation",
          "Lung Nodule Segmentation",
          "Medical Image Segmentation",
          "Medical Image Segmentation",
          "Metric Learning",
          "Metric Learning",
          "Metric Learning",
          "Metric Learning",
          "Monocular Depth Estimation",
          "Monocular Depth Estimation",
          "Monocular Depth Estimation",
          "Multi-Human Parsing",
          "Multi-Human Parsing",
          "Multi-Human Parsing",
          "Multi-Object Tracking",
          "Multi-Object Tracking",
          "Multi-Object Tracking",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-Person Pose Estimation",
          "Multi-tissue Nucleus Segmentation",
          "Multi-tissue Nucleus Segmentation",
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition",
          "Multimodal Activity Recognition",
          "Multimodal Unsupervised Image-To-Image Translation",
          "Multimodal Unsupervised Image-To-Image Translation",
          "Multimodal Unsupervised Image-To-Image Translation",
          "Multimodal Unsupervised Image-To-Image Translation",
          "Multiple Object Tracking",
          "Multiple Object Tracking",
          "Multiple Object Tracking",
          "Multivariate Time Series Imputation",
          "Multivariate Time Series Imputation",
          "Nuclear Segmentation",
          "Nuclear Segmentation",
          "Nuclear Segmentation",
          "Object Counting",
          "Object Counting",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Object Detection",
          "Pancreas Segmentation",
          "Pancreas Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Pedestrian Attribute Recognition",
          "Pedestrian Attribute Recognition",
          "Pedestrian Detection",
          "Pedestrian Detection",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Person Re-Identification",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Estimation",
          "Pose Tracking",
          "Pose Tracking",
          "Pose Tracking",
          "Pose Tracking",
          "RGB Salient Object Detection",
          "RGB Salient Object Detection",
          "RGB Salient Object Detection",
          "RGB Salient Object Detection",
          "RGB Salient Object Detection",
          "RGB Salient Object Detection",
          "Real-Time Object Detection",
          "Real-Time Object Detection",
          "Real-Time Object Detection",
          "Real-Time Object Detection",
          "Real-Time Object Detection",
          "Real-Time Object Detection",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Satellite Image Classification",
          "Satellite Image Classification",
          "Scene Graph Generation",
          "Scene Graph Generation",
          "Scene Graph Generation",
          "Scene Segmentation",
          "Scene Segmentation",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Scene Text Detection",
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification",
          "Self-Supervised Image Classification",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Image Classification",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Video Object Segmentation",
          "Sequential Image Classification",
          "Sequential Image Classification",
          "Sequential Image Classification",
          "Sequential Image Classification",
          "Sequential Image Classification",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skin Cancer Segmentation",
          "Skin Cancer Segmentation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Synthetic-to-Real Translation",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Proposal Generation",
          "Temporal Action Proposal Generation",
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Image-To-Image Translation",
          "Unsupervised Image-To-Image Translation",
          "Unsupervised Image-To-Image Translation",
          "Unsupervised Person Re-Identification",
          "Unsupervised Person Re-Identification",
          "Video Generation",
          "Video Generation",
          "Video Generation",
          "Video Generation",
          "Video Object Detection",
          "Video Object Detection",
          "Video Object Detection",
          "Video Prediction",
          "Video Prediction",
          "Video Retrieval",
          "Video Retrieval",
          "Video Retrieval",
          "Video Retrieval",
          "Video Retrieval",
          "Video Semantic Segmentation",
          "Video Semantic Segmentation",
          "Video Super-Resolution",
          "Video Super-Resolution",
          "Video Super-Resolution",
          "Video Super-Resolution",
          "Video Super-Resolution",
          "Video Super-Resolution",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Object Tracking",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Object Detection",
          "Weakly-supervised 3D Human Pose Estimation",
          "Weakly-supervised 3D Human Pose Estimation",
          "Weakly-supervised 3D Human Pose Estimation"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Weakly-supervised 3D Human Pose Estimation",
          "Weakly Supervised Object Detection",
          "Weakly Supervised Action Localization",
          "Visual Question Answering",
          "Visual Object Tracking",
          "Visual Dialog",
          "Video Super-Resolution",
          "Video Semantic Segmentation",
          "Video Retrieval",
          "Video Prediction",
          "Video Object Detection",
          "Video Generation",
          "Unsupervised Person Re-Identification",
          "Unsupervised Image-To-Image Translation",
          "Unsupervised Domain Adaptation",
          "Text-to-Image Generation",
          "Temporal Action Proposal Generation",
          "Temporal Action Localization",
          "Synthetic-to-Real Translation",
          "Skin Cancer Segmentation",
          "Skeleton Based Action Recognition",
          "Sequential Image Classification",
          "Semi-Supervised Video Object Segmentation",
          "Semi-Supervised Image Classification",
          "Semantic Segmentation",
          "Self-Supervised Image Classification",
          "Scene Text Detection",
          "Scene Segmentation",
          "Scene Graph Generation",
          "Satellite Image Classification",
          "Retinal Vessel Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Object Detection",
          "RGB Salient Object Detection",
          "Pose Tracking",
          "Pose Estimation",
          "Person Re-Identification",
          "Pedestrian Detection",
          "Pedestrian Attribute Recognition",
          "Panoptic Segmentation",
          "Pancreas Segmentation",
          "Object Detection",
          "Object Counting",
          "Nuclear Segmentation",
          "Multivariate Time Series Imputation",
          "Multiple Object Tracking",
          "Multimodal Unsupervised Image-To-Image Translation",
          "Multimodal Activity Recognition",
          "Multi-tissue Nucleus Segmentation",
          "Multi-Person Pose Estimation",
          "Multi-Object Tracking",
          "Multi-Human Parsing",
          "Monocular Depth Estimation",
          "Metric Learning",
          "Medical Image Segmentation",
          "Lung Nodule Segmentation",
          "Low-Light Image Enhancement",
          "Lesion Segmentation",
          "Layout-to-Image Generation",
          "Lane Detection",
          "Keypoint Detection",
          "Instance Segmentation",
          "Image-to-Image Translation",
          "Image Super-Resolution",
          "Image Retrieval",
          "Image Generation",
          "Image Clustering",
          "Image Classification",
          "Hyperspectral Image Classification",
          "Human-Object Interaction Detection",
          "Human Part Segmentation",
          "Human Interaction Recognition",
          "Horizon Line Estimation",
          "Hand Pose Estimation",
          "Hand Gesture Recognition",
          "Group Activity Recognition",
          "Grayscale Image Denoising",
          "Gesture-to-Gesture Translation",
          "Formation Energy",
          "Fine-Grained Image Classification",
          "Few-Shot Image Classification",
          "Facial Expression Recognition",
          "Face Verification",
          "Face Identification",
          "Face Detection",
          "Face Alignment",
          "Emotion Recognition in Conversation",
          "Electron Microscopy Image Segmentation",
          "Egocentric Activity Recognition",
          "Domain Generalization",
          "Domain Adaptation",
          "Document Image Classification",
          "Dense Object Detection",
          "Denoising",
          "Curved Text Detection",
          "Cross-View Image-to-Image Translation",
          "Cross-Modal Retrieval",
          "Conditional Image Generation",
          "Color Image Denoising",
          "Birds Eye View Object Detection",
          "Age-Invariant Face Recognition",
          "Aesthetics Quality Assessment",
          "Activity Recognition In Videos",
          "Action Segmentation",
          "Action Recognition",
          "Action Detection",
          "Action Classification",
          "6D Pose Estimation using RGB",
          "6D Pose Estimation",
          "3D Shape Classification",
          "3D Semantic Segmentation",
          "3D Semantic Instance Segmentation",
          "3D Room Layouts From A Single RGB Panorama",
          "3D Reconstruction",
          "3D Point Cloud Classification",
          "3D Part Segmentation",
          "3D Object Reconstruction",
          "3D Object Detection",
          "3D Instance Segmentation",
          "3D Human Pose Estimation"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00101: Vision process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"8893aeee-ed02-4698-ae10-4d5956236807\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8893aeee-ed02-4698-ae10-4d5956236807\")) {                    Plotly.newPlot(                        \"8893aeee-ed02-4698-ae10-4d5956236807\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Human Pose Estimation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Human Pose Estimation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-09\", \"2018-06\", \"2019-09\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"3D Human Pose Estimation\", \"3D Human Pose Estimation\", \"3D Human Pose Estimation\", \"3D Human Pose Estimation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Instance Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Instance Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-04\", \"2019-06\", \"2020-03\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"3D Instance Segmentation\", \"3D Instance Segmentation\", \"3D Instance Segmentation\", \"3D Instance Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Object Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Object Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-06\", \"2017-11\", \"2017-12\", \"2018-02\", \"2018-12\", \"2019-03\", \"2019-04\", \"2019-07\", \"2020-01\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Object Reconstruction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Object Reconstruction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2018-02\", \"2019-01\"], \"xaxis\": \"x\", \"y\": [\"3D Object Reconstruction\", \"3D Object Reconstruction\", \"3D Object Reconstruction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Part Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Part Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2017-06\", \"2017-11\", \"2018-01\", \"2019-04\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Point Cloud Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Point Cloud Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-04\", \"2017-06\", \"2018-01\", \"2018-03\", \"2018-12\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"3D Point Cloud Classification\", \"3D Point Cloud Classification\", \"3D Point Cloud Classification\", \"3D Point Cloud Classification\", \"3D Point Cloud Classification\", \"3D Point Cloud Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Reconstruction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Reconstruction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-12\", \"2018-08\"], \"xaxis\": \"x\", \"y\": [\"3D Reconstruction\", \"3D Reconstruction\", \"3D Reconstruction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Room Layouts From A Single RGB Panorama\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Room Layouts From A Single RGB Panorama\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-01\"], \"xaxis\": \"x\", \"y\": [\"3D Room Layouts From A Single RGB Panorama\", \"3D Room Layouts From A Single RGB Panorama\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Semantic Instance Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Semantic Instance Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-11\", \"2018-12\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"3D Semantic Instance Segmentation\", \"3D Semantic Instance Segmentation\", \"3D Semantic Instance Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Semantic Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Semantic Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2017-06\", \"2017-10\", \"2018-07\", \"2018-09\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Shape Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Shape Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-10\", \"2018-04\"], \"xaxis\": \"x\", \"y\": [\"3D Shape Classification\", \"3D Shape Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"6D Pose Estimation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"6D Pose Estimation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-01\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"6D Pose Estimation\", \"6D Pose Estimation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"6D Pose Estimation using RGB\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"6D Pose Estimation using RGB\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-03\", \"2019-02\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"6D Pose Estimation using RGB\", \"6D Pose Estimation using RGB\", \"6D Pose Estimation using RGB\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Action Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Action Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-06\", \"2016-12\", \"2017-11\", \"2017-12\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2018-12\", \"2019-05\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Action Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Action Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2017-12\", \"2018-03\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Action Detection\", \"Action Detection\", \"Action Detection\", \"Action Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Action Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Action Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2012-12\", \"2014-12\", \"2015-03\", \"2015-05\", \"2015-12\", \"2016-01\", \"2016-04\", \"2016-08\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-11\", \"2018-01\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2019-01\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Action Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Action Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2018-06\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"Action Segmentation\", \"Action Segmentation\", \"Action Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Activity Recognition In Videos\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Activity Recognition In Videos\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-12\", \"2015-05\", \"2016-05\"], \"xaxis\": \"x\", \"y\": [\"Activity Recognition In Videos\", \"Activity Recognition In Videos\", \"Activity Recognition In Videos\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Aesthetics Quality Assessment\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Aesthetics Quality Assessment\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-04\", \"2017-04\", \"2018-10\"], \"xaxis\": \"x\", \"y\": [\"Aesthetics Quality Assessment\", \"Aesthetics Quality Assessment\", \"Aesthetics Quality Assessment\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Age-Invariant Face Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Age-Invariant Face Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-03\", \"2018-09\"], \"xaxis\": \"x\", \"y\": [\"Age-Invariant Face Recognition\", \"Age-Invariant Face Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Birds Eye View Object Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Birds Eye View Object Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-12\", \"2016-08\", \"2017-12\", \"2018-12\", \"2019-07\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Color Image Denoising\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Color Image Denoising\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-04\", \"2018-02\", \"2018-07\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Color Image Denoising\", \"Color Image Denoising\", \"Color Image Denoising\", \"Color Image Denoising\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Conditional Image Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Conditional Image Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-06\", \"2016-10\", \"2016-12\", \"2017-03\", \"2017-09\", \"2018-05\", \"2018-09\"], \"xaxis\": \"x\", \"y\": [\"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Cross-Modal Retrieval\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Cross-Modal Retrieval\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-12\", \"2018-03\"], \"xaxis\": \"x\", \"y\": [\"Cross-Modal Retrieval\", \"Cross-Modal Retrieval\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Cross-View Image-to-Image Translation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Cross-View Image-to-Image Translation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2018-03\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Cross-View Image-to-Image Translation\", \"Cross-View Image-to-Image Translation\", \"Cross-View Image-to-Image Translation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Curved Text Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Curved Text Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-05\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Curved Text Detection\", \"Curved Text Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Denoising\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Denoising\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-05\", \"2018-07\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Denoising\", \"Denoising\", \"Denoising\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Dense Object Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Dense Object Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-06\", \"2016-12\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Dense Object Detection\", \"Dense Object Detection\", \"Dense Object Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Document Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Document Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-04\", \"2018-01\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Document Image Classification\", \"Document Image Classification\", \"Document Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Domain Adaptation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Domain Adaptation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-05\", \"2016-08\", \"2017-04\", \"2017-05\", \"2017-11\", \"2017-12\", \"2018-07\", \"2018-11\", \"2019-01\", \"2019-03\", \"2019-05\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Domain Generalization\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Domain Generalization\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-08\", \"2017-10\", \"2019-03\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Domain Generalization\", \"Domain Generalization\", \"Domain Generalization\", \"Domain Generalization\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Egocentric Activity Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Egocentric Activity Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-05\", \"2019-08\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Egocentric Activity Recognition\", \"Egocentric Activity Recognition\", \"Egocentric Activity Recognition\", \"Egocentric Activity Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Electron Microscopy Image Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Electron Microscopy Image Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-06\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Electron Microscopy Image Segmentation\", \"Electron Microscopy Image Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Emotion Recognition in Conversation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Emotion Recognition in Conversation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-06\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-08\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Face Alignment\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Face Alignment\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-07\", \"2017-11\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"Face Alignment\", \"Face Alignment\", \"Face Alignment\", \"Face Alignment\", \"Face Alignment\", \"Face Alignment\", \"Face Alignment\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Face Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Face Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2017-08\", \"2017-09\", \"2018-09\", \"2018-10\"], \"xaxis\": \"x\", \"y\": [\"Face Detection\", \"Face Detection\", \"Face Detection\", \"Face Detection\", \"Face Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Face Identification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Face Identification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-11\", \"2016-04\", \"2017-04\", \"2018-01\", \"2018-03\", \"2018-12\"], \"xaxis\": \"x\", \"y\": [\"Face Identification\", \"Face Identification\", \"Face Identification\", \"Face Identification\", \"Face Identification\", \"Face Identification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Face Verification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Face Verification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-06\", \"2015-02\", \"2015-03\", \"2015-08\", \"2015-11\", \"2016-03\", \"2016-04\", \"2017-03\", \"2017-04\", \"2017-12\", \"2018-01\", \"2018-03\", \"2018-09\", \"2018-12\", \"2019-03\", \"2019-04\", \"2019-08\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Facial Expression Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Facial Expression Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-08\", \"2018-05\", \"2019-02\", \"2019-05\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Facial Expression Recognition\", \"Facial Expression Recognition\", \"Facial Expression Recognition\", \"Facial Expression Recognition\", \"Facial Expression Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Few-Shot Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Few-Shot Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2013-06\", \"2016-03\", \"2017-03\", \"2017-11\", \"2018-06\", \"2018-10\", \"2019-03\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Fine-Grained Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Fine-Grained Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-12\", \"2018-01\", \"2018-06\", \"2018-11\", \"2019-01\", \"2019-06\", \"2019-10\", \"2019-12\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Formation Energy\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Formation Energy\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Formation Energy\", \"Formation Energy\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Gesture-to-Gesture Translation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Gesture-to-Gesture Translation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-07\", \"2017-12\", \"2018-08\"], \"xaxis\": \"x\", \"y\": [\"Gesture-to-Gesture Translation\", \"Gesture-to-Gesture Translation\", \"Gesture-to-Gesture Translation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Grayscale Image Denoising\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Grayscale Image Denoising\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-08\", \"2017-04\", \"2018-05\", \"2018-06\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Group Activity Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Group Activity Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Group Activity Recognition\", \"Group Activity Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Hand Gesture Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Hand Gesture Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-12\", \"2019-01\"], \"xaxis\": \"x\", \"y\": [\"Hand Gesture Recognition\", \"Hand Gesture Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Hand Pose Estimation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Hand Pose Estimation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-07\", \"2017-12\"], \"xaxis\": \"x\", \"y\": [\"Hand Pose Estimation\", \"Hand Pose Estimation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Horizon Line Estimation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Horizon Line Estimation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-08\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Horizon Line Estimation\", \"Horizon Line Estimation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Human Interaction Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Human Interaction Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-06\", \"2018-11\"], \"xaxis\": \"x\", \"y\": [\"Human Interaction Recognition\", \"Human Interaction Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Human Part Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Human Part Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-08\", \"2018-05\", \"2018-09\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Human Part Segmentation\", \"Human Part Segmentation\", \"Human Part Segmentation\", \"Human Part Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Human-Object Interaction Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Human-Object Interaction Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-04\", \"2017-04\", \"2018-07\", \"2018-08\", \"2018-11\", \"2019-04\", \"2019-12\", \"2020-03\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Hyperspectral Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Hyperspectral Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-07\", \"2019-02\"], \"xaxis\": \"x\", \"y\": [\"Hyperspectral Image Classification\", \"Hyperspectral Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2012-02\", \"2012-12\", \"2013-01\", \"2013-02\", \"2013-11\", \"2013-12\", \"2014-04\", \"2014-06\", \"2014-09\", \"2014-12\", \"2015-02\", \"2015-06\", \"2015-11\", \"2015-12\", \"2016-02\", \"2016-03\", \"2016-05\", \"2016-08\", \"2016-10\", \"2016-11\", \"2017-07\", \"2017-08\", \"2017-09\", \"2017-10\", \"2017-12\", \"2018-02\", \"2018-05\", \"2018-07\", \"2018-11\", \"2019-01\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-08\", \"2019-10\", \"2019-12\", \"2020-01\"], \"xaxis\": \"x\", \"y\": [\"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Image Clustering\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Image Clustering\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2013-12\", \"2015-11\", \"2016-04\", \"2017-03\", \"2017-04\", \"2017-09\", \"2017-10\", \"2018-04\", \"2018-07\", \"2018-10\", \"2018-11\", \"2018-12\", \"2019-01\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Image Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Image Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-05\", \"2017-02\", \"2017-03\", \"2017-09\", \"2017-10\", \"2018-02\", \"2018-09\", \"2018-11\", \"2018-12\", \"2019-03\"], \"xaxis\": \"x\", \"y\": [\"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Image Retrieval\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Image Retrieval\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-12\", \"2015-04\", \"2015-11\", \"2016-04\", \"2016-08\", \"2016-11\", \"2016-12\", \"2017-12\", \"2018-01\", \"2018-03\", \"2018-04\", \"2018-11\", \"2019-02\", \"2019-03\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Image Super-Resolution\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Image Super-Resolution\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-08\", \"2015-11\", \"2016-03\", \"2016-08\", \"2016-09\", \"2016-11\", \"2016-12\", \"2017-07\", \"2017-10\", \"2018-02\", \"2018-03\", \"2018-04\", \"2018-05\", \"2018-07\", \"2018-09\", \"2018-11\", \"2019-03\", \"2019-04\", \"2019-06\", \"2019-07\"], \"xaxis\": \"x\", \"y\": [\"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Image-to-Image Translation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Image-to-Image Translation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-12\", \"2016-06\", \"2017-11\", \"2018-04\", \"2018-11\", \"2019-03\", \"2019-04\", \"2019-05\", \"2019-08\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Instance Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Instance Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-03\", \"2017-04\", \"2017-12\", \"2019-02\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-11\", \"2020-01\"], \"xaxis\": \"x\", \"y\": [\"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Keypoint Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Keypoint Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-08\", \"2016-12\", \"2017-03\", \"2017-11\", \"2018-04\", \"2018-12\", \"2019-01\", \"2019-02\"], \"xaxis\": \"x\", \"y\": [\"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Lane Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Lane Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-10\", \"2017-12\", \"2018-06\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Lane Detection\", \"Lane Detection\", \"Lane Detection\", \"Lane Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Layout-to-Image Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Layout-to-Image Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Layout-to-Image Generation\", \"Layout-to-Image Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Lesion Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Lesion Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-10\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"Lesion Segmentation\", \"Lesion Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Low-Light Image Enhancement\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Low-Light Image Enhancement\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-06\", \"2020-01\"], \"xaxis\": \"x\", \"y\": [\"Low-Light Image Enhancement\", \"Low-Light Image Enhancement\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Lung Nodule Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Lung Nodule Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-11\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Lung Nodule Segmentation\", \"Lung Nodule Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Medical Image Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Medical Image Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-11\", \"2018-07\"], \"xaxis\": \"x\", \"y\": [\"Medical Image Segmentation\", \"Medical Image Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Metric Learning\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Metric Learning\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-06\", \"2018-04\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Metric Learning\", \"Metric Learning\", \"Metric Learning\", \"Metric Learning\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Monocular Depth Estimation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Monocular Depth Estimation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-09\", \"2018-03\", \"2018-05\"], \"xaxis\": \"x\", \"y\": [\"Monocular Depth Estimation\", \"Monocular Depth Estimation\", \"Monocular Depth Estimation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multi-Human Parsing\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multi-Human Parsing\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-05\", \"2017-09\", \"2018-04\"], \"xaxis\": \"x\", \"y\": [\"Multi-Human Parsing\", \"Multi-Human Parsing\", \"Multi-Human Parsing\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multi-Object Tracking\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multi-Object Tracking\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-04\", \"2018-11\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"Multi-Object Tracking\", \"Multi-Object Tracking\", \"Multi-Object Tracking\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multi-Person Pose Estimation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multi-Person Pose Estimation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-05\", \"2016-08\", \"2016-12\", \"2017-01\", \"2017-11\", \"2018-03\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multi-tissue Nucleus Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multi-tissue Nucleus Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-05\", \"2017-03\"], \"xaxis\": \"x\", \"y\": [\"Multi-tissue Nucleus Segmentation\", \"Multi-tissue Nucleus Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multimodal Activity Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multimodal Activity Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-11\", \"2016-03\", \"2016-08\", \"2017-04\", \"2018-01\", \"2019-01\"], \"xaxis\": \"x\", \"y\": [\"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multimodal Unsupervised Image-To-Image Translation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multimodal Unsupervised Image-To-Image Translation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-03\", \"2017-11\", \"2018-04\", \"2018-08\"], \"xaxis\": \"x\", \"y\": [\"Multimodal Unsupervised Image-To-Image Translation\", \"Multimodal Unsupervised Image-To-Image Translation\", \"Multimodal Unsupervised Image-To-Image Translation\", \"Multimodal Unsupervised Image-To-Image Translation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multiple Object Tracking\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multiple Object Tracking\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-02\", \"2018-11\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Multiple Object Tracking\", \"Multiple Object Tracking\", \"Multiple Object Tracking\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multivariate Time Series Imputation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multivariate Time Series Imputation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-06\", \"2018-12\"], \"xaxis\": \"x\", \"y\": [\"Multivariate Time Series Imputation\", \"Multivariate Time Series Imputation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Nuclear Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Nuclear Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-03\", \"2018-09\"], \"xaxis\": \"x\", \"y\": [\"Nuclear Segmentation\", \"Nuclear Segmentation\", \"Nuclear Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Object Counting\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Object Counting\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-06\", \"2016-04\"], \"xaxis\": \"x\", \"y\": [\"Object Counting\", \"Object Counting\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Object Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Object Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-06\", \"2015-12\", \"2017-03\", \"2017-07\", \"2017-08\", \"2017-11\", \"2017-12\", \"2018-03\", \"2018-05\", \"2018-11\", \"2018-12\", \"2019-01\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-10\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Pancreas Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Pancreas Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-09\", \"2018-04\"], \"xaxis\": \"x\", \"y\": [\"Pancreas Segmentation\", \"Pancreas Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Panoptic Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Panoptic Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-12\", \"2019-01\", \"2019-05\", \"2019-09\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Pedestrian Attribute Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Pedestrian Attribute Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-08\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Pedestrian Attribute Recognition\", \"Pedestrian Attribute Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Pedestrian Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Pedestrian Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-12\", \"2018-07\"], \"xaxis\": \"x\", \"y\": [\"Pedestrian Detection\", \"Pedestrian Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Person Re-Identification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Person Re-Identification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-06\", \"2016-03\", \"2016-07\", \"2016-10\", \"2016-11\", \"2017-01\", \"2017-03\", \"2017-07\", \"2017-08\", \"2017-09\", \"2017-10\", \"2017-11\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2018-12\", \"2019-03\", \"2019-05\", \"2019-08\", \"2019-10\", \"2019-11\", \"2019-12\", \"2020-01\"], \"xaxis\": \"x\", \"y\": [\"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Pose Estimation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Pose Estimation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-11\", \"2016-03\", \"2016-09\", \"2016-12\", \"2017-01\", \"2017-02\", \"2017-04\", \"2017-05\", \"2017-07\", \"2017-08\", \"2017-11\", \"2017-12\", \"2018-03\", \"2018-04\", \"2018-05\", \"2018-11\", \"2018-12\", \"2019-01\", \"2019-02\", \"2019-10\", \"2020-01\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Pose Tracking\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Pose Tracking\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-12\", \"2018-02\", \"2019-02\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Pose Tracking\", \"Pose Tracking\", \"Pose Tracking\", \"Pose Tracking\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"RGB Salient Object Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"RGB Salient Object Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-06\", \"2017-04\", \"2017-08\", \"2017-10\", \"2018-06\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"RGB Salient Object Detection\", \"RGB Salient Object Detection\", \"RGB Salient Object Detection\", \"RGB Salient Object Detection\", \"RGB Salient Object Detection\", \"RGB Salient Object Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Real-Time Object Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Real-Time Object Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-05\", \"2017-08\", \"2019-04\", \"2019-09\", \"2019-11\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Real-Time Object Detection\", \"Real-Time Object Detection\", \"Real-Time Object Detection\", \"Real-Time Object Detection\", \"Real-Time Object Detection\", \"Real-Time Object Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Real-Time Semantic Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Real-Time Semantic Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-02\", \"2015-11\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2018-08\", \"2018-11\", \"2019-03\", \"2019-09\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Retinal Vessel Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Retinal Vessel Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-11\", \"2018-02\", \"2018-06\", \"2018-10\", \"2019-07\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Satellite Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Satellite Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-12\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Satellite Image Classification\", \"Satellite Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Scene Graph Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Scene Graph Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-07\", \"2018-06\", \"2018-08\"], \"xaxis\": \"x\", \"y\": [\"Scene Graph Generation\", \"Scene Graph Generation\", \"Scene Graph Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Scene Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Scene Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-03\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Scene Segmentation\", \"Scene Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Scene Text Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Scene Text Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-04\", \"2016-04\", \"2017-03\", \"2017-04\", \"2017-07\", \"2017-08\", \"2017-09\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-06\", \"2018-07\", \"2018-11\", \"2019-03\", \"2019-04\", \"2019-10\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Self-Supervised Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Self-Supervised Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2019-01\", \"2019-06\", \"2019-07\", \"2019-11\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Semantic Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Semantic Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-02\", \"2015-03\", \"2015-04\", \"2015-09\", \"2015-11\", \"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-02\", \"2017-03\", \"2017-04\", \"2017-06\", \"2017-10\", \"2017-11\", \"2017-12\", \"2018-02\", \"2018-03\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-09\", \"2018-12\", \"2019-03\", \"2019-04\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-10\", \"2019-11\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Semi-Supervised Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Semi-Supervised Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-10\", \"2016-11\", \"2017-03\", \"2017-04\", \"2018-06\", \"2018-07\", \"2019-05\", \"2019-09\", \"2019-11\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Semi-Supervised Video Object Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Semi-Supervised Video Object Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-06\", \"2018-02\", \"2018-03\", \"2018-04\", \"2018-06\", \"2019-02\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Sequential Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Sequential Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-11\", \"2016-03\", \"2017-10\", \"2018-03\", \"2018-10\"], \"xaxis\": \"x\", \"y\": [\"Sequential Image Classification\", \"Sequential Image Classification\", \"Sequential Image Classification\", \"Sequential Image Classification\", \"Sequential Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Skeleton Based Action Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Skeleton Based Action Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2012-07\", \"2013-02\", \"2016-04\", \"2016-06\", \"2016-09\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-11\", \"2018-12\", \"2019-04\", \"2019-07\", \"2019-09\", \"2019-11\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Skin Cancer Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Skin Cancer Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-11\", \"2018-02\"], \"xaxis\": \"x\", \"y\": [\"Skin Cancer Segmentation\", \"Skin Cancer Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Synthetic-to-Real Translation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Synthetic-to-Real Translation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-07\", \"2018-08\", \"2018-10\", \"2019-04\", \"2019-09\", \"2019-10\", \"2019-11\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Temporal Action Localization\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Temporal Action Localization\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-06\", \"2016-01\", \"2016-09\", \"2017-03\", \"2017-05\", \"2018-04\", \"2018-06\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Temporal Action Proposal Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Temporal Action Proposal Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-07\"], \"xaxis\": \"x\", \"y\": [\"Temporal Action Proposal Generation\", \"Temporal Action Proposal Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Text-to-Image Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Text-to-Image Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2017-10\", \"2019-03\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Text-to-Image Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Unsupervised Domain Adaptation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Unsupervised Domain Adaptation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-02\", \"2015-05\", \"2017-11\", \"2018-11\", \"2018-12\", \"2019-11\", \"2020-01\"], \"xaxis\": \"x\", \"y\": [\"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Unsupervised Image-To-Image Translation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Unsupervised Image-To-Image Translation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-03\", \"2017-11\"], \"xaxis\": \"x\", \"y\": [\"Unsupervised Image-To-Image Translation\", \"Unsupervised Image-To-Image Translation\", \"Unsupervised Image-To-Image Translation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Unsupervised Person Re-Identification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Unsupervised Person Re-Identification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-05\", \"2017-11\"], \"xaxis\": \"x\", \"y\": [\"Unsupervised Person Re-Identification\", \"Unsupervised Person Re-Identification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Video Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Video Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-09\", \"2016-11\", \"2017-07\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Video Generation\", \"Video Generation\", \"Video Generation\", \"Video Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Video Object Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Video Object Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-07\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"Video Object Detection\", \"Video Object Detection\", \"Video Object Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Video Prediction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Video Prediction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Video Prediction\", \"Video Prediction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Video Retrieval\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Video Retrieval\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-09\", \"2016-12\", \"2017-07\", \"2018-04\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"Video Retrieval\", \"Video Retrieval\", \"Video Retrieval\", \"Video Retrieval\", \"Video Retrieval\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Video Semantic Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Video Semantic Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Video Semantic Segmentation\", \"Video Semantic Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Video Super-Resolution\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Video Super-Resolution\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-09\", \"2016-11\", \"2017-04\", \"2018-01\", \"2018-06\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Video Super-Resolution\", \"Video Super-Resolution\", \"Video Super-Resolution\", \"Video Super-Resolution\", \"Video Super-Resolution\", \"Video Super-Resolution\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Visual Dialog\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Visual Dialog\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-09\", \"2017-11\", \"2018-09\", \"2019-02\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Visual Object Tracking\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Visual Object Tracking\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-04\", \"2017-06\", \"2017-10\", \"2018-02\", \"2018-03\", \"2018-06\", \"2018-12\", \"2019-06\", \"2019-07\"], \"xaxis\": \"x\", \"y\": [\"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Visual Question Answering\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Visual Question Answering\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Weakly Supervised Action Localization\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Weakly Supervised Action Localization\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-05\", \"2019-06\", \"2019-08\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Weakly Supervised Object Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Weakly Supervised Object Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-03\", \"2015-05\", \"2015-11\", \"2016-03\", \"2016-09\", \"2016-11\", \"2017-04\", \"2017-06\", \"2017-07\", \"2017-08\", \"2017-11\", \"2018-02\", \"2018-04\", \"2018-06\", \"2018-07\", \"2018-11\", \"2019-10\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Weakly-supervised 3D Human Pose Estimation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Weakly-supervised 3D Human Pose Estimation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-01\", \"2017-04\", \"2019-03\"], \"xaxis\": \"x\", \"y\": [\"Weakly-supervised 3D Human Pose Estimation\", \"Weakly-supervised 3D Human Pose Estimation\", \"Weakly-supervised 3D Human Pose Estimation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"3D Human Pose Estimation<BR>task: 3D Human Pose Estimation<BR>date: 2017-09<BR>ratio: 0.07\", \"3D Human Pose Estimation<BR>task: 3D Human Pose Estimation<BR>date: 2018-06<BR>ratio: 0.25\", \"3D Human Pose Estimation<BR>task: 3D Human Pose Estimation<BR>date: 2019-09<BR>ratio: 0.45\", \"3D Human Pose Estimation<BR>task: 3D Human Pose Estimation<BR>date: 2020-02<BR>ratio: 0.0\", \"3D Instance Segmentation<BR>task: 3D Instance Segmentation<BR>date: 2019-04<BR>ratio: 0.26\", \"3D Instance Segmentation<BR>task: 3D Instance Segmentation<BR>date: 2019-06<BR>ratio: 0.01\", \"3D Instance Segmentation<BR>task: 3D Instance Segmentation<BR>date: 2020-03<BR>ratio: 0.24\", \"3D Instance Segmentation<BR>task: 3D Instance Segmentation<BR>date: 2020-04<BR>ratio: 0.07\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2016-06<BR>ratio: 0.09\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2017-11<BR>ratio: 0.48\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2017-12<BR>ratio: 0.03\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2018-02<BR>ratio: 0.03\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2018-12<BR>ratio: 0.09\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2019-03<BR>ratio: 0.15\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2019-04<BR>ratio: 0.4\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2019-07<BR>ratio: 0.04\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2020-01<BR>ratio: 0.15\", \"3D Object Detection<BR>task: 3D Object Detection<BR>date: 2020-03<BR>ratio: 0.21\", \"3D Object Reconstruction<BR>task: 3D Object Reconstruction<BR>date: 2016-12<BR>ratio: 0.15\", \"3D Object Reconstruction<BR>task: 3D Object Reconstruction<BR>date: 2018-02<BR>ratio: 0.26\", \"3D Object Reconstruction<BR>task: 3D Object Reconstruction<BR>date: 2019-01<BR>ratio: 0.01\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2016-12<BR>ratio: 0.32\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2017-06<BR>ratio: 0.01\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2017-11<BR>ratio: 0.01\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2018-01<BR>ratio: 0.01\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2019-04<BR>ratio: 0.01\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2019-09<BR>ratio: 0.0\", \"3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2017-04<BR>ratio: 0.02\", \"3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2017-06<BR>ratio: 0.06\", \"3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2018-01<BR>ratio: 0.01\", \"3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2018-03<BR>ratio: 0.01\", \"3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2018-12<BR>ratio: 0.0\", \"3D Point Cloud Classification<BR>task: 3D Point Cloud Classification<BR>date: 2019-04<BR>ratio: 0.0\", \"3D Reconstruction<BR>task: 3D Reconstruction<BR>date: 2016-03<BR>ratio: 0.32\", \"3D Reconstruction<BR>task: 3D Reconstruction<BR>date: 2016-12<BR>ratio: 0.16\", \"3D Reconstruction<BR>task: 3D Reconstruction<BR>date: 2018-08<BR>ratio: 0.0\", \"3D Room Layouts From A Single RGB Panorama<BR>task: 3D Room Layouts From A Single RGB Panorama<BR>date: 2018-11<BR>ratio: 0.09\", \"3D Room Layouts From A Single RGB Panorama<BR>task: 3D Room Layouts From A Single RGB Panorama<BR>date: 2019-01<BR>ratio: 0.03\", \"3D Semantic Instance Segmentation<BR>task: 3D Semantic Instance Segmentation<BR>date: 2017-11<BR>ratio: 0.23\", \"3D Semantic Instance Segmentation<BR>task: 3D Semantic Instance Segmentation<BR>date: 2018-12<BR>ratio: 0.39\", \"3D Semantic Instance Segmentation<BR>task: 3D Semantic Instance Segmentation<BR>date: 2020-03<BR>ratio: 0.37\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.25\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2017-06<BR>ratio: 0.09\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2017-10<BR>ratio: 0.16\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2018-07<BR>ratio: 0.11\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2018-09<BR>ratio: 0.06\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2019-04<BR>ratio: 0.32\", \"3D Shape Classification<BR>task: 3D Shape Classification<BR>date: 2016-10<BR>ratio: 0.16\", \"3D Shape Classification<BR>task: 3D Shape Classification<BR>date: 2018-04<BR>ratio: 0.14\", \"6D Pose Estimation<BR>task: 6D Pose Estimation<BR>date: 2019-01<BR>ratio: 0.47\", \"6D Pose Estimation<BR>task: 6D Pose Estimation<BR>date: 2019-11<BR>ratio: 0.04\", \"6D Pose Estimation using RGB<BR>task: 6D Pose Estimation using RGB<BR>date: 2018-03<BR>ratio: 0.48\", \"6D Pose Estimation using RGB<BR>task: 6D Pose Estimation using RGB<BR>date: 2019-02<BR>ratio: 0.38\", \"6D Pose Estimation using RGB<BR>task: 6D Pose Estimation using RGB<BR>date: 2019-09<BR>ratio: 0.0\", \"Action Classification<BR>task: Action Classification<BR>date: 2014-06<BR>ratio: 0.41\", \"Action Classification<BR>task: Action Classification<BR>date: 2016-12<BR>ratio: 0.08\", \"Action Classification<BR>task: Action Classification<BR>date: 2017-11<BR>ratio: 0.02\", \"Action Classification<BR>task: Action Classification<BR>date: 2017-12<BR>ratio: 0.47\", \"Action Classification<BR>task: Action Classification<BR>date: 2018-06<BR>ratio: 0.17\", \"Action Classification<BR>task: Action Classification<BR>date: 2018-07<BR>ratio: 0.05\", \"Action Classification<BR>task: Action Classification<BR>date: 2018-10<BR>ratio: 0.0\", \"Action Classification<BR>task: Action Classification<BR>date: 2018-11<BR>ratio: 0.07\", \"Action Classification<BR>task: Action Classification<BR>date: 2018-12<BR>ratio: 0.1\", \"Action Classification<BR>task: Action Classification<BR>date: 2019-05<BR>ratio: 0.0\", \"Action Classification<BR>task: Action Classification<BR>date: 2019-06<BR>ratio: 0.03\", \"Action Detection<BR>task: Action Detection<BR>date: 2016-12<BR>ratio: 0.43\", \"Action Detection<BR>task: Action Detection<BR>date: 2017-12<BR>ratio: 0.24\", \"Action Detection<BR>task: Action Detection<BR>date: 2018-03<BR>ratio: 0.17\", \"Action Detection<BR>task: Action Detection<BR>date: 2019-04<BR>ratio: 0.37\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2012-12<BR>ratio: 0.45\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2014-12<BR>ratio: 0.04\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2015-03<BR>ratio: 0.07\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2015-05<BR>ratio: 0.06\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2015-12<BR>ratio: 0.5\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2016-01<BR>ratio: 0.04\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2016-04<BR>ratio: 0.01\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2016-08<BR>ratio: 0.03\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2017-03<BR>ratio: 0.08\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2017-04<BR>ratio: 0.1\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2017-05<BR>ratio: 0.27\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2017-11<BR>ratio: 0.26\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-01<BR>ratio: 0.46\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-06<BR>ratio: 0.1\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-07<BR>ratio: 0.01\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-10<BR>ratio: 0.0\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-11<BR>ratio: 0.06\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-01<BR>ratio: 0.11\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-04<BR>ratio: 0.14\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-06<BR>ratio: 0.01\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-07<BR>ratio: 0.03\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-08<BR>ratio: 0.03\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-12<BR>ratio: 0.03\", \"Action Segmentation<BR>task: Action Segmentation<BR>date: 2016-11<BR>ratio: 0.14\", \"Action Segmentation<BR>task: Action Segmentation<BR>date: 2018-06<BR>ratio: 0.23\", \"Action Segmentation<BR>task: Action Segmentation<BR>date: 2020-03<BR>ratio: 0.1\", \"Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2014-12<BR>ratio: 0.16\", \"Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2015-05<BR>ratio: 0.04\", \"Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2016-05<BR>ratio: 0.06\", \"Aesthetics Quality Assessment<BR>task: Aesthetics Quality Assessment<BR>date: 2016-04<BR>ratio: 0.04\", \"Aesthetics Quality Assessment<BR>task: Aesthetics Quality Assessment<BR>date: 2017-04<BR>ratio: 0.04\", \"Aesthetics Quality Assessment<BR>task: Aesthetics Quality Assessment<BR>date: 2018-10<BR>ratio: 0.01\", \"Age-Invariant Face Recognition<BR>task: Age-Invariant Face Recognition<BR>date: 2017-03<BR>ratio: 0.01\", \"Age-Invariant Face Recognition<BR>task: Age-Invariant Face Recognition<BR>date: 2018-09<BR>ratio: 0.28\", \"Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2015-12<BR>ratio: 0.11\", \"Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2016-08<BR>ratio: 0.27\", \"Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2017-12<BR>ratio: 0.48\", \"Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2018-12<BR>ratio: 0.02\", \"Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2019-07<BR>ratio: 0.46\", \"Birds Eye View Object Detection<BR>task: Birds Eye View Object Detection<BR>date: 2019-10<BR>ratio: 0.0\", \"Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2017-04<BR>ratio: 0.38\", \"Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2018-02<BR>ratio: 0.01\", \"Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2018-07<BR>ratio: 0.06\", \"Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2019-04<BR>ratio: 0.01\", \"Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2016-06<BR>ratio: 0.16\", \"Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2016-10<BR>ratio: 0.12\", \"Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2016-12<BR>ratio: 0.03\", \"Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2017-03<BR>ratio: 0.01\", \"Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2017-09<BR>ratio: 0.02\", \"Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2018-05<BR>ratio: 0.13\", \"Conditional Image Generation<BR>task: Conditional Image Generation<BR>date: 2018-09<BR>ratio: 0.31\", \"Cross-Modal Retrieval<BR>task: Cross-Modal Retrieval<BR>date: 2017-12<BR>ratio: 0.49\", \"Cross-Modal Retrieval<BR>task: Cross-Modal Retrieval<BR>date: 2018-03<BR>ratio: 0.11\", \"Cross-View Image-to-Image Translation<BR>task: Cross-View Image-to-Image Translation<BR>date: 2016-12<BR>ratio: 0.0\", \"Cross-View Image-to-Image Translation<BR>task: Cross-View Image-to-Image Translation<BR>date: 2018-03<BR>ratio: 0.06\", \"Cross-View Image-to-Image Translation<BR>task: Cross-View Image-to-Image Translation<BR>date: 2019-04<BR>ratio: 0.34\", \"Curved Text Detection<BR>task: Curved Text Detection<BR>date: 2015-05<BR>ratio: 0.43\", \"Curved Text Detection<BR>task: Curved Text Detection<BR>date: 2019-04<BR>ratio: 0.15\", \"Denoising<BR>task: Denoising<BR>date: 2017-05<BR>ratio: 0.1\", \"Denoising<BR>task: Denoising<BR>date: 2018-07<BR>ratio: 0.01\", \"Denoising<BR>task: Denoising<BR>date: 2019-04<BR>ratio: 0.01\", \"Dense Object Detection<BR>task: Dense Object Detection<BR>date: 2015-06<BR>ratio: 0.06\", \"Dense Object Detection<BR>task: Dense Object Detection<BR>date: 2016-12<BR>ratio: 0.09\", \"Dense Object Detection<BR>task: Dense Object Detection<BR>date: 2019-04<BR>ratio: 0.18\", \"Document Image Classification<BR>task: Document Image Classification<BR>date: 2017-04<BR>ratio: 0.01\", \"Document Image Classification<BR>task: Document Image Classification<BR>date: 2018-01<BR>ratio: 0.01\", \"Document Image Classification<BR>task: Document Image Classification<BR>date: 2019-08<BR>ratio: 0.05\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2015-05<BR>ratio: 0.02\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2016-08<BR>ratio: 0.37\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-04<BR>ratio: 0.11\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-05<BR>ratio: 0.42\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-11<BR>ratio: 0.01\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-12<BR>ratio: 0.04\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2018-07<BR>ratio: 0.03\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2018-11<BR>ratio: 0.26\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-01<BR>ratio: 0.09\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-03<BR>ratio: 0.09\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-05<BR>ratio: 0.02\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-06<BR>ratio: 0.29\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-08<BR>ratio: 0.12\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-09<BR>ratio: 0.0\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-11<BR>ratio: 0.01\", \"Domain Generalization<BR>task: Domain Generalization<BR>date: 2017-08<BR>ratio: 0.03\", \"Domain Generalization<BR>task: Domain Generalization<BR>date: 2017-10<BR>ratio: 0.3\", \"Domain Generalization<BR>task: Domain Generalization<BR>date: 2019-03<BR>ratio: 0.1\", \"Domain Generalization<BR>task: Domain Generalization<BR>date: 2019-05<BR>ratio: 0.1\", \"Egocentric Activity Recognition<BR>task: Egocentric Activity Recognition<BR>date: 2018-11<BR>ratio: 0.34\", \"Egocentric Activity Recognition<BR>task: Egocentric Activity Recognition<BR>date: 2019-05<BR>ratio: 0.17\", \"Egocentric Activity Recognition<BR>task: Egocentric Activity Recognition<BR>date: 2019-08<BR>ratio: 0.06\", \"Egocentric Activity Recognition<BR>task: Egocentric Activity Recognition<BR>date: 2020-02<BR>ratio: 0.01\", \"Electron Microscopy Image Segmentation<BR>task: Electron Microscopy Image Segmentation<BR>date: 2019-06<BR>ratio: 0.48\", \"Electron Microscopy Image Segmentation<BR>task: Electron Microscopy Image Segmentation<BR>date: 2019-08<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-06<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-10<BR>ratio: 0.04\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-11<BR>ratio: 0.05\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-04<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-08<BR>ratio: 0.03\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-09<BR>ratio: 0.0\", \"Face Alignment<BR>task: Face Alignment<BR>date: 2017-07<BR>ratio: 0.17\", \"Face Alignment<BR>task: Face Alignment<BR>date: 2017-11<BR>ratio: 0.17\", \"Face Alignment<BR>task: Face Alignment<BR>date: 2018-03<BR>ratio: 0.19\", \"Face Alignment<BR>task: Face Alignment<BR>date: 2018-05<BR>ratio: 0.24\", \"Face Alignment<BR>task: Face Alignment<BR>date: 2019-02<BR>ratio: 0.0\", \"Face Alignment<BR>task: Face Alignment<BR>date: 2019-04<BR>ratio: 0.0\", \"Face Alignment<BR>task: Face Alignment<BR>date: 2019-06<BR>ratio: 0.0\", \"Face Detection<BR>task: Face Detection<BR>date: 2016-03<BR>ratio: 0.03\", \"Face Detection<BR>task: Face Detection<BR>date: 2017-08<BR>ratio: 0.03\", \"Face Detection<BR>task: Face Detection<BR>date: 2017-09<BR>ratio: 0.0\", \"Face Detection<BR>task: Face Detection<BR>date: 2018-09<BR>ratio: 0.0\", \"Face Detection<BR>task: Face Detection<BR>date: 2018-10<BR>ratio: 0.0\", \"Face Identification<BR>task: Face Identification<BR>date: 2015-11<BR>ratio: 0.03\", \"Face Identification<BR>task: Face Identification<BR>date: 2016-04<BR>ratio: 0.5\", \"Face Identification<BR>task: Face Identification<BR>date: 2017-04<BR>ratio: 0.06\", \"Face Identification<BR>task: Face Identification<BR>date: 2018-01<BR>ratio: 0.23\", \"Face Identification<BR>task: Face Identification<BR>date: 2018-03<BR>ratio: 0.03\", \"Face Identification<BR>task: Face Identification<BR>date: 2018-12<BR>ratio: 0.16\", \"Face Verification<BR>task: Face Verification<BR>date: 2014-06<BR>ratio: 0.01\", \"Face Verification<BR>task: Face Verification<BR>date: 2015-02<BR>ratio: 0.0\", \"Face Verification<BR>task: Face Verification<BR>date: 2015-03<BR>ratio: 0.23\", \"Face Verification<BR>task: Face Verification<BR>date: 2015-08<BR>ratio: 0.11\", \"Face Verification<BR>task: Face Verification<BR>date: 2015-11<BR>ratio: 0.43\", \"Face Verification<BR>task: Face Verification<BR>date: 2016-03<BR>ratio: 0.05\", \"Face Verification<BR>task: Face Verification<BR>date: 2016-04<BR>ratio: 0.47\", \"Face Verification<BR>task: Face Verification<BR>date: 2017-03<BR>ratio: 0.03\", \"Face Verification<BR>task: Face Verification<BR>date: 2017-04<BR>ratio: 0.04\", \"Face Verification<BR>task: Face Verification<BR>date: 2017-12<BR>ratio: 0.01\", \"Face Verification<BR>task: Face Verification<BR>date: 2018-01<BR>ratio: 0.09\", \"Face Verification<BR>task: Face Verification<BR>date: 2018-03<BR>ratio: 0.0\", \"Face Verification<BR>task: Face Verification<BR>date: 2018-09<BR>ratio: 0.12\", \"Face Verification<BR>task: Face Verification<BR>date: 2018-12<BR>ratio: 0.15\", \"Face Verification<BR>task: Face Verification<BR>date: 2019-03<BR>ratio: 0.02\", \"Face Verification<BR>task: Face Verification<BR>date: 2019-04<BR>ratio: 0.02\", \"Face Verification<BR>task: Face Verification<BR>date: 2019-08<BR>ratio: 0.0\", \"Face Verification<BR>task: Face Verification<BR>date: 2019-10<BR>ratio: 0.03\", \"Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2017-08<BR>ratio: 0.48\", \"Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2018-05<BR>ratio: 0.06\", \"Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2019-02<BR>ratio: 0.02\", \"Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2019-05<BR>ratio: 0.03\", \"Facial Expression Recognition<BR>task: Facial Expression Recognition<BR>date: 2019-11<BR>ratio: 0.06\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2013-06<BR>ratio: 0.32\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2016-03<BR>ratio: 0.08\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2017-03<BR>ratio: 0.01\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2017-11<BR>ratio: 0.25\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2018-06<BR>ratio: 0.49\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2018-10<BR>ratio: 0.0\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-03<BR>ratio: 0.19\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-04<BR>ratio: 0.12\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-05<BR>ratio: 0.01\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-06<BR>ratio: 0.05\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-07<BR>ratio: 0.1\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-08<BR>ratio: 0.02\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2016-11<BR>ratio: 0.35\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2017-12<BR>ratio: 0.01\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2018-01<BR>ratio: 0.03\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2018-06<BR>ratio: 0.0\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2018-11<BR>ratio: 0.5\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2019-01<BR>ratio: 0.02\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2019-06<BR>ratio: 0.02\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2019-10<BR>ratio: 0.01\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2019-12<BR>ratio: 0.03\", \"Fine-Grained Image Classification<BR>task: Fine-Grained Image Classification<BR>date: 2020-02<BR>ratio: 0.01\", \"Formation Energy<BR>task: Formation Energy<BR>date: 2018-11<BR>ratio: 0.22\", \"Formation Energy<BR>task: Formation Energy<BR>date: 2019-05<BR>ratio: 0.33\", \"Gesture-to-Gesture Translation<BR>task: Gesture-to-Gesture Translation<BR>date: 2017-07<BR>ratio: 0.03\", \"Gesture-to-Gesture Translation<BR>task: Gesture-to-Gesture Translation<BR>date: 2017-12<BR>ratio: 0.08\", \"Gesture-to-Gesture Translation<BR>task: Gesture-to-Gesture Translation<BR>date: 2018-08<BR>ratio: 0.42\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2016-08<BR>ratio: 0.33\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2017-04<BR>ratio: 0.5\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2018-05<BR>ratio: 0.18\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2018-06<BR>ratio: 0.01\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2019-10<BR>ratio: 0.16\", \"Group Activity Recognition<BR>task: Group Activity Recognition<BR>date: 2018-11<BR>ratio: 0.04\", \"Group Activity Recognition<BR>task: Group Activity Recognition<BR>date: 2019-04<BR>ratio: 0.07\", \"Hand Gesture Recognition<BR>task: Hand Gesture Recognition<BR>date: 2018-12<BR>ratio: 0.02\", \"Hand Gesture Recognition<BR>task: Hand Gesture Recognition<BR>date: 2019-01<BR>ratio: 0.03\", \"Hand Pose Estimation<BR>task: Hand Pose Estimation<BR>date: 2017-07<BR>ratio: 0.19\", \"Hand Pose Estimation<BR>task: Hand Pose Estimation<BR>date: 2017-12<BR>ratio: 0.02\", \"Horizon Line Estimation<BR>task: Horizon Line Estimation<BR>date: 2016-08<BR>ratio: 0.08\", \"Horizon Line Estimation<BR>task: Horizon Line Estimation<BR>date: 2019-05<BR>ratio: 0.05\", \"Human Interaction Recognition<BR>task: Human Interaction Recognition<BR>date: 2017-06<BR>ratio: 0.08\", \"Human Interaction Recognition<BR>task: Human Interaction Recognition<BR>date: 2018-11<BR>ratio: 0.02\", \"Human Part Segmentation<BR>task: Human Part Segmentation<BR>date: 2017-08<BR>ratio: 0.1\", \"Human Part Segmentation<BR>task: Human Part Segmentation<BR>date: 2018-05<BR>ratio: 0.04\", \"Human Part Segmentation<BR>task: Human Part Segmentation<BR>date: 2018-09<BR>ratio: 0.05\", \"Human Part Segmentation<BR>task: Human Part Segmentation<BR>date: 2019-10<BR>ratio: 0.04\", \"Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2016-04<BR>ratio: 0.16\", \"Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2017-04<BR>ratio: 0.36\", \"Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2018-07<BR>ratio: 0.08\", \"Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2018-08<BR>ratio: 0.41\", \"Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2018-11<BR>ratio: 0.32\", \"Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2019-04<BR>ratio: 0.15\", \"Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2019-12<BR>ratio: 0.18\", \"Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2020-03<BR>ratio: 0.05\", \"Human-Object Interaction Detection<BR>task: Human-Object Interaction Detection<BR>date: 2020-04<BR>ratio: 0.03\", \"Hyperspectral Image Classification<BR>task: Hyperspectral Image Classification<BR>date: 2018-07<BR>ratio: 0.02\", \"Hyperspectral Image Classification<BR>task: Hyperspectral Image Classification<BR>date: 2019-02<BR>ratio: 0.03\", \"Image Classification<BR>task: Image Classification<BR>date: 2012-02<BR>ratio: 0.47\", \"Image Classification<BR>task: Image Classification<BR>date: 2012-12<BR>ratio: 0.47\", \"Image Classification<BR>task: Image Classification<BR>date: 2013-01<BR>ratio: 0.33\", \"Image Classification<BR>task: Image Classification<BR>date: 2013-02<BR>ratio: 0.04\", \"Image Classification<BR>task: Image Classification<BR>date: 2013-11<BR>ratio: 0.01\", \"Image Classification<BR>task: Image Classification<BR>date: 2013-12<BR>ratio: 0.12\", \"Image Classification<BR>task: Image Classification<BR>date: 2014-04<BR>ratio: 0.02\", \"Image Classification<BR>task: Image Classification<BR>date: 2014-06<BR>ratio: 0.19\", \"Image Classification<BR>task: Image Classification<BR>date: 2014-09<BR>ratio: 0.04\", \"Image Classification<BR>task: Image Classification<BR>date: 2014-12<BR>ratio: 0.03\", \"Image Classification<BR>task: Image Classification<BR>date: 2015-02<BR>ratio: 0.0\", \"Image Classification<BR>task: Image Classification<BR>date: 2015-06<BR>ratio: 0.41\", \"Image Classification<BR>task: Image Classification<BR>date: 2015-11<BR>ratio: 0.16\", \"Image Classification<BR>task: Image Classification<BR>date: 2015-12<BR>ratio: 0.02\", \"Image Classification<BR>task: Image Classification<BR>date: 2016-02<BR>ratio: 0.01\", \"Image Classification<BR>task: Image Classification<BR>date: 2016-03<BR>ratio: 0.34\", \"Image Classification<BR>task: Image Classification<BR>date: 2016-05<BR>ratio: 0.04\", \"Image Classification<BR>task: Image Classification<BR>date: 2016-08<BR>ratio: 0.01\", \"Image Classification<BR>task: Image Classification<BR>date: 2016-10<BR>ratio: 0.0\", \"Image Classification<BR>task: Image Classification<BR>date: 2016-11<BR>ratio: 0.02\", \"Image Classification<BR>task: Image Classification<BR>date: 2017-07<BR>ratio: 0.24\", \"Image Classification<BR>task: Image Classification<BR>date: 2017-08<BR>ratio: 0.21\", \"Image Classification<BR>task: Image Classification<BR>date: 2017-09<BR>ratio: 0.01\", \"Image Classification<BR>task: Image Classification<BR>date: 2017-10<BR>ratio: 0.01\", \"Image Classification<BR>task: Image Classification<BR>date: 2017-12<BR>ratio: 0.0\", \"Image Classification<BR>task: Image Classification<BR>date: 2018-02<BR>ratio: 0.12\", \"Image Classification<BR>task: Image Classification<BR>date: 2018-05<BR>ratio: 0.16\", \"Image Classification<BR>task: Image Classification<BR>date: 2018-07<BR>ratio: 0.02\", \"Image Classification<BR>task: Image Classification<BR>date: 2018-11<BR>ratio: 0.01\", \"Image Classification<BR>task: Image Classification<BR>date: 2019-01<BR>ratio: 0.36\", \"Image Classification<BR>task: Image Classification<BR>date: 2019-04<BR>ratio: 0.15\", \"Image Classification<BR>task: Image Classification<BR>date: 2019-05<BR>ratio: 0.04\", \"Image Classification<BR>task: Image Classification<BR>date: 2019-06<BR>ratio: 0.17\", \"Image Classification<BR>task: Image Classification<BR>date: 2019-08<BR>ratio: 0.17\", \"Image Classification<BR>task: Image Classification<BR>date: 2019-10<BR>ratio: 0.18\", \"Image Classification<BR>task: Image Classification<BR>date: 2019-12<BR>ratio: 0.22\", \"Image Classification<BR>task: Image Classification<BR>date: 2020-01<BR>ratio: 0.0\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2013-12<BR>ratio: 0.44\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2015-11<BR>ratio: 0.19\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2016-04<BR>ratio: 0.38\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2017-03<BR>ratio: 0.25\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2017-04<BR>ratio: 0.14\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2017-09<BR>ratio: 0.2\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2017-10<BR>ratio: 0.22\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2018-04<BR>ratio: 0.26\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2018-07<BR>ratio: 0.2\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2018-10<BR>ratio: 0.24\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2018-11<BR>ratio: 0.24\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2018-12<BR>ratio: 0.21\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2019-01<BR>ratio: 0.0\", \"Image Clustering<BR>task: Image Clustering<BR>date: 2019-04<BR>ratio: 0.17\", \"Image Generation<BR>task: Image Generation<BR>date: 2016-05<BR>ratio: 0.09\", \"Image Generation<BR>task: Image Generation<BR>date: 2017-02<BR>ratio: 0.02\", \"Image Generation<BR>task: Image Generation<BR>date: 2017-03<BR>ratio: 0.37\", \"Image Generation<BR>task: Image Generation<BR>date: 2017-09<BR>ratio: 0.42\", \"Image Generation<BR>task: Image Generation<BR>date: 2017-10<BR>ratio: 0.33\", \"Image Generation<BR>task: Image Generation<BR>date: 2018-02<BR>ratio: 0.38\", \"Image Generation<BR>task: Image Generation<BR>date: 2018-09<BR>ratio: 0.31\", \"Image Generation<BR>task: Image Generation<BR>date: 2018-11<BR>ratio: 0.42\", \"Image Generation<BR>task: Image Generation<BR>date: 2018-12<BR>ratio: 0.02\", \"Image Generation<BR>task: Image Generation<BR>date: 2019-03<BR>ratio: 0.23\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2014-12<BR>ratio: 0.44\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2015-04<BR>ratio: 0.39\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2015-11<BR>ratio: 0.29\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2016-04<BR>ratio: 0.32\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2016-08<BR>ratio: 0.12\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2016-11<BR>ratio: 0.27\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2016-12<BR>ratio: 0.01\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2017-12<BR>ratio: 0.02\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2018-01<BR>ratio: 0.06\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2018-03<BR>ratio: 0.05\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2018-04<BR>ratio: 0.48\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2018-11<BR>ratio: 0.14\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2019-02<BR>ratio: 0.5\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2019-03<BR>ratio: 0.08\", \"Image Retrieval<BR>task: Image Retrieval<BR>date: 2019-09<BR>ratio: 0.07\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2015-08<BR>ratio: 0.01\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2015-11<BR>ratio: 0.41\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-03<BR>ratio: 0.01\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-08<BR>ratio: 0.11\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-09<BR>ratio: 0.32\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-11<BR>ratio: 0.01\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2016-12<BR>ratio: 0.03\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2017-07<BR>ratio: 0.17\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2017-10<BR>ratio: 0.15\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-02<BR>ratio: 0.0\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-03<BR>ratio: 0.0\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-04<BR>ratio: 0.03\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-05<BR>ratio: 0.01\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-07<BR>ratio: 0.01\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-09<BR>ratio: 0.02\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2018-11<BR>ratio: 0.0\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2019-03<BR>ratio: 0.42\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2019-04<BR>ratio: 0.23\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2019-06<BR>ratio: 0.16\", \"Image Super-Resolution<BR>task: Image Super-Resolution<BR>date: 2019-07<BR>ratio: 0.28\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2015-12<BR>ratio: 0.01\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2016-06<BR>ratio: 0.19\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2017-11<BR>ratio: 0.26\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2018-04<BR>ratio: 0.04\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2018-11<BR>ratio: 0.21\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-03<BR>ratio: 0.19\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-04<BR>ratio: 0.03\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-05<BR>ratio: 0.19\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-08<BR>ratio: 0.04\", \"Image-to-Image Translation<BR>task: Image-to-Image Translation<BR>date: 2019-10<BR>ratio: 0.06\", \"Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2017-03<BR>ratio: 0.3\", \"Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2017-04<BR>ratio: 0.1\", \"Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2017-12<BR>ratio: 0.02\", \"Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-02<BR>ratio: 0.02\", \"Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-06<BR>ratio: 0.11\", \"Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-08<BR>ratio: 0.08\", \"Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-09<BR>ratio: 0.03\", \"Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2019-11<BR>ratio: 0.08\", \"Instance Segmentation<BR>task: Instance Segmentation<BR>date: 2020-01<BR>ratio: 0.0\", \"Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2016-08<BR>ratio: 0.03\", \"Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2016-12<BR>ratio: 0.33\", \"Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2017-03<BR>ratio: 0.03\", \"Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2017-11<BR>ratio: 0.04\", \"Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2018-04<BR>ratio: 0.02\", \"Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2018-12<BR>ratio: 0.06\", \"Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2019-01<BR>ratio: 0.08\", \"Keypoint Detection<BR>task: Keypoint Detection<BR>date: 2019-02<BR>ratio: 0.01\", \"Lane Detection<BR>task: Lane Detection<BR>date: 2017-10<BR>ratio: 0.0\", \"Lane Detection<BR>task: Lane Detection<BR>date: 2017-12<BR>ratio: 0.5\", \"Lane Detection<BR>task: Lane Detection<BR>date: 2018-06<BR>ratio: 0.0\", \"Lane Detection<BR>task: Lane Detection<BR>date: 2019-08<BR>ratio: 0.5\", \"Layout-to-Image Generation<BR>task: Layout-to-Image Generation<BR>date: 2018-11<BR>ratio: 0.19\", \"Layout-to-Image Generation<BR>task: Layout-to-Image Generation<BR>date: 2019-09<BR>ratio: 0.32\", \"Lesion Segmentation<BR>task: Lesion Segmentation<BR>date: 2018-10<BR>ratio: 0.47\", \"Lesion Segmentation<BR>task: Lesion Segmentation<BR>date: 2020-03<BR>ratio: 0.0\", \"Low-Light Image Enhancement<BR>task: Low-Light Image Enhancement<BR>date: 2019-06<BR>ratio: 0.03\", \"Low-Light Image Enhancement<BR>task: Low-Light Image Enhancement<BR>date: 2020-01<BR>ratio: 0.11\", \"Lung Nodule Segmentation<BR>task: Lung Nodule Segmentation<BR>date: 2017-11<BR>ratio: 0.0\", \"Lung Nodule Segmentation<BR>task: Lung Nodule Segmentation<BR>date: 2019-08<BR>ratio: 0.5\", \"Medical Image Segmentation<BR>task: Medical Image Segmentation<BR>date: 2015-11<BR>ratio: 0.2\", \"Medical Image Segmentation<BR>task: Medical Image Segmentation<BR>date: 2018-07<BR>ratio: 0.4\", \"Metric Learning<BR>task: Metric Learning<BR>date: 2016-11<BR>ratio: 0.04\", \"Metric Learning<BR>task: Metric Learning<BR>date: 2017-06<BR>ratio: 0.47\", \"Metric Learning<BR>task: Metric Learning<BR>date: 2018-04<BR>ratio: 0.06\", \"Metric Learning<BR>task: Metric Learning<BR>date: 2019-08<BR>ratio: 0.04\", \"Monocular Depth Estimation<BR>task: Monocular Depth Estimation<BR>date: 2016-09<BR>ratio: 0.34\", \"Monocular Depth Estimation<BR>task: Monocular Depth Estimation<BR>date: 2018-03<BR>ratio: 0.5\", \"Monocular Depth Estimation<BR>task: Monocular Depth Estimation<BR>date: 2018-05<BR>ratio: 0.0\", \"Multi-Human Parsing<BR>task: Multi-Human Parsing<BR>date: 2017-05<BR>ratio: 0.12\", \"Multi-Human Parsing<BR>task: Multi-Human Parsing<BR>date: 2017-09<BR>ratio: 0.03\", \"Multi-Human Parsing<BR>task: Multi-Human Parsing<BR>date: 2018-04<BR>ratio: 0.23\", \"Multi-Object Tracking<BR>task: Multi-Object Tracking<BR>date: 2018-04<BR>ratio: 0.03\", \"Multi-Object Tracking<BR>task: Multi-Object Tracking<BR>date: 2018-11<BR>ratio: 0.02\", \"Multi-Object Tracking<BR>task: Multi-Object Tracking<BR>date: 2019-06<BR>ratio: 0.38\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2016-05<BR>ratio: 0.37\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2016-08<BR>ratio: 0.03\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2016-12<BR>ratio: 0.06\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2017-01<BR>ratio: 0.03\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2017-11<BR>ratio: 0.0\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2018-03<BR>ratio: 0.05\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2019-06<BR>ratio: 0.41\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2019-07<BR>ratio: 0.0\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2019-08<BR>ratio: 0.06\", \"Multi-Person Pose Estimation<BR>task: Multi-Person Pose Estimation<BR>date: 2019-10<BR>ratio: 0.0\", \"Multi-tissue Nucleus Segmentation<BR>task: Multi-tissue Nucleus Segmentation<BR>date: 2015-05<BR>ratio: 0.33\", \"Multi-tissue Nucleus Segmentation<BR>task: Multi-tissue Nucleus Segmentation<BR>date: 2017-03<BR>ratio: 0.06\", \"Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2015-11<BR>ratio: 0.5\", \"Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2016-03<BR>ratio: 0.03\", \"Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2016-08<BR>ratio: 0.42\", \"Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2017-04<BR>ratio: 0.08\", \"Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2018-01<BR>ratio: 0.25\", \"Multimodal Activity Recognition<BR>task: Multimodal Activity Recognition<BR>date: 2019-01<BR>ratio: 0.5\", \"Multimodal Unsupervised Image-To-Image Translation<BR>task: Multimodal Unsupervised Image-To-Image Translation<BR>date: 2017-03<BR>ratio: 0.45\", \"Multimodal Unsupervised Image-To-Image Translation<BR>task: Multimodal Unsupervised Image-To-Image Translation<BR>date: 2017-11<BR>ratio: 0.49\", \"Multimodal Unsupervised Image-To-Image Translation<BR>task: Multimodal Unsupervised Image-To-Image Translation<BR>date: 2018-04<BR>ratio: 0.35\", \"Multimodal Unsupervised Image-To-Image Translation<BR>task: Multimodal Unsupervised Image-To-Image Translation<BR>date: 2018-08<BR>ratio: 0.48\", \"Multiple Object Tracking<BR>task: Multiple Object Tracking<BR>date: 2018-02<BR>ratio: 0.07\", \"Multiple Object Tracking<BR>task: Multiple Object Tracking<BR>date: 2018-11<BR>ratio: 0.0\", \"Multiple Object Tracking<BR>task: Multiple Object Tracking<BR>date: 2019-09<BR>ratio: 0.0\", \"Multivariate Time Series Imputation<BR>task: Multivariate Time Series Imputation<BR>date: 2016-06<BR>ratio: 0.12\", \"Multivariate Time Series Imputation<BR>task: Multivariate Time Series Imputation<BR>date: 2018-12<BR>ratio: 0.25\", \"Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2016-11<BR>ratio: 0.0\", \"Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2017-03<BR>ratio: 0.13\", \"Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2018-09<BR>ratio: 0.0\", \"Object Counting<BR>task: Object Counting<BR>date: 2015-06<BR>ratio: 0.34\", \"Object Counting<BR>task: Object Counting<BR>date: 2016-04<BR>ratio: 0.48\", \"Object Detection<BR>task: Object Detection<BR>date: 2015-06<BR>ratio: 0.09\", \"Object Detection<BR>task: Object Detection<BR>date: 2015-12<BR>ratio: 0.42\", \"Object Detection<BR>task: Object Detection<BR>date: 2017-03<BR>ratio: 0.27\", \"Object Detection<BR>task: Object Detection<BR>date: 2017-07<BR>ratio: 0.27\", \"Object Detection<BR>task: Object Detection<BR>date: 2017-08<BR>ratio: 0.02\", \"Object Detection<BR>task: Object Detection<BR>date: 2017-11<BR>ratio: 0.05\", \"Object Detection<BR>task: Object Detection<BR>date: 2017-12<BR>ratio: 0.04\", \"Object Detection<BR>task: Object Detection<BR>date: 2018-03<BR>ratio: 0.04\", \"Object Detection<BR>task: Object Detection<BR>date: 2018-05<BR>ratio: 0.04\", \"Object Detection<BR>task: Object Detection<BR>date: 2018-11<BR>ratio: 0.06\", \"Object Detection<BR>task: Object Detection<BR>date: 2018-12<BR>ratio: 0.16\", \"Object Detection<BR>task: Object Detection<BR>date: 2019-01<BR>ratio: 0.03\", \"Object Detection<BR>task: Object Detection<BR>date: 2019-06<BR>ratio: 0.06\", \"Object Detection<BR>task: Object Detection<BR>date: 2019-08<BR>ratio: 0.03\", \"Object Detection<BR>task: Object Detection<BR>date: 2019-09<BR>ratio: 0.18\", \"Object Detection<BR>task: Object Detection<BR>date: 2019-10<BR>ratio: 0.02\", \"Object Detection<BR>task: Object Detection<BR>date: 2019-11<BR>ratio: 0.01\", \"Pancreas Segmentation<BR>task: Pancreas Segmentation<BR>date: 2017-09<BR>ratio: 0.11\", \"Pancreas Segmentation<BR>task: Pancreas Segmentation<BR>date: 2018-04<BR>ratio: 0.0\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2018-12<BR>ratio: 0.17\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-01<BR>ratio: 0.26\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-05<BR>ratio: 0.04\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-09<BR>ratio: 0.28\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-11<BR>ratio: 0.04\", \"Pedestrian Attribute Recognition<BR>task: Pedestrian Attribute Recognition<BR>date: 2016-08<BR>ratio: 0.05\", \"Pedestrian Attribute Recognition<BR>task: Pedestrian Attribute Recognition<BR>date: 2019-10<BR>ratio: 0.05\", \"Pedestrian Detection<BR>task: Pedestrian Detection<BR>date: 2014-12<BR>ratio: 0.16\", \"Pedestrian Detection<BR>task: Pedestrian Detection<BR>date: 2018-07<BR>ratio: 0.07\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2014-06<BR>ratio: 0.3\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2016-03<BR>ratio: 0.1\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2016-07<BR>ratio: 0.04\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2016-10<BR>ratio: 0.43\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2016-11<BR>ratio: 0.25\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-01<BR>ratio: 0.16\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-03<BR>ratio: 0.23\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-07<BR>ratio: 0.08\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-08<BR>ratio: 0.03\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-09<BR>ratio: 0.38\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-10<BR>ratio: 0.04\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2017-11<BR>ratio: 0.34\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-02<BR>ratio: 0.01\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-04<BR>ratio: 0.25\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-05<BR>ratio: 0.0\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-06<BR>ratio: 0.06\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-07<BR>ratio: 0.02\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-10<BR>ratio: 0.1\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-11<BR>ratio: 0.01\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2018-12<BR>ratio: 0.21\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-03<BR>ratio: 0.45\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-05<BR>ratio: 0.28\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-08<BR>ratio: 0.24\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-10<BR>ratio: 0.28\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-11<BR>ratio: 0.03\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2019-12<BR>ratio: 0.04\", \"Person Re-Identification<BR>task: Person Re-Identification<BR>date: 2020-01<BR>ratio: 0.03\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2015-11<BR>ratio: 0.0\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2016-03<BR>ratio: 0.37\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2016-09<BR>ratio: 0.0\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2016-12<BR>ratio: 0.3\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-01<BR>ratio: 0.04\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-02<BR>ratio: 0.01\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-04<BR>ratio: 0.0\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-05<BR>ratio: 0.01\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-07<BR>ratio: 0.08\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-08<BR>ratio: 0.0\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-11<BR>ratio: 0.04\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2017-12<BR>ratio: 0.5\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-03<BR>ratio: 0.0\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-04<BR>ratio: 0.01\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-05<BR>ratio: 0.01\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-11<BR>ratio: 0.09\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2018-12<BR>ratio: 0.01\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2019-01<BR>ratio: 0.14\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2019-02<BR>ratio: 0.01\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2019-10<BR>ratio: 0.0\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2020-01<BR>ratio: 0.02\", \"Pose Estimation<BR>task: Pose Estimation<BR>date: 2020-02<BR>ratio: 0.0\", \"Pose Tracking<BR>task: Pose Tracking<BR>date: 2017-12<BR>ratio: 0.03\", \"Pose Tracking<BR>task: Pose Tracking<BR>date: 2018-02<BR>ratio: 0.05\", \"Pose Tracking<BR>task: Pose Tracking<BR>date: 2019-02<BR>ratio: 0.01\", \"Pose Tracking<BR>task: Pose Tracking<BR>date: 2019-05<BR>ratio: 0.0\", \"RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2016-06<BR>ratio: 0.0\", \"RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2017-04<BR>ratio: 0.0\", \"RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2017-08<BR>ratio: 0.47\", \"RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2017-10<BR>ratio: 0.15\", \"RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2018-06<BR>ratio: 0.38\", \"RGB Salient Object Detection<BR>task: RGB Salient Object Detection<BR>date: 2019-06<BR>ratio: 0.0\", \"Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2016-05<BR>ratio: 0.09\", \"Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2017-08<BR>ratio: 0.01\", \"Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2019-04<BR>ratio: 0.09\", \"Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2019-09<BR>ratio: 0.11\", \"Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2019-11<BR>ratio: 0.04\", \"Real-Time Object Detection<BR>task: Real-Time Object Detection<BR>date: 2020-04<BR>ratio: 0.3\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2015-02<BR>ratio: 0.01\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2015-11<BR>ratio: 0.06\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-06<BR>ratio: 0.39\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-11<BR>ratio: 0.06\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.26\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2017-04<BR>ratio: 0.18\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2018-08<BR>ratio: 0.12\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2018-11<BR>ratio: 0.0\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2019-03<BR>ratio: 0.01\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2019-09<BR>ratio: 0.01\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.25\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2017-11<BR>ratio: 0.0\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-02<BR>ratio: 0.0\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-06<BR>ratio: 0.33\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-10<BR>ratio: 0.0\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2019-07<BR>ratio: 0.5\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2019-12<BR>ratio: 0.0\", \"Satellite Image Classification<BR>task: Satellite Image Classification<BR>date: 2015-12<BR>ratio: 0.01\", \"Satellite Image Classification<BR>task: Satellite Image Classification<BR>date: 2019-11<BR>ratio: 0.03\", \"Scene Graph Generation<BR>task: Scene Graph Generation<BR>date: 2017-07<BR>ratio: 0.34\", \"Scene Graph Generation<BR>task: Scene Graph Generation<BR>date: 2018-06<BR>ratio: 0.01\", \"Scene Graph Generation<BR>task: Scene Graph Generation<BR>date: 2018-08<BR>ratio: 0.02\", \"Scene Segmentation<BR>task: Scene Segmentation<BR>date: 2018-03<BR>ratio: 0.2\", \"Scene Segmentation<BR>task: Scene Segmentation<BR>date: 2019-08<BR>ratio: 0.04\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2015-04<BR>ratio: 0.03\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2016-04<BR>ratio: 0.33\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-03<BR>ratio: 0.43\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-04<BR>ratio: 0.18\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-07<BR>ratio: 0.05\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-08<BR>ratio: 0.02\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2017-09<BR>ratio: 0.28\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-01<BR>ratio: 0.38\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-02<BR>ratio: 0.05\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-04<BR>ratio: 0.06\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-06<BR>ratio: 0.27\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-07<BR>ratio: 0.02\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2018-11<BR>ratio: 0.12\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2019-03<BR>ratio: 0.05\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2019-04<BR>ratio: 0.35\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2019-10<BR>ratio: 0.02\", \"Scene Text Detection<BR>task: Scene Text Detection<BR>date: 2019-11<BR>ratio: 0.03\", \"Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2016-03<BR>ratio: 0.5\", \"Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2019-01<BR>ratio: 0.04\", \"Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2019-06<BR>ratio: 0.39\", \"Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2019-07<BR>ratio: 0.03\", \"Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2019-11<BR>ratio: 0.01\", \"Self-Supervised Image Classification<BR>task: Self-Supervised Image Classification<BR>date: 2020-03<BR>ratio: 0.07\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-02<BR>ratio: 0.03\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-03<BR>ratio: 0.02\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-04<BR>ratio: 0.08\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-09<BR>ratio: 0.21\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-11<BR>ratio: 0.36\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-03<BR>ratio: 0.38\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-05<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-06<BR>ratio: 0.47\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-11<BR>ratio: 0.25\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.44\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-02<BR>ratio: 0.42\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-03<BR>ratio: 0.4\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-04<BR>ratio: 0.06\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-06<BR>ratio: 0.21\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-10<BR>ratio: 0.09\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-11<BR>ratio: 0.34\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-12<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-02<BR>ratio: 0.04\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-03<BR>ratio: 0.03\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-04<BR>ratio: 0.06\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-06<BR>ratio: 0.05\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-08<BR>ratio: 0.5\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-09<BR>ratio: 0.04\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-12<BR>ratio: 0.05\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-03<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-04<BR>ratio: 0.13\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-06<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-08<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-09<BR>ratio: 0.02\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-10<BR>ratio: 0.28\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-11<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.04\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2016-10<BR>ratio: 0.15\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2016-11<BR>ratio: 0.04\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2017-03<BR>ratio: 0.25\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2017-04<BR>ratio: 0.27\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2018-06<BR>ratio: 0.31\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2018-07<BR>ratio: 0.21\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2019-05<BR>ratio: 0.24\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2019-09<BR>ratio: 0.09\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2019-11<BR>ratio: 0.11\", \"Semi-Supervised Image Classification<BR>task: Semi-Supervised Image Classification<BR>date: 2019-12<BR>ratio: 0.0\", \"Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2016-11<BR>ratio: 0.49\", \"Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2017-06<BR>ratio: 0.05\", \"Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2018-02<BR>ratio: 0.49\", \"Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2018-03<BR>ratio: 0.0\", \"Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2018-04<BR>ratio: 0.01\", \"Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2018-06<BR>ratio: 0.0\", \"Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2019-02<BR>ratio: 0.0\", \"Semi-Supervised Video Object Segmentation<BR>task: Semi-Supervised Video Object Segmentation<BR>date: 2019-08<BR>ratio: 0.01\", \"Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2015-11<BR>ratio: 0.03\", \"Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2016-03<BR>ratio: 0.04\", \"Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2017-10<BR>ratio: 0.0\", \"Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2018-03<BR>ratio: 0.43\", \"Sequential Image Classification<BR>task: Sequential Image Classification<BR>date: 2018-10<BR>ratio: 0.15\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2012-07<BR>ratio: 0.22\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2013-02<BR>ratio: 0.04\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-04<BR>ratio: 0.47\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-06<BR>ratio: 0.49\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-09<BR>ratio: 0.1\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-11<BR>ratio: 0.16\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-03<BR>ratio: 0.03\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-04<BR>ratio: 0.39\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-05<BR>ratio: 0.09\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-08<BR>ratio: 0.36\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-01<BR>ratio: 0.34\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-02<BR>ratio: 0.36\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-04<BR>ratio: 0.05\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-05<BR>ratio: 0.14\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-06<BR>ratio: 0.06\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-11<BR>ratio: 0.01\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-12<BR>ratio: 0.05\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-04<BR>ratio: 0.07\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-07<BR>ratio: 0.34\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-09<BR>ratio: 0.0\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-11<BR>ratio: 0.01\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-12<BR>ratio: 0.02\", \"Skin Cancer Segmentation<BR>task: Skin Cancer Segmentation<BR>date: 2017-11<BR>ratio: 0.0\", \"Skin Cancer Segmentation<BR>task: Skin Cancer Segmentation<BR>date: 2018-02<BR>ratio: 0.0\", \"Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2017-07<BR>ratio: 0.04\", \"Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2018-08<BR>ratio: 0.07\", \"Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2018-10<BR>ratio: 0.04\", \"Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-04<BR>ratio: 0.03\", \"Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-09<BR>ratio: 0.01\", \"Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-10<BR>ratio: 0.36\", \"Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-11<BR>ratio: 0.06\", \"Synthetic-to-Real Translation<BR>task: Synthetic-to-Real Translation<BR>date: 2019-12<BR>ratio: 0.03\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2015-06<BR>ratio: 0.4\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2016-01<BR>ratio: 0.03\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2016-09<BR>ratio: 0.37\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2017-03<BR>ratio: 0.19\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2017-05<BR>ratio: 0.23\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2018-04<BR>ratio: 0.26\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2018-06<BR>ratio: 0.3\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-04<BR>ratio: 0.08\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-06<BR>ratio: 0.06\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-07<BR>ratio: 0.07\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-09<BR>ratio: 0.1\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-11<BR>ratio: 0.03\", \"Temporal Action Proposal Generation<BR>task: Temporal Action Proposal Generation<BR>date: 2018-11<BR>ratio: 0.01\", \"Temporal Action Proposal Generation<BR>task: Temporal Action Proposal Generation<BR>date: 2019-07<BR>ratio: 0.01\", \"Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2016-12<BR>ratio: 0.43\", \"Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2017-10<BR>ratio: 0.34\", \"Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2019-03<BR>ratio: 0.03\", \"Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2019-04<BR>ratio: 0.14\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2015-02<BR>ratio: 0.25\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2015-05<BR>ratio: 0.03\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2017-11<BR>ratio: 0.44\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2018-11<BR>ratio: 0.36\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2018-12<BR>ratio: 0.25\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2019-11<BR>ratio: 0.04\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2020-01<BR>ratio: 0.23\", \"Unsupervised Image-To-Image Translation<BR>task: Unsupervised Image-To-Image Translation<BR>date: 2016-11<BR>ratio: 0.12\", \"Unsupervised Image-To-Image Translation<BR>task: Unsupervised Image-To-Image Translation<BR>date: 2017-03<BR>ratio: 0.44\", \"Unsupervised Image-To-Image Translation<BR>task: Unsupervised Image-To-Image Translation<BR>date: 2017-11<BR>ratio: 0.32\", \"Unsupervised Person Re-Identification<BR>task: Unsupervised Person Re-Identification<BR>date: 2017-05<BR>ratio: 0.49\", \"Unsupervised Person Re-Identification<BR>task: Unsupervised Person Re-Identification<BR>date: 2017-11<BR>ratio: 0.45\", \"Video Generation<BR>task: Video Generation<BR>date: 2016-09<BR>ratio: 0.36\", \"Video Generation<BR>task: Video Generation<BR>date: 2016-11<BR>ratio: 0.16\", \"Video Generation<BR>task: Video Generation<BR>date: 2017-07<BR>ratio: 0.03\", \"Video Generation<BR>task: Video Generation<BR>date: 2019-12<BR>ratio: 0.46\", \"Video Object Detection<BR>task: Video Object Detection<BR>date: 2018-11<BR>ratio: 0.04\", \"Video Object Detection<BR>task: Video Object Detection<BR>date: 2019-07<BR>ratio: 0.01\", \"Video Object Detection<BR>task: Video Object Detection<BR>date: 2020-03<BR>ratio: 0.01\", \"Video Prediction<BR>task: Video Prediction<BR>date: 2018-11<BR>ratio: 0.0\", \"Video Prediction<BR>task: Video Prediction<BR>date: 2019-05<BR>ratio: 0.5\", \"Video Retrieval<BR>task: Video Retrieval<BR>date: 2016-09<BR>ratio: 0.5\", \"Video Retrieval<BR>task: Video Retrieval<BR>date: 2016-12<BR>ratio: 0.07\", \"Video Retrieval<BR>task: Video Retrieval<BR>date: 2017-07<BR>ratio: 0.12\", \"Video Retrieval<BR>task: Video Retrieval<BR>date: 2018-04<BR>ratio: 0.24\", \"Video Retrieval<BR>task: Video Retrieval<BR>date: 2019-06<BR>ratio: 0.28\", \"Video Semantic Segmentation<BR>task: Video Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.06\", \"Video Semantic Segmentation<BR>task: Video Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.0\", \"Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2016-09<BR>ratio: 0.01\", \"Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2016-11<BR>ratio: 0.09\", \"Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2017-04<BR>ratio: 0.01\", \"Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2018-01<BR>ratio: 0.01\", \"Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2018-06<BR>ratio: 0.01\", \"Video Super-Resolution<BR>task: Video Super-Resolution<BR>date: 2019-05<BR>ratio: 0.0\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2017-09<BR>ratio: 0.06\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2017-11<BR>ratio: 0.04\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2018-09<BR>ratio: 0.02\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2019-02<BR>ratio: 0.02\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2019-04<BR>ratio: 0.05\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2016-11<BR>ratio: 0.45\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2017-04<BR>ratio: 0.41\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2017-06<BR>ratio: 0.4\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2017-10<BR>ratio: 0.0\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2018-02<BR>ratio: 0.1\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2018-03<BR>ratio: 0.0\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2018-06<BR>ratio: 0.0\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2018-12<BR>ratio: 0.04\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2019-06<BR>ratio: 0.0\", \"Visual Object Tracking<BR>task: Visual Object Tracking<BR>date: 2019-07<BR>ratio: 0.18\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-03<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-05<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-06<BR>ratio: 0.45\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-11<BR>ratio: 0.07\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-12<BR>ratio: 0.43\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-04<BR>ratio: 0.35\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-05<BR>ratio: 0.05\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-08<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-03<BR>ratio: 0.0\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-05<BR>ratio: 0.0\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-02<BR>ratio: 0.36\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-04<BR>ratio: 0.33\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-05<BR>ratio: 0.19\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-06<BR>ratio: 0.01\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-07<BR>ratio: 0.14\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-08<BR>ratio: 0.22\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-09<BR>ratio: 0.05\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2020-02<BR>ratio: 0.0\", \"Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-05<BR>ratio: 0.13\", \"Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-06<BR>ratio: 0.01\", \"Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-08<BR>ratio: 0.38\", \"Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-11<BR>ratio: 0.35\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2014-03<BR>ratio: 0.42\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2015-05<BR>ratio: 0.25\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2015-11<BR>ratio: 0.47\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2016-03<BR>ratio: 0.08\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2016-09<BR>ratio: 0.35\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2016-11<BR>ratio: 0.25\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-04<BR>ratio: 0.08\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-06<BR>ratio: 0.15\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-07<BR>ratio: 0.01\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-08<BR>ratio: 0.09\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2017-11<BR>ratio: 0.1\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-02<BR>ratio: 0.08\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-04<BR>ratio: 0.0\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-06<BR>ratio: 0.06\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-07<BR>ratio: 0.11\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2018-11<BR>ratio: 0.03\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2019-10<BR>ratio: 0.02\", \"Weakly Supervised Object Detection<BR>task: Weakly Supervised Object Detection<BR>date: 2019-11<BR>ratio: 0.02\", \"Weakly-supervised 3D Human Pose Estimation<BR>task: Weakly-supervised 3D Human Pose Estimation<BR>date: 2017-01<BR>ratio: 0.42\", \"Weakly-supervised 3D Human Pose Estimation<BR>task: Weakly-supervised 3D Human Pose Estimation<BR>date: 2017-04<BR>ratio: 0.25\", \"Weakly-supervised 3D Human Pose Estimation<BR>task: Weakly-supervised 3D Human Pose Estimation<BR>date: 2019-03<BR>ratio: 0.5\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.07, 0.25, 0.45, 0.0, 0.26, 0.01, 0.24, 0.07, 0.09, 0.48, 0.03, 0.03, 0.09, 0.15, 0.4, 0.04, 0.15, 0.21, 0.15, 0.26, 0.01, 0.32, 0.01, 0.01, 0.01, 0.01, 0.0, 0.02, 0.06, 0.01, 0.01, 0.0, 0.0, 0.32, 0.16, 0.0, 0.09, 0.03, 0.23, 0.39, 0.37, 0.25, 0.09, 0.16, 0.11, 0.06, 0.32, 0.16, 0.14, 0.47, 0.04, 0.48, 0.38, 0.0, 0.41, 0.08, 0.02, 0.47, 0.17, 0.05, 0.0, 0.07, 0.1, 0.0, 0.03, 0.43, 0.24, 0.17, 0.37, 0.45, 0.04, 0.07, 0.06, 0.5, 0.04, 0.01, 0.03, 0.08, 0.1, 0.27, 0.26, 0.46, 0.1, 0.01, 0.0, 0.06, 0.11, 0.14, 0.01, 0.03, 0.03, 0.03, 0.14, 0.23, 0.1, 0.16, 0.04, 0.06, 0.04, 0.04, 0.01, 0.01, 0.28, 0.11, 0.27, 0.48, 0.02, 0.46, 0.0, 0.38, 0.01, 0.06, 0.01, 0.16, 0.12, 0.03, 0.01, 0.02, 0.13, 0.31, 0.49, 0.11, 0.0, 0.06, 0.34, 0.43, 0.15, 0.1, 0.01, 0.01, 0.06, 0.09, 0.18, 0.01, 0.01, 0.05, 0.02, 0.37, 0.11, 0.42, 0.01, 0.04, 0.03, 0.26, 0.09, 0.09, 0.02, 0.29, 0.12, 0.0, 0.01, 0.03, 0.3, 0.1, 0.1, 0.34, 0.17, 0.06, 0.01, 0.48, 0.0, 0.0, 0.04, 0.05, 0.0, 0.03, 0.0, 0.17, 0.17, 0.19, 0.24, 0.0, 0.0, 0.0, 0.03, 0.03, 0.0, 0.0, 0.0, 0.03, 0.5, 0.06, 0.23, 0.03, 0.16, 0.01, 0.0, 0.23, 0.11, 0.43, 0.05, 0.47, 0.03, 0.04, 0.01, 0.09, 0.0, 0.12, 0.15, 0.02, 0.02, 0.0, 0.03, 0.48, 0.06, 0.02, 0.03, 0.06, 0.32, 0.08, 0.01, 0.25, 0.49, 0.0, 0.19, 0.12, 0.01, 0.05, 0.1, 0.02, 0.35, 0.01, 0.03, 0.0, 0.5, 0.02, 0.02, 0.01, 0.03, 0.01, 0.22, 0.33, 0.03, 0.08, 0.42, 0.33, 0.5, 0.18, 0.01, 0.16, 0.04, 0.07, 0.02, 0.03, 0.19, 0.02, 0.08, 0.05, 0.08, 0.02, 0.1, 0.04, 0.05, 0.04, 0.16, 0.36, 0.08, 0.41, 0.32, 0.15, 0.18, 0.05, 0.03, 0.02, 0.03, 0.47, 0.47, 0.33, 0.04, 0.01, 0.12, 0.02, 0.19, 0.04, 0.03, 0.0, 0.41, 0.16, 0.02, 0.01, 0.34, 0.04, 0.01, 0.0, 0.02, 0.24, 0.21, 0.01, 0.01, 0.0, 0.12, 0.16, 0.02, 0.01, 0.36, 0.15, 0.04, 0.17, 0.17, 0.18, 0.22, 0.0, 0.44, 0.19, 0.38, 0.25, 0.14, 0.2, 0.22, 0.26, 0.2, 0.24, 0.24, 0.21, 0.0, 0.17, 0.09, 0.02, 0.37, 0.42, 0.33, 0.38, 0.31, 0.42, 0.02, 0.23, 0.44, 0.39, 0.29, 0.32, 0.12, 0.27, 0.01, 0.02, 0.06, 0.05, 0.48, 0.14, 0.5, 0.08, 0.07, 0.01, 0.41, 0.01, 0.11, 0.32, 0.01, 0.03, 0.17, 0.15, 0.0, 0.0, 0.03, 0.01, 0.01, 0.02, 0.0, 0.42, 0.23, 0.16, 0.28, 0.01, 0.19, 0.26, 0.04, 0.21, 0.19, 0.03, 0.19, 0.04, 0.06, 0.3, 0.1, 0.02, 0.02, 0.11, 0.08, 0.03, 0.08, 0.0, 0.03, 0.33, 0.03, 0.04, 0.02, 0.06, 0.08, 0.01, 0.0, 0.5, 0.0, 0.5, 0.19, 0.32, 0.47, 0.0, 0.03, 0.11, 0.0, 0.5, 0.2, 0.4, 0.04, 0.47, 0.06, 0.04, 0.34, 0.5, 0.0, 0.12, 0.03, 0.23, 0.03, 0.02, 0.38, 0.37, 0.03, 0.06, 0.03, 0.0, 0.05, 0.41, 0.0, 0.06, 0.0, 0.33, 0.06, 0.5, 0.03, 0.42, 0.08, 0.25, 0.5, 0.45, 0.49, 0.35, 0.48, 0.07, 0.0, 0.0, 0.12, 0.25, 0.0, 0.13, 0.0, 0.34, 0.48, 0.09, 0.42, 0.27, 0.27, 0.02, 0.05, 0.04, 0.04, 0.04, 0.06, 0.16, 0.03, 0.06, 0.03, 0.18, 0.02, 0.01, 0.11, 0.0, 0.17, 0.26, 0.04, 0.28, 0.04, 0.05, 0.05, 0.16, 0.07, 0.3, 0.1, 0.04, 0.43, 0.25, 0.16, 0.23, 0.08, 0.03, 0.38, 0.04, 0.34, 0.01, 0.25, 0.0, 0.06, 0.02, 0.1, 0.01, 0.21, 0.45, 0.28, 0.24, 0.28, 0.03, 0.04, 0.03, 0.0, 0.37, 0.0, 0.3, 0.04, 0.01, 0.0, 0.01, 0.08, 0.0, 0.04, 0.5, 0.0, 0.01, 0.01, 0.09, 0.01, 0.14, 0.01, 0.0, 0.02, 0.0, 0.03, 0.05, 0.01, 0.0, 0.0, 0.0, 0.47, 0.15, 0.38, 0.0, 0.09, 0.01, 0.09, 0.11, 0.04, 0.3, 0.01, 0.06, 0.39, 0.06, 0.26, 0.18, 0.12, 0.0, 0.01, 0.01, 0.25, 0.0, 0.0, 0.33, 0.0, 0.5, 0.0, 0.01, 0.03, 0.34, 0.01, 0.02, 0.2, 0.04, 0.03, 0.33, 0.43, 0.18, 0.05, 0.02, 0.28, 0.38, 0.05, 0.06, 0.27, 0.02, 0.12, 0.05, 0.35, 0.02, 0.03, 0.5, 0.04, 0.39, 0.03, 0.01, 0.07, 0.03, 0.02, 0.08, 0.21, 0.36, 0.38, 0.01, 0.47, 0.25, 0.44, 0.42, 0.4, 0.06, 0.21, 0.09, 0.34, 0.01, 0.04, 0.03, 0.06, 0.05, 0.5, 0.04, 0.05, 0.01, 0.13, 0.01, 0.01, 0.02, 0.28, 0.01, 0.04, 0.15, 0.04, 0.25, 0.27, 0.31, 0.21, 0.24, 0.09, 0.11, 0.0, 0.49, 0.05, 0.49, 0.0, 0.01, 0.0, 0.0, 0.01, 0.03, 0.04, 0.0, 0.43, 0.15, 0.22, 0.04, 0.47, 0.49, 0.1, 0.16, 0.03, 0.39, 0.09, 0.36, 0.34, 0.36, 0.05, 0.14, 0.06, 0.01, 0.05, 0.07, 0.34, 0.0, 0.01, 0.02, 0.0, 0.0, 0.04, 0.07, 0.04, 0.03, 0.01, 0.36, 0.06, 0.03, 0.4, 0.03, 0.37, 0.19, 0.23, 0.26, 0.3, 0.08, 0.06, 0.07, 0.1, 0.03, 0.01, 0.01, 0.43, 0.34, 0.03, 0.14, 0.25, 0.03, 0.44, 0.36, 0.25, 0.04, 0.23, 0.12, 0.44, 0.32, 0.49, 0.45, 0.36, 0.16, 0.03, 0.46, 0.04, 0.01, 0.01, 0.0, 0.5, 0.5, 0.07, 0.12, 0.24, 0.28, 0.06, 0.0, 0.01, 0.09, 0.01, 0.01, 0.01, 0.0, 0.06, 0.04, 0.02, 0.02, 0.05, 0.45, 0.41, 0.4, 0.0, 0.1, 0.0, 0.0, 0.04, 0.0, 0.18, 0.03, 0.03, 0.45, 0.07, 0.43, 0.35, 0.05, 0.03, 0.0, 0.0, 0.36, 0.33, 0.19, 0.01, 0.14, 0.22, 0.05, 0.0, 0.13, 0.01, 0.38, 0.35, 0.42, 0.25, 0.47, 0.08, 0.35, 0.25, 0.08, 0.15, 0.01, 0.09, 0.1, 0.08, 0.0, 0.06, 0.11, 0.03, 0.02, 0.02, 0.42, 0.25, 0.5], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2017-09\", \"2018-06\", \"2019-09\", \"2020-02\", \"2019-04\", \"2019-06\", \"2020-03\", \"2020-04\", \"2016-06\", \"2017-11\", \"2017-12\", \"2018-02\", \"2018-12\", \"2019-03\", \"2019-04\", \"2019-07\", \"2020-01\", \"2020-03\", \"2016-12\", \"2018-02\", \"2019-01\", \"2016-12\", \"2017-06\", \"2017-11\", \"2018-01\", \"2019-04\", \"2019-09\", \"2017-04\", \"2017-06\", \"2018-01\", \"2018-03\", \"2018-12\", \"2019-04\", \"2016-03\", \"2016-12\", \"2018-08\", \"2018-11\", \"2019-01\", \"2017-11\", \"2018-12\", \"2020-03\", \"2016-12\", \"2017-06\", \"2017-10\", \"2018-07\", \"2018-09\", \"2019-04\", \"2016-10\", \"2018-04\", \"2019-01\", \"2019-11\", \"2018-03\", \"2019-02\", \"2019-09\", \"2014-06\", \"2016-12\", \"2017-11\", \"2017-12\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2018-12\", \"2019-05\", \"2019-06\", \"2016-12\", \"2017-12\", \"2018-03\", \"2019-04\", \"2012-12\", \"2014-12\", \"2015-03\", \"2015-05\", \"2015-12\", \"2016-01\", \"2016-04\", \"2016-08\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-11\", \"2018-01\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2019-01\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-12\", \"2016-11\", \"2018-06\", \"2020-03\", \"2014-12\", \"2015-05\", \"2016-05\", \"2016-04\", \"2017-04\", \"2018-10\", \"2017-03\", \"2018-09\", \"2015-12\", \"2016-08\", \"2017-12\", \"2018-12\", \"2019-07\", \"2019-10\", \"2017-04\", \"2018-02\", \"2018-07\", \"2019-04\", \"2016-06\", \"2016-10\", \"2016-12\", \"2017-03\", \"2017-09\", \"2018-05\", \"2018-09\", \"2017-12\", \"2018-03\", \"2016-12\", \"2018-03\", \"2019-04\", \"2015-05\", \"2019-04\", \"2017-05\", \"2018-07\", \"2019-04\", \"2015-06\", \"2016-12\", \"2019-04\", \"2017-04\", \"2018-01\", \"2019-08\", \"2015-05\", \"2016-08\", \"2017-04\", \"2017-05\", \"2017-11\", \"2017-12\", \"2018-07\", \"2018-11\", \"2019-01\", \"2019-03\", \"2019-05\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-11\", \"2017-08\", \"2017-10\", \"2019-03\", \"2019-05\", \"2018-11\", \"2019-05\", \"2019-08\", \"2020-02\", \"2019-06\", \"2019-08\", \"2018-06\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-08\", \"2019-09\", \"2017-07\", \"2017-11\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-06\", \"2016-03\", \"2017-08\", \"2017-09\", \"2018-09\", \"2018-10\", \"2015-11\", \"2016-04\", \"2017-04\", \"2018-01\", \"2018-03\", \"2018-12\", \"2014-06\", \"2015-02\", \"2015-03\", \"2015-08\", \"2015-11\", \"2016-03\", \"2016-04\", \"2017-03\", \"2017-04\", \"2017-12\", \"2018-01\", \"2018-03\", \"2018-09\", \"2018-12\", \"2019-03\", \"2019-04\", \"2019-08\", \"2019-10\", \"2017-08\", \"2018-05\", \"2019-02\", \"2019-05\", \"2019-11\", \"2013-06\", \"2016-03\", \"2017-03\", \"2017-11\", \"2018-06\", \"2018-10\", \"2019-03\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2016-11\", \"2017-12\", \"2018-01\", \"2018-06\", \"2018-11\", \"2019-01\", \"2019-06\", \"2019-10\", \"2019-12\", \"2020-02\", \"2018-11\", \"2019-05\", \"2017-07\", \"2017-12\", \"2018-08\", \"2016-08\", \"2017-04\", \"2018-05\", \"2018-06\", \"2019-10\", \"2018-11\", \"2019-04\", \"2018-12\", \"2019-01\", \"2017-07\", \"2017-12\", \"2016-08\", \"2019-05\", \"2017-06\", \"2018-11\", \"2017-08\", \"2018-05\", \"2018-09\", \"2019-10\", \"2016-04\", \"2017-04\", \"2018-07\", \"2018-08\", \"2018-11\", \"2019-04\", \"2019-12\", \"2020-03\", \"2020-04\", \"2018-07\", \"2019-02\", \"2012-02\", \"2012-12\", \"2013-01\", \"2013-02\", \"2013-11\", \"2013-12\", \"2014-04\", \"2014-06\", \"2014-09\", \"2014-12\", \"2015-02\", \"2015-06\", \"2015-11\", \"2015-12\", \"2016-02\", \"2016-03\", \"2016-05\", \"2016-08\", \"2016-10\", \"2016-11\", \"2017-07\", \"2017-08\", \"2017-09\", \"2017-10\", \"2017-12\", \"2018-02\", \"2018-05\", \"2018-07\", \"2018-11\", \"2019-01\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-08\", \"2019-10\", \"2019-12\", \"2020-01\", \"2013-12\", \"2015-11\", \"2016-04\", \"2017-03\", \"2017-04\", \"2017-09\", \"2017-10\", \"2018-04\", \"2018-07\", \"2018-10\", \"2018-11\", \"2018-12\", \"2019-01\", \"2019-04\", \"2016-05\", \"2017-02\", \"2017-03\", \"2017-09\", \"2017-10\", \"2018-02\", \"2018-09\", \"2018-11\", \"2018-12\", \"2019-03\", \"2014-12\", \"2015-04\", \"2015-11\", \"2016-04\", \"2016-08\", \"2016-11\", \"2016-12\", \"2017-12\", \"2018-01\", \"2018-03\", \"2018-04\", \"2018-11\", \"2019-02\", \"2019-03\", \"2019-09\", \"2015-08\", \"2015-11\", \"2016-03\", \"2016-08\", \"2016-09\", \"2016-11\", \"2016-12\", \"2017-07\", \"2017-10\", \"2018-02\", \"2018-03\", \"2018-04\", \"2018-05\", \"2018-07\", \"2018-09\", \"2018-11\", \"2019-03\", \"2019-04\", \"2019-06\", \"2019-07\", \"2015-12\", \"2016-06\", \"2017-11\", \"2018-04\", \"2018-11\", \"2019-03\", \"2019-04\", \"2019-05\", \"2019-08\", \"2019-10\", \"2017-03\", \"2017-04\", \"2017-12\", \"2019-02\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-11\", \"2020-01\", \"2016-08\", \"2016-12\", \"2017-03\", \"2017-11\", \"2018-04\", \"2018-12\", \"2019-01\", \"2019-02\", \"2017-10\", \"2017-12\", \"2018-06\", \"2019-08\", \"2018-11\", \"2019-09\", \"2018-10\", \"2020-03\", \"2019-06\", \"2020-01\", \"2017-11\", \"2019-08\", \"2015-11\", \"2018-07\", \"2016-11\", \"2017-06\", \"2018-04\", \"2019-08\", \"2016-09\", \"2018-03\", \"2018-05\", \"2017-05\", \"2017-09\", \"2018-04\", \"2018-04\", \"2018-11\", \"2019-06\", \"2016-05\", \"2016-08\", \"2016-12\", \"2017-01\", \"2017-11\", \"2018-03\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-10\", \"2015-05\", \"2017-03\", \"2015-11\", \"2016-03\", \"2016-08\", \"2017-04\", \"2018-01\", \"2019-01\", \"2017-03\", \"2017-11\", \"2018-04\", \"2018-08\", \"2018-02\", \"2018-11\", \"2019-09\", \"2016-06\", \"2018-12\", \"2016-11\", \"2017-03\", \"2018-09\", \"2015-06\", \"2016-04\", \"2015-06\", \"2015-12\", \"2017-03\", \"2017-07\", \"2017-08\", \"2017-11\", \"2017-12\", \"2018-03\", \"2018-05\", \"2018-11\", \"2018-12\", \"2019-01\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-10\", \"2019-11\", \"2017-09\", \"2018-04\", \"2018-12\", \"2019-01\", \"2019-05\", \"2019-09\", \"2019-11\", \"2016-08\", \"2019-10\", \"2014-12\", \"2018-07\", \"2014-06\", \"2016-03\", \"2016-07\", \"2016-10\", \"2016-11\", \"2017-01\", \"2017-03\", \"2017-07\", \"2017-08\", \"2017-09\", \"2017-10\", \"2017-11\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2018-12\", \"2019-03\", \"2019-05\", \"2019-08\", \"2019-10\", \"2019-11\", \"2019-12\", \"2020-01\", \"2015-11\", \"2016-03\", \"2016-09\", \"2016-12\", \"2017-01\", \"2017-02\", \"2017-04\", \"2017-05\", \"2017-07\", \"2017-08\", \"2017-11\", \"2017-12\", \"2018-03\", \"2018-04\", \"2018-05\", \"2018-11\", \"2018-12\", \"2019-01\", \"2019-02\", \"2019-10\", \"2020-01\", \"2020-02\", \"2017-12\", \"2018-02\", \"2019-02\", \"2019-05\", \"2016-06\", \"2017-04\", \"2017-08\", \"2017-10\", \"2018-06\", \"2019-06\", \"2016-05\", \"2017-08\", \"2019-04\", \"2019-09\", \"2019-11\", \"2020-04\", \"2015-02\", \"2015-11\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2018-08\", \"2018-11\", \"2019-03\", \"2019-09\", \"2020-04\", \"2017-11\", \"2018-02\", \"2018-06\", \"2018-10\", \"2019-07\", \"2019-12\", \"2015-12\", \"2019-11\", \"2017-07\", \"2018-06\", \"2018-08\", \"2018-03\", \"2019-08\", \"2015-04\", \"2016-04\", \"2017-03\", \"2017-04\", \"2017-07\", \"2017-08\", \"2017-09\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-06\", \"2018-07\", \"2018-11\", \"2019-03\", \"2019-04\", \"2019-10\", \"2019-11\", \"2016-03\", \"2019-01\", \"2019-06\", \"2019-07\", \"2019-11\", \"2020-03\", \"2015-02\", \"2015-03\", \"2015-04\", \"2015-09\", \"2015-11\", \"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-02\", \"2017-03\", \"2017-04\", \"2017-06\", \"2017-10\", \"2017-11\", \"2017-12\", \"2018-02\", \"2018-03\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-09\", \"2018-12\", \"2019-03\", \"2019-04\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-10\", \"2019-11\", \"2020-04\", \"2016-10\", \"2016-11\", \"2017-03\", \"2017-04\", \"2018-06\", \"2018-07\", \"2019-05\", \"2019-09\", \"2019-11\", \"2019-12\", \"2016-11\", \"2017-06\", \"2018-02\", \"2018-03\", \"2018-04\", \"2018-06\", \"2019-02\", \"2019-08\", \"2015-11\", \"2016-03\", \"2017-10\", \"2018-03\", \"2018-10\", \"2012-07\", \"2013-02\", \"2016-04\", \"2016-06\", \"2016-09\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-11\", \"2018-12\", \"2019-04\", \"2019-07\", \"2019-09\", \"2019-11\", \"2019-12\", \"2017-11\", \"2018-02\", \"2017-07\", \"2018-08\", \"2018-10\", \"2019-04\", \"2019-09\", \"2019-10\", \"2019-11\", \"2019-12\", \"2015-06\", \"2016-01\", \"2016-09\", \"2017-03\", \"2017-05\", \"2018-04\", \"2018-06\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\", \"2018-11\", \"2019-07\", \"2016-12\", \"2017-10\", \"2019-03\", \"2019-04\", \"2015-02\", \"2015-05\", \"2017-11\", \"2018-11\", \"2018-12\", \"2019-11\", \"2020-01\", \"2016-11\", \"2017-03\", \"2017-11\", \"2017-05\", \"2017-11\", \"2016-09\", \"2016-11\", \"2017-07\", \"2019-12\", \"2018-11\", \"2019-07\", \"2020-03\", \"2018-11\", \"2019-05\", \"2016-09\", \"2016-12\", \"2017-07\", \"2018-04\", \"2019-06\", \"2016-12\", \"2020-04\", \"2016-09\", \"2016-11\", \"2017-04\", \"2018-01\", \"2018-06\", \"2019-05\", \"2017-09\", \"2017-11\", \"2018-09\", \"2019-02\", \"2019-04\", \"2016-11\", \"2017-04\", \"2017-06\", \"2017-10\", \"2018-02\", \"2018-03\", \"2018-06\", \"2018-12\", \"2019-06\", \"2019-07\", \"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\", \"2020-02\", \"2019-05\", \"2019-06\", \"2019-08\", \"2019-11\", \"2014-03\", \"2015-05\", \"2015-11\", \"2016-03\", \"2016-09\", \"2016-11\", \"2017-04\", \"2017-06\", \"2017-07\", \"2017-08\", \"2017-11\", \"2018-02\", \"2018-04\", \"2018-06\", \"2018-07\", \"2018-11\", \"2019-10\", \"2019-11\", \"2017-01\", \"2017-04\", \"2019-03\"], \"y\": [\"3D Human Pose Estimation\", \"3D Human Pose Estimation\", \"3D Human Pose Estimation\", \"3D Human Pose Estimation\", \"3D Instance Segmentation\", \"3D Instance Segmentation\", \"3D Instance Segmentation\", \"3D Instance Segmentation\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Detection\", \"3D Object Reconstruction\", \"3D Object Reconstruction\", \"3D Object Reconstruction\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Point Cloud Classification\", \"3D Point Cloud Classification\", \"3D Point Cloud Classification\", \"3D Point Cloud Classification\", \"3D Point Cloud Classification\", \"3D Point Cloud Classification\", \"3D Reconstruction\", \"3D Reconstruction\", \"3D Reconstruction\", \"3D Room Layouts From A Single RGB Panorama\", \"3D Room Layouts From A Single RGB Panorama\", \"3D Semantic Instance Segmentation\", \"3D Semantic Instance Segmentation\", \"3D Semantic Instance Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Shape Classification\", \"3D Shape Classification\", \"6D Pose Estimation\", \"6D Pose Estimation\", \"6D Pose Estimation using RGB\", \"6D Pose Estimation using RGB\", \"6D Pose Estimation using RGB\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Classification\", \"Action Detection\", \"Action Detection\", \"Action Detection\", \"Action Detection\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Segmentation\", \"Action Segmentation\", \"Action Segmentation\", \"Activity Recognition In Videos\", \"Activity Recognition In Videos\", \"Activity Recognition In Videos\", \"Aesthetics Quality Assessment\", \"Aesthetics Quality Assessment\", \"Aesthetics Quality Assessment\", \"Age-Invariant Face Recognition\", \"Age-Invariant Face Recognition\", \"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\", \"Birds Eye View Object Detection\", \"Color Image Denoising\", \"Color Image Denoising\", \"Color Image Denoising\", \"Color Image Denoising\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Conditional Image Generation\", \"Cross-Modal Retrieval\", \"Cross-Modal Retrieval\", \"Cross-View Image-to-Image Translation\", \"Cross-View Image-to-Image Translation\", \"Cross-View Image-to-Image Translation\", \"Curved Text Detection\", \"Curved Text Detection\", \"Denoising\", \"Denoising\", \"Denoising\", \"Dense Object Detection\", \"Dense Object Detection\", \"Dense Object Detection\", \"Document Image Classification\", \"Document Image Classification\", \"Document Image Classification\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Generalization\", \"Domain Generalization\", \"Domain Generalization\", \"Domain Generalization\", \"Egocentric Activity Recognition\", \"Egocentric Activity Recognition\", \"Egocentric Activity Recognition\", \"Egocentric Activity Recognition\", \"Electron Microscopy Image Segmentation\", \"Electron Microscopy Image Segmentation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Face Alignment\", \"Face Alignment\", \"Face Alignment\", \"Face Alignment\", \"Face Alignment\", \"Face Alignment\", \"Face Alignment\", \"Face Detection\", \"Face Detection\", \"Face Detection\", \"Face Detection\", \"Face Detection\", \"Face Identification\", \"Face Identification\", \"Face Identification\", \"Face Identification\", \"Face Identification\", \"Face Identification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Face Verification\", \"Facial Expression Recognition\", \"Facial Expression Recognition\", \"Facial Expression Recognition\", \"Facial Expression Recognition\", \"Facial Expression Recognition\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Fine-Grained Image Classification\", \"Formation Energy\", \"Formation Energy\", \"Gesture-to-Gesture Translation\", \"Gesture-to-Gesture Translation\", \"Gesture-to-Gesture Translation\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Group Activity Recognition\", \"Group Activity Recognition\", \"Hand Gesture Recognition\", \"Hand Gesture Recognition\", \"Hand Pose Estimation\", \"Hand Pose Estimation\", \"Horizon Line Estimation\", \"Horizon Line Estimation\", \"Human Interaction Recognition\", \"Human Interaction Recognition\", \"Human Part Segmentation\", \"Human Part Segmentation\", \"Human Part Segmentation\", \"Human Part Segmentation\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Human-Object Interaction Detection\", \"Hyperspectral Image Classification\", \"Hyperspectral Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Classification\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Clustering\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Generation\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Retrieval\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image Super-Resolution\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Image-to-Image Translation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Instance Segmentation\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Keypoint Detection\", \"Lane Detection\", \"Lane Detection\", \"Lane Detection\", \"Lane Detection\", \"Layout-to-Image Generation\", \"Layout-to-Image Generation\", \"Lesion Segmentation\", \"Lesion Segmentation\", \"Low-Light Image Enhancement\", \"Low-Light Image Enhancement\", \"Lung Nodule Segmentation\", \"Lung Nodule Segmentation\", \"Medical Image Segmentation\", \"Medical Image Segmentation\", \"Metric Learning\", \"Metric Learning\", \"Metric Learning\", \"Metric Learning\", \"Monocular Depth Estimation\", \"Monocular Depth Estimation\", \"Monocular Depth Estimation\", \"Multi-Human Parsing\", \"Multi-Human Parsing\", \"Multi-Human Parsing\", \"Multi-Object Tracking\", \"Multi-Object Tracking\", \"Multi-Object Tracking\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-Person Pose Estimation\", \"Multi-tissue Nucleus Segmentation\", \"Multi-tissue Nucleus Segmentation\", \"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\", \"Multimodal Activity Recognition\", \"Multimodal Unsupervised Image-To-Image Translation\", \"Multimodal Unsupervised Image-To-Image Translation\", \"Multimodal Unsupervised Image-To-Image Translation\", \"Multimodal Unsupervised Image-To-Image Translation\", \"Multiple Object Tracking\", \"Multiple Object Tracking\", \"Multiple Object Tracking\", \"Multivariate Time Series Imputation\", \"Multivariate Time Series Imputation\", \"Nuclear Segmentation\", \"Nuclear Segmentation\", \"Nuclear Segmentation\", \"Object Counting\", \"Object Counting\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Object Detection\", \"Pancreas Segmentation\", \"Pancreas Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Pedestrian Attribute Recognition\", \"Pedestrian Attribute Recognition\", \"Pedestrian Detection\", \"Pedestrian Detection\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Person Re-Identification\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Estimation\", \"Pose Tracking\", \"Pose Tracking\", \"Pose Tracking\", \"Pose Tracking\", \"RGB Salient Object Detection\", \"RGB Salient Object Detection\", \"RGB Salient Object Detection\", \"RGB Salient Object Detection\", \"RGB Salient Object Detection\", \"RGB Salient Object Detection\", \"Real-Time Object Detection\", \"Real-Time Object Detection\", \"Real-Time Object Detection\", \"Real-Time Object Detection\", \"Real-Time Object Detection\", \"Real-Time Object Detection\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Satellite Image Classification\", \"Satellite Image Classification\", \"Scene Graph Generation\", \"Scene Graph Generation\", \"Scene Graph Generation\", \"Scene Segmentation\", \"Scene Segmentation\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Scene Text Detection\", \"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\", \"Self-Supervised Image Classification\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Image Classification\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Video Object Segmentation\", \"Sequential Image Classification\", \"Sequential Image Classification\", \"Sequential Image Classification\", \"Sequential Image Classification\", \"Sequential Image Classification\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skin Cancer Segmentation\", \"Skin Cancer Segmentation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Synthetic-to-Real Translation\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Proposal Generation\", \"Temporal Action Proposal Generation\", \"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Image-To-Image Translation\", \"Unsupervised Image-To-Image Translation\", \"Unsupervised Image-To-Image Translation\", \"Unsupervised Person Re-Identification\", \"Unsupervised Person Re-Identification\", \"Video Generation\", \"Video Generation\", \"Video Generation\", \"Video Generation\", \"Video Object Detection\", \"Video Object Detection\", \"Video Object Detection\", \"Video Prediction\", \"Video Prediction\", \"Video Retrieval\", \"Video Retrieval\", \"Video Retrieval\", \"Video Retrieval\", \"Video Retrieval\", \"Video Semantic Segmentation\", \"Video Semantic Segmentation\", \"Video Super-Resolution\", \"Video Super-Resolution\", \"Video Super-Resolution\", \"Video Super-Resolution\", \"Video Super-Resolution\", \"Video Super-Resolution\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Object Tracking\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Object Detection\", \"Weakly-supervised 3D Human Pose Estimation\", \"Weakly-supervised 3D Human Pose Estimation\", \"Weakly-supervised 3D Human Pose Estimation\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Weakly-supervised 3D Human Pose Estimation\", \"Weakly Supervised Object Detection\", \"Weakly Supervised Action Localization\", \"Visual Question Answering\", \"Visual Object Tracking\", \"Visual Dialog\", \"Video Super-Resolution\", \"Video Semantic Segmentation\", \"Video Retrieval\", \"Video Prediction\", \"Video Object Detection\", \"Video Generation\", \"Unsupervised Person Re-Identification\", \"Unsupervised Image-To-Image Translation\", \"Unsupervised Domain Adaptation\", \"Text-to-Image Generation\", \"Temporal Action Proposal Generation\", \"Temporal Action Localization\", \"Synthetic-to-Real Translation\", \"Skin Cancer Segmentation\", \"Skeleton Based Action Recognition\", \"Sequential Image Classification\", \"Semi-Supervised Video Object Segmentation\", \"Semi-Supervised Image Classification\", \"Semantic Segmentation\", \"Self-Supervised Image Classification\", \"Scene Text Detection\", \"Scene Segmentation\", \"Scene Graph Generation\", \"Satellite Image Classification\", \"Retinal Vessel Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Object Detection\", \"RGB Salient Object Detection\", \"Pose Tracking\", \"Pose Estimation\", \"Person Re-Identification\", \"Pedestrian Detection\", \"Pedestrian Attribute Recognition\", \"Panoptic Segmentation\", \"Pancreas Segmentation\", \"Object Detection\", \"Object Counting\", \"Nuclear Segmentation\", \"Multivariate Time Series Imputation\", \"Multiple Object Tracking\", \"Multimodal Unsupervised Image-To-Image Translation\", \"Multimodal Activity Recognition\", \"Multi-tissue Nucleus Segmentation\", \"Multi-Person Pose Estimation\", \"Multi-Object Tracking\", \"Multi-Human Parsing\", \"Monocular Depth Estimation\", \"Metric Learning\", \"Medical Image Segmentation\", \"Lung Nodule Segmentation\", \"Low-Light Image Enhancement\", \"Lesion Segmentation\", \"Layout-to-Image Generation\", \"Lane Detection\", \"Keypoint Detection\", \"Instance Segmentation\", \"Image-to-Image Translation\", \"Image Super-Resolution\", \"Image Retrieval\", \"Image Generation\", \"Image Clustering\", \"Image Classification\", \"Hyperspectral Image Classification\", \"Human-Object Interaction Detection\", \"Human Part Segmentation\", \"Human Interaction Recognition\", \"Horizon Line Estimation\", \"Hand Pose Estimation\", \"Hand Gesture Recognition\", \"Group Activity Recognition\", \"Grayscale Image Denoising\", \"Gesture-to-Gesture Translation\", \"Formation Energy\", \"Fine-Grained Image Classification\", \"Few-Shot Image Classification\", \"Facial Expression Recognition\", \"Face Verification\", \"Face Identification\", \"Face Detection\", \"Face Alignment\", \"Emotion Recognition in Conversation\", \"Electron Microscopy Image Segmentation\", \"Egocentric Activity Recognition\", \"Domain Generalization\", \"Domain Adaptation\", \"Document Image Classification\", \"Dense Object Detection\", \"Denoising\", \"Curved Text Detection\", \"Cross-View Image-to-Image Translation\", \"Cross-Modal Retrieval\", \"Conditional Image Generation\", \"Color Image Denoising\", \"Birds Eye View Object Detection\", \"Age-Invariant Face Recognition\", \"Aesthetics Quality Assessment\", \"Activity Recognition In Videos\", \"Action Segmentation\", \"Action Recognition\", \"Action Detection\", \"Action Classification\", \"6D Pose Estimation using RGB\", \"6D Pose Estimation\", \"3D Shape Classification\", \"3D Semantic Segmentation\", \"3D Semantic Instance Segmentation\", \"3D Room Layouts From A Single RGB Panorama\", \"3D Reconstruction\", \"3D Point Cloud Classification\", \"3D Part Segmentation\", \"3D Object Reconstruction\", \"3D Object Detection\", \"3D Instance Segmentation\", \"3D Human Pose Estimation\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00101: Vision process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8893aeee-ed02-4698-ae10-4d5956236807');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00113\n",
      "Number of metrics:  64\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  GPS - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",  Android Malware Dataset - Malware Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Bing News - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Book-Crossing - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MovieLens 1M - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  KDD  - Network Intrusion Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Last.FM - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Children\\'s Book Test Common noun - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Polyvore - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MIB Datasets - Twitter Bot Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  18\n",
      "####### 5\\\\ fold\\\\ cross\\\\ validation\n",
      "Creating ratio df for  5\\\\ fold\\\\ cross\\\\ validation ,  Cornell Grasp Dataset - Robotic Grasping benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### RMSE\\\\ \\\\(u1\\\\ Splits\\\\)\n",
      "Creating ratio df for  RMSE\\\\ \\\\(u1\\\\ Splits\\\\) ,  MovieLens 100K - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### EER\n",
      "Creating ratio df for  EER ,  CASIA-MFSD - Face Anti-Spoofing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  EER ,  Replay-Attack - Face Anti-Spoofing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  EER ,  UBI-Fights - Abnormal Event Detection In Video benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  EER ,  UBI-Fights - Semi-supervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### RMSE\n",
      "Creating ratio df for  RMSE ,  MovieLens 10M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  RMSE ,  MovieLens 1M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  RMSE ,  Flixster - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  Douban Monti - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  YahooMusic - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  Flixster Monti - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  YahooMusic Monti - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  Douban - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  Epinions - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  RMSE ,  Frappe - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  14\n",
      "####### NAB\\\\ score\n",
      "Creating ratio df for  NAB\\\\ score ,  Numenta Anomaly Benchmark - Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### HTER\n",
      "Creating ratio df for  HTER ,  Replay-Attack - Face Anti-Spoofing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Equal\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Equal\\\\ Error\\\\ Rate ,  MSU-MFSD - Face Anti-Spoofing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Test\\\\ perplexity\n",
      "Creating ratio df for  Test\\\\ perplexity ,  20 Newsgroups - Topic modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AUC\n",
      "Creating ratio df for  AUC ,  Criteo - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  AUC ,  iPinYou - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Company_ - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Bing News - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Dianping - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AUC ,  Amazon - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AUC ,  MovieLens 20M - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  AUC ,  WeChat - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  UBI-Fights - Abnormal Event Detection In Video benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  UBI-Fights - Semi-supervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  UCSD - Abnormal Event Detection In Video benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Book-Crossing - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  MovieLens 1M - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Avazu - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  KDD12 - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Last.FM - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Children\\'s Book Test Common noun - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  ECG5000 - Unsupervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Huawei App Store - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Avito - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Census - Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Kaggle-Credit Card Fraud Dataset - Fraud Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Thyroid - Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  NB15-Backdoor - Network Intrusion Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  49\n",
      "####### Log\\\\ Loss\n",
      "Creating ratio df for  Log\\\\ Loss ,  Criteo - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Log\\\\ Loss ,  Company_ - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Log\\\\ Loss ,  Bing News - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Log\\\\ Loss ,  Dianping - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Log\\\\ Loss ,  MovieLens 1M - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Log\\\\ Loss ,  KDD12 - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Log\\\\ Loss ,  Huawei App Store - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Log\\\\ Loss ,  Avito - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  17\n",
      "####### Percentage\\\\ correct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Percentage\\\\ correct ,  Metamath set.mm - Automated Theorem Proving benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Percentage\\\\ correct ,  HOList benchmark - Automated Theorem Proving benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Percentage\\\\ correct ,  CoqGym - Automated Theorem Proving benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Perplexity\n",
      "Creating ratio df for  Perplexity ,  allrecipes.com - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Perplexity ,  Now You\\'re Cooking! - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### BLEU\n",
      "Creating ratio df for  BLEU ,  allrecipes.com - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\n",
      "Creating ratio df for  MAE ,  QM9 - Formation Energy benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  Epinions - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  Materials Project - Formation Energy benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  OQMD v1.2 - Formation Energy benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  7\n",
      "####### Classification\\\\ Accuracy\n",
      "Creating ratio df for  Classification\\\\ Accuracy ,  HolStep (Unconditional) - Automated Theorem Proving benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Classification\\\\ Accuracy ,  HolStep (Conditional) - Automated Theorem Proving benchmarking , ds_count= 1\n",
      "null\n",
      "####### nDCG\\\\-at\\\\-10\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  MovieLens 1M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  MovieLens 20M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Netflix - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Amazon Beauty - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Amazon Games - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Steam - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Ciao - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Amazon C&A - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Flixster - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Declicious - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Book-Crossing - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Tradesy - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Pinterest - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  GoodReads-Children - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Amazon-CDs - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Amazon-Book - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  GoodReads-Comics - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  DBbook2014 - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Last.FM - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  24\n",
      "####### Recall\\\\-at\\\\-50\n",
      "Creating ratio df for  Recall\\\\-at\\\\-50 ,  Million Song Dataset - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Recall\\\\-at\\\\-50 ,  MovieLens 20M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Recall\\\\-at\\\\-50 ,  Netflix - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Recall\\\\-at\\\\-50 ,  Dianping-Food - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-50 ,  Book-Crossing - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-50 ,  Last.FM - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  17\n",
      "####### Recall\\\\-at\\\\-100\n",
      "Creating ratio df for  Recall\\\\-at\\\\-100 ,  MovieLens 20M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-100 ,  Million Song Dataset - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-100 ,  Dianping-Food - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-100 ,  Last.FM - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-100 ,  Book-Crossing - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### HR\\\\-at\\\\-10\n",
      "Creating ratio df for  HR\\\\-at\\\\-10 ,  MovieLens 1M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  HR\\\\-at\\\\-10 ,  MovieLens 20M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  HR\\\\-at\\\\-10 ,  Netflix - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  HR\\\\-at\\\\-10 ,  DBbook2014 - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  HR\\\\-at\\\\-10 ,  Last.FM - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### P\\\\-at\\\\-10\n",
      "Creating ratio df for  P\\\\-at\\\\-10 ,  WeChat - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Valence\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Valence\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Arousal\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Arousal\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(Expectancy\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Expectancy\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Power\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Power\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Weighted\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  8\n",
      "####### UA\n",
      "Creating ratio df for  UA ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  UA ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Macro\\\\-F1\n",
      "Creating ratio df for  Macro\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Decidability\n",
      "Creating ratio df for  Decidability ,  UBI-Fights - Abnormal Event Detection In Video benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Decidability ,  UBI-Fights - Semi-supervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Time\\\\ \\\\(ms\\\\)\n",
      "Creating ratio df for  Time\\\\ \\\\(ms\\\\) ,  Non-Linear Elasticity Benchmark - Stress-Strain Relation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### nDCG\\\\-at\\\\-100\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-100 ,  MovieLens 20M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-100 ,  Netflix - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-100 ,  Million Song Dataset - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  10\n",
      "####### Recall\\\\-at\\\\-20\n",
      "Creating ratio df for  Recall\\\\-at\\\\-20 ,  MovieLens 20M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Recall\\\\-at\\\\-20 ,  Million Song Dataset - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Recall\\\\-at\\\\-20 ,  Netflix - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Recall\\\\-at\\\\-20 ,  Douban - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-20 ,  Yelp - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-20 ,  Delicious - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  14\n",
      "####### v2v\\\\ error\n",
      "Creating ratio df for  v2v\\\\ error ,  Expressive hands and faces dataset (EHF). - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### F1\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  Recipe1M - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Last.FM - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  MovieLens 20M - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Book-Crossing - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Hit\\\\-at\\\\-10\n",
      "Creating ratio df for  Hit\\\\-at\\\\-10 ,  Amazon Games - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hit\\\\-at\\\\-10 ,  Steam - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hit\\\\-at\\\\-10 ,  Amazon Beauty - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### LogLoss\n",
      "Creating ratio df for  LogLoss ,  Avazu - Click-Through Rate Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ IoU\n",
      "Creating ratio df for  Mean\\\\ IoU ,  Recipe1M - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### All\n",
      "Creating ratio df for  All ,  ImageNet - Neural Network Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ADE\\\\-8/12\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  ActEV - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  ETH/UCY - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  ActEV - Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  Hotel BIWI Walking Pedestrians dataset - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### FDE\\\\-8/12\n",
      "Creating ratio df for  FDE\\\\-8/12 ,  ActEV - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NDCG\n",
      "Creating ratio df for  NDCG ,  DBbook2014 - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NDCG ,  MovieLens 1M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NDCG ,  Delicious - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NDCG ,  Douban - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NDCG ,  Yelp - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Recall\\\\-at\\\\-10\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  MovieLens-Latest - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Netflix - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Epinions-Extend - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Frappe - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Last.FM-360k - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Echonest - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  CiteULike - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Amazon-Book - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Last.FM - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Dianping-Food - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  MovieLens 20M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Book-Crossing - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  GoodReads-Children - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  GoodReads-Comics - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Amazon-CDs - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  15\n",
      "####### mAP\\\\-at\\\\-10\n",
      "Creating ratio df for  mAP\\\\-at\\\\-10 ,  Echonest - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-10 ,  CiteULike - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-10 ,  Frappe - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-10 ,  MovieLens-Latest - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-10 ,  Netflix - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-10 ,  Epinions-Extend - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-10 ,  Amazon-Book - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-10 ,  Last.FM-360k - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### AUC\\\\ \\\\(outlier\\\\ ratio\\\\ =\\\\ 0\\\\.5\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(outlier\\\\ ratio\\\\ =\\\\ 0\\\\.5\\\\) ,  Fashion-MNIST - Unsupervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC\\\\ \\\\(outlier\\\\ ratio\\\\ =\\\\ 0\\\\.5\\\\) ,  Caltech-101 - Unsupervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC\\\\ \\\\(outlier\\\\ ratio\\\\ =\\\\ 0\\\\.5\\\\) ,  20NEWS - Unsupervised Anomaly Detection benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC\\\\ \\\\(outlier\\\\ ratio\\\\ =\\\\ 0\\\\.5\\\\) ,  Reuters-21578 - Unsupervised Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Micro\\\\-F1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  EC - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Micro\\\\-F1 ,  DailyDialog - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Error\\\\ rate\n",
      "Creating ratio df for  Error\\\\ rate ,  ContactDB - Grasp Contact Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### FDE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\)\n",
      "Creating ratio df for  FDE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\) ,  Stanford Drone - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ADE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\)\n",
      "Creating ratio df for  ADE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\) ,  Stanford Drone - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AUROC\n",
      "Creating ratio df for  AUROC ,  UCI Epileptic Seizure Recognition - Synthetic Data Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUROC ,  One-class ImageNet-30 - Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUROC ,  One-class CIFAR-10 - Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Recall\\\\-at\\\\-2\n",
      "Creating ratio df for  Recall\\\\-at\\\\-2 ,  Dianping-Food - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-2 ,  MovieLens 20M - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-2 ,  Last.FM - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall\\\\-at\\\\-2 ,  Book-Crossing - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Hits\\\\-at\\\\-10\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  Ciao - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  Amazon C&A - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  Flixster - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  Tradesy - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  Declicious - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  Pinterest - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  Book-Crossing - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Hits\\\\-at\\\\-20\n",
      "Creating ratio df for  Hits\\\\-at\\\\-20 ,  Ciao - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-20 ,  Amazon C&A - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-20 ,  Flixster - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-20 ,  Declicious - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-20 ,  Book-Crossing - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-20 ,  Tradesy - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-20 ,  Pinterest - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### nDCG\\\\-at\\\\-20\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  Ciao - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  Amazon C&A - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  Flixster - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  Tradesy - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  Pinterest - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  Declicious - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  Book-Crossing - Recommendation Systems benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### BPE\\\\ Perplexity\n",
      "Creating ratio df for  BPE\\\\ Perplexity ,  Food.com - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Rouge\\\\-L\n",
      "Creating ratio df for  Rouge\\\\-L ,  Food.com - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### BLEU\\\\-1\n",
      "Creating ratio df for  BLEU\\\\-1 ,  Food.com - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### BLEU\\\\-4\n",
      "Creating ratio df for  BLEU\\\\-4 ,  Food.com - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### D\\\\-1\n",
      "Creating ratio df for  D\\\\-1 ,  Food.com - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### D\\\\-2\n",
      "Creating ratio df for  D\\\\-2 ,  Food.com - Recipe Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Weighted\\\\ Macro\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\ Macro\\\\-F1 ,  EmoryNLP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ADE\n",
      "Creating ratio df for  ADE ,  Citywalks - Multiple Object Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AIOU\n",
      "Creating ratio df for  AIOU ,  Citywalks - Multiple Object Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Precision\n",
      "Creating ratio df for  Average\\\\ Precision ,  Census - Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Precision ,  Thyroid - Anomaly Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Precision ,  Kaggle-Credit Card Fraud Dataset - Fraud Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Precision ,  NB15-Backdoor - Network Intrusion Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Size\\\\ \\\\(MB\\\\)\n",
      "Creating ratio df for  Size\\\\ \\\\(MB\\\\) ,  CIFAR-10 - Neural Network Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Anomaly Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Anomaly Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-10",
          "2017-06",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "Anomaly Detection",
          "Anomaly Detection",
          "Anomaly Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Automated Theorem Proving",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Automated Theorem Proving",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-04",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Automated Theorem Proving",
          "Automated Theorem Proving"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Click-Through Rate Prediction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Click-Through Rate Prediction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-03",
          "2017-06",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Click-Through Rate Prediction",
          "Click-Through Rate Prediction",
          "Click-Through Rate Prediction",
          "Click-Through Rate Prediction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Emotion Recognition in Conversation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Emotion Recognition in Conversation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-06",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-08",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Formation Energy",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Formation Energy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Formation Energy",
          "Formation Energy"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Recommendation Systems",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Recommendation Systems",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-11",
          "2016-05",
          "2017-07",
          "2018-02",
          "2018-09",
          "2019-03",
          "2019-11",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Robotic Grasping",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Robotic Grasping",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-12",
          "2016-11",
          "2018-10"
         ],
         "xaxis": "x",
         "y": [
          "Robotic Grasping",
          "Robotic Grasping",
          "Robotic Grasping"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Anomaly Detection<BR>task: Anomaly Detection<BR>date: 2015-10<BR>ratio: 0.46",
          "Anomaly Detection<BR>task: Anomaly Detection<BR>date: 2017-06<BR>ratio: 0.08",
          "Anomaly Detection<BR>task: Anomaly Detection<BR>date: 2019-06<BR>ratio: 0.33",
          "Automated Theorem Proving<BR>task: Automated Theorem Proving<BR>date: 2019-04<BR>ratio: 0.39",
          "Automated Theorem Proving<BR>task: Automated Theorem Proving<BR>date: 2019-05<BR>ratio: 0.22",
          "Click-Through Rate Prediction<BR>task: Click-Through Rate Prediction<BR>date: 2016-11<BR>ratio: 0.01",
          "Click-Through Rate Prediction<BR>task: Click-Through Rate Prediction<BR>date: 2017-03<BR>ratio: 0.0",
          "Click-Through Rate Prediction<BR>task: Click-Through Rate Prediction<BR>date: 2017-06<BR>ratio: 0.0",
          "Click-Through Rate Prediction<BR>task: Click-Through Rate Prediction<BR>date: 2019-08<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-06<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-10<BR>ratio: 0.04",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-11<BR>ratio: 0.05",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-04<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-08<BR>ratio: 0.03",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-09<BR>ratio: 0.0",
          "Formation Energy<BR>task: Formation Energy<BR>date: 2018-11<BR>ratio: 0.22",
          "Formation Energy<BR>task: Formation Energy<BR>date: 2019-05<BR>ratio: 0.33",
          "Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2015-11<BR>ratio: 0.0",
          "Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2016-05<BR>ratio: 0.0",
          "Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2017-07<BR>ratio: 0.12",
          "Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2018-02<BR>ratio: 0.45",
          "Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2018-09<BR>ratio: 0.0",
          "Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2019-03<BR>ratio: 0.0",
          "Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2019-11<BR>ratio: 0.0",
          "Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2019-12<BR>ratio: 0.0",
          "Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2014-12<BR>ratio: 0.29",
          "Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2016-11<BR>ratio: 0.01",
          "Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2018-10<BR>ratio: 0.07"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.46,
           0.08,
           0.33,
           0.39,
           0.22,
           0.01,
           0,
           0,
           0,
           0,
           0.04,
           0.05,
           0,
           0.03,
           0,
           0.22,
           0.33,
           0,
           0,
           0.12,
           0.45,
           0,
           0,
           0,
           0,
           0.29,
           0.01,
           0.07
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2015-10",
          "2017-06",
          "2019-06",
          "2019-04",
          "2019-05",
          "2016-11",
          "2017-03",
          "2017-06",
          "2019-08",
          "2018-06",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-08",
          "2019-09",
          "2018-11",
          "2019-05",
          "2015-11",
          "2016-05",
          "2017-07",
          "2018-02",
          "2018-09",
          "2019-03",
          "2019-11",
          "2019-12",
          "2014-12",
          "2016-11",
          "2018-10"
         ],
         "y": [
          "Anomaly Detection",
          "Anomaly Detection",
          "Anomaly Detection",
          "Automated Theorem Proving",
          "Automated Theorem Proving",
          "Click-Through Rate Prediction",
          "Click-Through Rate Prediction",
          "Click-Through Rate Prediction",
          "Click-Through Rate Prediction",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Formation Energy",
          "Formation Energy",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Recommendation Systems",
          "Robotic Grasping",
          "Robotic Grasping",
          "Robotic Grasping"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Robotic Grasping",
          "Recommendation Systems",
          "Formation Energy",
          "Emotion Recognition in Conversation",
          "Click-Through Rate Prediction",
          "Automated Theorem Proving",
          "Anomaly Detection"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00113: Miscellaneous process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"751798e4-5a5f-4cc6-9d9a-9a5307f53040\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"751798e4-5a5f-4cc6-9d9a-9a5307f53040\")) {                    Plotly.newPlot(                        \"751798e4-5a5f-4cc6-9d9a-9a5307f53040\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Anomaly Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Anomaly Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-10\", \"2017-06\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"Anomaly Detection\", \"Anomaly Detection\", \"Anomaly Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Automated Theorem Proving\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Automated Theorem Proving\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-04\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Automated Theorem Proving\", \"Automated Theorem Proving\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Click-Through Rate Prediction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Click-Through Rate Prediction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-03\", \"2017-06\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Click-Through Rate Prediction\", \"Click-Through Rate Prediction\", \"Click-Through Rate Prediction\", \"Click-Through Rate Prediction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Emotion Recognition in Conversation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Emotion Recognition in Conversation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-06\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-08\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Formation Energy\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Formation Energy\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Formation Energy\", \"Formation Energy\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Recommendation Systems\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Recommendation Systems\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-11\", \"2016-05\", \"2017-07\", \"2018-02\", \"2018-09\", \"2019-03\", \"2019-11\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Robotic Grasping\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Robotic Grasping\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-12\", \"2016-11\", \"2018-10\"], \"xaxis\": \"x\", \"y\": [\"Robotic Grasping\", \"Robotic Grasping\", \"Robotic Grasping\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Anomaly Detection<BR>task: Anomaly Detection<BR>date: 2015-10<BR>ratio: 0.46\", \"Anomaly Detection<BR>task: Anomaly Detection<BR>date: 2017-06<BR>ratio: 0.08\", \"Anomaly Detection<BR>task: Anomaly Detection<BR>date: 2019-06<BR>ratio: 0.33\", \"Automated Theorem Proving<BR>task: Automated Theorem Proving<BR>date: 2019-04<BR>ratio: 0.39\", \"Automated Theorem Proving<BR>task: Automated Theorem Proving<BR>date: 2019-05<BR>ratio: 0.22\", \"Click-Through Rate Prediction<BR>task: Click-Through Rate Prediction<BR>date: 2016-11<BR>ratio: 0.01\", \"Click-Through Rate Prediction<BR>task: Click-Through Rate Prediction<BR>date: 2017-03<BR>ratio: 0.0\", \"Click-Through Rate Prediction<BR>task: Click-Through Rate Prediction<BR>date: 2017-06<BR>ratio: 0.0\", \"Click-Through Rate Prediction<BR>task: Click-Through Rate Prediction<BR>date: 2019-08<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-06<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-10<BR>ratio: 0.04\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-11<BR>ratio: 0.05\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-04<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-08<BR>ratio: 0.03\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-09<BR>ratio: 0.0\", \"Formation Energy<BR>task: Formation Energy<BR>date: 2018-11<BR>ratio: 0.22\", \"Formation Energy<BR>task: Formation Energy<BR>date: 2019-05<BR>ratio: 0.33\", \"Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2015-11<BR>ratio: 0.0\", \"Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2016-05<BR>ratio: 0.0\", \"Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2017-07<BR>ratio: 0.12\", \"Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2018-02<BR>ratio: 0.45\", \"Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2018-09<BR>ratio: 0.0\", \"Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2019-03<BR>ratio: 0.0\", \"Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2019-11<BR>ratio: 0.0\", \"Recommendation Systems<BR>task: Recommendation Systems<BR>date: 2019-12<BR>ratio: 0.0\", \"Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2014-12<BR>ratio: 0.29\", \"Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2016-11<BR>ratio: 0.01\", \"Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2018-10<BR>ratio: 0.07\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.46, 0.08, 0.33, 0.39, 0.22, 0.01, 0.0, 0.0, 0.0, 0.0, 0.04, 0.05, 0.0, 0.03, 0.0, 0.22, 0.33, 0.0, 0.0, 0.12, 0.45, 0.0, 0.0, 0.0, 0.0, 0.29, 0.01, 0.07], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2015-10\", \"2017-06\", \"2019-06\", \"2019-04\", \"2019-05\", \"2016-11\", \"2017-03\", \"2017-06\", \"2019-08\", \"2018-06\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-08\", \"2019-09\", \"2018-11\", \"2019-05\", \"2015-11\", \"2016-05\", \"2017-07\", \"2018-02\", \"2018-09\", \"2019-03\", \"2019-11\", \"2019-12\", \"2014-12\", \"2016-11\", \"2018-10\"], \"y\": [\"Anomaly Detection\", \"Anomaly Detection\", \"Anomaly Detection\", \"Automated Theorem Proving\", \"Automated Theorem Proving\", \"Click-Through Rate Prediction\", \"Click-Through Rate Prediction\", \"Click-Through Rate Prediction\", \"Click-Through Rate Prediction\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Formation Energy\", \"Formation Energy\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Recommendation Systems\", \"Robotic Grasping\", \"Robotic Grasping\", \"Robotic Grasping\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Robotic Grasping\", \"Recommendation Systems\", \"Formation Energy\", \"Emotion Recognition in Conversation\", \"Click-Through Rate Prediction\", \"Automated Theorem Proving\", \"Anomaly Detection\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00113: Miscellaneous process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('751798e4-5a5f-4cc6-9d9a-9a5307f53040');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00115\n",
      "Number of metrics:  164\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  UWA3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  CAD-120 - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Office-Home - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  ImageNet - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Olympic-to-HMDBsmall - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  HMDBsmall-to-UCF - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  UCF-to-Olympic - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  UCF-to-HMDBsmall - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  UT-Kinect - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Florence 3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  DogCentric - Activity Recognition In Videos benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Office-Home - Multi-target Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Office-31 - Multi-target Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Office-Home - Transfer Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  UCF-to-HMDBfull - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  CUB-200 - 0-Shot Learning - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CUB 200 50-way (0-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Synth Digits-to-SVHN - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Synth Signs-to-GTSRB - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  SVNH-to-MNIST - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  SYNSIG-to-GTSRB - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MNIST-to-MNIST-M - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  ImageCLEF-DA - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  MNIST - One-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MNIST - Unsupervised MNIST benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  AWA - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SUN - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Flowers-102 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  HMDBfull-to-UCF - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  VisDA2017 - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 5-Shot, 20-way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 5-Shot, 5-way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 1-Shot, 20-way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 1-Shot, 5-way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  Meta-Dataset - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Stanford Dogs 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Stanford Cars 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Stanford Cars 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-ImageNet-CUB 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Gaming 3D (G3D) - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  SBU - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ECG5000 - Outlier Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Volleyball - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  BPI challenge \\'12 - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Helpdesk - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SYSU 3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  SVHN-to-MNIST - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  MNIST-to-USPS - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  Tiered ImageNet 10-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Tiered ImageNet 10-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 10-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 10-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 5-way (10-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Kinetics-Skeleton dataset - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  USPS-to-MNIST - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 20-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-Imagenet 20-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  CUB 200 5-way 5-shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  CUB 200 5-way 1-shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  CIFAR-FS 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  IRD - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ICVL-4 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  N-UCLA - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Caltech-256 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  CIFAR100 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "Creating ratio df for  Accuracy ,  FC100 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  FC100 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-ImageNet - 1-Shot Learning - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  ImageNet - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  Potsdam-3 - Unsupervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  COCO-Stuff-15 - Unsupervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Potsdam - Unsupervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  COCO-Stuff-3 - Unsupervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  BDD100K - Steering Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Tiered ImageNet 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Tiered ImageNet 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  FC100 5-way (10-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Diving-48 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  UTD-MHAD - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Mice Protein - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ISOLET - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Coil-20 - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MNIST - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Fashion-MNIST - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Activity - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 5-Shot, 1000 way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 1-Shot, 423 way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 5-Shot, 423 way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  OMNIGLOT - 1-Shot, 1000 way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Stanford Dogs 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Office-Home - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  CIFAR-FS 5-way (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Mini-ImageNet-CUB 5-way (5-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  miniSports - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  AWA2 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  AWA1 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  aPY - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10 - Network Pruning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-100 - Network Pruning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ImageNet - Network Pruning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MSR Action3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  UPenn Action - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-100 ResNet-18 - 200 Epochs - Stochastic Optimization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10 ResNet-18 - 200 Epochs - Stochastic Optimization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  UCF --> HMDB (full) - Domain Adaptation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  HMDB --> UCF (full) - Domain Adaptation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  mini-ImageNet - 100-Way - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Mini-ImageNet to CUB - 5 shot learning - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  186\n",
      "####### 3\\\\-fold\\\\ Accuracy\n",
      "Creating ratio df for  3\\\\-fold\\\\ Accuracy ,  UCF101 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  3\\\\-fold\\\\ Accuracy ,  UCF101 - Self-Supervised Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  12\n",
      "####### Top\\\\-1\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  CUB-200-2011 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  Something-Something V2 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  Something-Something V1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  HMDB51 - Self-Supervised Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  EPIC-KITCHENS-55 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Accuracy ,  EgoGesture - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### 10\\\\-20%\\\\ Mask\\\\ PSNR\n",
      "Creating ratio df for  10\\\\-20%\\\\ Mask\\\\ PSNR ,  200k Short Texts for Humor Detection - Latent Variable Models benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ accuracy\\\\ of\\\\ 3\\\\ splits\n",
      "Creating ratio df for  Average\\\\ accuracy\\\\ of\\\\ 3\\\\ splits ,  HMDB-51 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Average\\\\ accuracy\\\\ of\\\\ 3\\\\ splits ,  JHMDB (2D poses only) - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  7\n",
      "####### Video\\\\ hit\\\\-at\\\\-1\n",
      "Creating ratio df for  Video\\\\ hit\\\\-at\\\\-1 ,  Sports-1M - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Video\\\\ hit\\\\-at\\\\-1 ,  miniSports - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Video\\\\ hit\\\\-at\\\\-5\n",
      "Creating ratio df for  Video\\\\ hit\\\\-at\\\\-5 ,  Sports-1M - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Video\\\\ hit\\\\-at\\\\-5 ,  miniSports - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Clip\\\\ Hit\\\\-at\\\\-1\n",
      "Creating ratio df for  Clip\\\\ Hit\\\\-at\\\\-1 ,  Sports-1M - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Clip\\\\ Hit\\\\-at\\\\-1 ,  miniSports - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(CV\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\) ,  NTU RGB+D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\) ,  NTU RGB+D - Action Recognition benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "####### Accuracy\\\\ \\\\(CS\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CS\\\\) ,  NTU RGB+D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CS\\\\) ,  NTU RGB+D - Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CS\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Average\\\\ Accuracy\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  VIRAT Ground 2.0 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Office-Caltech - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Office-31 - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  ScanNet - Scene Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Glass identification - Outlier Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Balance scale_class 1 - Outlier Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Ionosphere_class b - Outlier Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Breast cancer Wisconsin_class 2 - Outlier Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  Breast cancer Wisconsin_class 4 - Outlier Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  UAV-Human - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  OMNIGLOT - Multi-Task Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  19\n",
      "####### Mean\\\\ IoU\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2012 test - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SkyScapes-Lane - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SkyScapes-Dense - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SUN-RGBD - Scene Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  CamVid - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2012 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2011 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  NYU Depth v2 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  S3DIS - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Mean\\\\ IoU ,  ShapeNet - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2007 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SUN-RGBD - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  ScanNetV2 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  Freiburg Forest - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ IoU ,  SYNTHIA-CVPRâ€™16 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2012 val - Weakly-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PASCAL VOC 2012 test - Weakly-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  S3DIS Area5 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  FSS-1000 - Few-Shot Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  45\n",
      "####### mIoU\n",
      "Creating ratio df for  mIoU ,  PASCAL Context - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  mIoU ,  COCO-Stuff test - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  Cityscapes test - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  mIoU ,  CamVid - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  mIoU ,  Kvasir-Instrument - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  Cityscapes val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  Semantic3D - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  PASCAL VOC 2012 val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  ADE20K val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  mIoU ,  S3DIS Area5 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  SemanticKITTI - 3D Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  mIoU ,  NYU Depth v2 - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mIoU ,  LIP val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mIoU ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mIoU ,  Cityscapes test - Multi-Task Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  SYNTHIA-to-Cityscapes - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mIoU ,  ParisLille3D - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  S3DIS - 3D Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  Mapillary val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  Cityscapes val - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  BDD - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  GTAV-to-Cityscapes Labels - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  COCO-Stuff - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  85\n",
      "####### Validation\\\\ mIoU\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  ADE20K - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Pascal VOC 2012 5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Pascal VOC 2012 2% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 12.5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 50% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 25% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Pascal VOC 2012 12.5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  PASCAL Context 25% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 2% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  PASCAL Context 12.5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Validation\\\\ mIoU ,  Cityscapes 5% labeled - Semi-Supervised Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  23\n",
      "####### Accuracy\\\\ \\\\(RGB\\\\+pose\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(RGB\\\\+pose\\\\) ,  J-HMDB - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Time\\\\ \\\\(ms\\\\)\n",
      "Creating ratio df for  Time\\\\ \\\\(ms\\\\) ,  Cityscapes test - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Time\\\\ \\\\(ms\\\\) ,  CamVid - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  4\n",
      "####### Mean\\\\ IoU\\\\ \\\\(class\\\\)\n",
      "Creating ratio df for  Mean\\\\ IoU\\\\ \\\\(class\\\\) ,  Cityscapes test - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  Mean\\\\ IoU\\\\ \\\\(class\\\\) ,  KITTI Semantic Segmentation - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  13\n",
      "####### Frame\\\\ \\\\(fps\\\\)\n",
      "Creating ratio df for  Frame\\\\ \\\\(fps\\\\) ,  CamVid - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Frame\\\\ \\\\(fps\\\\) ,  Cityscapes test - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  10\n",
      "####### DSC\n",
      "Creating ratio df for  DSC ,  Kvasir-Instrument - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Recall\n",
      "Creating ratio df for  Recall ,  CrossTask - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### CR\n",
      "Creating ratio df for  CR ,  Google Dataset - Sentence Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### F1\n",
      "Creating ratio df for  F1 ,  Google Dataset - Sentence Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Global\\\\ Accuracy\n",
      "Creating ratio df for  Global\\\\ Accuracy ,  CamVid - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.4\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.4 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "number of sota per dataset/metric:  9\n",
      "####### mAP\\\\-at\\\\-0\\\\.5\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  THUMOS 2014 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  ActivityNet-1.3 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  Cityscapes to Foggy Cityscapes - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  ActivityNet-1.2 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  SIM10K to BDD100K - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.5 ,  THUMOSâ€™14 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  26\n",
      "####### mAP\\\\-at\\\\-0\\\\.1\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.1 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### mAP\\\\-at\\\\-0\\\\.2\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.2 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### mAP\\\\-at\\\\-0\\\\.3\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.3 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "number of sota per dataset/metric:  7\n",
      "####### mAP\\\\-at\\\\-0\\\\.4\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.4 ,  THUMOSâ€™14 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "number of sota per dataset/metric:  8\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.5\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.5 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.5 ,  ActivityNet-1.3 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.5 ,  ActivityNet-1.2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  14\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.1\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.1 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.1 ,  ActivityNet-1.2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.2\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.2 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.3\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.3 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.3 ,  ActivityNet-1.2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### Top\\\\-1\\\\ accuracy\\\\ %\n",
      "Creating ratio df for  Top\\\\-1\\\\ accuracy\\\\ % ,  ImageNet-A - Domain Generalization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Top\\\\-1\\\\ accuracy\\\\ % ,  MIT-States - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ accuracy\\\\ % ,  UT-Zappos - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Top\\\\-1\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  ImageNet-R - Domain Generalization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  ImageNet - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-1\\\\ Error\\\\ Rate ,  CIFAR-10 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  5\n",
      "####### mAP\n",
      "Creating ratio df for  mAP ,  ActivityNet - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mAP ,  MEXaction2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  PASCAL VOC 2007 - Multi-Label Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  PASCAL VOC 2012 - Multi-Label Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mAP ,  ActivityNet-1.3 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  Market to Duke - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  Duke to Market - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  Market to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  Duke to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  AVA v2.2 - Action Recognition benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP ,  ActEV - Activity Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  24\n",
      "####### Accuracy\\\\ \\\\(Cross\\\\-Subject\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Subject\\\\) ,  NTU RGB+D 120 - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Subject\\\\) ,  NTU RGB+D 120 - Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(Cross\\\\-Setup\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Setup\\\\) ,  NTU RGB+D 120 - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Setup\\\\) ,  NTU RGB+D 120 - Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(CV\\\\ I\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\ I\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Accuracy\\\\ \\\\(CV\\\\ II\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\ II\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(AV\\\\ I\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(AV\\\\ I\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(AV\\\\ II\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(AV\\\\ II\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Score\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Acrobot (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Acrobot - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Score ,  Inverted Pendulum (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Inverted Pendulum - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Mountain Car (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Ant + Gathering - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Acrobot (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Full Humanoid - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Mountain Car - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Score ,  Inverted Pendulum (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Swimmer - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Ant - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Double Inverted Pendulum - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  2D Walker - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Acrobot (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Simple Humanoid - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Hopper - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Mountain Car (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Mountain Car (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Inverted Pendulum (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Half-Cheetah - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Lunar Lander (OpenAI Gym) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Cart Pole (OpenAI Gym) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  10\n",
      "####### Frame\\\\-mAP\n",
      "Creating ratio df for  Frame\\\\-mAP ,  J-HMDB-21 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Frame\\\\-mAP ,  UCF101-24 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  8\n",
      "####### AP50\n",
      "Creating ratio df for  AP50 ,  CUB-200-2011 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP50 ,  Flowers-102 - 0-Shot - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### MSE\\\\ \\\\(10\\\\^\\\\-2,\\\\ 50%\\\\ missing\\\\)\n",
      "Creating ratio df for  MSE\\\\ \\\\(10\\\\^\\\\-2,\\\\ 50%\\\\ missing\\\\) ,  MuJoCo - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Average\\\\ Treatment\\\\ Effect\\\\ Error\n",
      "Creating ratio df for  Average\\\\ Treatment\\\\ Effect\\\\ Error ,  IDHP - Causal Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Mean\\\\ Rank\n",
      "Creating ratio df for  Mean\\\\ Rank ,  Meta-Dataset Rank - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Instance\\\\ Average\\\\ IoU\n",
      "Creating ratio df for  Instance\\\\ Average\\\\ IoU ,  ShapeNet-Part - 3D Part Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Mean\\\\ Angle\\\\ Error\n",
      "Creating ratio df for  Mean\\\\ Angle\\\\ Error ,  Synth Objects-to-LINEMOD - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Classification\\\\ Accuracy\n",
      "Creating ratio df for  Classification\\\\ Accuracy ,  Synth Objects-to-LINEMOD - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MSE\n",
      "Creating ratio df for  MSE ,  USHCN-Daily - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MSE ,  MIMIC-III - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### NegLL\n",
      "Creating ratio df for  NegLL ,  MIMIC-III - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### R\\\\-at\\\\-1\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  CUB-200-2011 - Metric Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  CARS196 - Metric Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  7\n",
      "####### Percentage\\\\ error\n",
      "Creating ratio df for  Percentage\\\\ error ,  CIFAR-10 Image Classification - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Params\n",
      "Creating ratio df for  Params ,  CIFAR-10 Image Classification - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Params ,  ImageNet - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  9\n",
      "####### Class\\\\ Average\\\\ IoU\n",
      "Creating ratio df for  Class\\\\ Average\\\\ IoU ,  ShapeNet-Part - 3D Part Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### mAcc\n",
      "Creating ratio df for  mAcc ,  S3DIS Area5 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAcc ,  S3DIS - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  mAcc ,  S3DIS - 3D Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### oAcc\n",
      "Creating ratio df for  oAcc ,  S3DIS - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  oAcc ,  S3DIS Area5 - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  oAcc ,  Semantic3D - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  7\n",
      "####### Test\\\\ Score\n",
      "Creating ratio df for  Test\\\\ Score ,  ADE20K - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Speed\\\\(ms/f\\\\)\n",
      "Creating ratio df for  Speed\\\\(ms/f\\\\) ,  NYU Depth v2 - Real-Time Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.1\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.1 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### PCK\\\\-at\\\\-0\\\\.2\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.2 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.3\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.3 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.4\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.4 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.5\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.5 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### 3DIoU\n",
      "Creating ratio df for  3DIoU ,  ScanNet - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  3DIoU ,  ScanNet - Scene Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.6\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.6 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.7\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.7 ,  THUMOSâ€™14 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.7 ,  ActivityNet-1.2 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### PQth\n",
      "Creating ratio df for  PQth ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  PQth ,  COCO test-dev - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  7\n",
      "####### PQ\n",
      "Creating ratio df for  PQ ,  Cityscapes test - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PQ ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PQ ,  Mapillary val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PQ ,  COCO test-dev - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PQ ,  Indian Driving Dataset - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PQ ,  KITTI Panoptic Segmentation - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PQ ,  COCO panoptic - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  21\n",
      "####### mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CV\\\\)\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CV\\\\) ,  PKU-MMD - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CS\\\\)\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CS\\\\) ,  PKU-MMD - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Log\\\\-likelihood\n",
      "Creating ratio df for  Log\\\\-likelihood ,  UCI POWER - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Log\\\\-likelihood ,  MNIST (Conditional) - Density Estimation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Log\\\\-likelihood ,  CIFAR-10 (Conditional) - Density Estimation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Log\\\\-likelihood ,  CIFAR-10 - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Log\\\\-likelihood ,  UCI MINIBOONE - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Log\\\\-likelihood ,  MNIST - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Log\\\\-likelihood ,  UCI HEPMASS - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Log\\\\-likelihood ,  BSDS300 - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Log\\\\-likelihood ,  UCI GAS - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  8\n",
      "####### mAP\\\\ \\\\(Val\\\\)\n",
      "Creating ratio df for  mAP\\\\ \\\\(Val\\\\) ,  AVA v2.1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Video\\\\-mAP\\\\ 0\\\\.5\n",
      "Creating ratio df for  Video\\\\-mAP\\\\ 0\\\\.5 ,  J-HMDB-21 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Video\\\\-mAP\\\\ 0\\\\.5 ,  UCF101-24 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Top\\\\-5\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\-5\\\\ Accuracy ,  Something-Something V2 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Top\\\\-5\\\\ Accuracy ,  ImageNet (1-shot) - Few-Shot Image Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Top\\\\-5\\\\ Accuracy ,  EgoGesture - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### AUC\\\\ \\\\(val\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(val\\\\) ,  ActivityNet-1.3 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### AUC\\\\ \\\\(test\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(test\\\\) ,  ActivityNet-1.3 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AR@100\n",
      "Creating ratio df for  AR@100 ,  ActivityNet-1.3 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AR@100 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Average\\\\ Recall\n",
      "Creating ratio df for  Average\\\\ Recall ,  EGTEA - Long-tail Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Precision\n",
      "Creating ratio df for  Average\\\\ Precision ,  EGTEA - Long-tail Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F\\\\-measure\\\\ \\\\(%\\\\)\n",
      "Creating ratio df for  F\\\\-measure\\\\ \\\\(%\\\\) ,  ActionNet-VE - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 10%\n",
      "Creating ratio df for  10% ,  J-HMBD Early Action - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### rank\\\\-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  rank\\\\-1 ,  Market to Duke - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-1 ,  Duke to Market - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-1 ,  Duke to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-1 ,  Market to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  12\n",
      "####### rank\\\\-5\n",
      "Creating ratio df for  rank\\\\-5 ,  Market to Duke - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-5 ,  Duke to Market - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-5 ,  Market to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  rank\\\\-5 ,  Duke to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  10\n",
      "####### rank\\\\-10\n",
      "Creating ratio df for  rank\\\\-10 ,  Duke to Market - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-10 ,  Market to Duke - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-10 ,  Duke to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  rank\\\\-10 ,  Market to MSMT - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  12\n",
      "####### Top\\\\ 1\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  Something-Something V1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  ImageNet ResNet-50 - 50 Epochs - Stochastic Optimization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  ImageNet ResNet-50 - 60 Epochs - Stochastic Optimization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  12\n",
      "####### Val\n",
      "Creating ratio df for  Val ,  Jester - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Top\\\\ 5\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  Something-Something V1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  ImageNet ResNet-50 - 50 Epochs - Stochastic Optimization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  ImageNet ResNet-50 - 60 Epochs - Stochastic Optimization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### mAP@0\\\\.1:0\\\\.7\n",
      "Creating ratio df for  mAP@0\\\\.1:0\\\\.7 ,  THUMOS 2014 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### PQst\n",
      "Creating ratio df for  PQst ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PQst ,  COCO test-dev - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  4\n",
      "####### AP\n",
      "Creating ratio df for  AP ,  Cityscapes val - Panoptic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Search\\\\ time\\\\ \\\\(s\\\\)\n",
      "Creating ratio df for  Search\\\\ time\\\\ \\\\(s\\\\) ,  NAS-Bench-201, ImageNet-16-120 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Search\\\\ time\\\\ \\\\(s\\\\) ,  NAS-Bench-201, CIFAR-100 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Search\\\\ time\\\\ \\\\(s\\\\) ,  NAS-Bench-201, CIFAR-10 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Accuracy\\\\ \\\\(Test\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\) ,  NAS-Bench-201, ImageNet-16-120 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\) ,  NAS-Bench-201, CIFAR-10 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\) ,  NAS-Bench-201, CIFAR-100 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Accuracy\\\\ \\\\(val\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(val\\\\) ,  NAS-Bench-201, ImageNet-16-120 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(val\\\\) ,  NAS-Bench-201, CIFAR-10 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Cumulative\\\\ regret\n",
      "Creating ratio df for  Cumulative\\\\ regret ,  Mushroom - Multi-Armed Bandits benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### IoU\\\\ \\\\[32\\\\ distractors\\\\]\n",
      "Creating ratio df for  IoU\\\\ \\\\[32\\\\ distractors\\\\] ,  Cluttered Omniglot - One-Shot Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### IoU\\\\ \\\\[4\\\\ distractors\\\\]\n",
      "Creating ratio df for  IoU\\\\ \\\\[4\\\\ distractors\\\\] ,  Cluttered Omniglot - One-Shot Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### IoU\\\\ \\\\[256\\\\ distractors\\\\]\n",
      "Creating ratio df for  IoU\\\\ \\\\[256\\\\ distractors\\\\] ,  Cluttered Omniglot - One-Shot Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.75\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.75 ,  ActivityNet-1.3 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mAP\\\\ IOU\\\\-at\\\\-0\\\\.95\n",
      "Creating ratio df for  mAP\\\\ IOU\\\\-at\\\\-0\\\\.95 ,  ActivityNet-1.3 - Temporal Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Accuracy\\\\ \\\\(%\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  Measles - Unsupervised Pre-training benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  Office-Caltech-10 - Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  Office-Home - Partial Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  Hendrycks Test - Multi-Task Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Sensitivity\\\\ \\\\(VEB\\\\)\n",
      "Creating ratio df for  Sensitivity\\\\ \\\\(VEB\\\\) ,  UCI measles - Unsupervised Pre-training benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Sensitivity\n",
      "Creating ratio df for  Sensitivity ,  UCI measles - Unsupervised Pre-training benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR@1000\n",
      "Creating ratio df for  AR@1000 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR@200\n",
      "Creating ratio df for  AR@200 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR@50\n",
      "Creating ratio df for  AR@50 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AR@500\n",
      "Creating ratio df for  AR@500 ,  THUMOS\\' 14 - Temporal Action Proposal Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mse\\\\ \\\\(10\\\\^\\\\-3\\\\)\n",
      "Creating ratio df for  mse\\\\ \\\\(10\\\\^\\\\-3\\\\) ,  PhysioNet Challenge 2012 - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MSE\\\\ stdev\n",
      "Creating ratio df for  MSE\\\\ stdev ,  PhysioNet Challenge 2012 - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MACs\n",
      "Creating ratio df for  MACs ,  ImageNet - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### NLL\n",
      "Creating ratio df for  NLL ,  CIFAR-10 - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NLL ,  UCI MINIBOONE - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NLL ,  BSDS300 - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  NLL ,  UCI HEPMASS - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NLL ,  UCI POWER - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  NLL ,  MNIST - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  NLL ,  Caltech-101 - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NLL ,  OMNIGLOT - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NLL ,  Freyfaces - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### Negative\\\\ ELBO\n",
      "Creating ratio df for  Negative\\\\ ELBO ,  Caltech-101 - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Negative\\\\ ELBO ,  Freyfaces - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Negative\\\\ ELBO ,  MNIST - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Negative\\\\ ELBO ,  OMNIGLOT - Density Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Error\n",
      "Creating ratio df for  Error ,  CelebA - Multi-Task Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\n",
      "Creating ratio df for  MAE ,  Comma.ai - Steering Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  Udacity - Steering Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Return\n",
      "Creating ratio df for  Return ,  DeepMind Walker Walk (Images) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Return ,  DeepMind Cup Catch (Images) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Return ,  DeepMind Cheetah Run (Images) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "####### mean\\\\ Corruption\\\\ Error\\\\ \\\\(mCE\\\\)\n",
      "Creating ratio df for  mean\\\\ Corruption\\\\ Error\\\\ \\\\(mCE\\\\) ,  ImageNet-C - Domain Generalization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### GFlops\n",
      "Creating ratio df for  GFlops ,  AVA v2.1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Params\\\\ \\\\(M\\\\)\n",
      "Creating ratio df for  Params\\\\ \\\\(M\\\\) ,  AVA v2.1 - Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Speed\\\\ \\\\ \\\\(FPS\\\\)\n",
      "Creating ratio df for  Speed\\\\ \\\\ \\\\(FPS\\\\) ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 14\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  2019_test set - Feature Engineering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### 28\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  28\\\\ gestures\\\\ accuracy ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Pixel\\\\ Accuracy\n",
      "Creating ratio df for  Pixel\\\\ Accuracy ,  ADE20K val - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### All\n",
      "Creating ratio df for  All ,  ImageNet - Neural Network Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAP\n",
      "Creating ratio df for  MAP ,  CIFAR-10 - Quantization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Search\\\\ Time\\\\ \\\\(GPU\\\\ days\\\\)\n",
      "Creating ratio df for  Search\\\\ Time\\\\ \\\\(GPU\\\\ days\\\\) ,  CIFAR-10 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### 4\n",
      "Creating ratio df for  4 ,  4 - 4D Spatio Temporal Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mIOU\n",
      "Creating ratio df for  mIOU ,  Paris-Lille-3D - LIDAR Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\(10\\\\-fold\\\\)\n",
      "Creating ratio df for  Accuracy\\\\(10\\\\-fold\\\\) ,  Glass identification - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy\\\\(10\\\\-fold\\\\) ,  Zoo - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### AP\\\\-at\\\\-0\\\\.7\n",
      "Creating ratio df for  AP\\\\-at\\\\-0\\\\.7 ,  PreSIL to KITTI - Unsupervised Domain Adaptation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### GFLOPs\n",
      "Creating ratio df for  GFLOPs ,  CIFAR-100 - Network Pruning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  GFLOPs ,  ImageNet - Network Pruning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  GFLOPs ,  CIFAR-10 - Network Pruning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### nDCG\\\\-at\\\\-5\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### nDCG\\\\-at\\\\-3\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  6\n",
      "####### P\\\\-at\\\\-1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### P\\\\-at\\\\-5\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### P\\\\-at\\\\-3\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  6\n",
      "####### RP\\\\-at\\\\-5\n",
      "Creating ratio df for  RP\\\\-at\\\\-5 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Micro\\\\ F1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### nDCG\\\\-at\\\\-1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-1 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Per\\\\-Class\\\\ Accuracy\n",
      "Creating ratio df for  Average\\\\ Per\\\\-Class\\\\ Accuracy ,  CUB-200 - 0-Shot Learning - Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### No\\\\.\\\\ parameters\n",
      "Creating ratio df for  No\\\\.\\\\ parameters ,  JHMDB (2D poses only) - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  No\\\\.\\\\ parameters ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ mAP\n",
      "Creating ratio df for  Mean\\\\ mAP ,  ActivityNet-1.2 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### final\\\\ agent\\\\ reward\n",
      "Creating ratio df for  final\\\\ agent\\\\ reward ,  ParticleEnvs Cooperative Communication - Multi-Agent Reinforcement Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "####### Accuracy\\\\ \\\\(Val\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Val\\\\) ,  NAS-Bench-201, CIFAR-100 - Neural Architecture Search benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mAP@0\\\\.1:0\\\\.5\n",
      "Creating ratio df for  mAP@0\\\\.1:0\\\\.5 ,  THUMOS 2014 - Weakly Supervised Action Localization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Category\\\\ mIoU\n",
      "Creating ratio df for  Category\\\\ mIoU ,  Cityscapes test - Semantic Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Inference\\\\ Time\\\\ \\\\(ms\\\\)\n",
      "Creating ratio df for  Inference\\\\ Time\\\\ \\\\(ms\\\\) ,  CIFAR-10 - Network Pruning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Size\\\\ \\\\(MB\\\\)\n",
      "Creating ratio df for  Size\\\\ \\\\(MB\\\\) ,  CIFAR-10 - Neural Network Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Micro\\\\-F1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  Slashdot - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  Reuters-21578 - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  RCV1-v2 - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Sparsity\n",
      "Creating ratio df for  Sparsity ,  ImageNet32 - Sparse Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Sparsity ,  CINIC-10 - Sparse Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Acc\n",
      "Creating ratio df for  Acc ,  Mini-ImageNet - 1-Shot Learning - Few-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Test\\\\ AUC\\\\ top\\\\ 1\n",
      "Creating ratio df for  Test\\\\ AUC\\\\ top\\\\ 1 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Test\\\\ AUC\\\\ top\\\\ 2\n",
      "Creating ratio df for  Test\\\\ AUC\\\\ top\\\\ 2 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Test\\\\ AUC\\\\ top\\\\ 3\n",
      "Creating ratio df for  Test\\\\ AUC\\\\ top\\\\ 3 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Val\\\\ AUC\\\\ top\\\\ 1\n",
      "Creating ratio df for  Val\\\\ AUC\\\\ top\\\\ 1 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Val\\\\ AUC\\\\ top\\\\ 2\n",
      "Creating ratio df for  Val\\\\ AUC\\\\ top\\\\ 2 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Val\\\\ AUC\\\\ top\\\\ 3\n",
      "Creating ratio df for  Val\\\\ AUC\\\\ top\\\\ 3 ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Top\\\\-2\\\\ accuracy\\\\ %\n",
      "Creating ratio df for  Top\\\\-2\\\\ accuracy\\\\ % ,  MIT-States - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-2\\\\ accuracy\\\\ % ,  UT-Zappos - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Top\\\\-3\\\\ accuracy\\\\ %\n",
      "Creating ratio df for  Top\\\\-3\\\\ accuracy\\\\ % ,  UT-Zappos - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Top\\\\-3\\\\ accuracy\\\\ % ,  MIT-States - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Seen\\\\ accuracy\n",
      "Creating ratio df for  Seen\\\\ accuracy ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Unseen\\\\ accuracy\n",
      "Creating ratio df for  Unseen\\\\ accuracy ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### H\\\\-Mean\n",
      "Creating ratio df for  H\\\\-Mean ,  MIT-States, generalized split - Compositional Zero-Shot Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Part Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Part Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2017-06",
          "2017-11",
          "2018-01",
          "2019-04",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "3D Semantic Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "3D Semantic Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2017-06",
          "2017-10",
          "2018-07",
          "2018-09",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Action Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Action Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2012-12",
          "2014-12",
          "2015-03",
          "2015-05",
          "2015-12",
          "2016-01",
          "2016-04",
          "2016-08",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-11",
          "2018-01",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2018-12",
          "2019-01",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Activity Recognition In Videos",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Activity Recognition In Videos",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-12",
          "2015-05",
          "2016-05"
         ],
         "xaxis": "x",
         "y": [
          "Activity Recognition In Videos",
          "Activity Recognition In Videos",
          "Activity Recognition In Videos"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Domain Adaptation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Domain Adaptation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-05",
          "2016-08",
          "2017-04",
          "2017-05",
          "2017-11",
          "2017-12",
          "2018-07",
          "2018-11",
          "2019-01",
          "2019-03",
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Domain Generalization",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Domain Generalization",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08",
          "2017-10",
          "2019-03",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Domain Generalization",
          "Domain Generalization",
          "Domain Generalization",
          "Domain Generalization"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Few-Shot Image Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Few-Shot Image Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2013-06",
          "2016-03",
          "2017-03",
          "2017-11",
          "2018-06",
          "2018-10",
          "2019-03",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Metric Learning",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Metric Learning",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-06",
          "2018-04",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Metric Learning",
          "Metric Learning",
          "Metric Learning",
          "Metric Learning"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Neural Architecture Search",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Neural Architecture Search",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-12",
          "2019-02",
          "2019-03",
          "2019-07",
          "2019-08",
          "2020-03",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Outlier Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Outlier Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-09",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Outlier Detection",
          "Outlier Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Panoptic Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Panoptic Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-12",
          "2019-01",
          "2019-05",
          "2019-09",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Real-Time Semantic Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Real-Time Semantic Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-02",
          "2015-11",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2018-08",
          "2018-11",
          "2019-03",
          "2019-09",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Scene Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Scene Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-03",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Scene Segmentation",
          "Scene Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Semantic Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Semantic Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-02",
          "2015-03",
          "2015-04",
          "2015-09",
          "2015-11",
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-02",
          "2017-03",
          "2017-04",
          "2017-06",
          "2017-10",
          "2017-11",
          "2017-12",
          "2018-02",
          "2018-03",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-09",
          "2018-12",
          "2019-03",
          "2019-04",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-10",
          "2019-11",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Sentence Compression",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Sentence Compression",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-07",
          "2018-07"
         ],
         "xaxis": "x",
         "y": [
          "Sentence Compression",
          "Sentence Compression"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Skeleton Based Action Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Skeleton Based Action Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2012-07",
          "2013-02",
          "2016-04",
          "2016-06",
          "2016-09",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-11",
          "2018-12",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Temporal Action Localization",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Temporal Action Localization",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-06",
          "2016-01",
          "2016-09",
          "2017-03",
          "2017-05",
          "2018-04",
          "2018-06",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Temporal Action Proposal Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Temporal Action Proposal Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-07"
         ],
         "xaxis": "x",
         "y": [
          "Temporal Action Proposal Generation",
          "Temporal Action Proposal Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Transfer Learning",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Transfer Learning",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-07",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Transfer Learning",
          "Transfer Learning"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Unsupervised Domain Adaptation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Unsupervised Domain Adaptation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-02",
          "2015-05",
          "2017-11",
          "2018-11",
          "2018-12",
          "2019-11",
          "2020-01"
         ],
         "xaxis": "x",
         "y": [
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Unsupervised MNIST",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Unsupervised MNIST",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-03",
          "2018-07"
         ],
         "xaxis": "x",
         "y": [
          "Unsupervised MNIST",
          "Unsupervised MNIST"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Weakly Supervised Action Localization",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Weakly Supervised Action Localization",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2016-12<BR>ratio: 0.32",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2017-06<BR>ratio: 0.01",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2017-11<BR>ratio: 0.01",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2018-01<BR>ratio: 0.01",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2019-04<BR>ratio: 0.01",
          "3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2019-09<BR>ratio: 0.0",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.25",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2017-06<BR>ratio: 0.09",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2017-10<BR>ratio: 0.16",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2018-07<BR>ratio: 0.11",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2018-09<BR>ratio: 0.06",
          "3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2019-04<BR>ratio: 0.32",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2012-12<BR>ratio: 0.45",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2014-12<BR>ratio: 0.04",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2015-03<BR>ratio: 0.07",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2015-05<BR>ratio: 0.06",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2015-12<BR>ratio: 0.5",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2016-01<BR>ratio: 0.04",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2016-04<BR>ratio: 0.01",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2016-08<BR>ratio: 0.03",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2017-03<BR>ratio: 0.08",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2017-04<BR>ratio: 0.1",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2017-05<BR>ratio: 0.27",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2017-11<BR>ratio: 0.26",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-01<BR>ratio: 0.46",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-06<BR>ratio: 0.1",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-07<BR>ratio: 0.01",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-10<BR>ratio: 0.0",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-11<BR>ratio: 0.06",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2018-12<BR>ratio: 0.46",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-01<BR>ratio: 0.11",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-04<BR>ratio: 0.14",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-06<BR>ratio: 0.01",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-07<BR>ratio: 0.03",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-08<BR>ratio: 0.03",
          "Action Recognition<BR>task: Action Recognition<BR>date: 2019-12<BR>ratio: 0.03",
          "Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2014-12<BR>ratio: 0.16",
          "Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2015-05<BR>ratio: 0.04",
          "Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2016-05<BR>ratio: 0.06",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2015-05<BR>ratio: 0.02",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2016-08<BR>ratio: 0.37",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-04<BR>ratio: 0.11",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-05<BR>ratio: 0.42",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-11<BR>ratio: 0.01",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-12<BR>ratio: 0.04",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2018-07<BR>ratio: 0.03",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2018-11<BR>ratio: 0.26",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-01<BR>ratio: 0.09",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-03<BR>ratio: 0.09",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-05<BR>ratio: 0.02",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-06<BR>ratio: 0.29",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-08<BR>ratio: 0.12",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-09<BR>ratio: 0.0",
          "Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-11<BR>ratio: 0.01",
          "Domain Generalization<BR>task: Domain Generalization<BR>date: 2017-08<BR>ratio: 0.03",
          "Domain Generalization<BR>task: Domain Generalization<BR>date: 2017-10<BR>ratio: 0.3",
          "Domain Generalization<BR>task: Domain Generalization<BR>date: 2019-03<BR>ratio: 0.1",
          "Domain Generalization<BR>task: Domain Generalization<BR>date: 2019-05<BR>ratio: 0.1",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2013-06<BR>ratio: 0.32",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2016-03<BR>ratio: 0.08",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2017-03<BR>ratio: 0.01",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2017-11<BR>ratio: 0.25",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2018-06<BR>ratio: 0.49",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2018-10<BR>ratio: 0.0",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-03<BR>ratio: 0.19",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-04<BR>ratio: 0.12",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-05<BR>ratio: 0.01",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-06<BR>ratio: 0.05",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-07<BR>ratio: 0.1",
          "Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-08<BR>ratio: 0.02",
          "Metric Learning<BR>task: Metric Learning<BR>date: 2016-11<BR>ratio: 0.04",
          "Metric Learning<BR>task: Metric Learning<BR>date: 2017-06<BR>ratio: 0.47",
          "Metric Learning<BR>task: Metric Learning<BR>date: 2018-04<BR>ratio: 0.06",
          "Metric Learning<BR>task: Metric Learning<BR>date: 2019-08<BR>ratio: 0.04",
          "Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2018-12<BR>ratio: 0.03",
          "Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2019-02<BR>ratio: 0.37",
          "Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2019-03<BR>ratio: 0.38",
          "Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2019-07<BR>ratio: 0.01",
          "Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2019-08<BR>ratio: 0.04",
          "Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2020-03<BR>ratio: 0.0",
          "Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2020-04<BR>ratio: 0.01",
          "Outlier Detection<BR>task: Outlier Detection<BR>date: 2017-09<BR>ratio: 0.0",
          "Outlier Detection<BR>task: Outlier Detection<BR>date: 2019-04<BR>ratio: 0.0",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2018-12<BR>ratio: 0.17",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-01<BR>ratio: 0.26",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-05<BR>ratio: 0.04",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-09<BR>ratio: 0.28",
          "Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-11<BR>ratio: 0.04",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2015-02<BR>ratio: 0.01",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2015-11<BR>ratio: 0.06",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-06<BR>ratio: 0.39",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-11<BR>ratio: 0.06",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.26",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2017-04<BR>ratio: 0.18",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2018-08<BR>ratio: 0.12",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2018-11<BR>ratio: 0.0",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2019-03<BR>ratio: 0.01",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2019-09<BR>ratio: 0.01",
          "Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.2",
          "Scene Segmentation<BR>task: Scene Segmentation<BR>date: 2018-03<BR>ratio: 0.2",
          "Scene Segmentation<BR>task: Scene Segmentation<BR>date: 2019-08<BR>ratio: 0.04",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-02<BR>ratio: 0.03",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-03<BR>ratio: 0.02",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-04<BR>ratio: 0.08",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-09<BR>ratio: 0.21",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-11<BR>ratio: 0.36",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-03<BR>ratio: 0.38",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-05<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-06<BR>ratio: 0.47",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-11<BR>ratio: 0.25",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.44",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-02<BR>ratio: 0.42",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-03<BR>ratio: 0.4",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-04<BR>ratio: 0.06",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-06<BR>ratio: 0.21",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-10<BR>ratio: 0.09",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-11<BR>ratio: 0.34",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-12<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-02<BR>ratio: 0.04",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-03<BR>ratio: 0.03",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-04<BR>ratio: 0.06",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-06<BR>ratio: 0.05",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-08<BR>ratio: 0.5",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-09<BR>ratio: 0.04",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-12<BR>ratio: 0.05",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-03<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-04<BR>ratio: 0.13",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-06<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-08<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-09<BR>ratio: 0.02",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-10<BR>ratio: 0.28",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-11<BR>ratio: 0.01",
          "Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.04",
          "Sentence Compression<BR>task: Sentence Compression<BR>date: 2017-07<BR>ratio: 0.0",
          "Sentence Compression<BR>task: Sentence Compression<BR>date: 2018-07<BR>ratio: 0.0",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2012-07<BR>ratio: 0.22",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2013-02<BR>ratio: 0.04",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-04<BR>ratio: 0.47",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-06<BR>ratio: 0.49",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-09<BR>ratio: 0.1",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-11<BR>ratio: 0.16",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-03<BR>ratio: 0.03",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-04<BR>ratio: 0.39",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-05<BR>ratio: 0.09",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-08<BR>ratio: 0.36",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-01<BR>ratio: 0.34",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-02<BR>ratio: 0.36",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-04<BR>ratio: 0.05",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-05<BR>ratio: 0.14",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-06<BR>ratio: 0.06",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-11<BR>ratio: 0.01",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-12<BR>ratio: 0.05",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-04<BR>ratio: 0.07",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-06<BR>ratio: 0.01",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-07<BR>ratio: 0.34",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-09<BR>ratio: 0.0",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-11<BR>ratio: 0.01",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-12<BR>ratio: 0.02",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2015-06<BR>ratio: 0.4",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2016-01<BR>ratio: 0.03",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2016-09<BR>ratio: 0.37",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2017-03<BR>ratio: 0.19",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2017-05<BR>ratio: 0.23",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2018-04<BR>ratio: 0.26",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2018-06<BR>ratio: 0.3",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-04<BR>ratio: 0.08",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-06<BR>ratio: 0.06",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-07<BR>ratio: 0.07",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-09<BR>ratio: 0.1",
          "Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-11<BR>ratio: 0.03",
          "Temporal Action Proposal Generation<BR>task: Temporal Action Proposal Generation<BR>date: 2018-11<BR>ratio: 0.01",
          "Temporal Action Proposal Generation<BR>task: Temporal Action Proposal Generation<BR>date: 2019-07<BR>ratio: 0.01",
          "Transfer Learning<BR>task: Transfer Learning<BR>date: 2018-07<BR>ratio: 0.04",
          "Transfer Learning<BR>task: Transfer Learning<BR>date: 2019-04<BR>ratio: 0.05",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2015-02<BR>ratio: 0.25",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2015-05<BR>ratio: 0.03",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2017-11<BR>ratio: 0.43",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2018-11<BR>ratio: 0.36",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2018-12<BR>ratio: 0.25",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2019-11<BR>ratio: 0.04",
          "Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2020-01<BR>ratio: 0.23",
          "Unsupervised MNIST<BR>task: Unsupervised MNIST<BR>date: 2018-03<BR>ratio: 0.01",
          "Unsupervised MNIST<BR>task: Unsupervised MNIST<BR>date: 2018-07<BR>ratio: 0.03",
          "Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-05<BR>ratio: 0.13",
          "Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-06<BR>ratio: 0.01",
          "Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-08<BR>ratio: 0.38",
          "Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-11<BR>ratio: 0.35"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.32,
           0.01,
           0.01,
           0.01,
           0.01,
           0,
           0.25,
           0.09,
           0.16,
           0.11,
           0.06,
           0.32,
           0.45,
           0.04,
           0.07,
           0.06,
           0.5,
           0.04,
           0.01,
           0.03,
           0.08,
           0.1,
           0.27,
           0.26,
           0.46,
           0.1,
           0.01,
           0,
           0.06,
           0.46,
           0.11,
           0.14,
           0.01,
           0.03,
           0.03,
           0.03,
           0.16,
           0.04,
           0.06,
           0.02,
           0.37,
           0.11,
           0.42,
           0.01,
           0.04,
           0.03,
           0.26,
           0.09,
           0.09,
           0.02,
           0.29,
           0.12,
           0,
           0.01,
           0.03,
           0.3,
           0.1,
           0.1,
           0.32,
           0.08,
           0.01,
           0.25,
           0.49,
           0,
           0.19,
           0.12,
           0.01,
           0.05,
           0.1,
           0.02,
           0.04,
           0.47,
           0.06,
           0.04,
           0.03,
           0.37,
           0.38,
           0.01,
           0.04,
           0,
           0.01,
           0,
           0,
           0.17,
           0.26,
           0.04,
           0.28,
           0.04,
           0.01,
           0.06,
           0.39,
           0.06,
           0.26,
           0.18,
           0.12,
           0,
           0.01,
           0.01,
           0.2,
           0.2,
           0.04,
           0.03,
           0.02,
           0.08,
           0.21,
           0.36,
           0.38,
           0.01,
           0.47,
           0.25,
           0.44,
           0.42,
           0.4,
           0.06,
           0.21,
           0.09,
           0.34,
           0.01,
           0.04,
           0.03,
           0.06,
           0.05,
           0.5,
           0.04,
           0.05,
           0.01,
           0.13,
           0.01,
           0.01,
           0.02,
           0.28,
           0.01,
           0.04,
           0,
           0,
           0.22,
           0.04,
           0.47,
           0.49,
           0.1,
           0.16,
           0.03,
           0.39,
           0.09,
           0.36,
           0.34,
           0.36,
           0.05,
           0.14,
           0.06,
           0.01,
           0.05,
           0.07,
           0.01,
           0.34,
           0,
           0.01,
           0.02,
           0.4,
           0.03,
           0.37,
           0.19,
           0.23,
           0.26,
           0.3,
           0.08,
           0.06,
           0.07,
           0.1,
           0.03,
           0.01,
           0.01,
           0.04,
           0.05,
           0.25,
           0.03,
           0.43,
           0.36,
           0.25,
           0.04,
           0.23,
           0.01,
           0.03,
           0.13,
           0.01,
           0.38,
           0.35
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2016-12",
          "2017-06",
          "2017-11",
          "2018-01",
          "2019-04",
          "2019-09",
          "2016-12",
          "2017-06",
          "2017-10",
          "2018-07",
          "2018-09",
          "2019-04",
          "2012-12",
          "2014-12",
          "2015-03",
          "2015-05",
          "2015-12",
          "2016-01",
          "2016-04",
          "2016-08",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-11",
          "2018-01",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2018-12",
          "2019-01",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-12",
          "2014-12",
          "2015-05",
          "2016-05",
          "2015-05",
          "2016-08",
          "2017-04",
          "2017-05",
          "2017-11",
          "2017-12",
          "2018-07",
          "2018-11",
          "2019-01",
          "2019-03",
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-11",
          "2017-08",
          "2017-10",
          "2019-03",
          "2019-05",
          "2013-06",
          "2016-03",
          "2017-03",
          "2017-11",
          "2018-06",
          "2018-10",
          "2019-03",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2016-11",
          "2017-06",
          "2018-04",
          "2019-08",
          "2018-12",
          "2019-02",
          "2019-03",
          "2019-07",
          "2019-08",
          "2020-03",
          "2020-04",
          "2017-09",
          "2019-04",
          "2018-12",
          "2019-01",
          "2019-05",
          "2019-09",
          "2019-11",
          "2015-02",
          "2015-11",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2018-08",
          "2018-11",
          "2019-03",
          "2019-09",
          "2020-04",
          "2018-03",
          "2019-08",
          "2015-02",
          "2015-03",
          "2015-04",
          "2015-09",
          "2015-11",
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-02",
          "2017-03",
          "2017-04",
          "2017-06",
          "2017-10",
          "2017-11",
          "2017-12",
          "2018-02",
          "2018-03",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-09",
          "2018-12",
          "2019-03",
          "2019-04",
          "2019-06",
          "2019-08",
          "2019-09",
          "2019-10",
          "2019-11",
          "2020-04",
          "2017-07",
          "2018-07",
          "2012-07",
          "2013-02",
          "2016-04",
          "2016-06",
          "2016-09",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-11",
          "2018-12",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11",
          "2019-12",
          "2015-06",
          "2016-01",
          "2016-09",
          "2017-03",
          "2017-05",
          "2018-04",
          "2018-06",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11",
          "2018-11",
          "2019-07",
          "2018-07",
          "2019-04",
          "2015-02",
          "2015-05",
          "2017-11",
          "2018-11",
          "2018-12",
          "2019-11",
          "2020-01",
          "2018-03",
          "2018-07",
          "2019-05",
          "2019-06",
          "2019-08",
          "2019-11"
         ],
         "y": [
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Part Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "3D Semantic Segmentation",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Action Recognition",
          "Activity Recognition In Videos",
          "Activity Recognition In Videos",
          "Activity Recognition In Videos",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Adaptation",
          "Domain Generalization",
          "Domain Generalization",
          "Domain Generalization",
          "Domain Generalization",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Few-Shot Image Classification",
          "Metric Learning",
          "Metric Learning",
          "Metric Learning",
          "Metric Learning",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Neural Architecture Search",
          "Outlier Detection",
          "Outlier Detection",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Panoptic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Real-Time Semantic Segmentation",
          "Scene Segmentation",
          "Scene Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Semantic Segmentation",
          "Sentence Compression",
          "Sentence Compression",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Localization",
          "Temporal Action Proposal Generation",
          "Temporal Action Proposal Generation",
          "Transfer Learning",
          "Transfer Learning",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised Domain Adaptation",
          "Unsupervised MNIST",
          "Unsupervised MNIST",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization",
          "Weakly Supervised Action Localization"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Weakly Supervised Action Localization",
          "Unsupervised MNIST",
          "Unsupervised Domain Adaptation",
          "Transfer Learning",
          "Temporal Action Proposal Generation",
          "Temporal Action Localization",
          "Skeleton Based Action Recognition",
          "Sentence Compression",
          "Semantic Segmentation",
          "Scene Segmentation",
          "Real-Time Semantic Segmentation",
          "Panoptic Segmentation",
          "Outlier Detection",
          "Neural Architecture Search",
          "Metric Learning",
          "Few-Shot Image Classification",
          "Domain Generalization",
          "Domain Adaptation",
          "Activity Recognition In Videos",
          "Action Recognition",
          "3D Semantic Segmentation",
          "3D Part Segmentation"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00115: Fundamental AI process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"41df9aea-0bfc-44e4-8d0a-b505f390688a\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"41df9aea-0bfc-44e4-8d0a-b505f390688a\")) {                    Plotly.newPlot(                        \"41df9aea-0bfc-44e4-8d0a-b505f390688a\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Part Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Part Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2017-06\", \"2017-11\", \"2018-01\", \"2019-04\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"3D Semantic Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"3D Semantic Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2017-06\", \"2017-10\", \"2018-07\", \"2018-09\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Action Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Action Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2012-12\", \"2014-12\", \"2015-03\", \"2015-05\", \"2015-12\", \"2016-01\", \"2016-04\", \"2016-08\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-11\", \"2018-01\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2018-12\", \"2019-01\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Activity Recognition In Videos\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Activity Recognition In Videos\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-12\", \"2015-05\", \"2016-05\"], \"xaxis\": \"x\", \"y\": [\"Activity Recognition In Videos\", \"Activity Recognition In Videos\", \"Activity Recognition In Videos\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Domain Adaptation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Domain Adaptation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-05\", \"2016-08\", \"2017-04\", \"2017-05\", \"2017-11\", \"2017-12\", \"2018-07\", \"2018-11\", \"2019-01\", \"2019-03\", \"2019-05\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Domain Generalization\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Domain Generalization\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-08\", \"2017-10\", \"2019-03\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Domain Generalization\", \"Domain Generalization\", \"Domain Generalization\", \"Domain Generalization\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Few-Shot Image Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Few-Shot Image Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2013-06\", \"2016-03\", \"2017-03\", \"2017-11\", \"2018-06\", \"2018-10\", \"2019-03\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Metric Learning\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Metric Learning\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-06\", \"2018-04\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Metric Learning\", \"Metric Learning\", \"Metric Learning\", \"Metric Learning\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Neural Architecture Search\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Neural Architecture Search\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-12\", \"2019-02\", \"2019-03\", \"2019-07\", \"2019-08\", \"2020-03\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Outlier Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Outlier Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-09\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Outlier Detection\", \"Outlier Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Panoptic Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Panoptic Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-12\", \"2019-01\", \"2019-05\", \"2019-09\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Real-Time Semantic Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Real-Time Semantic Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-02\", \"2015-11\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2018-08\", \"2018-11\", \"2019-03\", \"2019-09\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Scene Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Scene Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-03\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Scene Segmentation\", \"Scene Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Semantic Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Semantic Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-02\", \"2015-03\", \"2015-04\", \"2015-09\", \"2015-11\", \"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-02\", \"2017-03\", \"2017-04\", \"2017-06\", \"2017-10\", \"2017-11\", \"2017-12\", \"2018-02\", \"2018-03\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-09\", \"2018-12\", \"2019-03\", \"2019-04\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-10\", \"2019-11\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Sentence Compression\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Sentence Compression\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-07\", \"2018-07\"], \"xaxis\": \"x\", \"y\": [\"Sentence Compression\", \"Sentence Compression\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Skeleton Based Action Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Skeleton Based Action Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2012-07\", \"2013-02\", \"2016-04\", \"2016-06\", \"2016-09\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-11\", \"2018-12\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Temporal Action Localization\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Temporal Action Localization\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-06\", \"2016-01\", \"2016-09\", \"2017-03\", \"2017-05\", \"2018-04\", \"2018-06\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Temporal Action Proposal Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Temporal Action Proposal Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-07\"], \"xaxis\": \"x\", \"y\": [\"Temporal Action Proposal Generation\", \"Temporal Action Proposal Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Transfer Learning\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Transfer Learning\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-07\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Transfer Learning\", \"Transfer Learning\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Unsupervised Domain Adaptation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Unsupervised Domain Adaptation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-02\", \"2015-05\", \"2017-11\", \"2018-11\", \"2018-12\", \"2019-11\", \"2020-01\"], \"xaxis\": \"x\", \"y\": [\"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Unsupervised MNIST\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Unsupervised MNIST\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-03\", \"2018-07\"], \"xaxis\": \"x\", \"y\": [\"Unsupervised MNIST\", \"Unsupervised MNIST\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Weakly Supervised Action Localization\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Weakly Supervised Action Localization\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-05\", \"2019-06\", \"2019-08\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2016-12<BR>ratio: 0.32\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2017-06<BR>ratio: 0.01\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2017-11<BR>ratio: 0.01\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2018-01<BR>ratio: 0.01\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2019-04<BR>ratio: 0.01\", \"3D Part Segmentation<BR>task: 3D Part Segmentation<BR>date: 2019-09<BR>ratio: 0.0\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.25\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2017-06<BR>ratio: 0.09\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2017-10<BR>ratio: 0.16\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2018-07<BR>ratio: 0.11\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2018-09<BR>ratio: 0.06\", \"3D Semantic Segmentation<BR>task: 3D Semantic Segmentation<BR>date: 2019-04<BR>ratio: 0.32\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2012-12<BR>ratio: 0.45\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2014-12<BR>ratio: 0.04\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2015-03<BR>ratio: 0.07\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2015-05<BR>ratio: 0.06\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2015-12<BR>ratio: 0.5\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2016-01<BR>ratio: 0.04\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2016-04<BR>ratio: 0.01\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2016-08<BR>ratio: 0.03\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2017-03<BR>ratio: 0.08\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2017-04<BR>ratio: 0.1\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2017-05<BR>ratio: 0.27\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2017-11<BR>ratio: 0.26\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-01<BR>ratio: 0.46\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-06<BR>ratio: 0.1\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-07<BR>ratio: 0.01\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-10<BR>ratio: 0.0\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-11<BR>ratio: 0.06\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2018-12<BR>ratio: 0.46\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-01<BR>ratio: 0.11\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-04<BR>ratio: 0.14\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-06<BR>ratio: 0.01\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-07<BR>ratio: 0.03\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-08<BR>ratio: 0.03\", \"Action Recognition<BR>task: Action Recognition<BR>date: 2019-12<BR>ratio: 0.03\", \"Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2014-12<BR>ratio: 0.16\", \"Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2015-05<BR>ratio: 0.04\", \"Activity Recognition In Videos<BR>task: Activity Recognition In Videos<BR>date: 2016-05<BR>ratio: 0.06\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2015-05<BR>ratio: 0.02\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2016-08<BR>ratio: 0.37\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-04<BR>ratio: 0.11\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-05<BR>ratio: 0.42\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-11<BR>ratio: 0.01\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2017-12<BR>ratio: 0.04\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2018-07<BR>ratio: 0.03\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2018-11<BR>ratio: 0.26\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-01<BR>ratio: 0.09\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-03<BR>ratio: 0.09\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-05<BR>ratio: 0.02\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-06<BR>ratio: 0.29\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-08<BR>ratio: 0.12\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-09<BR>ratio: 0.0\", \"Domain Adaptation<BR>task: Domain Adaptation<BR>date: 2019-11<BR>ratio: 0.01\", \"Domain Generalization<BR>task: Domain Generalization<BR>date: 2017-08<BR>ratio: 0.03\", \"Domain Generalization<BR>task: Domain Generalization<BR>date: 2017-10<BR>ratio: 0.3\", \"Domain Generalization<BR>task: Domain Generalization<BR>date: 2019-03<BR>ratio: 0.1\", \"Domain Generalization<BR>task: Domain Generalization<BR>date: 2019-05<BR>ratio: 0.1\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2013-06<BR>ratio: 0.32\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2016-03<BR>ratio: 0.08\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2017-03<BR>ratio: 0.01\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2017-11<BR>ratio: 0.25\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2018-06<BR>ratio: 0.49\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2018-10<BR>ratio: 0.0\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-03<BR>ratio: 0.19\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-04<BR>ratio: 0.12\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-05<BR>ratio: 0.01\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-06<BR>ratio: 0.05\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-07<BR>ratio: 0.1\", \"Few-Shot Image Classification<BR>task: Few-Shot Image Classification<BR>date: 2019-08<BR>ratio: 0.02\", \"Metric Learning<BR>task: Metric Learning<BR>date: 2016-11<BR>ratio: 0.04\", \"Metric Learning<BR>task: Metric Learning<BR>date: 2017-06<BR>ratio: 0.47\", \"Metric Learning<BR>task: Metric Learning<BR>date: 2018-04<BR>ratio: 0.06\", \"Metric Learning<BR>task: Metric Learning<BR>date: 2019-08<BR>ratio: 0.04\", \"Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2018-12<BR>ratio: 0.03\", \"Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2019-02<BR>ratio: 0.37\", \"Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2019-03<BR>ratio: 0.38\", \"Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2019-07<BR>ratio: 0.01\", \"Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2019-08<BR>ratio: 0.04\", \"Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2020-03<BR>ratio: 0.0\", \"Neural Architecture Search<BR>task: Neural Architecture Search<BR>date: 2020-04<BR>ratio: 0.01\", \"Outlier Detection<BR>task: Outlier Detection<BR>date: 2017-09<BR>ratio: 0.0\", \"Outlier Detection<BR>task: Outlier Detection<BR>date: 2019-04<BR>ratio: 0.0\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2018-12<BR>ratio: 0.17\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-01<BR>ratio: 0.26\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-05<BR>ratio: 0.04\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-09<BR>ratio: 0.28\", \"Panoptic Segmentation<BR>task: Panoptic Segmentation<BR>date: 2019-11<BR>ratio: 0.04\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2015-02<BR>ratio: 0.01\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2015-11<BR>ratio: 0.06\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-06<BR>ratio: 0.39\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-11<BR>ratio: 0.06\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.26\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2017-04<BR>ratio: 0.18\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2018-08<BR>ratio: 0.12\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2018-11<BR>ratio: 0.0\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2019-03<BR>ratio: 0.01\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2019-09<BR>ratio: 0.01\", \"Real-Time Semantic Segmentation<BR>task: Real-Time Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.2\", \"Scene Segmentation<BR>task: Scene Segmentation<BR>date: 2018-03<BR>ratio: 0.2\", \"Scene Segmentation<BR>task: Scene Segmentation<BR>date: 2019-08<BR>ratio: 0.04\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-02<BR>ratio: 0.03\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-03<BR>ratio: 0.02\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-04<BR>ratio: 0.08\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-09<BR>ratio: 0.21\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2015-11<BR>ratio: 0.36\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-03<BR>ratio: 0.38\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-05<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-06<BR>ratio: 0.47\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-11<BR>ratio: 0.25\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2016-12<BR>ratio: 0.44\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-02<BR>ratio: 0.42\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-03<BR>ratio: 0.4\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-04<BR>ratio: 0.06\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-06<BR>ratio: 0.21\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-10<BR>ratio: 0.09\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-11<BR>ratio: 0.34\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2017-12<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-02<BR>ratio: 0.04\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-03<BR>ratio: 0.03\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-04<BR>ratio: 0.06\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-06<BR>ratio: 0.05\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-08<BR>ratio: 0.5\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-09<BR>ratio: 0.04\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2018-12<BR>ratio: 0.05\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-03<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-04<BR>ratio: 0.13\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-06<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-08<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-09<BR>ratio: 0.02\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-10<BR>ratio: 0.28\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2019-11<BR>ratio: 0.01\", \"Semantic Segmentation<BR>task: Semantic Segmentation<BR>date: 2020-04<BR>ratio: 0.04\", \"Sentence Compression<BR>task: Sentence Compression<BR>date: 2017-07<BR>ratio: 0.0\", \"Sentence Compression<BR>task: Sentence Compression<BR>date: 2018-07<BR>ratio: 0.0\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2012-07<BR>ratio: 0.22\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2013-02<BR>ratio: 0.04\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-04<BR>ratio: 0.47\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-06<BR>ratio: 0.49\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-09<BR>ratio: 0.1\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-11<BR>ratio: 0.16\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-03<BR>ratio: 0.03\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-04<BR>ratio: 0.39\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-05<BR>ratio: 0.09\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-08<BR>ratio: 0.36\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-01<BR>ratio: 0.34\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-02<BR>ratio: 0.36\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-04<BR>ratio: 0.05\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-05<BR>ratio: 0.14\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-06<BR>ratio: 0.06\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-11<BR>ratio: 0.01\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-12<BR>ratio: 0.05\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-04<BR>ratio: 0.07\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-06<BR>ratio: 0.01\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-07<BR>ratio: 0.34\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-09<BR>ratio: 0.0\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-11<BR>ratio: 0.01\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-12<BR>ratio: 0.02\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2015-06<BR>ratio: 0.4\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2016-01<BR>ratio: 0.03\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2016-09<BR>ratio: 0.37\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2017-03<BR>ratio: 0.19\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2017-05<BR>ratio: 0.23\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2018-04<BR>ratio: 0.26\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2018-06<BR>ratio: 0.3\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-04<BR>ratio: 0.08\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-06<BR>ratio: 0.06\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-07<BR>ratio: 0.07\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-09<BR>ratio: 0.1\", \"Temporal Action Localization<BR>task: Temporal Action Localization<BR>date: 2019-11<BR>ratio: 0.03\", \"Temporal Action Proposal Generation<BR>task: Temporal Action Proposal Generation<BR>date: 2018-11<BR>ratio: 0.01\", \"Temporal Action Proposal Generation<BR>task: Temporal Action Proposal Generation<BR>date: 2019-07<BR>ratio: 0.01\", \"Transfer Learning<BR>task: Transfer Learning<BR>date: 2018-07<BR>ratio: 0.04\", \"Transfer Learning<BR>task: Transfer Learning<BR>date: 2019-04<BR>ratio: 0.05\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2015-02<BR>ratio: 0.25\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2015-05<BR>ratio: 0.03\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2017-11<BR>ratio: 0.43\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2018-11<BR>ratio: 0.36\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2018-12<BR>ratio: 0.25\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2019-11<BR>ratio: 0.04\", \"Unsupervised Domain Adaptation<BR>task: Unsupervised Domain Adaptation<BR>date: 2020-01<BR>ratio: 0.23\", \"Unsupervised MNIST<BR>task: Unsupervised MNIST<BR>date: 2018-03<BR>ratio: 0.01\", \"Unsupervised MNIST<BR>task: Unsupervised MNIST<BR>date: 2018-07<BR>ratio: 0.03\", \"Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-05<BR>ratio: 0.13\", \"Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-06<BR>ratio: 0.01\", \"Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-08<BR>ratio: 0.38\", \"Weakly Supervised Action Localization<BR>task: Weakly Supervised Action Localization<BR>date: 2019-11<BR>ratio: 0.35\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.32, 0.01, 0.01, 0.01, 0.01, 0.0, 0.25, 0.09, 0.16, 0.11, 0.06, 0.32, 0.45, 0.04, 0.07, 0.06, 0.5, 0.04, 0.01, 0.03, 0.08, 0.1, 0.27, 0.26, 0.46, 0.1, 0.01, 0.0, 0.06, 0.46, 0.11, 0.14, 0.01, 0.03, 0.03, 0.03, 0.16, 0.04, 0.06, 0.02, 0.37, 0.11, 0.42, 0.01, 0.04, 0.03, 0.26, 0.09, 0.09, 0.02, 0.29, 0.12, 0.0, 0.01, 0.03, 0.3, 0.1, 0.1, 0.32, 0.08, 0.01, 0.25, 0.49, 0.0, 0.19, 0.12, 0.01, 0.05, 0.1, 0.02, 0.04, 0.47, 0.06, 0.04, 0.03, 0.37, 0.38, 0.01, 0.04, 0.0, 0.01, 0.0, 0.0, 0.17, 0.26, 0.04, 0.28, 0.04, 0.01, 0.06, 0.39, 0.06, 0.26, 0.18, 0.12, 0.0, 0.01, 0.01, 0.2, 0.2, 0.04, 0.03, 0.02, 0.08, 0.21, 0.36, 0.38, 0.01, 0.47, 0.25, 0.44, 0.42, 0.4, 0.06, 0.21, 0.09, 0.34, 0.01, 0.04, 0.03, 0.06, 0.05, 0.5, 0.04, 0.05, 0.01, 0.13, 0.01, 0.01, 0.02, 0.28, 0.01, 0.04, 0.0, 0.0, 0.22, 0.04, 0.47, 0.49, 0.1, 0.16, 0.03, 0.39, 0.09, 0.36, 0.34, 0.36, 0.05, 0.14, 0.06, 0.01, 0.05, 0.07, 0.01, 0.34, 0.0, 0.01, 0.02, 0.4, 0.03, 0.37, 0.19, 0.23, 0.26, 0.3, 0.08, 0.06, 0.07, 0.1, 0.03, 0.01, 0.01, 0.04, 0.05, 0.25, 0.03, 0.43, 0.36, 0.25, 0.04, 0.23, 0.01, 0.03, 0.13, 0.01, 0.38, 0.35], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2016-12\", \"2017-06\", \"2017-11\", \"2018-01\", \"2019-04\", \"2019-09\", \"2016-12\", \"2017-06\", \"2017-10\", \"2018-07\", \"2018-09\", \"2019-04\", \"2012-12\", \"2014-12\", \"2015-03\", \"2015-05\", \"2015-12\", \"2016-01\", \"2016-04\", \"2016-08\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-11\", \"2018-01\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2018-12\", \"2019-01\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-12\", \"2014-12\", \"2015-05\", \"2016-05\", \"2015-05\", \"2016-08\", \"2017-04\", \"2017-05\", \"2017-11\", \"2017-12\", \"2018-07\", \"2018-11\", \"2019-01\", \"2019-03\", \"2019-05\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-11\", \"2017-08\", \"2017-10\", \"2019-03\", \"2019-05\", \"2013-06\", \"2016-03\", \"2017-03\", \"2017-11\", \"2018-06\", \"2018-10\", \"2019-03\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2016-11\", \"2017-06\", \"2018-04\", \"2019-08\", \"2018-12\", \"2019-02\", \"2019-03\", \"2019-07\", \"2019-08\", \"2020-03\", \"2020-04\", \"2017-09\", \"2019-04\", \"2018-12\", \"2019-01\", \"2019-05\", \"2019-09\", \"2019-11\", \"2015-02\", \"2015-11\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2018-08\", \"2018-11\", \"2019-03\", \"2019-09\", \"2020-04\", \"2018-03\", \"2019-08\", \"2015-02\", \"2015-03\", \"2015-04\", \"2015-09\", \"2015-11\", \"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-02\", \"2017-03\", \"2017-04\", \"2017-06\", \"2017-10\", \"2017-11\", \"2017-12\", \"2018-02\", \"2018-03\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-09\", \"2018-12\", \"2019-03\", \"2019-04\", \"2019-06\", \"2019-08\", \"2019-09\", \"2019-10\", \"2019-11\", \"2020-04\", \"2017-07\", \"2018-07\", \"2012-07\", \"2013-02\", \"2016-04\", \"2016-06\", \"2016-09\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-11\", \"2018-12\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\", \"2019-12\", \"2015-06\", \"2016-01\", \"2016-09\", \"2017-03\", \"2017-05\", \"2018-04\", \"2018-06\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\", \"2018-11\", \"2019-07\", \"2018-07\", \"2019-04\", \"2015-02\", \"2015-05\", \"2017-11\", \"2018-11\", \"2018-12\", \"2019-11\", \"2020-01\", \"2018-03\", \"2018-07\", \"2019-05\", \"2019-06\", \"2019-08\", \"2019-11\"], \"y\": [\"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Part Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"3D Semantic Segmentation\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Action Recognition\", \"Activity Recognition In Videos\", \"Activity Recognition In Videos\", \"Activity Recognition In Videos\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Adaptation\", \"Domain Generalization\", \"Domain Generalization\", \"Domain Generalization\", \"Domain Generalization\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Few-Shot Image Classification\", \"Metric Learning\", \"Metric Learning\", \"Metric Learning\", \"Metric Learning\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Neural Architecture Search\", \"Outlier Detection\", \"Outlier Detection\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Panoptic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Real-Time Semantic Segmentation\", \"Scene Segmentation\", \"Scene Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Semantic Segmentation\", \"Sentence Compression\", \"Sentence Compression\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Localization\", \"Temporal Action Proposal Generation\", \"Temporal Action Proposal Generation\", \"Transfer Learning\", \"Transfer Learning\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised Domain Adaptation\", \"Unsupervised MNIST\", \"Unsupervised MNIST\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\", \"Weakly Supervised Action Localization\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Weakly Supervised Action Localization\", \"Unsupervised MNIST\", \"Unsupervised Domain Adaptation\", \"Transfer Learning\", \"Temporal Action Proposal Generation\", \"Temporal Action Localization\", \"Skeleton Based Action Recognition\", \"Sentence Compression\", \"Semantic Segmentation\", \"Scene Segmentation\", \"Real-Time Semantic Segmentation\", \"Panoptic Segmentation\", \"Outlier Detection\", \"Neural Architecture Search\", \"Metric Learning\", \"Few-Shot Image Classification\", \"Domain Generalization\", \"Domain Adaptation\", \"Activity Recognition In Videos\", \"Action Recognition\", \"3D Semantic Segmentation\", \"3D Part Segmentation\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00115: Fundamental AI process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('41df9aea-0bfc-44e4-8d0a-b505f390688a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00126\n",
      "Number of metrics:  94\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  MIT-BIH AF - Atrial Fibrillation Detection benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  PTB dataset, ECG lead II - Myocardial Infarction Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  SEED-IV - Electroencephalogram (EEG) process benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  SEED - Electroencephalogram (EEG) process benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  JIGSAWS - Surgical Skills Evaluation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MISTIC-SIL - Surgical Skills Evaluation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Sleep-EDF - Sleep Stage Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ALS EMG (University of Copenhagen) - ALS Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  LIDC-IDRI - Lung Nodule Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MASS SS2 - Sleep Stage Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Dreem_NCT03657329 - Sleep apnea detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  DRIVE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  LUNA - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  100 sleep nights of 8 caregivers - Sleep Quality Task benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  QT - QRS Complex Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  INCART - QRS Complex Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  MIT-BIH AR - QRS Complex Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CHF database - Congestive Heart Failure detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Montgomery County - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MIT-BIH+BIDMC - Congestive Heart Failure detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  MIT-BIH+BIDMC - Heartbeat Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Jpred4 blind set - Protein Secondary Structure Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  27\n",
      "####### Accuracy\\\\ \\\\(Inter\\\\-Patient\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Inter\\\\-Patient\\\\) ,  MIT-BIH AR - Arrhythmia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(Intra\\\\-Patient\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Intra\\\\-Patient\\\\) ,  MIT-BIH AR - Arrhythmia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AMrTRE\n",
      "Creating ratio df for  AMrTRE ,  CIMA-10k - BIRL: Benchmark on Image Registration methods with Landmark validations benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MMrTRE\n",
      "Creating ratio df for  MMrTRE ,  CIMA-10k - BIRL: Benchmark on Image Registration methods with Landmark validations benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ target\\\\ overlap\\\\ ratio\n",
      "Creating ratio df for  Mean\\\\ target\\\\ overlap\\\\ ratio ,  CUMC12 - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### RMSE\n",
      "Creating ratio df for  RMSE ,  Automatic Cardiac Diagnosis Challenge (ACDC) - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  RMSE ,  Multi-day Continuous BP Prediction - Blood pressure estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Hausdorff\\\\ Distance\\\\ \\\\(mm\\\\)\n",
      "Creating ratio df for  Hausdorff\\\\ Distance\\\\ \\\\(mm\\\\) ,  Automatic Cardiac Diagnosis Challenge (ACDC) - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Hausdorff\\\\ Distance\\\\ \\\\(mm\\\\) ,  Kumar - Multi-tissue Nucleus Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Hausdorff\\\\ Distance\\\\ \\\\(mm\\\\) ,  CRAG - Colorectal Gland Segmentation: benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### CPU\\\\ \\\\(sec\\\\)\n",
      "Creating ratio df for  CPU\\\\ \\\\(sec\\\\) ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Neg\\\\ Jacob\\\\ Det\n",
      "Creating ratio df for  Neg\\\\ Jacob\\\\ Det ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Grad\\\\ Det\\\\-Jac\n",
      "Creating ratio df for  Grad\\\\ Det\\\\-Jac ,  Automatic Cardiac Diagnosis Challenge (ACDC) - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Dice\n",
      "Creating ratio df for  Dice ,  Automatic Cardiac Diagnosis Challenge (ACDC) - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice ,  Kumar - Multi-tissue Nucleus Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice ,  RITE - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice ,  Anatomical Tracings of Lesions After Stroke (ATLAS)  - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice ,  CRAG - Colorectal Gland Segmentation: benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice ,  Cell17 - Nuclear Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Dice ,  Anatomical Tracings of Lesions After Stroke (ATLAS) - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice ,  2018 Data Science Bowl - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice ,  LIDC-IDRI - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice ,  LiTS2017 - Liver Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  11\n",
      "####### Dice\\\\ \\\\(Average\\\\)\n",
      "Creating ratio df for  Dice\\\\ \\\\(Average\\\\) ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Dice\\\\ \\\\(SE\\\\)\n",
      "Creating ratio df for  Dice\\\\ \\\\(SE\\\\) ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### PPV\\\\ \\\\(VEB\\\\)\n",
      "Creating ratio df for  PPV\\\\ \\\\(VEB\\\\) ,  MIT-BIH AR - Heartbeat Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Sensitivity\\\\ \\\\(VEB\\\\)\n",
      "Creating ratio df for  Sensitivity\\\\ \\\\(VEB\\\\) ,  MIT-BIH AR - Heartbeat Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(TEST\\\\-DB\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(TEST\\\\-DB\\\\) ,  The PhysioNet Computing in Cardiology Challenge 2017 - Arrhythmia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(TRAIN\\\\-DB\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(TRAIN\\\\-DB\\\\) ,  The PhysioNet Computing in Cardiology Challenge 2017 - Arrhythmia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Dice\\\\ Score\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2013 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2013 leaderboard - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  TCIA Pancreas-CT Dataset - Pancreas Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  CT-150 - Pancreas Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  ISLES-2015 - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2015 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  PROMISE 2012 - Volumetric Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  TCIA Pancreas-CT - 3D Medical Imaging Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2017 val - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS-2014 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  iSEG 2017 Challenge - Infant Brain MRI Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  iSEG 2017 Challenge - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Dice\\\\ Score ,  BUS 2017 Dataset B - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  ISIC 2018 - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS 2018 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  T1-weighted MRI - Brain Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  BRATS 2018 val - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  CHAOS MRI Dataset - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  HSVM - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  Brain MRI segmentation - Brain Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Dice\\\\ Score ,  Lung Nodule  - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  29\n",
      "####### Precision\n",
      "Creating ratio df for  Precision ,  Anatomical Tracings of Lesions After Stroke (ATLAS)  - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  CT-150 - Pancreas Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Precision ,  Anatomical Tracings of Lesions After Stroke (ATLAS) - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  MIMIC-III - Mortality Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Precision ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  CHF database - Congestive Heart Failure detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Warping\\\\ Error\n",
      "Creating ratio df for  Warping\\\\ Error ,  ISBI 2012 EM Segmentation - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mean\\\\ Dice\n",
      "Creating ratio df for  mean\\\\ Dice ,  Kvasir-SEG - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mean\\\\ Dice ,  CVC-ClinicDB - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Average\\\\ MAE\n",
      "Creating ratio df for  Average\\\\ MAE ,  Kvasir-SEG - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### S\\\\-Measure\n",
      "Creating ratio df for  S\\\\-Measure ,  Kvasir-SEG - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### max\\\\ E\\\\-Measure\n",
      "Creating ratio df for  max\\\\ E\\\\-Measure ,  Kvasir-SEG - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AUC\n",
      "Creating ratio df for  AUC ,  DRIVE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AUC ,  STARE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  LUNA - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC ,  CHASE_DB1 - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  AUC ,  SNEMI3D - Electron Microscopy Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Kaggle Skin Lesion Segmentation - Skin Cancer Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC ,  PCBA - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Tox21 - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  AUC ,  ToxCast - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  HIV dataset - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  MUV - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  PCam - Breast Tumour Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  HRF - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Melbourne University Seizure Prediction - Seizure Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  LIDC-IDRI - Lung Nodule Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  BACE - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  ClinTox - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  BBBP - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  SIDER - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  egfr-inh - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  PE-CAD FPRED - Pulmonary Embolism Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  LUNA2016 FPRED - Lung Nodule Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  46\n",
      "####### Recall\n",
      "Creating ratio df for  Recall ,  Anatomical Tracings of Lesions After Stroke (ATLAS)  - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  CT-150 - Pancreas Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Recall ,  Anatomical Tracings of Lesions After Stroke (ATLAS) - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  MIMIC-III - Mortality Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Recall ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### IoU\n",
      "Creating ratio df for  IoU ,  Anatomical Tracings of Lesions After Stroke (ATLAS)  - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  IoU ,  Anatomical Tracings of Lesions After Stroke (ATLAS) - Lesion Segmentation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  IoU ,  LIDC-IDRI - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IoU ,  LiTS2017 - Liver Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IoU ,  PH2 - Skin Cancer Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IoU ,  EM - Medical Image Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  IoU ,  Cell - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Mean\\\\ IoU\n",
      "Creating ratio df for  Mean\\\\ IoU ,  PhC-U373 - Cell Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  DIC-HeLa - Cell Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ IoU ,  ISIC 2017 - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### F1\\\\-score\n",
      "Creating ratio df for  F1\\\\-score ,  CRAG - Colorectal Gland Segmentation: benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score ,  Cell17 - Nuclear Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  5\n",
      "####### F1\\\\ score\n",
      "Creating ratio df for  F1\\\\ score ,  DRIVE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  LUNA - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  STARE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  CHASE_DB1 - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1\\\\ score ,  Kaggle Skin Lesion Segmentation - Skin Cancer Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  MIMIC-III - Mortality Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  HRF - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  DRIVE - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  22\n",
      "####### Jaccard\\\\ Index\n",
      "Creating ratio df for  Jaccard\\\\ Index ,  RITE - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### SSIM\\\\ \\\\(sRGB\\\\)\n",
      "Creating ratio df for  SSIM\\\\ \\\\(sRGB\\\\) ,  Darmstadt Noise Dataset - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  SSIM\\\\ \\\\(sRGB\\\\) ,  DND - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM\\\\ \\\\(sRGB\\\\) ,  SIDD - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### PSNR\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma15 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  Urban100 sigma15 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  BSD200 sigma10 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  BSD200 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  BSD200 sigma30 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  BSD200 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma35 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma25 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma15 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  Urban100 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma50 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma35 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma5 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma25 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  McMaster sigma15 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  McMaster sigma25 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma35 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma75 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma25 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  McMaster sigma75 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma15 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  McMaster sigma50 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  CBSD68 sigma75 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma15 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Kodak25 sigma50 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  McMaster sigma35 - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma60 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma75 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma35 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma15 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set12 sigma15 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma35 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Clip300 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set12 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set12 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Urban100 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PSNR ,  Urban100 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set12 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  BSD68 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR ,  Set12 sigma30 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  71\n",
      "####### PSNR\\\\ \\\\(sRGB\\\\)\n",
      "Creating ratio df for  PSNR\\\\ \\\\(sRGB\\\\) ,  Darmstadt Noise Dataset - Color Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  PSNR\\\\ \\\\(sRGB\\\\) ,  DND - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PSNR\\\\ \\\\(sRGB\\\\) ,  SIDD - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Error\\\\ ratio\n",
      "Creating ratio df for  Error\\\\ ratio ,  QM9 - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Acc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Acc ,  OCT2017 - Retinal OCT Disease Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Acc ,  Srinivasan2014 - Retinal OCT Disease Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Acc ,  LIDC-IDRI - Lung Nodule Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Sensitivity\n",
      "Creating ratio df for  Sensitivity ,  OCT2017 - Retinal OCT Disease Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Sensitivity ,  CHF database - Congestive Heart Failure detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Q8\n",
      "Creating ratio df for  Q8 ,  CB513 - Protein Secondary Structure Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Q8 ,  CullPDB - Protein Secondary Structure Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Q8 ,  2017_test set - Protein Secondary Structure Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Hausdorff\n",
      "Creating ratio df for  Hausdorff ,  Cell17 - Nuclear Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Edit\\\\ Distance\n",
      "Creating ratio df for  Edit\\\\ Distance ,  JIGSAWS - Surgical Skills Evaluation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Edit\\\\ Distance ,  MISTIC-SIL - Surgical Skills Evaluation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### SSIM\n",
      "Creating ratio df for  SSIM ,  BSD200 sigma10 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  BSD200 sigma50 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  BSD200 sigma30 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  BSD200 sigma70 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SSIM ,  Urban100 sigma25 - Grayscale Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### AUC\\\\ \\\\(ABPA\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(ABPA\\\\) ,  UK CF trust - Disease Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AUC\\\\ \\\\(Diabetes\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(Diabetes\\\\) ,  UK CF trust - Disease Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AUC\\\\ \\\\(I\\\\.\\\\ Obstruction\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(I\\\\.\\\\ Obstruction\\\\) ,  UK CF trust - Disease Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### I\\\\.\\\\ Obstruction\n",
      "Creating ratio df for  I\\\\.\\\\ Obstruction ,  UK CF trust - Disease Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AUC\\\\ \\\\(K\\\\.\\\\ Pneumonia\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(K\\\\.\\\\ Pneumonia\\\\) ,  UK CF trust - Disease Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AUC\\\\ \\\\(E\\\\.\\\\ Coli\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(E\\\\.\\\\ Coli\\\\) ,  UK CF trust - Disease Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AUC\\\\ \\\\(Aspergillus\\\\)\n",
      "Creating ratio df for  AUC\\\\ \\\\(Aspergillus\\\\) ,  UK CF trust - Disease Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\n",
      "Creating ratio df for  MAE ,  UNBC-McMaster ShoulderPain dataset - Pain Intensity Regression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\-score\\\\ \\\\(at\\\\-IoU\\\\ =\\\\ 0\\\\.3\\\\)\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(at\\\\-IoU\\\\ =\\\\ 0\\\\.3\\\\) ,  MASS SS2 - K-complex detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(at\\\\-IoU\\\\ =\\\\ 0\\\\.3\\\\) ,  MASS SS2 - Spindle Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(at\\\\-IoU\\\\ =\\\\ 0\\\\.3\\\\) ,  MESA - Sleep Arousal Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(at\\\\-IoU\\\\ =\\\\ 0\\\\.3\\\\) ,  Wisconsin Sleep Cohort (WSC) - Spindle Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1\\\\-score\\\\ \\\\(at\\\\-IoU\\\\ =\\\\ 0\\\\.3\\\\) ,  Stanford Sleep Cohort (SSC) - Spindle Detection benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  6\n",
      "####### Mean\\\\ Accuracy\n",
      "Creating ratio df for  Mean\\\\ Accuracy ,  Barrettâ€™s Esophagus - Medical Object Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ for\\\\ SBP\\\\ \\\\[mmHg\\\\]\n",
      "Creating ratio df for  MAE\\\\ for\\\\ SBP\\\\ \\\\[mmHg\\\\] ,  MIMIC-III - Blood pressure estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ for\\\\ DBP\\\\ \\\\[mmHg\\\\]\n",
      "Creating ratio df for  MAE\\\\ for\\\\ DBP\\\\ \\\\[mmHg\\\\] ,  MIMIC-III - Blood pressure estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### F1\\\\ \\\\(Hidden\\\\ Test\\\\ Set\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(Hidden\\\\ Test\\\\ Set\\\\) ,  The PhysioNet Computing in Cardiology Challenge 2017 - Arrhythmia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ \\\\(Hidden\\\\ Test\\\\ Set\\\\) ,  The China Physiological Signal Challenge 2018 - Arrhythmia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### FLOPS\n",
      "Creating ratio df for  FLOPS ,  ChestX-ray14 - Pneumonia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AUROC\n",
      "Creating ratio df for  AUROC ,  ChestX-ray14 - Pneumonia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUROC ,  You Snooze You Win - The PhysioNet Computing in Cardiology Challenge 2018 - Sleep Arousal Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Params\n",
      "Creating ratio df for  Params ,  ChestX-ray14 - Pneumonia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(median\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(median\\\\) ,  LUMC - Pulmonary Arteryâ€“Vein Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(median\\\\) ,  SunYs - Pulmonary Arteryâ€“Vein Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  5\n",
      "####### F1\n",
      "Creating ratio df for  F1 ,  EBM-NLP - Participant Intervention Comparison Outcome Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  MICHE - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  CASIA - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  UBIRIS - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  PhysioNet Challenge 2017 - Atrial Fibrillation Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Average\\\\ Class\\\\ Accuracy\n",
      "Creating ratio df for  Average\\\\ Class\\\\ Accuracy ,  CT Lesion Stroke Dataset - Stroke Classification from CT data benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### mIoU\n",
      "Creating ratio df for  mIoU ,  2018 Data Science Bowl - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  MICHE - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  CASIA - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  UBIRIS - Iris Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  LUNA - Lung Nodule Segmentation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  Montgomery County - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  mIoU ,  DRIVE - Retinal Vessel Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### GPU\\\\ sec\n",
      "Creating ratio df for  GPU\\\\ sec ,  OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP - Diffeomorphic Medical Image Registration benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\(10\\\\-fold\\\\)\n",
      "Creating ratio df for  Accuracy\\\\(10\\\\-fold\\\\) ,  LIDC-IDRI - Lung Nodule Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\ \\\\(Set\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(Set\\\\) ,  \\\"Cardiologist-level\\\" 12-rhythm ECG dataset - Arrhythmia Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### VInfo\n",
      "Creating ratio df for  VInfo ,  ISBI 2012 EM Segmentation - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### VRand\n",
      "Creating ratio df for  VRand ,  ISBI 2012 EM Segmentation - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MSE\n",
      "Creating ratio df for  MSE ,  UnoViS_auto2012 - ECG Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\ \\\\(1dAVb\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(1dAVb\\\\) ,  Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG) - ECG Classification benchmarking , ds_count= 1\n",
      "null\n",
      "####### F1\\\\ \\\\(RBBB\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(RBBB\\\\) ,  Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG) - ECG Classification benchmarking , ds_count= 1\n",
      "null\n",
      "####### F1\\\\ \\\\(LBBB\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(LBBB\\\\) ,  Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG) - ECG Classification benchmarking , ds_count= 1\n",
      "null\n",
      "####### F1\\\\ \\\\(SB\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(SB\\\\) ,  Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG) - ECG Classification benchmarking , ds_count= 1\n",
      "null\n",
      "####### F1\\\\ \\\\(AF\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(AF\\\\) ,  Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG) - ECG Classification benchmarking , ds_count= 1\n",
      "null\n",
      "####### F1\\\\ \\\\(ST\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(ST\\\\) ,  Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG) - ECG Classification benchmarking , ds_count= 1\n",
      "null\n",
      "####### Average\\\\ Precision\n",
      "Creating ratio df for  Average\\\\ Precision ,  BioGRID (human) - Gene Interaction Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Average\\\\ Precision ,  BioGRID(yeast) - Gene Interaction Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "####### AVD\n",
      "Creating ratio df for  AVD ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### VS\n",
      "Creating ratio df for  VS ,  NIH - Lung Nodule Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  VS ,  HSVM - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  VS ,  CHAOS MRI Dataset - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  VS ,  BRATS 2018 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### ROC\\\\-AUC\n",
      "Creating ratio df for  ROC\\\\-AUC ,  PhysioNet Challenge 2017 - Atrial Fibrillation Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PR\\\\-AUC\n",
      "Creating ratio df for  PR\\\\-AUC ,  PhysioNet Challenge 2017 - Atrial Fibrillation Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Total\\\\ Variation\\\\ of\\\\ Information\n",
      "Creating ratio df for  Total\\\\ Variation\\\\ of\\\\ Information ,  SNEMI3D - Electron Microscopy Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### VI\\\\ Split\n",
      "Creating ratio df for  VI\\\\ Split ,  SNEMI3D - Electron Microscopy Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### VI\\\\ Merge\n",
      "Creating ratio df for  VI\\\\ Merge ,  SNEMI3D - Electron Microscopy Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MSD\n",
      "Creating ratio df for  MSD ,  HSVM - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSD ,  CHAOS MRI Dataset - Medical Image Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSD ,  BRATS 2018 - Brain Tumor Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Diversity\n",
      "Creating ratio df for  Diversity ,  QED - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Diversity ,  DRD2 - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Success\n",
      "Creating ratio df for  Success ,  QED - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Success ,  DRD2 - Drug Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Specificity\\\\ \\\\(VEB\\\\+\\\\)\n",
      "Creating ratio df for  Specificity\\\\ \\\\(VEB\\\\+\\\\) ,  AHA - Heartbeat Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(VEB\\\\+\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(VEB\\\\+\\\\) ,  AHA - Heartbeat Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PPV\\\\ \\\\(VEB\\\\+\\\\)\n",
      "Creating ratio df for  PPV\\\\ \\\\(VEB\\\\+\\\\) ,  AHA - Heartbeat Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Sensitivity\\\\ \\\\(VEB\\\\+\\\\)\n",
      "Creating ratio df for  Sensitivity\\\\ \\\\(VEB\\\\+\\\\) ,  AHA - Heartbeat Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\-Score\n",
      "Creating ratio df for  F1\\\\-Score ,  ISIC 2018 - Lesion Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AUPRC\n",
      "Creating ratio df for  AUPRC ,  You Snooze You Win - The PhysioNet Computing in Cardiology Challenge 2018 - Sleep Arousal Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Q3\n",
      "Creating ratio df for  Q3 ,  2019_test set - Protein Secondary Structure Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Q3 ,  2017_test set - Protein Secondary Structure Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### ODRMSE\n",
      "Creating ratio df for  ODRMSE ,  ultracold fermions Technion system, pixelfly - Image Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Arrhythmia Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Arrhythmia Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-04",
          "2018-08",
          "2019-07",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Arrhythmia Detection",
          "Arrhythmia Detection",
          "Arrhythmia Detection",
          "Arrhythmia Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Atrial Fibrillation Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Atrial Fibrillation Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-02",
          "2018-08"
         ],
         "xaxis": "x",
         "y": [
          "Atrial Fibrillation Detection",
          "Atrial Fibrillation Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Color Image Denoising",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Color Image Denoising",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-04",
          "2018-02",
          "2018-07",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Color Image Denoising",
          "Color Image Denoising",
          "Color Image Denoising",
          "Color Image Denoising"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Drug Discovery",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Drug Discovery",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2017-09",
          "2018-06",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Drug Discovery",
          "Drug Discovery",
          "Drug Discovery",
          "Drug Discovery"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Electron Microscopy Image Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Electron Microscopy Image Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-06",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Electron Microscopy Image Segmentation",
          "Electron Microscopy Image Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Grayscale Image Denoising",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Grayscale Image Denoising",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-08",
          "2017-04",
          "2018-05",
          "2018-06",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Lesion Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Lesion Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-10",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "Lesion Segmentation",
          "Lesion Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Lung Nodule Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Lung Nodule Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-11",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Lung Nodule Segmentation",
          "Lung Nodule Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Medical Image Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Medical Image Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-11",
          "2018-07"
         ],
         "xaxis": "x",
         "y": [
          "Medical Image Segmentation",
          "Medical Image Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multi-tissue Nucleus Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multi-tissue Nucleus Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-05",
          "2017-03"
         ],
         "xaxis": "x",
         "y": [
          "Multi-tissue Nucleus Segmentation",
          "Multi-tissue Nucleus Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Nuclear Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Nuclear Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-03",
          "2018-09"
         ],
         "xaxis": "x",
         "y": [
          "Nuclear Segmentation",
          "Nuclear Segmentation",
          "Nuclear Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Pancreas Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Pancreas Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-09",
          "2018-04"
         ],
         "xaxis": "x",
         "y": [
          "Pancreas Segmentation",
          "Pancreas Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Retinal Vessel Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Retinal Vessel Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-11",
          "2018-02",
          "2018-06",
          "2018-10",
          "2019-07",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Skin Cancer Segmentation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Skin Cancer Segmentation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-11",
          "2018-02"
         ],
         "xaxis": "x",
         "y": [
          "Skin Cancer Segmentation",
          "Skin Cancer Segmentation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Spindle Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Spindle Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08",
          "2018-12"
         ],
         "xaxis": "x",
         "y": [
          "Spindle Detection",
          "Spindle Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Arrhythmia Detection<BR>task: Arrhythmia Detection<BR>date: 2018-04<BR>ratio: 0.01",
          "Arrhythmia Detection<BR>task: Arrhythmia Detection<BR>date: 2018-08<BR>ratio: 0.13",
          "Arrhythmia Detection<BR>task: Arrhythmia Detection<BR>date: 2019-07<BR>ratio: 0.06",
          "Arrhythmia Detection<BR>task: Arrhythmia Detection<BR>date: 2019-08<BR>ratio: 0.0",
          "Atrial Fibrillation Detection<BR>task: Atrial Fibrillation Detection<BR>date: 2014-02<BR>ratio: 0.03",
          "Atrial Fibrillation Detection<BR>task: Atrial Fibrillation Detection<BR>date: 2018-08<BR>ratio: 0.02",
          "Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2017-04<BR>ratio: 0.38",
          "Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2018-02<BR>ratio: 0.01",
          "Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2018-07<BR>ratio: 0.06",
          "Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2019-04<BR>ratio: 0.01",
          "Drug Discovery<BR>task: Drug Discovery<BR>date: 2016-03<BR>ratio: 0.46",
          "Drug Discovery<BR>task: Drug Discovery<BR>date: 2017-09<BR>ratio: 0.0",
          "Drug Discovery<BR>task: Drug Discovery<BR>date: 2018-06<BR>ratio: 0.0",
          "Drug Discovery<BR>task: Drug Discovery<BR>date: 2019-05<BR>ratio: 0.0",
          "Electron Microscopy Image Segmentation<BR>task: Electron Microscopy Image Segmentation<BR>date: 2019-06<BR>ratio: 0.48",
          "Electron Microscopy Image Segmentation<BR>task: Electron Microscopy Image Segmentation<BR>date: 2019-08<BR>ratio: 0.0",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2016-08<BR>ratio: 0.33",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2017-04<BR>ratio: 0.5",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2018-05<BR>ratio: 0.18",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2018-06<BR>ratio: 0.01",
          "Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2019-10<BR>ratio: 0.16",
          "Lesion Segmentation<BR>task: Lesion Segmentation<BR>date: 2018-10<BR>ratio: 0.47",
          "Lesion Segmentation<BR>task: Lesion Segmentation<BR>date: 2020-03<BR>ratio: 0.0",
          "Lung Nodule Segmentation<BR>task: Lung Nodule Segmentation<BR>date: 2017-11<BR>ratio: 0.0",
          "Lung Nodule Segmentation<BR>task: Lung Nodule Segmentation<BR>date: 2019-08<BR>ratio: 0.5",
          "Medical Image Segmentation<BR>task: Medical Image Segmentation<BR>date: 2015-11<BR>ratio: 0.2",
          "Medical Image Segmentation<BR>task: Medical Image Segmentation<BR>date: 2018-07<BR>ratio: 0.4",
          "Multi-tissue Nucleus Segmentation<BR>task: Multi-tissue Nucleus Segmentation<BR>date: 2015-05<BR>ratio: 0.33",
          "Multi-tissue Nucleus Segmentation<BR>task: Multi-tissue Nucleus Segmentation<BR>date: 2017-03<BR>ratio: 0.06",
          "Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2016-11<BR>ratio: 0.0",
          "Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2017-03<BR>ratio: 0.13",
          "Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2018-09<BR>ratio: 0.0",
          "Pancreas Segmentation<BR>task: Pancreas Segmentation<BR>date: 2017-09<BR>ratio: 0.11",
          "Pancreas Segmentation<BR>task: Pancreas Segmentation<BR>date: 2018-04<BR>ratio: 0.0",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2017-11<BR>ratio: 0.0",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-02<BR>ratio: 0.0",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-06<BR>ratio: 0.33",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-10<BR>ratio: 0.0",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2019-07<BR>ratio: 0.5",
          "Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2019-12<BR>ratio: 0.0",
          "Skin Cancer Segmentation<BR>task: Skin Cancer Segmentation<BR>date: 2017-11<BR>ratio: 0.0",
          "Skin Cancer Segmentation<BR>task: Skin Cancer Segmentation<BR>date: 2018-02<BR>ratio: 0.0",
          "Spindle Detection<BR>task: Spindle Detection<BR>date: 2017-08<BR>ratio: 0.0",
          "Spindle Detection<BR>task: Spindle Detection<BR>date: 2018-12<BR>ratio: 0.27"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.01,
           0.13,
           0.06,
           0,
           0.03,
           0.02,
           0.38,
           0.01,
           0.06,
           0.01,
           0.46,
           0,
           0,
           0,
           0.48,
           0,
           0.33,
           0.5,
           0.18,
           0.01,
           0.16,
           0.47,
           0,
           0,
           0.5,
           0.2,
           0.4,
           0.33,
           0.06,
           0,
           0.13,
           0,
           0.11,
           0,
           0,
           0,
           0.33,
           0,
           0.5,
           0,
           0,
           0,
           0,
           0.27
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2018-04",
          "2018-08",
          "2019-07",
          "2019-08",
          "2014-02",
          "2018-08",
          "2017-04",
          "2018-02",
          "2018-07",
          "2019-04",
          "2016-03",
          "2017-09",
          "2018-06",
          "2019-05",
          "2019-06",
          "2019-08",
          "2016-08",
          "2017-04",
          "2018-05",
          "2018-06",
          "2019-10",
          "2018-10",
          "2020-03",
          "2017-11",
          "2019-08",
          "2015-11",
          "2018-07",
          "2015-05",
          "2017-03",
          "2016-11",
          "2017-03",
          "2018-09",
          "2017-09",
          "2018-04",
          "2017-11",
          "2018-02",
          "2018-06",
          "2018-10",
          "2019-07",
          "2019-12",
          "2017-11",
          "2018-02",
          "2017-08",
          "2018-12"
         ],
         "y": [
          "Arrhythmia Detection",
          "Arrhythmia Detection",
          "Arrhythmia Detection",
          "Arrhythmia Detection",
          "Atrial Fibrillation Detection",
          "Atrial Fibrillation Detection",
          "Color Image Denoising",
          "Color Image Denoising",
          "Color Image Denoising",
          "Color Image Denoising",
          "Drug Discovery",
          "Drug Discovery",
          "Drug Discovery",
          "Drug Discovery",
          "Electron Microscopy Image Segmentation",
          "Electron Microscopy Image Segmentation",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Grayscale Image Denoising",
          "Lesion Segmentation",
          "Lesion Segmentation",
          "Lung Nodule Segmentation",
          "Lung Nodule Segmentation",
          "Medical Image Segmentation",
          "Medical Image Segmentation",
          "Multi-tissue Nucleus Segmentation",
          "Multi-tissue Nucleus Segmentation",
          "Nuclear Segmentation",
          "Nuclear Segmentation",
          "Nuclear Segmentation",
          "Pancreas Segmentation",
          "Pancreas Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Retinal Vessel Segmentation",
          "Skin Cancer Segmentation",
          "Skin Cancer Segmentation",
          "Spindle Detection",
          "Spindle Detection"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Spindle Detection",
          "Skin Cancer Segmentation",
          "Retinal Vessel Segmentation",
          "Pancreas Segmentation",
          "Nuclear Segmentation",
          "Multi-tissue Nucleus Segmentation",
          "Medical Image Segmentation",
          "Lung Nodule Segmentation",
          "Lesion Segmentation",
          "Grayscale Image Denoising",
          "Electron Microscopy Image Segmentation",
          "Drug Discovery",
          "Color Image Denoising",
          "Atrial Fibrillation Detection",
          "Arrhythmia Detection"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00126: Biomedical AI process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"e2aeaf19-7ab4-4261-af89-70db61884057\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e2aeaf19-7ab4-4261-af89-70db61884057\")) {                    Plotly.newPlot(                        \"e2aeaf19-7ab4-4261-af89-70db61884057\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Arrhythmia Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Arrhythmia Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-04\", \"2018-08\", \"2019-07\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Arrhythmia Detection\", \"Arrhythmia Detection\", \"Arrhythmia Detection\", \"Arrhythmia Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Atrial Fibrillation Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Atrial Fibrillation Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-02\", \"2018-08\"], \"xaxis\": \"x\", \"y\": [\"Atrial Fibrillation Detection\", \"Atrial Fibrillation Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Color Image Denoising\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Color Image Denoising\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-04\", \"2018-02\", \"2018-07\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Color Image Denoising\", \"Color Image Denoising\", \"Color Image Denoising\", \"Color Image Denoising\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Drug Discovery\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Drug Discovery\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2017-09\", \"2018-06\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Drug Discovery\", \"Drug Discovery\", \"Drug Discovery\", \"Drug Discovery\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Electron Microscopy Image Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Electron Microscopy Image Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-06\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Electron Microscopy Image Segmentation\", \"Electron Microscopy Image Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Grayscale Image Denoising\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Grayscale Image Denoising\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-08\", \"2017-04\", \"2018-05\", \"2018-06\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Lesion Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Lesion Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-10\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"Lesion Segmentation\", \"Lesion Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Lung Nodule Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Lung Nodule Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-11\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Lung Nodule Segmentation\", \"Lung Nodule Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Medical Image Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Medical Image Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-11\", \"2018-07\"], \"xaxis\": \"x\", \"y\": [\"Medical Image Segmentation\", \"Medical Image Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multi-tissue Nucleus Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multi-tissue Nucleus Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-05\", \"2017-03\"], \"xaxis\": \"x\", \"y\": [\"Multi-tissue Nucleus Segmentation\", \"Multi-tissue Nucleus Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Nuclear Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Nuclear Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-03\", \"2018-09\"], \"xaxis\": \"x\", \"y\": [\"Nuclear Segmentation\", \"Nuclear Segmentation\", \"Nuclear Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Pancreas Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Pancreas Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-09\", \"2018-04\"], \"xaxis\": \"x\", \"y\": [\"Pancreas Segmentation\", \"Pancreas Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Retinal Vessel Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Retinal Vessel Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-11\", \"2018-02\", \"2018-06\", \"2018-10\", \"2019-07\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Skin Cancer Segmentation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Skin Cancer Segmentation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-11\", \"2018-02\"], \"xaxis\": \"x\", \"y\": [\"Skin Cancer Segmentation\", \"Skin Cancer Segmentation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Spindle Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Spindle Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-08\", \"2018-12\"], \"xaxis\": \"x\", \"y\": [\"Spindle Detection\", \"Spindle Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Arrhythmia Detection<BR>task: Arrhythmia Detection<BR>date: 2018-04<BR>ratio: 0.01\", \"Arrhythmia Detection<BR>task: Arrhythmia Detection<BR>date: 2018-08<BR>ratio: 0.13\", \"Arrhythmia Detection<BR>task: Arrhythmia Detection<BR>date: 2019-07<BR>ratio: 0.06\", \"Arrhythmia Detection<BR>task: Arrhythmia Detection<BR>date: 2019-08<BR>ratio: 0.0\", \"Atrial Fibrillation Detection<BR>task: Atrial Fibrillation Detection<BR>date: 2014-02<BR>ratio: 0.03\", \"Atrial Fibrillation Detection<BR>task: Atrial Fibrillation Detection<BR>date: 2018-08<BR>ratio: 0.02\", \"Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2017-04<BR>ratio: 0.38\", \"Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2018-02<BR>ratio: 0.01\", \"Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2018-07<BR>ratio: 0.06\", \"Color Image Denoising<BR>task: Color Image Denoising<BR>date: 2019-04<BR>ratio: 0.01\", \"Drug Discovery<BR>task: Drug Discovery<BR>date: 2016-03<BR>ratio: 0.46\", \"Drug Discovery<BR>task: Drug Discovery<BR>date: 2017-09<BR>ratio: 0.0\", \"Drug Discovery<BR>task: Drug Discovery<BR>date: 2018-06<BR>ratio: 0.0\", \"Drug Discovery<BR>task: Drug Discovery<BR>date: 2019-05<BR>ratio: 0.0\", \"Electron Microscopy Image Segmentation<BR>task: Electron Microscopy Image Segmentation<BR>date: 2019-06<BR>ratio: 0.48\", \"Electron Microscopy Image Segmentation<BR>task: Electron Microscopy Image Segmentation<BR>date: 2019-08<BR>ratio: 0.0\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2016-08<BR>ratio: 0.33\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2017-04<BR>ratio: 0.5\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2018-05<BR>ratio: 0.18\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2018-06<BR>ratio: 0.01\", \"Grayscale Image Denoising<BR>task: Grayscale Image Denoising<BR>date: 2019-10<BR>ratio: 0.16\", \"Lesion Segmentation<BR>task: Lesion Segmentation<BR>date: 2018-10<BR>ratio: 0.47\", \"Lesion Segmentation<BR>task: Lesion Segmentation<BR>date: 2020-03<BR>ratio: 0.0\", \"Lung Nodule Segmentation<BR>task: Lung Nodule Segmentation<BR>date: 2017-11<BR>ratio: 0.0\", \"Lung Nodule Segmentation<BR>task: Lung Nodule Segmentation<BR>date: 2019-08<BR>ratio: 0.5\", \"Medical Image Segmentation<BR>task: Medical Image Segmentation<BR>date: 2015-11<BR>ratio: 0.2\", \"Medical Image Segmentation<BR>task: Medical Image Segmentation<BR>date: 2018-07<BR>ratio: 0.4\", \"Multi-tissue Nucleus Segmentation<BR>task: Multi-tissue Nucleus Segmentation<BR>date: 2015-05<BR>ratio: 0.33\", \"Multi-tissue Nucleus Segmentation<BR>task: Multi-tissue Nucleus Segmentation<BR>date: 2017-03<BR>ratio: 0.06\", \"Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2016-11<BR>ratio: 0.0\", \"Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2017-03<BR>ratio: 0.13\", \"Nuclear Segmentation<BR>task: Nuclear Segmentation<BR>date: 2018-09<BR>ratio: 0.0\", \"Pancreas Segmentation<BR>task: Pancreas Segmentation<BR>date: 2017-09<BR>ratio: 0.11\", \"Pancreas Segmentation<BR>task: Pancreas Segmentation<BR>date: 2018-04<BR>ratio: 0.0\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2017-11<BR>ratio: 0.0\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-02<BR>ratio: 0.0\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-06<BR>ratio: 0.33\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2018-10<BR>ratio: 0.0\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2019-07<BR>ratio: 0.5\", \"Retinal Vessel Segmentation<BR>task: Retinal Vessel Segmentation<BR>date: 2019-12<BR>ratio: 0.0\", \"Skin Cancer Segmentation<BR>task: Skin Cancer Segmentation<BR>date: 2017-11<BR>ratio: 0.0\", \"Skin Cancer Segmentation<BR>task: Skin Cancer Segmentation<BR>date: 2018-02<BR>ratio: 0.0\", \"Spindle Detection<BR>task: Spindle Detection<BR>date: 2017-08<BR>ratio: 0.0\", \"Spindle Detection<BR>task: Spindle Detection<BR>date: 2018-12<BR>ratio: 0.27\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.01, 0.13, 0.06, 0.0, 0.03, 0.02, 0.38, 0.01, 0.06, 0.01, 0.46, 0.0, 0.0, 0.0, 0.48, 0.0, 0.33, 0.5, 0.18, 0.01, 0.16, 0.47, 0.0, 0.0, 0.5, 0.2, 0.4, 0.33, 0.06, 0.0, 0.13, 0.0, 0.11, 0.0, 0.0, 0.0, 0.33, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.27], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2018-04\", \"2018-08\", \"2019-07\", \"2019-08\", \"2014-02\", \"2018-08\", \"2017-04\", \"2018-02\", \"2018-07\", \"2019-04\", \"2016-03\", \"2017-09\", \"2018-06\", \"2019-05\", \"2019-06\", \"2019-08\", \"2016-08\", \"2017-04\", \"2018-05\", \"2018-06\", \"2019-10\", \"2018-10\", \"2020-03\", \"2017-11\", \"2019-08\", \"2015-11\", \"2018-07\", \"2015-05\", \"2017-03\", \"2016-11\", \"2017-03\", \"2018-09\", \"2017-09\", \"2018-04\", \"2017-11\", \"2018-02\", \"2018-06\", \"2018-10\", \"2019-07\", \"2019-12\", \"2017-11\", \"2018-02\", \"2017-08\", \"2018-12\"], \"y\": [\"Arrhythmia Detection\", \"Arrhythmia Detection\", \"Arrhythmia Detection\", \"Arrhythmia Detection\", \"Atrial Fibrillation Detection\", \"Atrial Fibrillation Detection\", \"Color Image Denoising\", \"Color Image Denoising\", \"Color Image Denoising\", \"Color Image Denoising\", \"Drug Discovery\", \"Drug Discovery\", \"Drug Discovery\", \"Drug Discovery\", \"Electron Microscopy Image Segmentation\", \"Electron Microscopy Image Segmentation\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Grayscale Image Denoising\", \"Lesion Segmentation\", \"Lesion Segmentation\", \"Lung Nodule Segmentation\", \"Lung Nodule Segmentation\", \"Medical Image Segmentation\", \"Medical Image Segmentation\", \"Multi-tissue Nucleus Segmentation\", \"Multi-tissue Nucleus Segmentation\", \"Nuclear Segmentation\", \"Nuclear Segmentation\", \"Nuclear Segmentation\", \"Pancreas Segmentation\", \"Pancreas Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Retinal Vessel Segmentation\", \"Skin Cancer Segmentation\", \"Skin Cancer Segmentation\", \"Spindle Detection\", \"Spindle Detection\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Spindle Detection\", \"Skin Cancer Segmentation\", \"Retinal Vessel Segmentation\", \"Pancreas Segmentation\", \"Nuclear Segmentation\", \"Multi-tissue Nucleus Segmentation\", \"Medical Image Segmentation\", \"Lung Nodule Segmentation\", \"Lesion Segmentation\", \"Grayscale Image Denoising\", \"Electron Microscopy Image Segmentation\", \"Drug Discovery\", \"Color Image Denoising\", \"Atrial Fibrillation Detection\", \"Arrhythmia Detection\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00126: Biomedical AI process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e2aeaf19-7ab4-4261-af89-70db61884057');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00131\n",
      "Number of metrics:  70\n",
      "####### MAE\\\\ \\\\(10%\\\\ missing\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(10%\\\\ missing\\\\) ,  UCI localization data - Multivariate Time Series Imputation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(10%\\\\ of\\\\ data\\\\ as\\\\ GT\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(10%\\\\ of\\\\ data\\\\ as\\\\ GT\\\\) ,  PhysioNet Challenge 2012 - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(PM2\\\\.5\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(PM2\\\\.5\\\\) ,  Beijing Air Quality - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MSE\\\\ \\\\(10%\\\\ missing\\\\)\n",
      "Creating ratio df for  MSE\\\\ \\\\(10%\\\\ missing\\\\) ,  KDD CUP Challenge 2018 - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  UWA3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  CAD-120 - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  GPS - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Cambridge - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  VIVA Hand Gestures Dataset - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  UT-Kinect - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Florence 3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  SEED-IV - Electroencephalogram (EEG) process benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  SEED - Electroencephalogram (EEG) process benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Gaming 3D (G3D) - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  SBU - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  BPI challenge \\'12 - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Helpdesk - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SYSU 3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  ChaLearn val - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Kinetics-Skeleton dataset - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  EgoGesture - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  BUAA - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SmartWatch - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MGB - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Chalearn 2014 - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  LP1 - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  AUSLAN - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  NetFlow - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  LP3 - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ArabicDigits - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  UWave - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  LP5 - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  LP2 - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Shapes - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Libras - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ECG - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  LP4 - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  N-UCLA - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  ChaLean test - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  NVGesture - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  ChaLearn 2013 - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MSRC-12 - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ChaLearn 2016 - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Northwestern University - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CapgMyo DB-c - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CapgMyo DB-b - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Ninapro DB-1 12 gestures - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Ninapro DB-1 8 gestures - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Bitcoin-Alpha - Time Series process benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MSR Action3D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  UPenn Action - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  DHG-28 - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  DHG-14 - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  72\n",
      "####### Accuracy\\\\ \\\\(CV\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\) ,  NTU RGB+D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(CS\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CS\\\\) ,  NTU RGB+D - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CS\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### MAE\\\\ \\\\(60\\\\ min\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(60\\\\ min\\\\) ,  PeMS-M - Traffic Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(RGB\\\\+pose\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(RGB\\\\+pose\\\\) ,  J-HMDB - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Error\\\\ rate\n",
      "Creating ratio df for  Error\\\\ rate ,  Montalbano - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Precision\n",
      "Creating ratio df for  Precision ,  Montalbano - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Recall\n",
      "Creating ratio df for  Recall ,  Montalbano - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Jaccard\\\\ \\\\(Mean\\\\)\n",
      "Creating ratio df for  Jaccard\\\\ \\\\(Mean\\\\) ,  Montalbano - Gesture Recognition benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Cross\\\\-Setup\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Setup\\\\) ,  NTU RGB+D 120 - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(CV\\\\ I\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\ I\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Accuracy\\\\ \\\\(CV\\\\ II\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(CV\\\\ II\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(AV\\\\ I\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(AV\\\\ I\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(AV\\\\ II\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(AV\\\\ II\\\\) ,  Varying-view RGB-D Action-Skeleton - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Accuracy\\\\ \\\\(Cross\\\\-Subject\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Cross\\\\-Subject\\\\) ,  NTU RGB+D 120 - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### AUC\n",
      "Creating ratio df for  AUC ,  PhysioNet Challenge 2012 - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Physionet 2017 Atrial Fibrillation - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### MSE\\\\ \\\\(10\\\\^2,\\\\ 50%\\\\ missing\\\\)\n",
      "Creating ratio df for  MSE\\\\ \\\\(10\\\\^2,\\\\ 50%\\\\ missing\\\\) ,  MuJoCo - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MSE\\\\ \\\\(10\\\\^\\\\-2,\\\\ 50%\\\\ missing\\\\)\n",
      "Creating ratio df for  MSE\\\\ \\\\(10\\\\^\\\\-2,\\\\ 50%\\\\ missing\\\\) ,  MuJoCo - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### AUC\\\\ Stdev\n",
      "Creating ratio df for  AUC\\\\ Stdev ,  PhysioNet Challenge 2012 - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MSE\n",
      "Creating ratio df for  MSE ,  USHCN-Daily - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MSE ,  MIMIC-III - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MSE ,  Human3.6M - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### NegLL\n",
      "Creating ratio df for  NegLL ,  MIMIC-III - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PCK\\\\-at\\\\-0\\\\.1\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.1 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### PCK\\\\-at\\\\-0\\\\.2\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.2 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.3\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.3 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.4\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.4 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### PCK\\\\-at\\\\-0\\\\.5\n",
      "Creating ratio df for  PCK\\\\-at\\\\-0\\\\.5 ,  JHMDB Pose Tracking - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Average\\\\ accuracy\\\\ of\\\\ 3\\\\ splits\n",
      "Creating ratio df for  Average\\\\ accuracy\\\\ of\\\\ 3\\\\ splits ,  JHMDB (2D poses only) - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CV\\\\)\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CV\\\\) ,  PKU-MMD - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CS\\\\)\n",
      "Creating ratio df for  mAP\\\\-at\\\\-0\\\\.50\\\\ \\\\(CS\\\\) ,  PKU-MMD - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### RMSE\n",
      "Creating ratio df for  RMSE ,  PEMS-BAY - Traffic Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ @\\\\ 12\\\\ step\n",
      "Creating ratio df for  MAE\\\\ @\\\\ 12\\\\ step ,  METR-LA - Traffic Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE\\\\ @\\\\ 12\\\\ step ,  PEMS-BAY - Traffic Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### F1\\\\ \\\\(Hidden\\\\ Test\\\\ Set\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(Hidden\\\\ Test\\\\ Set\\\\) ,  Physionet 2017 Atrial Fibrillation - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 10%\n",
      "Creating ratio df for  10% ,  J-HMBD Early Action - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Top\\\\ 1\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  Jester test - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Top\\\\ 1\\\\ Accuracy ,  Jester val - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Absolute\\\\ Time\\\\ \\\\(ms\\\\)\n",
      "Creating ratio df for  Absolute\\\\ Time\\\\ \\\\(ms\\\\) ,  AATLD Gesture Recognition - Time Series Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\n",
      "Creating ratio df for  MAE ,  Human3.6M - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### SSIM\n",
      "Creating ratio df for  SSIM ,  Human3.6M - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### L2\\\\ Loss\\\\ \\\\(10\\\\^\\\\-4\\\\)\n",
      "Creating ratio df for  L2\\\\ Loss\\\\ \\\\(10\\\\^\\\\-4\\\\) ,  PEMS-SF - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Path\\\\ Length\n",
      "Creating ratio df for  Path\\\\ Length ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Step\\\\ Change\\\\ \\\\(10\\\\^âˆ’3\\\\)\n",
      "Creating ratio df for  Step\\\\ Change\\\\ \\\\(10\\\\^âˆ’3\\\\) ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Path\\\\ Difference\n",
      "Creating ratio df for  Path\\\\ Difference ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Player\\\\ Distance\n",
      "Creating ratio df for  Player\\\\ Distance ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Accuracy\n",
      "Creating ratio df for  Average\\\\ Accuracy ,  UAV-Human - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### OOB\\\\ Rate\\\\ \\\\(10\\\\^âˆ’3\\\\)\n",
      "Creating ratio df for  OOB\\\\ Rate\\\\ \\\\(10\\\\^âˆ’3\\\\) ,  Basketball Players Movement - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Top\\\\ 5\\\\ Accuracy\n",
      "Creating ratio df for  Top\\\\ 5\\\\ Accuracy ,  Jester val - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NMI\\\\ \\\\(physiology_6_hours\\\\)\n",
      "Creating ratio df for  NMI\\\\ \\\\(physiology_6_hours\\\\) ,  eICU Collaborative Research Database - Time Series Clustering benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NMI\\\\ \\\\(physiology_12_hours\\\\)\n",
      "Creating ratio df for  NMI\\\\ \\\\(physiology_12_hours\\\\) ,  eICU Collaborative Research Database - Time Series Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NMI\\\\ \\\\(physiology_24_hours\\\\)\n",
      "Creating ratio df for  NMI\\\\ \\\\(physiology_24_hours\\\\) ,  eICU Collaborative Research Database - Time Series Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mse\\\\ \\\\(10\\\\^\\\\-3\\\\)\n",
      "Creating ratio df for  mse\\\\ \\\\(10\\\\^\\\\-3\\\\) ,  PhysioNet Challenge 2012 - Multivariate Time Series Imputation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  mse\\\\ \\\\(10\\\\^\\\\-3\\\\) ,  PhysioNet Challenge 2012 - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### MSE\\\\ stdev\n",
      "Creating ratio df for  MSE\\\\ stdev ,  PhysioNet Challenge 2012 - Multivariate Time Series Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Speed\\\\ \\\\ \\\\(FPS\\\\)\n",
      "Creating ratio df for  Speed\\\\ \\\\ \\\\(FPS\\\\) ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 14\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  SHREC 2017 - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  SHREC 2017 track on 3D Hand Gesture Recognition - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### 28\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  28\\\\ gestures\\\\ accuracy ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  28\\\\ gestures\\\\ accuracy ,  SHREC 2017 - Hand Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### ADE\\\\-8/12\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  ActEV - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  ETH/UCY - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  ActEV - Trajectory Forecasting benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ADE\\\\-8/12 ,  Hotel BIWI Walking Pedestrians dataset - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### FDE\\\\-8/12\n",
      "Creating ratio df for  FDE\\\\-8/12 ,  ActEV - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mAP\n",
      "Creating ratio df for  mAP ,  ActEV - Activity Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(70\\\\ min\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(70\\\\ min\\\\) ,  Paper Field - Time Series process benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### FDE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\)\n",
      "Creating ratio df for  FDE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\) ,  Stanford Drone - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ADE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\)\n",
      "Creating ratio df for  ADE\\\\ \\\\(in\\\\ world\\\\ coordinates\\\\) ,  Stanford Drone - Trajectory Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Test\\\\ Error\n",
      "Creating ratio df for  Test\\\\ Error ,  CMU Mocap-1 - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Test\\\\ Error ,  CMU Mocap-2 - Video Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  3\n",
      "####### No\\\\.\\\\ parameters\n",
      "Creating ratio df for  No\\\\.\\\\ parameters ,  JHMDB (2D poses only) - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  No\\\\.\\\\ parameters ,  SHREC 2017 track on 3D Hand Gesture Recognition - Skeleton Based Action Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Real\\\\ World\\\\ Accuracy\n",
      "Creating ratio df for  Real\\\\ World\\\\ Accuracy ,  GesturePod - Gesture Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(H50\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(H50\\\\) ,  FI-2010 - Stock Trend Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\ \\\\(H50\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(H50\\\\) ,  FI-2010 - Stock Trend Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 10\\\\ fold\\\\ Cross\\\\ validation\n",
      "Creating ratio df for  10\\\\ fold\\\\ Cross\\\\ validation ,  2019_test set - Stock Price Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Hand Gesture Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Hand Gesture Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-12",
          "2019-01"
         ],
         "xaxis": "x",
         "y": [
          "Hand Gesture Recognition",
          "Hand Gesture Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Multivariate Time Series Imputation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Multivariate Time Series Imputation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-06",
          "2018-12"
         ],
         "xaxis": "x",
         "y": [
          "Multivariate Time Series Imputation",
          "Multivariate Time Series Imputation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Skeleton Based Action Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Skeleton Based Action Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2012-07",
          "2013-02",
          "2016-04",
          "2016-06",
          "2016-09",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-11",
          "2018-12",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Time Series Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Time Series Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-06",
          "2018-05",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Time Series Classification",
          "Time Series Classification",
          "Time Series Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Video Prediction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Video Prediction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Video Prediction",
          "Video Prediction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Hand Gesture Recognition<BR>task: Hand Gesture Recognition<BR>date: 2018-12<BR>ratio: 0.02",
          "Hand Gesture Recognition<BR>task: Hand Gesture Recognition<BR>date: 2019-01<BR>ratio: 0.03",
          "Multivariate Time Series Imputation<BR>task: Multivariate Time Series Imputation<BR>date: 2016-06<BR>ratio: 0.12",
          "Multivariate Time Series Imputation<BR>task: Multivariate Time Series Imputation<BR>date: 2018-12<BR>ratio: 0.25",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2012-07<BR>ratio: 0.22",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2013-02<BR>ratio: 0.04",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-04<BR>ratio: 0.47",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-06<BR>ratio: 0.49",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-09<BR>ratio: 0.1",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-11<BR>ratio: 0.16",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-03<BR>ratio: 0.03",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-04<BR>ratio: 0.39",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-05<BR>ratio: 0.09",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-08<BR>ratio: 0.36",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-01<BR>ratio: 0.34",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-02<BR>ratio: 0.36",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-04<BR>ratio: 0.05",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-05<BR>ratio: 0.14",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-06<BR>ratio: 0.06",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-11<BR>ratio: 0.01",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-12<BR>ratio: 0.05",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-04<BR>ratio: 0.07",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-06<BR>ratio: 0.01",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-07<BR>ratio: 0.34",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-09<BR>ratio: 0.0",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-11<BR>ratio: 0.01",
          "Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-12<BR>ratio: 0.02",
          "Time Series Classification<BR>task: Time Series Classification<BR>date: 2016-06<BR>ratio: 0.49",
          "Time Series Classification<BR>task: Time Series Classification<BR>date: 2018-05<BR>ratio: 0.0",
          "Time Series Classification<BR>task: Time Series Classification<BR>date: 2019-09<BR>ratio: 0.03",
          "Video Prediction<BR>task: Video Prediction<BR>date: 2018-11<BR>ratio: 0.0",
          "Video Prediction<BR>task: Video Prediction<BR>date: 2019-05<BR>ratio: 0.5"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.02,
           0.03,
           0.12,
           0.25,
           0.22,
           0.04,
           0.47,
           0.49,
           0.1,
           0.16,
           0.03,
           0.39,
           0.09,
           0.36,
           0.34,
           0.36,
           0.05,
           0.14,
           0.06,
           0.01,
           0.05,
           0.07,
           0.01,
           0.34,
           0,
           0.01,
           0.02,
           0.49,
           0,
           0.03,
           0,
           0.5
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2018-12",
          "2019-01",
          "2016-06",
          "2018-12",
          "2012-07",
          "2013-02",
          "2016-04",
          "2016-06",
          "2016-09",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-11",
          "2018-12",
          "2019-04",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11",
          "2019-12",
          "2016-06",
          "2018-05",
          "2019-09",
          "2018-11",
          "2019-05"
         ],
         "y": [
          "Hand Gesture Recognition",
          "Hand Gesture Recognition",
          "Multivariate Time Series Imputation",
          "Multivariate Time Series Imputation",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Skeleton Based Action Recognition",
          "Time Series Classification",
          "Time Series Classification",
          "Time Series Classification",
          "Video Prediction",
          "Video Prediction"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Video Prediction",
          "Time Series Classification",
          "Skeleton Based Action Recognition",
          "Multivariate Time Series Imputation",
          "Hand Gesture Recognition"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00131: Time Series process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"ec2ea38a-da23-44a0-a5d0-f366d6e740a0\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ec2ea38a-da23-44a0-a5d0-f366d6e740a0\")) {                    Plotly.newPlot(                        \"ec2ea38a-da23-44a0-a5d0-f366d6e740a0\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Hand Gesture Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Hand Gesture Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-12\", \"2019-01\"], \"xaxis\": \"x\", \"y\": [\"Hand Gesture Recognition\", \"Hand Gesture Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Multivariate Time Series Imputation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Multivariate Time Series Imputation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-06\", \"2018-12\"], \"xaxis\": \"x\", \"y\": [\"Multivariate Time Series Imputation\", \"Multivariate Time Series Imputation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Skeleton Based Action Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Skeleton Based Action Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2012-07\", \"2013-02\", \"2016-04\", \"2016-06\", \"2016-09\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-11\", \"2018-12\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Time Series Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Time Series Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-06\", \"2018-05\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Time Series Classification\", \"Time Series Classification\", \"Time Series Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Video Prediction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Video Prediction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Video Prediction\", \"Video Prediction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Hand Gesture Recognition<BR>task: Hand Gesture Recognition<BR>date: 2018-12<BR>ratio: 0.02\", \"Hand Gesture Recognition<BR>task: Hand Gesture Recognition<BR>date: 2019-01<BR>ratio: 0.03\", \"Multivariate Time Series Imputation<BR>task: Multivariate Time Series Imputation<BR>date: 2016-06<BR>ratio: 0.12\", \"Multivariate Time Series Imputation<BR>task: Multivariate Time Series Imputation<BR>date: 2018-12<BR>ratio: 0.25\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2012-07<BR>ratio: 0.22\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2013-02<BR>ratio: 0.04\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-04<BR>ratio: 0.47\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-06<BR>ratio: 0.49\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-09<BR>ratio: 0.1\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2016-11<BR>ratio: 0.16\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-03<BR>ratio: 0.03\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-04<BR>ratio: 0.39\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-05<BR>ratio: 0.09\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2017-08<BR>ratio: 0.36\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-01<BR>ratio: 0.34\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-02<BR>ratio: 0.36\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-04<BR>ratio: 0.05\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-05<BR>ratio: 0.14\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-06<BR>ratio: 0.06\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-11<BR>ratio: 0.01\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2018-12<BR>ratio: 0.05\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-04<BR>ratio: 0.07\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-06<BR>ratio: 0.01\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-07<BR>ratio: 0.34\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-09<BR>ratio: 0.0\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-11<BR>ratio: 0.01\", \"Skeleton Based Action Recognition<BR>task: Skeleton Based Action Recognition<BR>date: 2019-12<BR>ratio: 0.02\", \"Time Series Classification<BR>task: Time Series Classification<BR>date: 2016-06<BR>ratio: 0.49\", \"Time Series Classification<BR>task: Time Series Classification<BR>date: 2018-05<BR>ratio: 0.0\", \"Time Series Classification<BR>task: Time Series Classification<BR>date: 2019-09<BR>ratio: 0.03\", \"Video Prediction<BR>task: Video Prediction<BR>date: 2018-11<BR>ratio: 0.0\", \"Video Prediction<BR>task: Video Prediction<BR>date: 2019-05<BR>ratio: 0.5\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.02, 0.03, 0.12, 0.25, 0.22, 0.04, 0.47, 0.49, 0.1, 0.16, 0.03, 0.39, 0.09, 0.36, 0.34, 0.36, 0.05, 0.14, 0.06, 0.01, 0.05, 0.07, 0.01, 0.34, 0.0, 0.01, 0.02, 0.49, 0.0, 0.03, 0.0, 0.5], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2018-12\", \"2019-01\", \"2016-06\", \"2018-12\", \"2012-07\", \"2013-02\", \"2016-04\", \"2016-06\", \"2016-09\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-11\", \"2018-12\", \"2019-04\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\", \"2019-12\", \"2016-06\", \"2018-05\", \"2019-09\", \"2018-11\", \"2019-05\"], \"y\": [\"Hand Gesture Recognition\", \"Hand Gesture Recognition\", \"Multivariate Time Series Imputation\", \"Multivariate Time Series Imputation\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Skeleton Based Action Recognition\", \"Time Series Classification\", \"Time Series Classification\", \"Time Series Classification\", \"Video Prediction\", \"Video Prediction\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Video Prediction\", \"Time Series Classification\", \"Skeleton Based Action Recognition\", \"Multivariate Time Series Imputation\", \"Hand Gesture Recognition\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00131: Time Series process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ec2ea38a-da23-44a0-a5d0-f366d6e740a0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00137\n",
      "Number of metrics:  42\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  PROTEINS - Graph Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Accuracy ,  HIV-fMRI-77  - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  HIV-DTI-77 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  BP-fMRI-97 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  BlogCatalog - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Wikipedia - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  NEURON-BINARY - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  NEURON-Average - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  NEURON-MULTI - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  FRANKENSTEIN - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  COLLAB - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  RE-M12K - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  NCI1 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  RE-M5K - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  IMDb-B - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  MUTAG - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  ENZYMES - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  D&D - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Accuracy ,  IMDb-M - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  PubMed (0.1%) - Node Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Cora (3%) - Node Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Cora (1%) - Node Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  PubMed with Public Split: fixed 20 nodes per class - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  PubMed (0.03%) - Node Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Cora with Public Split: fixed 20 nodes per class - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  PubMed (0.05%) - Node Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  CiteSeer (0.5%) - Node Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  CiteSeer (1%) - Node Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Cora (0.5%) - Node Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  CiteSeer with Public Split: fixed 20 nodes per class - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  20NEWS - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  IPC-lifted - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  IPC-grounded - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Cora - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Citeseer - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Pubmed - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Pubmed - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Citeseer - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  NELL - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  USA Air-Traffic - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Cora - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  PTC - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  NCI109 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Flickr - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Brazil Air-Traffic - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Cora Full-supervised - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Pubmed Full-supervised - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Facebook - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Citeseer Full-supervised - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Wiki-Vote - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Europe Air-Traffic - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Reddit - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Cora - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Pubmed - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Citeseer - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  BGS - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  AIFB - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MUTAG - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  AM - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  WordNet - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  AIDS - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  REDDIT-MULTI-12K - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  HIV dataset - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  NCI-83 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  NCI33 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  NCI-123 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  REDDIT-B - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MS ACADEMIC - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  YAGO39K - Triple Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Web - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  HYDRIDES - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SYNTHIE - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  COIL-RAG - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  NC1 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Accuracy ,  Cancer - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Wine - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Digits - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Cora - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  20NEWS - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Citeseer - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Citeseer (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Cora (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Pubmed (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Bitcoin-Alpha - Link Sign Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Epinions - Link Sign Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Slashdot - Link Sign Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  HIV-fMRI-77 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Coauthor CS - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  AMZ Photo - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  PPI - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  AMZ Comp - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Mutagenicity - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  REDDIT-MULTI-5k - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Coauthor Phy - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Cora: fixed 20 node per class - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  197\n",
      "####### F1\n",
      "Creating ratio df for  F1 ,  HIV-DTI-77 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  BP-fMRI-97 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  HIV-fMRI-77  - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F1 ,  PPI - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  F1 ,  Cora - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Citeseer - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Pubmed - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Amazon2M - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  HIV-fMRI-77 - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  21\n",
      "####### Hits\\\\-at\\\\-10\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB122 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB15k (filtered) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  WN18 (filtered) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  YAGO3-10 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  AKSW-bib - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  YAGO39K - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  DBbook2014 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  MovieLens 1M - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  MovieLens 25M - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  LiveJournal - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  NELL-995 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  36\n",
      "####### Hits\\\\-at\\\\-1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  AKSW-bib - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  YAGO39K - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  YAGO3-10 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  NELL-995 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  29\n",
      "####### Hits\\\\-at\\\\-5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-5 ,  FB122 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Hits\\\\-at\\\\-5 ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-5 ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### HITS@3\n",
      "Creating ratio df for  HITS@3 ,  FB122 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### MRR\n",
      "Creating ratio df for  MRR ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MRR ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  MRR ,  FB122 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MRR ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  MRR ,  FB15k - Knowledge graph process benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MRR ,  YAGO3-10 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  YAGO39K - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  LiveJournal - Link Prediction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  NELL-995 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  ICEWS14 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  ICEWS05-15 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  YAGO15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  34\n",
      "####### MR\n",
      "Creating ratio df for  MR ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MR ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MR ,  FB15k (filtered) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MR ,  WN18 (filtered) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MR ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MR ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MR ,  LiveJournal - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MR ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### Number\\\\ of\\\\ params\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-ppa - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-collab - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-ddi - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-biokg - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-wikikg2 - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbg-molpcba - Graph Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-citation2 - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbg-ppa - Graph Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbg-code2 - Graph Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbg-molhiv - Graph Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  18\n",
      "####### Macro\\\\-F1\n",
      "Creating ratio df for  Macro\\\\-F1 ,  Wikipedia - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Macro\\\\-F1 ,  BlogCatalog - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Macro\\\\-F1 ,  Slashdot - Link Sign Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Macro\\\\-F1 ,  Bitcoin-Alpha - Link Sign Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Macro\\\\-F1 ,  Epinions - Link Sign Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### Hits\\\\-at\\\\-3\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  AKSW-bib - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  YAGO39K - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  YAGO3-10 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  31\n",
      "####### RMSE\n",
      "Creating ratio df for  RMSE ,  Lipophilicity  - Graph Regression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  RMSE ,  Lipophilicity - Graph Regression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### MAE\n",
      "Creating ratio df for  MAE ,  ZINC-500k - Graph Regression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAE ,  ZINC 100k - Graph Regression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  QM9 - Formation Energy benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  Materials Project - Formation Energy benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAE ,  OQMD v1.2 - Formation Energy benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  10\n",
      "####### RMSE\\\\-at\\\\-80%Train\n",
      "Creating ratio df for  RMSE\\\\-at\\\\-80%Train ,  Lipophilicity  - Graph Regression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(%\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  PATTERN 100k - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  CIFAR10 100k - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### AUC\\\\-at\\\\-80%Train\n",
      "Creating ratio df for  AUC\\\\-at\\\\-80%Train ,  Tox21  - Graph Regression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Mean\\\\ AP\n",
      "Creating ratio df for  Mean\\\\ AP ,  NELL-995 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NMI\n",
      "Creating ratio df for  NMI ,  Amazon - Community Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NMI ,  Citeseer - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NMI ,  Cora - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### F1\\\\-score\n",
      "Creating ratio df for  F1\\\\-score ,  Amazon - Community Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### 14\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  2010 i2b2/VA - Community Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Precision\n",
      "Creating ratio df for  Precision ,  Cora - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  Citeseer - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  YAGO39K - Triple Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### AUC\n",
      "Creating ratio df for  AUC ,  Citeseer - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC ,  Pubmed - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Cora - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Cora (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Citeseer (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Pubmed (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Wiki - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Wiki - Link Prediction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Gnutella - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Cit-HepPH - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Wiki-Vote - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Douban - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  IMDb - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  DBLP - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Yelp - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  MIT - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Epinions - Link Sign Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Bitcoin-Alpha - Link Sign Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Slashdot - Link Sign Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Pubmed (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Citeseer (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  ACM - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Cora (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Last.FM - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  24\n",
      "####### ARI\n",
      "Creating ratio df for  ARI ,  Cora - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ARI ,  Citeseer - Graph Clustering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### AP\n",
      "Creating ratio df for  AP ,  Citeseer - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  Pubmed - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  Cora - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  Cora (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  Pubmed (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  Citeseer (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  Pubmed (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  DBLP - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  Citeseer (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  ACM - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  Cora (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  Last.FM - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### Recall\n",
      "Creating ratio df for  Recall ,  YAGO39K - Triple Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\-Score\n",
      "Creating ratio df for  F1\\\\-Score ,  YAGO39K - Triple Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  DBLP - Community Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  Alibaba - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  Twitter - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  Amazon - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  Alibaba-S - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Mean\\\\ Rank\n",
      "Creating ratio df for  Mean\\\\ Rank ,  DBbook2014 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ Rank ,  MovieLens 1M - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### training\\\\ time\\\\ \\\\(s\\\\)\n",
      "Creating ratio df for  training\\\\ time\\\\ \\\\(s\\\\) ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  training\\\\ time\\\\ \\\\(s\\\\) ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  training\\\\ time\\\\ \\\\(s\\\\) ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### runtime\\\\ \\\\(s\\\\)\n",
      "Creating ratio df for  runtime\\\\ \\\\(s\\\\) ,  YouTube - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Macro\\\\-F1\\\\-at\\\\-2%\n",
      "Creating ratio df for  Macro\\\\-F1\\\\-at\\\\-2% ,  YouTube - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Micro\\\\-F1\\\\-at\\\\-2%\n",
      "Creating ratio df for  Micro\\\\-F1\\\\-at\\\\-2% ,  YouTube - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### nDCG\\\\-at\\\\-10\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  MovieLens 25M - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Yelp - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### HR\\\\-at\\\\-10\n",
      "Creating ratio df for  HR\\\\-at\\\\-10 ,  Yelp - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MRR\\\\ filtered\n",
      "Creating ratio df for  MRR\\\\ filtered ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MRR\\\\ raw\n",
      "Creating ratio df for  MRR\\\\ raw ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Macro\\\\ F1\n",
      "Creating ratio df for  Macro\\\\ F1 ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Macro\\\\ F1 ,  BlogCatalog - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Macro\\\\ F1 ,  DBLP - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Macro\\\\ F1 ,  Wiki - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Micro\\\\ F1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  BlogCatalog - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  Wiki - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  DBLP - Node Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### Average\\\\ Precision\n",
      "Creating ratio df for  Average\\\\ Precision ,  BioGRID (human) - Gene Interaction Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Average\\\\ Precision ,  BioGRID(yeast) - Gene Interaction Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "####### ROC\\\\ AUC\n",
      "Creating ratio df for  ROC\\\\ AUC ,  Alibaba - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROC\\\\ AUC ,  Twitter - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROC\\\\ AUC ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROC\\\\ AUC ,  Alibaba-S - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROC\\\\ AUC ,  Amazon - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### PR\\\\ AUC\n",
      "Creating ratio df for  PR\\\\ AUC ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PR\\\\ AUC ,  Alibaba - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PR\\\\ AUC ,  Alibaba-S - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PR\\\\ AUC ,  Amazon - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PR\\\\ AUC ,  Twitter - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Mean\\\\ Accuracy\n",
      "Creating ratio df for  Mean\\\\ Accuracy ,  MUTAG - Graph Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Macro\\\\-F1\\\\ \\\\(60%\\\\ training\\\\ data\\\\)\n",
      "Creating ratio df for  Macro\\\\-F1\\\\ \\\\(60%\\\\ training\\\\ data\\\\) ,  DBLP (PACT) 14k - Heterogeneous Node Classification benchmarking , ds_count= 1\n",
      "null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Formation Energy",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Formation Energy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Formation Energy",
          "Formation Energy"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Graph Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Graph Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-09",
          "2017-06",
          "2017-07",
          "2017-12",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-07",
          "2019-09",
          "2019-11",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Graph Clustering",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Graph Clustering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-11",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "Graph Clustering",
          "Graph Clustering",
          "Graph Clustering"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Graph Property Prediction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Graph Property Prediction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-06",
          "2016-09",
          "2018-10",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "Graph Property Prediction",
          "Graph Property Prediction",
          "Graph Property Prediction",
          "Graph Property Prediction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Graph Regression",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Graph Regression",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2017-04",
          "2017-06",
          "2017-10",
          "2018-03",
          "2018-10",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Graph Regression",
          "Graph Regression",
          "Graph Regression",
          "Graph Regression",
          "Graph Regression",
          "Graph Regression",
          "Graph Regression"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Link Prediction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Link Prediction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-07",
          "2015-10",
          "2016-06",
          "2017-02",
          "2017-05",
          "2017-07",
          "2017-12",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-12",
          "2019-01",
          "2019-02",
          "2019-04",
          "2019-06",
          "2019-11",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Node Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Node Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-11",
          "2016-06",
          "2016-09",
          "2016-11",
          "2017-04",
          "2017-06",
          "2017-10",
          "2017-11",
          "2018-03",
          "2018-09",
          "2018-10",
          "2019-02",
          "2019-06",
          "2019-07",
          "2019-08",
          "2020-02",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Formation Energy<BR>task: Formation Energy<BR>date: 2018-11<BR>ratio: 0.22",
          "Formation Energy<BR>task: Formation Energy<BR>date: 2019-05<BR>ratio: 0.33",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2016-03<BR>ratio: 0.01",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2016-05<BR>ratio: 0.18",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2016-06<BR>ratio: 0.1",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2016-09<BR>ratio: 0.31",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2017-06<BR>ratio: 0.13",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2017-07<BR>ratio: 0.17",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2017-12<BR>ratio: 0.04",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2018-04<BR>ratio: 0.03",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2018-05<BR>ratio: 0.07",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2018-06<BR>ratio: 0.02",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2018-07<BR>ratio: 0.08",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2018-10<BR>ratio: 0.09",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2018-11<BR>ratio: 0.02",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2019-04<BR>ratio: 0.01",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2019-07<BR>ratio: 0.23",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2019-09<BR>ratio: 0.02",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2019-11<BR>ratio: 0.04",
          "Graph Classification<BR>task: Graph Classification<BR>date: 2020-03<BR>ratio: 0.09",
          "Graph Clustering<BR>task: Graph Clustering<BR>date: 2016-11<BR>ratio: 0.22",
          "Graph Clustering<BR>task: Graph Clustering<BR>date: 2017-11<BR>ratio: 0.34",
          "Graph Clustering<BR>task: Graph Clustering<BR>date: 2019-06<BR>ratio: 0.06",
          "Graph Property Prediction<BR>task: Graph Property Prediction<BR>date: 2016-06<BR>ratio: 0.44",
          "Graph Property Prediction<BR>task: Graph Property Prediction<BR>date: 2016-09<BR>ratio: 0.35",
          "Graph Property Prediction<BR>task: Graph Property Prediction<BR>date: 2018-10<BR>ratio: 0.3",
          "Graph Property Prediction<BR>task: Graph Property Prediction<BR>date: 2019-06<BR>ratio: 0.27",
          "Graph Regression<BR>task: Graph Regression<BR>date: 2016-03<BR>ratio: 0.1",
          "Graph Regression<BR>task: Graph Regression<BR>date: 2017-04<BR>ratio: 0.0",
          "Graph Regression<BR>task: Graph Regression<BR>date: 2017-06<BR>ratio: 0.0",
          "Graph Regression<BR>task: Graph Regression<BR>date: 2017-10<BR>ratio: 0.21",
          "Graph Regression<BR>task: Graph Regression<BR>date: 2018-03<BR>ratio: 0.0",
          "Graph Regression<BR>task: Graph Regression<BR>date: 2018-10<BR>ratio: 0.19",
          "Graph Regression<BR>task: Graph Regression<BR>date: 2019-08<BR>ratio: 0.04",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2015-07<BR>ratio: 0.33",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2015-10<BR>ratio: 0.28",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2016-06<BR>ratio: 0.09",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-02<BR>ratio: 0.32",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-05<BR>ratio: 0.2",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-07<BR>ratio: 0.35",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-12<BR>ratio: 0.09",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-04<BR>ratio: 0.02",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-06<BR>ratio: 0.05",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-08<BR>ratio: 0.02",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-12<BR>ratio: 0.16",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-01<BR>ratio: 0.48",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-02<BR>ratio: 0.03",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-04<BR>ratio: 0.02",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-06<BR>ratio: 0.45",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-11<BR>ratio: 0.1",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-12<BR>ratio: 0.33",
          "Node Classification<BR>task: Node Classification<BR>date: 2015-11<BR>ratio: 0.06",
          "Node Classification<BR>task: Node Classification<BR>date: 2016-06<BR>ratio: 0.04",
          "Node Classification<BR>task: Node Classification<BR>date: 2016-09<BR>ratio: 0.47",
          "Node Classification<BR>task: Node Classification<BR>date: 2016-11<BR>ratio: 0.23",
          "Node Classification<BR>task: Node Classification<BR>date: 2017-04<BR>ratio: 0.03",
          "Node Classification<BR>task: Node Classification<BR>date: 2017-06<BR>ratio: 0.39",
          "Node Classification<BR>task: Node Classification<BR>date: 2017-10<BR>ratio: 0.09",
          "Node Classification<BR>task: Node Classification<BR>date: 2017-11<BR>ratio: 0.05",
          "Node Classification<BR>task: Node Classification<BR>date: 2018-03<BR>ratio: 0.01",
          "Node Classification<BR>task: Node Classification<BR>date: 2018-09<BR>ratio: 0.01",
          "Node Classification<BR>task: Node Classification<BR>date: 2018-10<BR>ratio: 0.5",
          "Node Classification<BR>task: Node Classification<BR>date: 2019-02<BR>ratio: 0.02",
          "Node Classification<BR>task: Node Classification<BR>date: 2019-06<BR>ratio: 0.18",
          "Node Classification<BR>task: Node Classification<BR>date: 2019-07<BR>ratio: 0.01",
          "Node Classification<BR>task: Node Classification<BR>date: 2019-08<BR>ratio: 0.01",
          "Node Classification<BR>task: Node Classification<BR>date: 2020-02<BR>ratio: 0.02",
          "Node Classification<BR>task: Node Classification<BR>date: 2020-03<BR>ratio: 0.0"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.22,
           0.33,
           0.01,
           0.18,
           0.1,
           0.31,
           0.13,
           0.17,
           0.04,
           0.03,
           0.07,
           0.02,
           0.08,
           0.09,
           0.02,
           0.01,
           0.23,
           0.02,
           0.04,
           0.09,
           0.22,
           0.34,
           0.06,
           0.44,
           0.35,
           0.3,
           0.27,
           0.1,
           0,
           0,
           0.21,
           0,
           0.19,
           0.04,
           0.33,
           0.28,
           0.09,
           0.32,
           0.2,
           0.35,
           0.09,
           0.02,
           0.05,
           0.02,
           0.16,
           0.48,
           0.03,
           0.02,
           0.45,
           0.1,
           0.33,
           0.06,
           0.04,
           0.47,
           0.23,
           0.03,
           0.39,
           0.09,
           0.05,
           0.01,
           0.01,
           0.5,
           0.02,
           0.18,
           0.01,
           0.01,
           0.02,
           0
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2018-11",
          "2019-05",
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-09",
          "2017-06",
          "2017-07",
          "2017-12",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-07",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-07",
          "2019-09",
          "2019-11",
          "2020-03",
          "2016-11",
          "2017-11",
          "2019-06",
          "2016-06",
          "2016-09",
          "2018-10",
          "2019-06",
          "2016-03",
          "2017-04",
          "2017-06",
          "2017-10",
          "2018-03",
          "2018-10",
          "2019-08",
          "2015-07",
          "2015-10",
          "2016-06",
          "2017-02",
          "2017-05",
          "2017-07",
          "2017-12",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-12",
          "2019-01",
          "2019-02",
          "2019-04",
          "2019-06",
          "2019-11",
          "2019-12",
          "2015-11",
          "2016-06",
          "2016-09",
          "2016-11",
          "2017-04",
          "2017-06",
          "2017-10",
          "2017-11",
          "2018-03",
          "2018-09",
          "2018-10",
          "2019-02",
          "2019-06",
          "2019-07",
          "2019-08",
          "2020-02",
          "2020-03"
         ],
         "y": [
          "Formation Energy",
          "Formation Energy",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Classification",
          "Graph Clustering",
          "Graph Clustering",
          "Graph Clustering",
          "Graph Property Prediction",
          "Graph Property Prediction",
          "Graph Property Prediction",
          "Graph Property Prediction",
          "Graph Regression",
          "Graph Regression",
          "Graph Regression",
          "Graph Regression",
          "Graph Regression",
          "Graph Regression",
          "Graph Regression",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification",
          "Node Classification"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Node Classification",
          "Link Prediction",
          "Graph Regression",
          "Graph Property Prediction",
          "Graph Clustering",
          "Graph Classification",
          "Formation Energy"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00137: Graph process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"6a2b2aa1-3a6d-4528-af6e-9341d2f452f7\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6a2b2aa1-3a6d-4528-af6e-9341d2f452f7\")) {                    Plotly.newPlot(                        \"6a2b2aa1-3a6d-4528-af6e-9341d2f452f7\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Formation Energy\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Formation Energy\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Formation Energy\", \"Formation Energy\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Graph Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Graph Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-05\", \"2016-06\", \"2016-09\", \"2017-06\", \"2017-07\", \"2017-12\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-07\", \"2019-09\", \"2019-11\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Graph Clustering\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Graph Clustering\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-11\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"Graph Clustering\", \"Graph Clustering\", \"Graph Clustering\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Graph Property Prediction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Graph Property Prediction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-06\", \"2016-09\", \"2018-10\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"Graph Property Prediction\", \"Graph Property Prediction\", \"Graph Property Prediction\", \"Graph Property Prediction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Graph Regression\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Graph Regression\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2017-04\", \"2017-06\", \"2017-10\", \"2018-03\", \"2018-10\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Graph Regression\", \"Graph Regression\", \"Graph Regression\", \"Graph Regression\", \"Graph Regression\", \"Graph Regression\", \"Graph Regression\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Link Prediction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Link Prediction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-07\", \"2015-10\", \"2016-06\", \"2017-02\", \"2017-05\", \"2017-07\", \"2017-12\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-12\", \"2019-01\", \"2019-02\", \"2019-04\", \"2019-06\", \"2019-11\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Node Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Node Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-11\", \"2016-06\", \"2016-09\", \"2016-11\", \"2017-04\", \"2017-06\", \"2017-10\", \"2017-11\", \"2018-03\", \"2018-09\", \"2018-10\", \"2019-02\", \"2019-06\", \"2019-07\", \"2019-08\", \"2020-02\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Formation Energy<BR>task: Formation Energy<BR>date: 2018-11<BR>ratio: 0.22\", \"Formation Energy<BR>task: Formation Energy<BR>date: 2019-05<BR>ratio: 0.33\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2016-03<BR>ratio: 0.01\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2016-05<BR>ratio: 0.18\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2016-06<BR>ratio: 0.1\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2016-09<BR>ratio: 0.31\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2017-06<BR>ratio: 0.13\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2017-07<BR>ratio: 0.17\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2017-12<BR>ratio: 0.04\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2018-04<BR>ratio: 0.03\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2018-05<BR>ratio: 0.07\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2018-06<BR>ratio: 0.02\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2018-07<BR>ratio: 0.08\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2018-10<BR>ratio: 0.09\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2018-11<BR>ratio: 0.02\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2019-04<BR>ratio: 0.01\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2019-07<BR>ratio: 0.23\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2019-09<BR>ratio: 0.02\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2019-11<BR>ratio: 0.04\", \"Graph Classification<BR>task: Graph Classification<BR>date: 2020-03<BR>ratio: 0.09\", \"Graph Clustering<BR>task: Graph Clustering<BR>date: 2016-11<BR>ratio: 0.22\", \"Graph Clustering<BR>task: Graph Clustering<BR>date: 2017-11<BR>ratio: 0.34\", \"Graph Clustering<BR>task: Graph Clustering<BR>date: 2019-06<BR>ratio: 0.06\", \"Graph Property Prediction<BR>task: Graph Property Prediction<BR>date: 2016-06<BR>ratio: 0.44\", \"Graph Property Prediction<BR>task: Graph Property Prediction<BR>date: 2016-09<BR>ratio: 0.35\", \"Graph Property Prediction<BR>task: Graph Property Prediction<BR>date: 2018-10<BR>ratio: 0.3\", \"Graph Property Prediction<BR>task: Graph Property Prediction<BR>date: 2019-06<BR>ratio: 0.27\", \"Graph Regression<BR>task: Graph Regression<BR>date: 2016-03<BR>ratio: 0.1\", \"Graph Regression<BR>task: Graph Regression<BR>date: 2017-04<BR>ratio: 0.0\", \"Graph Regression<BR>task: Graph Regression<BR>date: 2017-06<BR>ratio: 0.0\", \"Graph Regression<BR>task: Graph Regression<BR>date: 2017-10<BR>ratio: 0.21\", \"Graph Regression<BR>task: Graph Regression<BR>date: 2018-03<BR>ratio: 0.0\", \"Graph Regression<BR>task: Graph Regression<BR>date: 2018-10<BR>ratio: 0.19\", \"Graph Regression<BR>task: Graph Regression<BR>date: 2019-08<BR>ratio: 0.04\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2015-07<BR>ratio: 0.33\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2015-10<BR>ratio: 0.28\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2016-06<BR>ratio: 0.09\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-02<BR>ratio: 0.32\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-05<BR>ratio: 0.2\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-07<BR>ratio: 0.35\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-12<BR>ratio: 0.09\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-04<BR>ratio: 0.02\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-06<BR>ratio: 0.05\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-08<BR>ratio: 0.02\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-12<BR>ratio: 0.16\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-01<BR>ratio: 0.48\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-02<BR>ratio: 0.03\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-04<BR>ratio: 0.02\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-06<BR>ratio: 0.45\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-11<BR>ratio: 0.1\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-12<BR>ratio: 0.33\", \"Node Classification<BR>task: Node Classification<BR>date: 2015-11<BR>ratio: 0.06\", \"Node Classification<BR>task: Node Classification<BR>date: 2016-06<BR>ratio: 0.04\", \"Node Classification<BR>task: Node Classification<BR>date: 2016-09<BR>ratio: 0.47\", \"Node Classification<BR>task: Node Classification<BR>date: 2016-11<BR>ratio: 0.23\", \"Node Classification<BR>task: Node Classification<BR>date: 2017-04<BR>ratio: 0.03\", \"Node Classification<BR>task: Node Classification<BR>date: 2017-06<BR>ratio: 0.39\", \"Node Classification<BR>task: Node Classification<BR>date: 2017-10<BR>ratio: 0.09\", \"Node Classification<BR>task: Node Classification<BR>date: 2017-11<BR>ratio: 0.05\", \"Node Classification<BR>task: Node Classification<BR>date: 2018-03<BR>ratio: 0.01\", \"Node Classification<BR>task: Node Classification<BR>date: 2018-09<BR>ratio: 0.01\", \"Node Classification<BR>task: Node Classification<BR>date: 2018-10<BR>ratio: 0.5\", \"Node Classification<BR>task: Node Classification<BR>date: 2019-02<BR>ratio: 0.02\", \"Node Classification<BR>task: Node Classification<BR>date: 2019-06<BR>ratio: 0.18\", \"Node Classification<BR>task: Node Classification<BR>date: 2019-07<BR>ratio: 0.01\", \"Node Classification<BR>task: Node Classification<BR>date: 2019-08<BR>ratio: 0.01\", \"Node Classification<BR>task: Node Classification<BR>date: 2020-02<BR>ratio: 0.02\", \"Node Classification<BR>task: Node Classification<BR>date: 2020-03<BR>ratio: 0.0\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.22, 0.33, 0.01, 0.18, 0.1, 0.31, 0.13, 0.17, 0.04, 0.03, 0.07, 0.02, 0.08, 0.09, 0.02, 0.01, 0.23, 0.02, 0.04, 0.09, 0.22, 0.34, 0.06, 0.44, 0.35, 0.3, 0.27, 0.1, 0.0, 0.0, 0.21, 0.0, 0.19, 0.04, 0.33, 0.28, 0.09, 0.32, 0.2, 0.35, 0.09, 0.02, 0.05, 0.02, 0.16, 0.48, 0.03, 0.02, 0.45, 0.1, 0.33, 0.06, 0.04, 0.47, 0.23, 0.03, 0.39, 0.09, 0.05, 0.01, 0.01, 0.5, 0.02, 0.18, 0.01, 0.01, 0.02, 0.0], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2018-11\", \"2019-05\", \"2016-03\", \"2016-05\", \"2016-06\", \"2016-09\", \"2017-06\", \"2017-07\", \"2017-12\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-07\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-07\", \"2019-09\", \"2019-11\", \"2020-03\", \"2016-11\", \"2017-11\", \"2019-06\", \"2016-06\", \"2016-09\", \"2018-10\", \"2019-06\", \"2016-03\", \"2017-04\", \"2017-06\", \"2017-10\", \"2018-03\", \"2018-10\", \"2019-08\", \"2015-07\", \"2015-10\", \"2016-06\", \"2017-02\", \"2017-05\", \"2017-07\", \"2017-12\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-12\", \"2019-01\", \"2019-02\", \"2019-04\", \"2019-06\", \"2019-11\", \"2019-12\", \"2015-11\", \"2016-06\", \"2016-09\", \"2016-11\", \"2017-04\", \"2017-06\", \"2017-10\", \"2017-11\", \"2018-03\", \"2018-09\", \"2018-10\", \"2019-02\", \"2019-06\", \"2019-07\", \"2019-08\", \"2020-02\", \"2020-03\"], \"y\": [\"Formation Energy\", \"Formation Energy\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Classification\", \"Graph Clustering\", \"Graph Clustering\", \"Graph Clustering\", \"Graph Property Prediction\", \"Graph Property Prediction\", \"Graph Property Prediction\", \"Graph Property Prediction\", \"Graph Regression\", \"Graph Regression\", \"Graph Regression\", \"Graph Regression\", \"Graph Regression\", \"Graph Regression\", \"Graph Regression\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\", \"Node Classification\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Node Classification\", \"Link Prediction\", \"Graph Regression\", \"Graph Property Prediction\", \"Graph Clustering\", \"Graph Classification\", \"Formation Energy\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00137: Graph process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6a2b2aa1-3a6d-4528-af6e-9341d2f452f7');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00141\n",
      "Number of metrics:  250\n",
      "####### F1\n",
      "Creating ratio df for  F1 ,  ACL-ARC - Citation Intent Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F1 ,  MSRP - Paraphrase Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  MRPC - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  WebQuestions - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  SciERC - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  SensEval 2 Lexical Sample - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  SensEval 3 Lexical Sample - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  SimpleQuestions - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  MSRA - Chinese Word Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Google Dataset - Sentence Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  CoNLL 2003 (English) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  Ontonotes v5 (English) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL++ - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  SensEval 3 Task 1 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  SemEval 2007 Task 17 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  SemEval 2013 Task 12 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1 ,  SemEval 2007 Task 7 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F1 ,  SensEval 2 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1 ,  OntoNotes - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  F1 ,  Twitter Dialogue (Noun) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  Ubuntu Dialogue (Activity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  Ubuntu Dialogue (Entity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  SemEval-2010 Task 8 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  F1 ,  SQuAD1.1 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  F1 ,  SQuAD1.1 dev - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  F1 ,  NewsQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F1 ,  Natural Questions (long) - Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  Natural Questions (short) - Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  TriviaQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1 ,  WebNLG - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  NYT-single - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  NYT - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  OntoNotes - Semantic Role Labeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1 ,  CoNLL 2005 - Predicate Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  COMPLEXQUESTIONS - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  SCv1 - Sarcasm Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Long-tail emerging entities - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  Re-TACRED - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  TACRED - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F1 ,  SQuAD2.0 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  F1 ,  ACL-ARC - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  SciCite - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  WebQSP-WD - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  CoNLL 2005 - Semantic Role Labeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  CoNLL 2012 - Predicate Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  CoNLL 2012 - Semantic Role Labeling (predicted predicates) benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL 2005 - Semantic Role Labeling (predicted predicates) benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  OntoNotes 4 - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Weibo NER - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Resume NER - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  MSRA - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F1 ,  SemEval 2015 Task 13 - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F1 ,  CoNLL 2000 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  ACE 2005 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  F1 ,  GENIA - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  SearchQA - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  Ontonotes v5 (English) - Entity Typing benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL 2003 (German) Revised - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  GENIA - UAS - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  GENIA - LAS - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  SQuAD2.0 dev - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  PubMed 20k RCT - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  BC5CDR - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F1 ,  SighanNER - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  ACE 2004 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  ACE 2004 - Nested Mention Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  ACE 2005 - Nested Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  QuAC - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  NCBI-disease - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  ReCoRD - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  ATIS - Slot Filling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  ChemProt - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  JNLPBA - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Quora Question Pairs - Paraphrase Identification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  Reuters-21578 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  JNLPBA - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  SciERC - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  ScienceCite - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  Paper Field - Sentence Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  SciCite - Citation Intent Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  WetLab - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  WLPC - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  WLPC - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  AAPD - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  MSRA Dev - Chinese Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1 ,  FewRel - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Open Entity - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  DocRED - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1 ,  SemEval 2014 Task 4 Subtask 1+2 - Sentiment Analysis benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  ChnSentiCorp - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  ATIS - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  NaturalQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  Species-800 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  LINNAEUS - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  CoNLL 2002 (Dutch) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL 2002 (Spanish) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  CoNLL 2003 (German) - Named Entity Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1 ,  Code-Switching English-Spanish NER - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  ontontoes chinese v5 - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  MSR - Chinese Word Segmentation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  NYT29 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  NYT24 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  ASOS.com user intent - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  _sem 2012 Shared Task: Sherlock Dataset - Negation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  BioScope : Full Papers - Negation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  SFU Review Corpus - Negation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  BioScope : Abstracts - Negation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  SFU Review Corpus - Speculation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  BioScope : Abstracts - Speculation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  BioScope : Full Papers - Speculation Scope Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1 ,  SoSciSoCi - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  228\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  MRPC - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  MSRP - Paraphrase Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  SST-5 Fine-grained classification - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  SST-2 Binary classification - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "Creating ratio df for  Accuracy ,  Reuters RCV1/RCV2 German-to-English - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Reuters RCV1/RCV2 English-to-German - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Cora - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Accuracy ,  Reverb - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Reuters De-En - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Reuters En-De - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ATIS - Semantic Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  IMDb - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Accuracy ,  SUBJ - Subjectivity Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Penn Treebank - Part-Of-Speech Tagging benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  20NEWS - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  VQA v1 test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  VQA v1 test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Switchboard corpus - Dialog Act Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Django - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MCTest-500 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MCTest-160 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Story Cloze Test - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CCGbank - Combinatory Categorical Grammar (CCG) Supertagging benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Ubuntu Dialogue (Tense) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Ubuntu Dialogue (Cmd) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Twitter Dialogue (Tense) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VQA v2 test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Accuracy ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ReferIt - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Sogou News - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Yahoo! Answers - Text Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Amazon Review Full - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Amazon Review Polarity - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MR - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Quora Question Pairs - Paraphrase Identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  MSRVTT-QA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MSVD-QA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  SARC (all-bal) - Sarcasm Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  SARC (pol-bal) - Sarcasm Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  RumourEval - Stance Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  XNLI Zero-Shot English-to-Spanish - Cross-Lingual Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  XNLI Zero-Shot English-to-German - Cross-Lingual Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  XNLI Zero-Shot English-to-French - Cross-Lingual Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MOSI - Multimodal Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  Ohsumed - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  ICSI Meeting Recorder Dialog Act (MRDA) corpus - Dialog Act Classification benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  WOS-46985 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  WOS-5736 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  WOS-11967 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  LexNorm - Lexical Normalization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CR - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  SciTail - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MPQA - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  20NEWS - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Geo - Semantic Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Quora Question Pairs - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Japanese - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Spanish - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Italian - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Russian - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-Chinese - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-German - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot English-to-French - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MLDoc Zero-Shot German-to-French - Cross-Lingual Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MemexQA - Memex Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  R8 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  V-SNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  CMU-MOSEI - Multimodal Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  LAMBADA - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CLEVR - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Query Wellformedness - Query Wellformedness benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  XNLI French - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  R52 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  spider - Semantic Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  WNLI - Natural Language Understanding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  PDP60 - Natural Language Understanding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Sogou News - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  HowmanyQA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  TallyQA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CommonsenseQA - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  Quora Question Pairs - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Automatic Misogynistic Identification - Hate Speech Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ATIS - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Yelp-5 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CoLA - Linguistic Acceptability Assessment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  GQA test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  TDIUC - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Twitter - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  BBCSport - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Twitter - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Reuters-21578 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Recipe - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Amazon - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Classic - Document Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CODAH - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Yelp-14 - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  XNLI Chinese - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  XNLI Chinese Dev - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Yelp-2 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  FIGER - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  RTE - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  QNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  IMDb-M - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  RACE - Reading Comprehension benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  WNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  GQA test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Helsinki Prosody Corpus - Prosody Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-A) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (QA-R) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-AR) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-AR) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  NLVR2 Dev - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MPQA - Document Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  NLVR2 Test - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-A) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (QA-R) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Financial PhraseBank - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  WikiSQL - Semantic Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CoNLL-Aida - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  TAC-KBP 2010 - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  MNIST - Handwritten Digit Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  265\n",
      "####### PPL\n",
      "Creating ratio df for  PPL ,  One Billion Word - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PPL ,  CNN / Daily Mail - Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  PPL ,  PTB - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### %\\\\ Test\\\\ Accuracy\n",
      "Creating ratio df for  %\\\\ Test\\\\ Accuracy ,  SNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "number of sota per dataset/metric:  11\n",
      "####### MRR\n",
      "Creating ratio df for  MRR ,  WikiQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  MRR ,  QASent - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MRR ,  TrecQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MRR ,  YahooCQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MRR ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  MRR ,  Medical domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  Music domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  General - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  MS MARCO - Passage Re-Ranking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  Py150 - Type prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  Py150 - Value prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  35\n",
      "####### Accuracy\\\\ \\\\(2\\\\ classes\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(2\\\\ classes\\\\) ,  IMDb - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### MAP\n",
      "Creating ratio df for  MAP ,  WikiQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  MAP ,  QASent - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  TrecQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MAP ,  SemEvalCQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  Music domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAP ,  Medical domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MAP ,  General - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MAP ,  TREC Robust04 - Ad-Hoc Information Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  32\n",
      "####### RE\\\\+\\\\ Micro\\\\ F1\n",
      "Creating ratio df for  RE\\\\+\\\\ Micro\\\\ F1 ,  ACE 2004 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  RE\\\\+\\\\ Micro\\\\ F1 ,  ACE 2005 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  RE\\\\+\\\\ Micro\\\\ F1 ,  CoNLL04 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  11\n",
      "####### RE\\\\ Micro\\\\ F1\n",
      "Creating ratio df for  RE\\\\ Micro\\\\ F1 ,  ACE 2005 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  RE\\\\ Micro\\\\ F1 ,  ACE 2004 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  7\n",
      "####### NER\\\\ Micro\\\\ F1\n",
      "Creating ratio df for  NER\\\\ Micro\\\\ F1 ,  ACE 2005 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  NER\\\\ Micro\\\\ F1 ,  ACE 2004 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  NER\\\\ Micro\\\\ F1 ,  CoNLL04 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  11\n",
      "####### BLEU\\\\ score\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 English-French - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  BLEU\\\\ score ,  IWSLT2015 German-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2015 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2015 English-Russian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 English-Czech - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 English-Romanian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 English-German - Machine Translation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 German-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 Romanian-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 Czech-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 Russian-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2016 English-Russian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\ score ,  IWSLT2015 Thai-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\ score ,  IWSLT2014 German-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  BLEU\\\\ score ,  IWSLT2015 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 German-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT 2017 English-Chinese - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 French-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2014 English-Czech - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\ score ,  WMT2019 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  65\n",
      "####### Avg\\\\ F1\n",
      "Creating ratio df for  Avg\\\\ F1 ,  Persona-Chat - Dialog Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Avg\\\\ F1 ,  SARC (pol-unbal) - Sarcasm Detection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Avg\\\\ F1 ,  CoNLL 2012 - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Avg\\\\ F1 ,  SemEval - Aspect Term Extraction and Sentiment Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### Test\\\\ perplexity\n",
      "Creating ratio df for  Test\\\\ perplexity ,  Penn Treebank (Word Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Test\\\\ perplexity ,  20 Newsgroups - Topic modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Test\\\\ perplexity ,  WikiText-2 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Test\\\\ perplexity ,  WikiText-103 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Validation\\\\ perplexity\n",
      "Creating ratio df for  Validation\\\\ perplexity ,  Penn Treebank (Word Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Validation\\\\ perplexity ,  WikiText-2 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Validation\\\\ perplexity ,  WikiText-103 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Validation\\\\ perplexity ,  One Billion Word - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### BLEU\\\\-1\n",
      "Creating ratio df for  BLEU\\\\-1 ,  COCO Visual Question Answering (VQA) real images 1.0 open ended - Question Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  BLEU\\\\-1 ,  NarrativeQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  BLEU\\\\-1 ,  MS MARCO - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  BLEU\\\\-1 ,  quora - Paraphrase Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\-1 ,  Visual Question Generation - Question Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-1 ,  DailyDialog - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-1 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  13\n",
      "####### F1\\\\ score\n",
      "Creating ratio df for  F1\\\\ score ,  Penn Treebank - Constituency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F1\\\\ score ,  BUCC German-to-English - Cross-Lingual Bitext Mining benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  BUCC French-to-English - Cross-Lingual Bitext Mining benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  Penn Treebank - Chunking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ score ,  TimeBank - Temporal Information Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  SemEval 2015 Task 12 - Extract Aspect benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1\\\\ score ,  SemEval 2015 Task 12 - Extract aspect-polarity tuple benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  BUCC Chinese-to-English - Cross-Lingual Bitext Mining benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  BUCC Russian-to-English - Cross-Lingual Bitext Mining benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  Financial PhraseBank - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  Conll 2003 Spanish - Low Resource Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  CONLL 2003 Dutch - Low Resource Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  CONLL 2003 German - Low Resource Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\ score ,  Q2Q Arabic Benchmark - Question Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  26\n",
      "####### Pearson\\\\ Correlation\n",
      "Creating ratio df for  Pearson\\\\ Correlation ,  SICK - Semantic Similarity Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Pearson\\\\ Correlation ,  STS Benchmark - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  4\n",
      "####### Spearman\\\\ Correlation\n",
      "Creating ratio df for  Spearman\\\\ Correlation ,  SICK - Semantic Similarity Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MSE\n",
      "Creating ratio df for  MSE ,  SICK - Semantic Similarity Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MSE ,  FiQA - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### P\\\\-at\\\\-1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  SemEvalCQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  YahooCQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  AI2 Kaggle Dataset - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  fr-en - Word Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  en-es - Word Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  es-en - Word Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  en-fr - Word Alignment benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-1 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  21\n",
      "####### Mean\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Mean\\\\ Error\\\\ Rate ,  bAbi - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(trained\\\\ on\\\\ 10k\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(trained\\\\ on\\\\ 10k\\\\) ,  bAbi - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(trained\\\\ on\\\\ 1k\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(trained\\\\ on\\\\ 1k\\\\) ,  bAbi - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Error\n",
      "Creating ratio df for  Error ,  TREC-6 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Error ,  AG News - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Error ,  DBpedia - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Error ,  Yelp Fine-grained classification - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Error ,  Yelp Binary classification - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Error ,  TREC-50 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Error ,  Amazon-2 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Error ,  Amazon-5 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  16\n",
      "####### Percentage\\\\ correct\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 2.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 1.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) abstract images 1.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 1.0 multiple choice - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) abstract 1.0 multiple choice - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual7W - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual Genome (subjects) - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual Genome (pairs) - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  2\n",
      "####### Average\n",
      "Creating ratio df for  Average ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### DVD\n",
      "Creating ratio df for  DVD ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Books\n",
      "Creating ratio df for  Books ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Electronics\n",
      "Creating ratio df for  Electronics ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Kitchen\n",
      "Creating ratio df for  Kitchen ,  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### CNN\n",
      "Creating ratio df for  CNN ,  CNN / Daily Mail - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Daily\\\\ Mail\n",
      "Creating ratio df for  Daily\\\\ Mail ,  CNN / Daily Mail - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### LAS\n",
      "Creating ratio df for  LAS ,  Penn Treebank - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  LAS ,  CoNLL-2009 - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### UAS\n",
      "Creating ratio df for  UAS ,  Penn Treebank - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  UAS ,  CoNLL-2009 - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  UAS ,  WSJ10 - Dependency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### POS\n",
      "Creating ratio df for  POS ,  Penn Treebank - Dependency Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### R10\\\\-at\\\\-1\n",
      "Creating ratio df for  R10\\\\-at\\\\-1 ,  Ubuntu Dialogue (v1, Ranking) - Conversational Response Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### R10\\\\-at\\\\-2\n",
      "Creating ratio df for  R10\\\\-at\\\\-2 ,  Ubuntu Dialogue (v1, Ranking) - Conversational Response Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### R10\\\\-at\\\\-5\n",
      "Creating ratio df for  R10\\\\-at\\\\-5 ,  Ubuntu Dialogue (v1, Ranking) - Conversational Response Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### R2\\\\-at\\\\-1\n",
      "Creating ratio df for  R2\\\\-at\\\\-1 ,  Ubuntu Dialogue (v1, Ranking) - Conversational Response Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### %\\\\ Train\\\\ Accuracy\n",
      "Creating ratio df for  %\\\\ Train\\\\ Accuracy ,  SNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Parameters\n",
      "Creating ratio df for  Parameters ,  SNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "number of sota per dataset/metric:  11\n",
      "####### P\\\\-at\\\\-10%\n",
      "Creating ratio df for  P\\\\-at\\\\-10% ,  New York Times Corpus - Relationship extraction using distant supervision benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  P\\\\-at\\\\-10% ,  NYT Corpus - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### P\\\\-at\\\\-30%\n",
      "Creating ratio df for  P\\\\-at\\\\-30% ,  New York Times Corpus - Relationship extraction using distant supervision benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  P\\\\-at\\\\-30% ,  NYT Corpus - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### CR\n",
      "Creating ratio df for  CR ,  Google Dataset - Sentence Compression benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### ROUGE\\\\-1\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  GigaWord - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  DUC 2004 Task 1 - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  DUC 2004 Task 1 - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  CNN / Daily Mail (Anonymized) - Text Summarization benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  CNN / Daily Mail - Abstractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  CNN / Daily Mail - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  Pubmed - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  arXiv - Text Summarization benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  Debatepedia - Query-Based Extractive Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  CNN / Daily Mail - Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  Multi-News - Multi-Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  RASG - Reader-Aware Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  MTS - Timeline Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-1 ,  X-Sum - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  32\n",
      "####### ROUGE\\\\-2\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  DUC 2004 Task 1 - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  DUC 2004 Task 1 - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  GigaWord - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  CNN / Daily Mail (Anonymized) - Text Summarization benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  CNN / Daily Mail - Abstractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  CNN / Daily Mail - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  CNN / Daily Mail - Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  Multi-News - Multi-Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  ROUGE\\\\-2 ,  X-Sum - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  25\n",
      "####### ROUGE\\\\-L\n",
      "Creating ratio df for  ROUGE\\\\-L ,  DUC 2004 Task 1 - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  ROUGE\\\\-L ,  DUC 2004 Task 1 - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE\\\\-L ,  CNN / Daily Mail - Abstractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  ROUGE\\\\-L ,  CNN / Daily Mail (Anonymized) - Text Summarization benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  ROUGE\\\\-L ,  GigaWord - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  ROUGE\\\\-L ,  CNN / Daily Mail - Extractive Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  ROUGE\\\\-L ,  CNN / Daily Mail - Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  ROUGE\\\\-L ,  E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  ROUGE\\\\-L ,  ACL Title and Abstract Dataset - Paper generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  23\n",
      "####### Mean\\\\ Acc\\\\ \\\\(Restaurant\\\\ \\\\+\\\\ Laptop\\\\)\n",
      "Creating ratio df for  Mean\\\\ Acc\\\\ \\\\(Restaurant\\\\ \\\\+\\\\ Laptop\\\\) ,  SemEval 2014 Task 4 Sub Task 2 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "number of sota per dataset/metric:  11\n",
      "####### Restaurant\\\\ \\\\(Acc\\\\)\n",
      "Creating ratio df for  Restaurant\\\\ \\\\(Acc\\\\) ,  SemEval 2014 Task 4 Sub Task 2 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Restaurant\\\\ \\\\(Acc\\\\) ,  SemEval-2016 Task 5 Subtask 1 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Restaurant\\\\ \\\\(Acc\\\\) ,  SemEval 2015 Task 12 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  12\n",
      "####### Laptop\\\\ \\\\(Acc\\\\)\n",
      "Creating ratio df for  Laptop\\\\ \\\\(Acc\\\\) ,  SemEval 2014 Task 4 Sub Task 2 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "number of sota per dataset/metric:  10\n",
      "####### BLEU\n",
      "Creating ratio df for  BLEU ,  IWSLT2015 English-Vietnamese - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  BLEU ,  WikiBio - Table-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU ,  RotoWire (Content Ordering) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  BLEU ,  RotoWire - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  BLEU ,  WMT 2017 Latvian-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU ,  E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  BLEU ,  WMT2014 French-English - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  BLEU ,  WMT2016 German-English - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  BLEU ,  WMT2014 English-French - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  BLEU ,  WMT2016 English-German - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  BLEU ,  ACCURAT balanced test corpus for under resourced languages Estonian-Russian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  ACCURAT balanced test corpus for under resourced languages Russian-Estonian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  LDC2016E25 - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  LDC2015E86: - Graph-to-Sequence benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  Wikipedia Person and Animal Dataset - KB-to-Language Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  Wikipedia Person and Animal Dataset - Table-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WMT 2018 English-Estonian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WMT 2018 Estonian-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  CoNaLa-Ext - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  CoNaLa - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WMT 2017 English-Latvian - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WMT 2018 English-Finnish - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WMT 2018 Finnish-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU ,  WebNLG - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  SR11Deep - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WMT2014 English-German - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU ,  WMT2014 German-English - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU ,  WMT2016 Romanian-English - Unsupervised Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU ,  JD Product Question Answer - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WMT2016 Finnish-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WMT2017 Finnish-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WMT2019 Finnish-English - Machine Translation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  WebNLG Full - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  ViGGO - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  Cleaned E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  IWSLT2015 Chinese-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  68\n",
      "####### Micro\\\\ Precision\n",
      "Creating ratio df for  Micro\\\\ Precision ,  TAC2010 - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Micro\\\\ Precision ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Micro\\\\ Precision ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  2\n",
      "####### In\\\\-KB\\\\ Accuracy\n",
      "Creating ratio df for  In\\\\-KB\\\\ Accuracy ,  AIDA-CoNLL - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\)\n",
      "Creating ratio df for  Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\) ,  Text8 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\) ,  enwik8 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\) ,  Hutter Prize - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Bit\\\\ per\\\\ Character\\\\ \\\\(BPC\\\\) ,  Penn Treebank (Character Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\-CN\n",
      "Creating ratio df for  Accuracy\\\\-CN ,  Children\\'s Book Test - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\-NE\n",
      "Creating ratio df for  Accuracy\\\\-NE ,  Children\\'s Book Test - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Unigram\\\\ Acc\n",
      "Creating ratio df for  Unigram\\\\ Acc ,  SearchQA - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### N\\\\-gram\\\\ F1\n",
      "Creating ratio df for  N\\\\-gram\\\\ F1 ,  SearchQA - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### ROUGE\n",
      "Creating ratio df for  ROUGE ,  WikiBio - Table-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  ROUGE ,  Wikipedia Person and Animal Dataset - KB-to-Language Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE ,  Wikipedia Person and Animal Dataset - Table-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROUGE ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Number\\\\ of\\\\ params\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  Text8 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  enwik8 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  Hutter Prize - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  Penn Treebank (Character Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  WikiText-2 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  WikiText-103 - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  26\n",
      "####### Avg\\\\ accuracy\n",
      "Creating ratio df for  Avg\\\\ accuracy ,  UD - Part-Of-Speech Tagging benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### R\\\\-at\\\\-1\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Advising Corpus - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  R\\\\-at\\\\-1 ,  Flickr30k Entities Dev - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  15\n",
      "####### R\\\\-at\\\\-10\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Advising Corpus - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  R\\\\-at\\\\-10 ,  Flickr30k Entities Dev - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  14\n",
      "####### R\\\\-at\\\\-5\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Flickr30k Entities Test - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  R\\\\-at\\\\-5 ,  Flickr30k Entities Dev - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  13\n",
      "####### Mean\\\\ Rank\n",
      "Creating ratio df for  Mean\\\\ Rank ,  VisDial v0.9 val - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Precision\n",
      "Creating ratio df for  Precision ,  Twitter Dialogue (Noun) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  Ubuntu Dialogue (Entity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  Ubuntu Dialogue (Activity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  RotoWire (Relation Generation) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  Rotowire (Content Selection) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  Ontonotes v5 (English) - Entity Typing benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Precision ,  CoNLL-2014 Shared Task - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  FewRel - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  Open Entity - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  20NEWS - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Precision ,  SoSciSoCi - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Recall\n",
      "Creating ratio df for  Recall ,  Ubuntu Dialogue (Activity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  Ubuntu Dialogue (Entity) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  Twitter Dialogue (Noun) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  Rotowire (Content Selection) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  Ontonotes v5 (English) - Entity Typing benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Recall ,  CoNLL-2014 Shared Task - Grammatical Error Correction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall ,  FewRel - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall ,  Open Entity - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall ,  20NEWS - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Recall ,  SoSciSoCi - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### EM\\\\ \\\\(Quasar\\\\-T\\\\)\n",
      "Creating ratio df for  EM\\\\ \\\\(Quasar\\\\-T\\\\) ,  Quasar - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### F1\\\\ \\\\(Quasar\\\\-T\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(Quasar\\\\-T\\\\) ,  Quasar - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Joint\n",
      "Creating ratio df for  Joint ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Joint ,  Wizard-of-Oz - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  6\n",
      "####### Area\n",
      "Creating ratio df for  Area ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Food\n",
      "Creating ratio df for  Food ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Price\n",
      "Creating ratio df for  Price ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Request\n",
      "Creating ratio df for  Request ,  Wizard-of-Oz - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Request ,  Second dialogue state tracking challenge - Dialog State Tracking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### Params\n",
      "Creating ratio df for  Params ,  Penn Treebank (Word Level) - Language Modelling benchmarking , ds_count= 1\n",
      "null\n",
      "####### F0\\\\.5\n",
      "Creating ratio df for  F0\\\\.5 ,  CoNLL-2014 A1 - Grammatical Error Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F0\\\\.5 ,  FCE - Grammatical Error Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  F0\\\\.5 ,  CoNLL-2014 A2 - Grammatical Error Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F0\\\\.5 ,  CoNLL-2014 Shared Task - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F0\\\\.5 ,  CoNLL-2014 Shared Task (10 annotations) - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F0\\\\.5 ,  Unrestricted - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F0\\\\.5 ,  Restricted - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F0\\\\.5 ,  JFLEG - Grammatical Error Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  15\n",
      "####### F1\\\\ Newswire\n",
      "Creating ratio df for  F1\\\\ Newswire ,  LDC2014T12: - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  F1\\\\ Newswire ,  LDC2014T12 - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  7\n",
      "####### EM\n",
      "Creating ratio df for  EM ,  SQuAD1.1 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  EM ,  SQuAD1.1 dev - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  EM ,  SQuAD1.1 - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  EM ,  NewsQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  EM ,  SearchQA - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  EM ,  Quasart-T - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  EM ,  TriviaQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  EM ,  SQuAD2.0 - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  EM ,  SQuAD2.0 dev - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  EM ,  ReCoRD - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  EM ,  DuReader - Open-Domain Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  46\n",
      "####### BLEU\\\\-4\n",
      "Creating ratio df for  BLEU\\\\-4 ,  COCO Captions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  BLEU\\\\-4 ,  EMNLP2017 WMT - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\-4 ,  NarrativeQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  BLEU\\\\-4 ,  SQuAD1.1 - Question Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  BLEU\\\\-4 ,  DailyDialog - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  Flickr30k Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-4 ,  COCO Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  17\n",
      "####### BLEU\\\\-2\n",
      "Creating ratio df for  BLEU\\\\-2 ,  Chinese Poems - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\-2 ,  EMNLP2017 WMT - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\-2 ,  COCO Captions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  BLEU\\\\-2 ,  DailyDialog - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-2 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  10\n",
      "####### BLEU\\\\-3\n",
      "Creating ratio df for  BLEU\\\\-3 ,  COCO Captions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  BLEU\\\\-3 ,  EMNLP2017 WMT - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  BLEU\\\\-3 ,  DailyDialog - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU\\\\-3 ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### BLEU\\\\-5\n",
      "Creating ratio df for  BLEU\\\\-5 ,  COCO Captions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  BLEU\\\\-5 ,  EMNLP2017 WMT - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  7\n",
      "####### Inception\\\\ score\n",
      "Creating ratio df for  Inception\\\\ score ,  CUB - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Inception\\\\ score ,  COCO - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Inception\\\\ score ,  Oxford 102 Flowers - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  12\n",
      "####### FID\n",
      "Creating ratio df for  FID ,  CUB - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  FID ,  COCO - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  Oxford 102 Flowers - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  FID ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  7\n",
      "####### Aspect\n",
      "Creating ratio df for  Aspect ,  Sentihood - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Sentiment\n",
      "Creating ratio df for  Sentiment ,  Sentihood - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### P\\\\-at\\\\-5\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Music domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Medical domain - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  General - Hypernym Discovery benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  P\\\\-at\\\\-5 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  14\n",
      "####### F1\\\\ Full\n",
      "Creating ratio df for  F1\\\\ Full ,  LDC2014T12: - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  F1\\\\ Full ,  LDC2014T12 - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  6\n",
      "####### Rouge\\\\-L\n",
      "Creating ratio df for  Rouge\\\\-L ,  MS MARCO - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Rouge\\\\-L ,  NarrativeQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  9\n",
      "####### overall\n",
      "Creating ratio df for  overall ,  VQA v2 test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  overall ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  10\n",
      "####### 1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-2\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-2 ,  Amazon-5 - Dialog Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-2 ,  Ubuntu Dialogue (v1, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-2 ,  Ubuntu Dialogue (v2, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  1\n",
      "####### Sequence\\\\ error\n",
      "Creating ratio df for  Sequence\\\\ error ,  FSNS - Test - Optical Character Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Perplexity\n",
      "Creating ratio df for  Perplexity ,  Yahoo Questions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Perplexity ,  Android Repos - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### KL\n",
      "Creating ratio df for  KL ,  Yahoo Questions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NLL\n",
      "Creating ratio df for  NLL ,  Yahoo Questions - Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Micro\\\\-F1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  WNED-CWEB - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Micro\\\\-F1 ,  WNED-WIKI - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Micro\\\\-F1 ,  MSNBC - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Micro\\\\-F1 ,  ACE2004 - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Micro\\\\-F1 ,  MSNBC - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  OKE-2016 - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  N3-Reuters-128 - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  OKE-2015 - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  Derczynski - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  EC - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Micro\\\\-F1 ,  AQUAINT - Entity Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Micro\\\\-F1 ,  DailyDialog - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  Slashdot - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  RCV1-v2 - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  Reuters-21578 - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  23\n",
      "####### NDCG\\\\ \\\\(x\\\\ 100\\\\)\n",
      "Creating ratio df for  NDCG\\\\ \\\\(x\\\\ 100\\\\) ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MRR\\\\ \\\\(x\\\\ 100\\\\)\n",
      "Creating ratio df for  MRR\\\\ \\\\(x\\\\ 100\\\\) ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Mean\n",
      "Creating ratio df for  Mean ,  Visual Dialog v1.0 test-std - Visual Dialog benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Recall\n",
      "Creating ratio df for  Average\\\\ Recall ,  SemEval 2017 Task 4-A - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Recall ,  ASTD - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Recall ,  ArSAS - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### F1\\\\-score\n",
      "Creating ratio df for  F1\\\\-score ,  SemEval - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-score ,  GeNeVA (i-CLEVR) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1\\\\-score ,  GeNeVA (CoDraw) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  F1\\\\-score ,  200k Short Texts for Humor Detection - Humor Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### SICK\\\\-E\n",
      "Creating ratio df for  SICK\\\\-E ,  SentEval - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### SICK\\\\-R\n",
      "Creating ratio df for  SICK\\\\-R ,  SentEval - Semantic Textual Similarity benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### 14\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  100 sleep nights of 8 caregivers - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  100 sleep nights of 8 caregivers - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Average\\\\ Precision\n",
      "Creating ratio df for  Average\\\\ Precision ,  The ARRAU Corpus - Abstract Anaphora Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Precision ,  New York Times Corpus - Relationship extraction using distant supervision benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Valence\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Valence\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Arousal\\\\)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  MAE\\\\ \\\\(Arousal\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(Expectancy\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Expectancy\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Power\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Power\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Weighted\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  8\n",
      "####### UA\n",
      "Creating ratio df for  UA ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  UA ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Macro\\\\-F1\n",
      "Creating ratio df for  Macro\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Macro\\\\-F1 ,  SemEval 2018 Task 1E-c - Emotion Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### Weighted\\\\ Accuracy\n",
      "Creating ratio df for  Weighted\\\\ Accuracy ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Per\\\\-class\\\\ Accuracy\\\\ \\\\(Unrelated\\\\)\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy\\\\ \\\\(Unrelated\\\\) ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Per\\\\-class\\\\ Accuracy\\\\ \\\\(Agree\\\\)\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy\\\\ \\\\(Agree\\\\) ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Per\\\\-class\\\\ Accuracy\\\\ \\\\(Disagree\\\\)\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy\\\\ \\\\(Disagree\\\\) ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Per\\\\-class\\\\ Accuracy\\\\ \\\\(Discuss\\\\)\n",
      "Creating ratio df for  Per\\\\-class\\\\ Accuracy\\\\ \\\\(Discuss\\\\) ,  FNC-1 - Fake News Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Consistency\n",
      "Creating ratio df for  Consistency ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Plausibility\n",
      "Creating ratio df for  Plausibility ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Validity\n",
      "Creating ratio df for  Validity ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Distribution\n",
      "Creating ratio df for  Distribution ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### DLD\n",
      "Creating ratio df for  DLD ,  RotoWire (Content Ordering) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### count\n",
      "Creating ratio df for  count ,  RotoWire (Relation Generation) - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### Binary\n",
      "Creating ratio df for  Binary ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Open\n",
      "Creating ratio df for  Open ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Execution\\\\ Accuracy\n",
      "Creating ratio df for  Execution\\\\ Accuracy ,  WikiSQL - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Exact\\\\ Match\\\\ Accuracy\n",
      "Creating ratio df for  Exact\\\\ Match\\\\ Accuracy ,  WikiSQL - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Error\\\\ rate\n",
      "Creating ratio df for  Error\\\\ rate ,  Wikipedia-Wikidata relations - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Senseval\\\\ 2\n",
      "Creating ratio df for  Senseval\\\\ 2 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Senseval\\\\ 3\n",
      "Creating ratio df for  Senseval\\\\ 3 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### SemEval\\\\ 2013\n",
      "Creating ratio df for  SemEval\\\\ 2013 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  SemEval\\\\ 2013 ,  Knowledge-based: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### SemEval\\\\ 2015\n",
      "Creating ratio df for  SemEval\\\\ 2015 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  SemEval\\\\ 2015 ,  Knowledge-based: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### F1\\\\ \\\\(surface\\\\ form\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(surface\\\\ form\\\\) ,  Long-tail emerging entities - Named Entity Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 1\\\\-of\\\\-100\\\\ Accuracy\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  20NEWS - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  PolyAI Reddit - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  DSTC7 Ubuntu - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  PolyAI AmazonQA - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  1\\\\-of\\\\-100\\\\ Accuracy ,  PolyAI OpenSubtitles - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  13\n",
      "####### 1\\\\ in\\\\ 2\\\\ R\\\\-at\\\\-1\n",
      "Creating ratio df for  1\\\\ in\\\\ 2\\\\ R\\\\-at\\\\-1 ,  Ubuntu Dialogue (v1, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 2\\\\ R\\\\-at\\\\-1 ,  Ubuntu Dialogue (v2, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### 1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-1\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-1 ,  Ubuntu Dialogue (v1, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-1 ,  Ubuntu Dialogue (v2, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "####### 1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Ubuntu Dialogue (v1, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Ubuntu Dialogue (v2, Ranking) - Answer Selection benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Visual Dialog v0.9 - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Visual Dialog  v0.9 - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Test\n",
      "Creating ratio df for  Test ,  WikiHop - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Test ,  SWAG - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  7\n",
      "####### Holder\\\\ Binary\\\\ F1\n",
      "Creating ratio df for  Holder\\\\ Binary\\\\ F1 ,  MPQA - Fine-Grained Opinion Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Target\\\\ Binary\\\\ F1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  Target\\\\ Binary\\\\ F1 ,  MPQA - Fine-Grained Opinion Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Mean\\\\ F1\\\\ \\\\(WSJ\\\\)\n",
      "Creating ratio df for  Mean\\\\ F1\\\\ \\\\(WSJ\\\\) ,  PTB - Constituency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Max\\\\ F1\\\\ \\\\(WSJ\\\\)\n",
      "Creating ratio df for  Max\\\\ F1\\\\ \\\\(WSJ\\\\) ,  PTB - Constituency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Exact\\\\ Span\\\\ F1\n",
      "Creating ratio df for  Exact\\\\ Span\\\\ F1 ,  CoNLL 2000 - Chunking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Exact\\\\ Span\\\\ F1 ,  STM-corpus - Scientific Concept Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### nDCG\\\\-at\\\\-20\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  TREC Robust04 - Ad-Hoc Information Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-20 ,  ClueWeb09-B - Document Ranking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### P\\\\-at\\\\-20\n",
      "Creating ratio df for  P\\\\-at\\\\-20 ,  TREC Robust04 - Ad-Hoc Information Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### LPIPS\n",
      "Creating ratio df for  LPIPS ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Acc\n",
      "Creating ratio df for  Acc ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Real\n",
      "Creating ratio df for  Real ,  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### SOA\\\\-C\n",
      "Creating ratio df for  SOA\\\\-C ,  COCO - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### CIDEr\n",
      "Creating ratio df for  CIDEr ,  E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  CIDEr ,  COCO - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  CIDEr ,  COCO Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  CIDEr ,  Flickr30k Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### NIST\n",
      "Creating ratio df for  NIST ,  E2E NLG Challenge - Data-to-Text Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### All\n",
      "Creating ratio df for  All ,  Knowledge-based: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### GLEU\n",
      "Creating ratio df for  GLEU ,  _Restricted_ - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  GLEU ,  Unrestricted - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  GLEU ,  JFLEG - Grammatical Error Correction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### SemEval\\\\ 2007\n",
      "Creating ratio df for  SemEval\\\\ 2007 ,  Supervised: - Word Sense Disambiguation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### RACE\\\\-m\n",
      "Creating ratio df for  RACE\\\\-m ,  RACE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### RACE\\\\-h\n",
      "Creating ratio df for  RACE\\\\-h ,  RACE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### RACE\n",
      "Creating ratio df for  RACE ,  RACE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Matched\n",
      "Creating ratio df for  Matched ,  MultiNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Mismatched\n",
      "Creating ratio df for  Mismatched ,  MultiNLI - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### v2v\\\\ error\n",
      "Creating ratio df for  v2v\\\\ error ,  Expressive hands and faces dataset (EHF). - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### RE\\\\+\\\\ Macro\\\\ F1\n",
      "Creating ratio df for  RE\\\\+\\\\ Macro\\\\ F1 ,  ADE Corpus - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  RE\\\\+\\\\ Macro\\\\ F1 ,  CoNLL04 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### NER\\\\ Macro\\\\ F1\n",
      "Creating ratio df for  NER\\\\ Macro\\\\ F1 ,  ADE Corpus - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  NER\\\\ Macro\\\\ F1 ,  CoNLL04 - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\\\\ \\\\(%\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(%\\\\) ,  LOCAL DATASET - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Cross\\\\-Ent\n",
      "Creating ratio df for  Average\\\\ Cross\\\\-Ent ,  Event2Mind dev - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Cross\\\\-Ent ,  Event2Mind test - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  3\n",
      "####### AUC\n",
      "Creating ratio df for  AUC ,  SLAM 2018 - Language Acquisition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  New York Times Corpus - Relationship extraction using distant supervision benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Score\n",
      "Creating ratio df for  Score ,  Winograd Schema Challenge - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Score ,  VQA-CP - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  6\n",
      "####### BEP\n",
      "Creating ratio df for  BEP ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F\\\\-measure\n",
      "Creating ratio df for  F\\\\-measure ,  R8 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F\\\\-measure ,  20NEWS - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  4\n",
      "####### Macro\\\\ F1\n",
      "Creating ratio df for  Macro\\\\ F1 ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Macro\\\\ F1 ,  FIGER - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Macro\\\\ F1 ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Macro\\\\ F1 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Macro\\\\ F1 ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  3\n",
      "####### Micro\\\\ F1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  Freebase FIGER - Entity Typing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  FIGER - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Micro\\\\ F1 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Micro\\\\ F1 ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  5\n",
      "####### 10\\\\ fold\\\\ Cross\\\\ validation\n",
      "Creating ratio df for  10\\\\ fold\\\\ Cross\\\\ validation ,  2017_test set - Paraphrase Identification benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\n",
      "Creating ratio df for  MAE ,  CMU-MOSEI - Multimodal Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Dev\n",
      "Creating ratio df for  Dev ,  SWAG - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### In\\\\-domain\n",
      "Creating ratio df for  In\\\\-domain ,  CoQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Overall\n",
      "Creating ratio df for  Overall ,  CoQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Out\\\\-of\\\\-domain\n",
      "Creating ratio df for  Out\\\\-of\\\\-domain ,  CoQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### F1\\\\-Score\n",
      "Creating ratio df for  F1\\\\-Score ,  CoQA - Generative Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Micro\\\\-F1\\\\ strong\n",
      "Creating ratio df for  Micro\\\\-F1\\\\ strong ,  AIDA-CoNLL - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Macro\\\\-F1\\\\ strong\n",
      "Creating ratio df for  Macro\\\\-F1\\\\ strong ,  AIDA-CoNLL - Entity Linking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### SacreBLEU\n",
      "Creating ratio df for  SacreBLEU ,  WMT2014 English-French - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SacreBLEU ,  WMT2014 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SacreBLEU ,  WMT2019 English-German - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Mean\\\\ F1\\\\ \\\\(WSJ10\\\\)\n",
      "Creating ratio df for  Mean\\\\ F1\\\\ \\\\(WSJ10\\\\) ,  PTB - Constituency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Entity\\\\ F1\n",
      "Creating ratio df for  Entity\\\\ F1 ,  SciERC - Joint Entity and Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Relation\\\\ F1\n",
      "Creating ratio df for  Relation\\\\ F1 ,  SciERC - Joint Entity and Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### ROUGE\\\\-SU4\n",
      "Creating ratio df for  ROUGE\\\\-SU4 ,  Multi-News - Multi-Document Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### HEQD\n",
      "Creating ratio df for  HEQD ,  QuAC - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### HEQQ\n",
      "Creating ratio df for  HEQQ ,  QuAC - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Max\\\\ F1\\\\ \\\\(WSJ10\\\\)\n",
      "Creating ratio df for  Max\\\\ F1\\\\ \\\\(WSJ10\\\\) ,  PTB - Constituency Grammar Induction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### infNDCG\n",
      "Creating ratio df for  infNDCG ,  TREC-PM - Information Retrieval benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### rsim\n",
      "Creating ratio df for  rsim ,  GeNeVA (CoDraw) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  rsim ,  GeNeVA (i-CLEVR) - Text-to-Image Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### Pointing\\\\ Game\\\\ Accuracy\n",
      "Creating ratio df for  Pointing\\\\ Game\\\\ Accuracy ,  Flickr30k - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Pointing\\\\ Game\\\\ Accuracy ,  ReferIt - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Pointing\\\\ Game\\\\ Accuracy ,  Visual Genome - Phrase Grounding benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Slot\\\\ F1\\\\ Score\n",
      "Creating ratio df for  Slot\\\\ F1\\\\ Score ,  SNIPS - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Intent\\\\ Accuracy\n",
      "Creating ratio df for  Intent\\\\ Accuracy ,  SNIPS - Intent Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### R@50\n",
      "Creating ratio df for  R@50 ,  Advising Corpus - Conversational Response Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\ \\\\(Long\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(Long\\\\) ,  Natural Questions - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\\\\ \\\\(Short\\\\)\n",
      "Creating ratio df for  F1\\\\ \\\\(Short\\\\) ,  Natural Questions - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Bits\\\\ per\\\\ byte\n",
      "Creating ratio df for  Bits\\\\ per\\\\ byte ,  The Pile - Language Modelling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### interest\\\\ \\\\(human\\\\)\n",
      "Creating ratio df for  interest\\\\ \\\\(human\\\\) ,  Reddit (multi-ref) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### relevance\\\\ \\\\(human\\\\)\n",
      "Creating ratio df for  relevance\\\\ \\\\(human\\\\) ,  Reddit (multi-ref) - Dialog Generation benchmarking , ds_count= 1\n",
      "null\n",
      "####### Accuracy\\\\ \\\\(3\\\\-way\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(3\\\\-way\\\\) ,  SemEval 2014 Task 4 Subtask 4 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(4\\\\-way\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(4\\\\-way\\\\) ,  SemEval 2014 Task 4 Subtask 4 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Binary\\\\ Accuracy\n",
      "Creating ratio df for  Binary\\\\ Accuracy ,  SemEval 2014 Task 4 Subtask 4 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Laptop\\\\ \\\\(F1\\\\)\n",
      "Creating ratio df for  Laptop\\\\ \\\\(F1\\\\) ,  SemEval 2014 Task 4 Sub Task 1 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Restaurant\\\\ \\\\(F1\\\\)\n",
      "Creating ratio df for  Restaurant\\\\ \\\\(F1\\\\) ,  SemEval 2014 Task 4 Sub Task 1 - Aspect-Based Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Phoneme\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Phoneme\\\\ Error\\\\ Rate ,  CMUDict 0.7b - Text-To-Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\)\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  CMUDict 0.7b - Text-To-Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  Tashkeela - Arabic Text Diacritization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\ \\\\(10\\\\ classes\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(10\\\\ classes\\\\) ,  IMDb - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### mAP\n",
      "Creating ratio df for  mAP ,  TREC-PM - Passage Re-Ranking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Diacritic\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Diacritic\\\\ Error\\\\ Rate ,  Tashkeela - Arabic Text Diacritization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### JOINT\\\\-F1\n",
      "Creating ratio df for  JOINT\\\\-F1 ,  HotpotQA - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Smatch\n",
      "Creating ratio df for  Smatch ,  LDC2017T10 - AMR Parsing benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Audio\\\\ Quality\\\\ MOS\n",
      "Creating ratio df for  Audio\\\\ Quality\\\\ MOS ,  LJSpeech - Text-To-Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### nDCG\\\\-at\\\\-5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-5 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### nDCG\\\\-at\\\\-3\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-3 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### P\\\\-at\\\\-3\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  Kan-Shan Cup - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  Wiki-30K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  AAPD - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  Amazon-12K - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  P\\\\-at\\\\-3 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### RP\\\\-at\\\\-5\n",
      "Creating ratio df for  RP\\\\-at\\\\-5 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### nDCG\\\\-at\\\\-1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-1 ,  RCV1 - Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-1 ,  EUR-Lex - Multi-Label Text Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Ign\\\\ F1\n",
      "Creating ratio df for  Ign\\\\ F1 ,  DocRED - Relation Extraction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Restaurant\\\\ 2014\\\\ \\\\(F1\\\\)\n",
      "Creating ratio df for  Restaurant\\\\ 2014\\\\ \\\\(F1\\\\) ,  SemEval - Aspect Term Extraction and Sentiment Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Laptop\\\\ 2014\\\\ \\\\(F1\\\\)\n",
      "Creating ratio df for  Laptop\\\\ 2014\\\\ \\\\(F1\\\\) ,  SemEval - Aspect Term Extraction and Sentiment Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Restaurant\\\\ 2015\\\\ \\\\(F1\\\\)\n",
      "Creating ratio df for  Restaurant\\\\ 2015\\\\ \\\\(F1\\\\) ,  SemEval - Aspect Term Extraction and Sentiment Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### A1\n",
      "Creating ratio df for  A1 ,  ANLI test - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### A2\n",
      "Creating ratio df for  A2 ,  ANLI test - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### A3\n",
      "Creating ratio df for  A3 ,  ANLI test - Natural Language Inference benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ERR\\\\-at\\\\-20\n",
      "Creating ratio df for  ERR\\\\-at\\\\-20 ,  ClueWeb09-B - Document Ranking benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(High\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(High\\\\) ,  RACE - Reading Comprehension benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Accuracy\\\\ \\\\(Middle\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Middle\\\\) ,  RACE - Reading Comprehension benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Macro\\\\ Recall\n",
      "Creating ratio df for  Macro\\\\ Recall ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Macro\\\\ Recall ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "####### Micro\\\\ Recall\n",
      "Creating ratio df for  Micro\\\\ Recall ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Micro\\\\ Recall ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "####### Macro\\\\ Precision\n",
      "Creating ratio df for  Macro\\\\ Precision ,  NLP-TDMS (Exp, arXiv only) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Macro\\\\ Precision ,  PWC Leaderboards (restricted) - Scientific Results Extraction benchmarking , ds_count= 1\n",
      "null\n",
      "####### Bias\\\\ \\\\(F/M\\\\)\n",
      "Creating ratio df for  Bias\\\\ \\\\(F/M\\\\) ,  GAP - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Overall\\\\ F1\n",
      "Creating ratio df for  Overall\\\\ F1 ,  GAP - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Masculine\\\\ F1\\\\ \\\\(M\\\\)\n",
      "Creating ratio df for  Masculine\\\\ F1\\\\ \\\\(M\\\\) ,  GAP - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Feminine\\\\ F1\\\\ \\\\(F\\\\)\n",
      "Creating ratio df for  Feminine\\\\ F1\\\\ \\\\(F\\\\) ,  GAP - Coreference Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Dev\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Dev\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Test\\\\-P\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\-P\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Test\\\\-U\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\-U\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### number\n",
      "Creating ratio df for  number ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### unanswerable\n",
      "Creating ratio df for  unanswerable ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### yes/no\n",
      "Creating ratio df for  yes/no ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### other\n",
      "Creating ratio df for  other ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ROUGE\\\\-3\n",
      "Creating ratio df for  ROUGE\\\\-3 ,  X-Sum - Text Summarization benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### R\\\\^2\n",
      "Creating ratio df for  R\\\\^2 ,  FiQA - Sentiment Analysis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Recall\\\\-at\\\\-10\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Visual Dialog  v0.9 - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### SPICE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ratio df for  SPICE ,  Flickr30k Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  SPICE ,  COCO Captions test - Image Captioning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Weighted\\\\ Macro\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\ Macro\\\\-F1 ,  EmoryNLP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Cased\\\\ sacreBLEU\n",
      "Creating ratio df for  Cased\\\\ sacreBLEU ,  IWSLT2017 French-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Cased\\\\ sacreBLEU ,  IWSLT2017 Arabic-English - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Cased\\\\ sacreBLEU ,  IWSLT2017 English-Arabic - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Cased\\\\ sacreBLEU ,  IWSLT2017 English-French - Machine Translation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  4\n",
      "####### ICAT\\\\ Score\n",
      "Creating ratio df for  ICAT\\\\ Score ,  StereoSet - Bias Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### PA\n",
      "Creating ratio df for  PA ,  SCDE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### DE\n",
      "Creating ratio df for  DE ,  SCDE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### BA\n",
      "Creating ratio df for  BA ,  SCDE - Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "AMR Parsing",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "AMR Parsing",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2018-10",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "AMR Parsing",
          "AMR Parsing",
          "AMR Parsing"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Abstractive Text Summarization",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Abstractive Text Summarization",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-08",
          "2019-05",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Abstractive Text Summarization",
          "Abstractive Text Summarization",
          "Abstractive Text Summarization"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Ad-Hoc Information Retrieval",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Ad-Hoc Information Retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-04",
          "2018-09",
          "2018-10",
          "2018-12",
          "2019-03",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Aspect-Based Sentiment Analysis",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Aspect-Based Sentiment Analysis",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-05",
          "2017-09",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-10",
          "2019-02",
          "2019-06",
          "2019-08",
          "2019-12",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Chinese Named Entity Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Chinese Named Entity Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-04",
          "2019-07",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Chinese Named Entity Recognition",
          "Chinese Named Entity Recognition",
          "Chinese Named Entity Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Chunking",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Chunking",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2018-08"
         ],
         "xaxis": "x",
         "y": [
          "Chunking",
          "Chunking"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Citation Intent Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Citation Intent Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-06",
          "2018-01",
          "2018-02"
         ],
         "xaxis": "x",
         "y": [
          "Citation Intent Classification",
          "Citation Intent Classification",
          "Citation Intent Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Code Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Code Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08",
          "2018-03",
          "2018-04",
          "2018-10",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Common Sense Reasoning",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Common Sense Reasoning",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-02",
          "2019-06",
          "2019-07"
         ],
         "xaxis": "x",
         "y": [
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Constituency Grammar Induction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Constituency Grammar Induction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-08",
          "2018-10",
          "2019-04",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "Constituency Grammar Induction",
          "Constituency Grammar Induction",
          "Constituency Grammar Induction",
          "Constituency Grammar Induction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Constituency Parsing",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Constituency Parsing",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-07",
          "2018-05",
          "2019-03"
         ],
         "xaxis": "x",
         "y": [
          "Constituency Parsing",
          "Constituency Parsing",
          "Constituency Parsing",
          "Constituency Parsing"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Conversational Response Selection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Conversational Response Selection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-02",
          "2018-03",
          "2019-04",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Conversational Response Selection",
          "Conversational Response Selection",
          "Conversational Response Selection",
          "Conversational Response Selection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Coreference Resolution",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Coreference Resolution",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-06",
          "2016-09",
          "2017-07",
          "2018-02",
          "2018-04",
          "2019-07"
         ],
         "xaxis": "x",
         "y": [
          "Coreference Resolution",
          "Coreference Resolution",
          "Coreference Resolution",
          "Coreference Resolution",
          "Coreference Resolution",
          "Coreference Resolution"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Cross-Lingual Bitext Mining",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Cross-Lingual Bitext Mining",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-11",
          "2018-12"
         ],
         "xaxis": "x",
         "y": [
          "Cross-Lingual Bitext Mining",
          "Cross-Lingual Bitext Mining"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Cross-Lingual Document Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Cross-Lingual Document Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-04",
          "2014-12",
          "2018-05",
          "2018-12",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Cross-Lingual Document Classification",
          "Cross-Lingual Document Classification",
          "Cross-Lingual Document Classification",
          "Cross-Lingual Document Classification",
          "Cross-Lingual Document Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Data-to-Text Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Data-to-Text Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-03",
          "2018-04",
          "2018-05",
          "2018-09",
          "2019-04",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Data-to-Text Generation",
          "Data-to-Text Generation",
          "Data-to-Text Generation",
          "Data-to-Text Generation",
          "Data-to-Text Generation",
          "Data-to-Text Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Dependency Parsing",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Dependency Parsing",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-11",
          "2018-07"
         ],
         "xaxis": "x",
         "y": [
          "Dependency Parsing",
          "Dependency Parsing",
          "Dependency Parsing"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Dialog Act Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Dialog Act Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-09",
          "2017-11"
         ],
         "xaxis": "x",
         "y": [
          "Dialog Act Classification",
          "Dialog Act Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Dialog State Tracking",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Dialog State Tracking",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-05",
          "2018-10"
         ],
         "xaxis": "x",
         "y": [
          "Dialog State Tracking",
          "Dialog State Tracking"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Document Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Document Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-09",
          "2016-11",
          "2017-10",
          "2018-08",
          "2019-08",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Document Classification",
          "Document Classification",
          "Document Classification",
          "Document Classification",
          "Document Classification",
          "Document Classification",
          "Document Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Document Summarization",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Document Summarization",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-05",
          "2018-08",
          "2019-03",
          "2019-05",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Document Summarization",
          "Document Summarization",
          "Document Summarization",
          "Document Summarization",
          "Document Summarization"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Emotion Recognition in Conversation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Emotion Recognition in Conversation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-06",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-08",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Entity Disambiguation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Entity Disambiguation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-05",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Entity Disambiguation",
          "Entity Disambiguation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Fake News Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Fake News Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-12",
          "2018-11"
         ],
         "xaxis": "x",
         "y": [
          "Fake News Detection",
          "Fake News Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Grammatical Error Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Grammatical Error Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-11",
          "2017-04",
          "2017-07"
         ],
         "xaxis": "x",
         "y": [
          "Grammatical Error Detection",
          "Grammatical Error Detection",
          "Grammatical Error Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Intent Detection",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Intent Detection",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-06",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Intent Detection",
          "Intent Detection"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Joint Entity and Relation Extraction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Joint Entity and Relation Extraction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-04",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Joint Entity and Relation Extraction",
          "Joint Entity and Relation Extraction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Language Modelling",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Language Modelling",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-12",
          "2016-03",
          "2016-07",
          "2016-09",
          "2016-12",
          "2017-05",
          "2017-07",
          "2017-08",
          "2017-10",
          "2017-11",
          "2018-03",
          "2018-08",
          "2018-09",
          "2019-01"
         ],
         "xaxis": "x",
         "y": [
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Linguistic Acceptability Assessment",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Linguistic Acceptability Assessment",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-06",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Linguistic Acceptability Assessment",
          "Linguistic Acceptability Assessment"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Machine Translation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Machine Translation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-09",
          "2014-10",
          "2016-03",
          "2016-08",
          "2016-09",
          "2016-10",
          "2016-11",
          "2017-01",
          "2017-05",
          "2017-06",
          "2017-11",
          "2018-02",
          "2018-03",
          "2018-06",
          "2018-08",
          "2019-01",
          "2019-05",
          "2019-06",
          "2019-09",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Named Entity Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Named Entity Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-08",
          "2018-10",
          "2019-03",
          "2019-06",
          "2019-08",
          "2019-11"
         ],
         "xaxis": "x",
         "y": [
          "Named Entity Recognition",
          "Named Entity Recognition",
          "Named Entity Recognition",
          "Named Entity Recognition",
          "Named Entity Recognition",
          "Named Entity Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Natural Language Inference",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Natural Language Inference",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-08",
          "2016-09",
          "2017-02",
          "2017-09",
          "2017-11",
          "2017-12",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-09",
          "2018-10",
          "2019-01",
          "2019-07",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Open-Domain Question Answering",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Open-Domain Question Answering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-11",
          "2017-03",
          "2017-11",
          "2018-01",
          "2018-10",
          "2018-11",
          "2019-07"
         ],
         "xaxis": "x",
         "y": [
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Paraphrase Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Paraphrase Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-09",
          "2018-06"
         ],
         "xaxis": "x",
         "y": [
          "Paraphrase Generation",
          "Paraphrase Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Paraphrase Identification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Paraphrase Identification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2013-10",
          "2017-04",
          "2017-09",
          "2018-07",
          "2019-01",
          "2019-06"
         ],
         "xaxis": "x",
         "y": [
          "Paraphrase Identification",
          "Paraphrase Identification",
          "Paraphrase Identification",
          "Paraphrase Identification",
          "Paraphrase Identification",
          "Paraphrase Identification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Part-Of-Speech Tagging",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Part-Of-Speech Tagging",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-08",
          "2017-11",
          "2018-05",
          "2019-08"
         ],
         "xaxis": "x",
         "y": [
          "Part-Of-Speech Tagging",
          "Part-Of-Speech Tagging",
          "Part-Of-Speech Tagging",
          "Part-Of-Speech Tagging"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Question Answering",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Question Answering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-06",
          "2014-12",
          "2015-06",
          "2015-11",
          "2016-02",
          "2016-03",
          "2016-06",
          "2016-08",
          "2016-09",
          "2016-10",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-06",
          "2017-07",
          "2017-08",
          "2017-10",
          "2017-12",
          "2018-01",
          "2018-04",
          "2018-06",
          "2018-07",
          "2018-08",
          "2018-09",
          "2018-10",
          "2018-11",
          "2019-01",
          "2019-02",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Question Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Question Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-06",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Question Generation",
          "Question Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Relation Extraction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Relation Extraction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-01",
          "2017-07",
          "2017-09",
          "2018-07",
          "2018-08",
          "2018-09",
          "2018-10",
          "2018-12",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11",
          "2020-03",
          "2020-04"
         ],
         "xaxis": "x",
         "y": [
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Semantic Parsing",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Semantic Parsing",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-04",
          "2018-10"
         ],
         "xaxis": "x",
         "y": [
          "Semantic Parsing",
          "Semantic Parsing"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Semantic Role Labeling",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Semantic Role Labeling",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-12",
          "2018-02",
          "2018-05",
          "2018-10"
         ],
         "xaxis": "x",
         "y": [
          "Semantic Role Labeling",
          "Semantic Role Labeling",
          "Semantic Role Labeling",
          "Semantic Role Labeling"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Semantic Textual Similarity",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Semantic Textual Similarity",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-03",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Semantic Textual Similarity",
          "Semantic Textual Similarity",
          "Semantic Textual Similarity",
          "Semantic Textual Similarity",
          "Semantic Textual Similarity"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Sentence Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Sentence Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-10",
          "2019-03"
         ],
         "xaxis": "x",
         "y": [
          "Sentence Classification",
          "Sentence Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Sentence Compression",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Sentence Compression",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-07",
          "2018-07"
         ],
         "xaxis": "x",
         "y": [
          "Sentence Compression",
          "Sentence Compression"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Sentiment Analysis",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Sentiment Analysis",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-06",
          "2014-08",
          "2015-02",
          "2015-06",
          "2015-11",
          "2016-02",
          "2017-02",
          "2017-07",
          "2017-08",
          "2017-12",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-10",
          "2019-01",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Text Classification",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Text Classification",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-04",
          "2015-11",
          "2017-02",
          "2018-03",
          "2018-05",
          "2018-07",
          "2018-08",
          "2018-09",
          "2019-01",
          "2019-02",
          "2019-05",
          "2019-09",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Text Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Text Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-05",
          "2017-09"
         ],
         "xaxis": "x",
         "y": [
          "Text Generation",
          "Text Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Text Summarization",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Text Summarization",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-02",
          "2016-06",
          "2017-06",
          "2018-07",
          "2018-08",
          "2019-04",
          "2019-05",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Text-to-Image Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Text-to-Image Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-12",
          "2017-10",
          "2019-03",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Text-to-Image Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Unsupervised Machine Translation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Unsupervised Machine Translation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-10",
          "2019-01",
          "2019-02",
          "2019-05"
         ],
         "xaxis": "x",
         "y": [
          "Unsupervised Machine Translation",
          "Unsupervised Machine Translation",
          "Unsupervised Machine Translation",
          "Unsupervised Machine Translation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Visual Dialog",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Visual Dialog",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-09",
          "2017-11",
          "2018-09",
          "2019-02",
          "2019-04"
         ],
         "xaxis": "x",
         "y": [
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Visual Question Answering",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Visual Question Answering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Word Sense Disambiguation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Word Sense Disambiguation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-06",
          "2018-02",
          "2018-05",
          "2018-11",
          "2019-05",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "AMR Parsing<BR>task: AMR Parsing<BR>date: 2016-11<BR>ratio: 0.47",
          "AMR Parsing<BR>task: AMR Parsing<BR>date: 2018-10<BR>ratio: 0.01",
          "AMR Parsing<BR>task: AMR Parsing<BR>date: 2019-05<BR>ratio: 0.01",
          "Abstractive Text Summarization<BR>task: Abstractive Text Summarization<BR>date: 2018-08<BR>ratio: 0.04",
          "Abstractive Text Summarization<BR>task: Abstractive Text Summarization<BR>date: 2019-05<BR>ratio: 0.06",
          "Abstractive Text Summarization<BR>task: Abstractive Text Summarization<BR>date: 2019-10<BR>ratio: 0.02",
          "Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2017-04<BR>ratio: 0.43",
          "Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2018-09<BR>ratio: 0.0",
          "Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2018-10<BR>ratio: 0.0",
          "Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2018-12<BR>ratio: 0.0",
          "Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2019-03<BR>ratio: 0.0",
          "Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2019-04<BR>ratio: 0.1",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2016-05<BR>ratio: 0.05",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2017-09<BR>ratio: 0.02",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2018-02<BR>ratio: 0.01",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2018-04<BR>ratio: 0.04",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2018-05<BR>ratio: 0.01",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2018-10<BR>ratio: 0.02",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2019-02<BR>ratio: 0.02",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2019-06<BR>ratio: 0.01",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2019-08<BR>ratio: 0.03",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2019-12<BR>ratio: 0.02",
          "Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2020-04<BR>ratio: 0.01",
          "Chinese Named Entity Recognition<BR>task: Chinese Named Entity Recognition<BR>date: 2019-04<BR>ratio: 0.5",
          "Chinese Named Entity Recognition<BR>task: Chinese Named Entity Recognition<BR>date: 2019-07<BR>ratio: 0.01",
          "Chinese Named Entity Recognition<BR>task: Chinese Named Entity Recognition<BR>date: 2019-11<BR>ratio: 0.01",
          "Chunking<BR>task: Chunking<BR>date: 2016-11<BR>ratio: 0.0",
          "Chunking<BR>task: Chunking<BR>date: 2018-08<BR>ratio: 0.01",
          "Citation Intent Classification<BR>task: Citation Intent Classification<BR>date: 2016-06<BR>ratio: 0.2",
          "Citation Intent Classification<BR>task: Citation Intent Classification<BR>date: 2018-01<BR>ratio: 0.02",
          "Citation Intent Classification<BR>task: Citation Intent Classification<BR>date: 2018-02<BR>ratio: 0.03",
          "Code Generation<BR>task: Code Generation<BR>date: 2017-08<BR>ratio: 0.31",
          "Code Generation<BR>task: Code Generation<BR>date: 2018-03<BR>ratio: 0.14",
          "Code Generation<BR>task: Code Generation<BR>date: 2018-04<BR>ratio: 0.08",
          "Code Generation<BR>task: Code Generation<BR>date: 2018-10<BR>ratio: 0.11",
          "Code Generation<BR>task: Code Generation<BR>date: 2019-10<BR>ratio: 0.12",
          "Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-02<BR>ratio: 0.1",
          "Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-06<BR>ratio: 0.12",
          "Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-07<BR>ratio: 0.07",
          "Constituency Grammar Induction<BR>task: Constituency Grammar Induction<BR>date: 2018-08<BR>ratio: 0.45",
          "Constituency Grammar Induction<BR>task: Constituency Grammar Induction<BR>date: 2018-10<BR>ratio: 0.22",
          "Constituency Grammar Induction<BR>task: Constituency Grammar Induction<BR>date: 2019-04<BR>ratio: 0.04",
          "Constituency Grammar Induction<BR>task: Constituency Grammar Induction<BR>date: 2019-06<BR>ratio: 0.06",
          "Constituency Parsing<BR>task: Constituency Parsing<BR>date: 2016-11<BR>ratio: 0.02",
          "Constituency Parsing<BR>task: Constituency Parsing<BR>date: 2017-07<BR>ratio: 0.01",
          "Constituency Parsing<BR>task: Constituency Parsing<BR>date: 2018-05<BR>ratio: 0.01",
          "Constituency Parsing<BR>task: Constituency Parsing<BR>date: 2019-03<BR>ratio: 0.01",
          "Conversational Response Selection<BR>task: Conversational Response Selection<BR>date: 2018-02<BR>ratio: 0.27",
          "Conversational Response Selection<BR>task: Conversational Response Selection<BR>date: 2018-03<BR>ratio: 0.4",
          "Conversational Response Selection<BR>task: Conversational Response Selection<BR>date: 2019-04<BR>ratio: 0.28",
          "Conversational Response Selection<BR>task: Conversational Response Selection<BR>date: 2019-11<BR>ratio: 0.1",
          "Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2016-06<BR>ratio: 0.01",
          "Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2016-09<BR>ratio: 0.01",
          "Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2017-07<BR>ratio: 0.31",
          "Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2018-02<BR>ratio: 0.04",
          "Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2018-04<BR>ratio: 0.03",
          "Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2019-07<BR>ratio: 0.05",
          "Cross-Lingual Bitext Mining<BR>task: Cross-Lingual Bitext Mining<BR>date: 2018-11<BR>ratio: 0.18",
          "Cross-Lingual Bitext Mining<BR>task: Cross-Lingual Bitext Mining<BR>date: 2018-12<BR>ratio: 0.01",
          "Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2014-04<BR>ratio: 0.03",
          "Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2014-12<BR>ratio: 0.06",
          "Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2018-05<BR>ratio: 0.48",
          "Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2018-12<BR>ratio: 0.04",
          "Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2019-09<BR>ratio: 0.19",
          "Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2018-03<BR>ratio: 0.04",
          "Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2018-04<BR>ratio: 0.01",
          "Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2018-05<BR>ratio: 0.01",
          "Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2018-09<BR>ratio: 0.13",
          "Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2019-04<BR>ratio: 0.03",
          "Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2019-12<BR>ratio: 0.06",
          "Dependency Parsing<BR>task: Dependency Parsing<BR>date: 2016-03<BR>ratio: 0.01",
          "Dependency Parsing<BR>task: Dependency Parsing<BR>date: 2016-11<BR>ratio: 0.34",
          "Dependency Parsing<BR>task: Dependency Parsing<BR>date: 2018-07<BR>ratio: 0.01",
          "Dialog Act Classification<BR>task: Dialog Act Classification<BR>date: 2017-09<BR>ratio: 0.08",
          "Dialog Act Classification<BR>task: Dialog Act Classification<BR>date: 2017-11<BR>ratio: 0.03",
          "Dialog State Tracking<BR>task: Dialog State Tracking<BR>date: 2018-05<BR>ratio: 0.02",
          "Dialog State Tracking<BR>task: Dialog State Tracking<BR>date: 2018-10<BR>ratio: 0.01",
          "Document Classification<BR>task: Document Classification<BR>date: 2016-03<BR>ratio: 0.1",
          "Document Classification<BR>task: Document Classification<BR>date: 2016-09<BR>ratio: 0.07",
          "Document Classification<BR>task: Document Classification<BR>date: 2016-11<BR>ratio: 0.0",
          "Document Classification<BR>task: Document Classification<BR>date: 2017-10<BR>ratio: 0.02",
          "Document Classification<BR>task: Document Classification<BR>date: 2018-08<BR>ratio: 0.0",
          "Document Classification<BR>task: Document Classification<BR>date: 2019-08<BR>ratio: 0.35",
          "Document Classification<BR>task: Document Classification<BR>date: 2020-02<BR>ratio: 0.01",
          "Document Summarization<BR>task: Document Summarization<BR>date: 2017-05<BR>ratio: 0.43",
          "Document Summarization<BR>task: Document Summarization<BR>date: 2018-08<BR>ratio: 0.12",
          "Document Summarization<BR>task: Document Summarization<BR>date: 2019-03<BR>ratio: 0.05",
          "Document Summarization<BR>task: Document Summarization<BR>date: 2019-05<BR>ratio: 0.01",
          "Document Summarization<BR>task: Document Summarization<BR>date: 2019-08<BR>ratio: 0.01",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-06<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-10<BR>ratio: 0.04",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-11<BR>ratio: 0.05",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-04<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-08<BR>ratio: 0.03",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-09<BR>ratio: 0.5",
          "Entity Disambiguation<BR>task: Entity Disambiguation<BR>date: 2017-05<BR>ratio: 0.03",
          "Entity Disambiguation<BR>task: Entity Disambiguation<BR>date: 2019-09<BR>ratio: 0.13",
          "Fake News Detection<BR>task: Fake News Detection<BR>date: 2017-12<BR>ratio: 0.1",
          "Fake News Detection<BR>task: Fake News Detection<BR>date: 2018-11<BR>ratio: 0.04",
          "Grammatical Error Detection<BR>task: Grammatical Error Detection<BR>date: 2016-11<BR>ratio: 0.02",
          "Grammatical Error Detection<BR>task: Grammatical Error Detection<BR>date: 2017-04<BR>ratio: 0.13",
          "Grammatical Error Detection<BR>task: Grammatical Error Detection<BR>date: 2017-07<BR>ratio: 0.03",
          "Intent Detection<BR>task: Intent Detection<BR>date: 2019-06<BR>ratio: 0.34",
          "Intent Detection<BR>task: Intent Detection<BR>date: 2019-12<BR>ratio: 0.49",
          "Joint Entity and Relation Extraction<BR>task: Joint Entity and Relation Extraction<BR>date: 2019-04<BR>ratio: 0.03",
          "Joint Entity and Relation Extraction<BR>task: Joint Entity and Relation Extraction<BR>date: 2019-09<BR>ratio: 0.09",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2014-12<BR>ratio: 0.03",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2016-03<BR>ratio: 0.01",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2016-07<BR>ratio: 0.5",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2016-09<BR>ratio: 0.08",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2016-12<BR>ratio: 0.37",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2017-05<BR>ratio: 0.0",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2017-07<BR>ratio: 0.02",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2017-08<BR>ratio: 0.01",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2017-10<BR>ratio: 0.0",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2017-11<BR>ratio: 0.0",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2018-03<BR>ratio: 0.34",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2018-08<BR>ratio: 0.26",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2018-09<BR>ratio: 0.34",
          "Language Modelling<BR>task: Language Modelling<BR>date: 2019-01<BR>ratio: 0.05",
          "Linguistic Acceptability Assessment<BR>task: Linguistic Acceptability Assessment<BR>date: 2019-06<BR>ratio: 0.01",
          "Linguistic Acceptability Assessment<BR>task: Linguistic Acceptability Assessment<BR>date: 2019-09<BR>ratio: 0.0",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2014-09<BR>ratio: 0.29",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2014-10<BR>ratio: 0.02",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2016-03<BR>ratio: 0.03",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2016-08<BR>ratio: 0.02",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2016-09<BR>ratio: 0.08",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2016-10<BR>ratio: 0.11",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2016-11<BR>ratio: 0.01",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2017-01<BR>ratio: 0.02",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2017-05<BR>ratio: 0.03",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2017-06<BR>ratio: 0.09",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2017-11<BR>ratio: 0.21",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2018-02<BR>ratio: 0.08",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2018-03<BR>ratio: 0.33",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2018-06<BR>ratio: 0.03",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2018-08<BR>ratio: 0.38",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2019-01<BR>ratio: 0.22",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2019-05<BR>ratio: 0.09",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2019-06<BR>ratio: 0.06",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2019-09<BR>ratio: 0.04",
          "Machine Translation<BR>task: Machine Translation<BR>date: 2019-10<BR>ratio: 0.06",
          "Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2018-08<BR>ratio: 0.19",
          "Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2018-10<BR>ratio: 0.37",
          "Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2019-03<BR>ratio: 0.01",
          "Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2019-06<BR>ratio: 0.04",
          "Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2019-08<BR>ratio: 0.03",
          "Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2019-11<BR>ratio: 0.01",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2014-08<BR>ratio: 0.01",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2016-09<BR>ratio: 0.01",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2017-02<BR>ratio: 0.0",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2017-09<BR>ratio: 0.0",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2017-11<BR>ratio: 0.0",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2017-12<BR>ratio: 0.45",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-04<BR>ratio: 0.01",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-05<BR>ratio: 0.01",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-06<BR>ratio: 0.25",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-09<BR>ratio: 0.43",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-10<BR>ratio: 0.04",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2019-01<BR>ratio: 0.05",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2019-07<BR>ratio: 0.03",
          "Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2019-09<BR>ratio: 0.01",
          "Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2016-03<BR>ratio: 0.49",
          "Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2016-11<BR>ratio: 0.49",
          "Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2017-03<BR>ratio: 0.36",
          "Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2017-11<BR>ratio: 0.41",
          "Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2018-01<BR>ratio: 0.28",
          "Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2018-10<BR>ratio: 0.04",
          "Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2018-11<BR>ratio: 0.14",
          "Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2019-07<BR>ratio: 0.41",
          "Paraphrase Generation<BR>task: Paraphrase Generation<BR>date: 2017-09<BR>ratio: 0.5",
          "Paraphrase Generation<BR>task: Paraphrase Generation<BR>date: 2018-06<BR>ratio: 0.5",
          "Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2013-10<BR>ratio: 0.5",
          "Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2017-04<BR>ratio: 0.0",
          "Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2017-09<BR>ratio: 0.01",
          "Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2018-07<BR>ratio: 0.0",
          "Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2019-01<BR>ratio: 0.49",
          "Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2019-06<BR>ratio: 0.01",
          "Part-Of-Speech Tagging<BR>task: Part-Of-Speech Tagging<BR>date: 2015-08<BR>ratio: 0.49",
          "Part-Of-Speech Tagging<BR>task: Part-Of-Speech Tagging<BR>date: 2017-11<BR>ratio: 0.0",
          "Part-Of-Speech Tagging<BR>task: Part-Of-Speech Tagging<BR>date: 2018-05<BR>ratio: 0.0",
          "Part-Of-Speech Tagging<BR>task: Part-Of-Speech Tagging<BR>date: 2019-08<BR>ratio: 0.0",
          "Question Answering<BR>task: Question Answering<BR>date: 2014-06<BR>ratio: 0.23",
          "Question Answering<BR>task: Question Answering<BR>date: 2014-12<BR>ratio: 0.21",
          "Question Answering<BR>task: Question Answering<BR>date: 2015-06<BR>ratio: 0.36",
          "Question Answering<BR>task: Question Answering<BR>date: 2015-11<BR>ratio: 0.0",
          "Question Answering<BR>task: Question Answering<BR>date: 2016-02<BR>ratio: 0.25",
          "Question Answering<BR>task: Question Answering<BR>date: 2016-03<BR>ratio: 0.39",
          "Question Answering<BR>task: Question Answering<BR>date: 2016-06<BR>ratio: 0.08",
          "Question Answering<BR>task: Question Answering<BR>date: 2016-08<BR>ratio: 0.49",
          "Question Answering<BR>task: Question Answering<BR>date: 2016-09<BR>ratio: 0.03",
          "Question Answering<BR>task: Question Answering<BR>date: 2016-10<BR>ratio: 0.41",
          "Question Answering<BR>task: Question Answering<BR>date: 2016-11<BR>ratio: 0.28",
          "Question Answering<BR>task: Question Answering<BR>date: 2017-03<BR>ratio: 0.28",
          "Question Answering<BR>task: Question Answering<BR>date: 2017-04<BR>ratio: 0.01",
          "Question Answering<BR>task: Question Answering<BR>date: 2017-05<BR>ratio: 0.27",
          "Question Answering<BR>task: Question Answering<BR>date: 2017-06<BR>ratio: 0.05",
          "Question Answering<BR>task: Question Answering<BR>date: 2017-07<BR>ratio: 0.05",
          "Question Answering<BR>task: Question Answering<BR>date: 2017-08<BR>ratio: 0.33",
          "Question Answering<BR>task: Question Answering<BR>date: 2017-10<BR>ratio: 0.34",
          "Question Answering<BR>task: Question Answering<BR>date: 2017-12<BR>ratio: 0.01",
          "Question Answering<BR>task: Question Answering<BR>date: 2018-01<BR>ratio: 0.1",
          "Question Answering<BR>task: Question Answering<BR>date: 2018-04<BR>ratio: 0.23",
          "Question Answering<BR>task: Question Answering<BR>date: 2018-06<BR>ratio: 0.07",
          "Question Answering<BR>task: Question Answering<BR>date: 2018-07<BR>ratio: 0.11",
          "Question Answering<BR>task: Question Answering<BR>date: 2018-08<BR>ratio: 0.41",
          "Question Answering<BR>task: Question Answering<BR>date: 2018-09<BR>ratio: 0.1",
          "Question Answering<BR>task: Question Answering<BR>date: 2018-10<BR>ratio: 0.16",
          "Question Answering<BR>task: Question Answering<BR>date: 2018-11<BR>ratio: 0.05",
          "Question Answering<BR>task: Question Answering<BR>date: 2019-01<BR>ratio: 0.29",
          "Question Answering<BR>task: Question Answering<BR>date: 2019-02<BR>ratio: 0.2",
          "Question Answering<BR>task: Question Answering<BR>date: 2019-05<BR>ratio: 0.12",
          "Question Answering<BR>task: Question Answering<BR>date: 2019-06<BR>ratio: 0.12",
          "Question Answering<BR>task: Question Answering<BR>date: 2019-07<BR>ratio: 0.11",
          "Question Answering<BR>task: Question Answering<BR>date: 2019-08<BR>ratio: 0.0",
          "Question Answering<BR>task: Question Answering<BR>date: 2019-09<BR>ratio: 0.02",
          "Question Generation<BR>task: Question Generation<BR>date: 2018-06<BR>ratio: 0.03",
          "Question Generation<BR>task: Question Generation<BR>date: 2019-05<BR>ratio: 0.39",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2016-01<BR>ratio: 0.05",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2017-07<BR>ratio: 0.04",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2017-09<BR>ratio: 0.34",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-07<BR>ratio: 0.16",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-08<BR>ratio: 0.01",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-09<BR>ratio: 0.03",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-10<BR>ratio: 0.03",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-12<BR>ratio: 0.07",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-02<BR>ratio: 0.01",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-04<BR>ratio: 0.28",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-05<BR>ratio: 0.28",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-06<BR>ratio: 0.22",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-07<BR>ratio: 0.07",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-09<BR>ratio: 0.16",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-11<BR>ratio: 0.01",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2020-03<BR>ratio: 0.03",
          "Relation Extraction<BR>task: Relation Extraction<BR>date: 2020-04<BR>ratio: 0.01",
          "Semantic Parsing<BR>task: Semantic Parsing<BR>date: 2017-04<BR>ratio: 0.01",
          "Semantic Parsing<BR>task: Semantic Parsing<BR>date: 2018-10<BR>ratio: 0.01",
          "Semantic Role Labeling<BR>task: Semantic Role Labeling<BR>date: 2017-12<BR>ratio: 0.01",
          "Semantic Role Labeling<BR>task: Semantic Role Labeling<BR>date: 2018-02<BR>ratio: 0.02",
          "Semantic Role Labeling<BR>task: Semantic Role Labeling<BR>date: 2018-05<BR>ratio: 0.01",
          "Semantic Role Labeling<BR>task: Semantic Role Labeling<BR>date: 2018-10<BR>ratio: 0.02",
          "Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2018-03<BR>ratio: 0.29",
          "Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2019-05<BR>ratio: 0.04",
          "Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2019-06<BR>ratio: 0.07",
          "Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2019-07<BR>ratio: 0.01",
          "Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2019-09<BR>ratio: 0.01",
          "Sentence Classification<BR>task: Sentence Classification<BR>date: 2018-10<BR>ratio: 0.06",
          "Sentence Classification<BR>task: Sentence Classification<BR>date: 2019-03<BR>ratio: 0.32",
          "Sentence Compression<BR>task: Sentence Compression<BR>date: 2017-07<BR>ratio: 0.0",
          "Sentence Compression<BR>task: Sentence Compression<BR>date: 2018-07<BR>ratio: 0.0",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2014-06<BR>ratio: 0.07",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2014-08<BR>ratio: 0.03",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2015-02<BR>ratio: 0.02",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2015-06<BR>ratio: 0.01",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2015-11<BR>ratio: 0.03",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2016-02<BR>ratio: 0.02",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2017-02<BR>ratio: 0.3",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2017-07<BR>ratio: 0.05",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2017-08<BR>ratio: 0.05",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2017-12<BR>ratio: 0.01",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-01<BR>ratio: 0.0",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-02<BR>ratio: 0.04",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-04<BR>ratio: 0.02",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-05<BR>ratio: 0.02",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-10<BR>ratio: 0.04",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-01<BR>ratio: 0.1",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-05<BR>ratio: 0.0",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-06<BR>ratio: 0.0",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-07<BR>ratio: 0.01",
          "Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-09<BR>ratio: 0.0",
          "Text Classification<BR>task: Text Classification<BR>date: 2015-04<BR>ratio: 0.42",
          "Text Classification<BR>task: Text Classification<BR>date: 2015-11<BR>ratio: 0.15",
          "Text Classification<BR>task: Text Classification<BR>date: 2017-02<BR>ratio: 0.17",
          "Text Classification<BR>task: Text Classification<BR>date: 2018-03<BR>ratio: 0.02",
          "Text Classification<BR>task: Text Classification<BR>date: 2018-05<BR>ratio: 0.42",
          "Text Classification<BR>task: Text Classification<BR>date: 2018-07<BR>ratio: 0.03",
          "Text Classification<BR>task: Text Classification<BR>date: 2018-08<BR>ratio: 0.32",
          "Text Classification<BR>task: Text Classification<BR>date: 2018-09<BR>ratio: 0.48",
          "Text Classification<BR>task: Text Classification<BR>date: 2019-01<BR>ratio: 0.03",
          "Text Classification<BR>task: Text Classification<BR>date: 2019-02<BR>ratio: 0.0",
          "Text Classification<BR>task: Text Classification<BR>date: 2019-05<BR>ratio: 0.26",
          "Text Classification<BR>task: Text Classification<BR>date: 2019-09<BR>ratio: 0.13",
          "Text Classification<BR>task: Text Classification<BR>date: 2020-02<BR>ratio: 0.06",
          "Text Generation<BR>task: Text Generation<BR>date: 2017-05<BR>ratio: 0.05",
          "Text Generation<BR>task: Text Generation<BR>date: 2017-09<BR>ratio: 0.13",
          "Text Summarization<BR>task: Text Summarization<BR>date: 2016-02<BR>ratio: 0.35",
          "Text Summarization<BR>task: Text Summarization<BR>date: 2016-06<BR>ratio: 0.01",
          "Text Summarization<BR>task: Text Summarization<BR>date: 2017-06<BR>ratio: 0.04",
          "Text Summarization<BR>task: Text Summarization<BR>date: 2018-07<BR>ratio: 0.0",
          "Text Summarization<BR>task: Text Summarization<BR>date: 2018-08<BR>ratio: 0.04",
          "Text Summarization<BR>task: Text Summarization<BR>date: 2019-04<BR>ratio: 0.12",
          "Text Summarization<BR>task: Text Summarization<BR>date: 2019-05<BR>ratio: 0.02",
          "Text Summarization<BR>task: Text Summarization<BR>date: 2019-10<BR>ratio: 0.19",
          "Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2016-12<BR>ratio: 0.43",
          "Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2017-10<BR>ratio: 0.34",
          "Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2019-03<BR>ratio: 0.03",
          "Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2019-04<BR>ratio: 0.14",
          "Unsupervised Machine Translation<BR>task: Unsupervised Machine Translation<BR>date: 2018-10<BR>ratio: 0.04",
          "Unsupervised Machine Translation<BR>task: Unsupervised Machine Translation<BR>date: 2019-01<BR>ratio: 0.32",
          "Unsupervised Machine Translation<BR>task: Unsupervised Machine Translation<BR>date: 2019-02<BR>ratio: 0.1",
          "Unsupervised Machine Translation<BR>task: Unsupervised Machine Translation<BR>date: 2019-05<BR>ratio: 0.04",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2017-09<BR>ratio: 0.06",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2017-11<BR>ratio: 0.04",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2018-09<BR>ratio: 0.02",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2019-02<BR>ratio: 0.02",
          "Visual Dialog<BR>task: Visual Dialog<BR>date: 2019-04<BR>ratio: 0.05",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-03<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-05<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-06<BR>ratio: 0.45",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-11<BR>ratio: 0.07",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-12<BR>ratio: 0.43",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-04<BR>ratio: 0.35",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-05<BR>ratio: 0.05",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-08<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-03<BR>ratio: 0.0",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-05<BR>ratio: 0.0",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-02<BR>ratio: 0.36",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-04<BR>ratio: 0.33",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-05<BR>ratio: 0.19",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-06<BR>ratio: 0.01",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-07<BR>ratio: 0.14",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-08<BR>ratio: 0.22",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-09<BR>ratio: 0.05",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2020-02<BR>ratio: 0.0",
          "Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2016-03<BR>ratio: 0.41",
          "Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2016-06<BR>ratio: 0.01",
          "Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2018-02<BR>ratio: 0.42",
          "Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2018-05<BR>ratio: 0.15",
          "Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2018-11<BR>ratio: 0.04",
          "Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2019-05<BR>ratio: 0.08",
          "Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2019-09<BR>ratio: 0.11"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.47,
           0.01,
           0.01,
           0.04,
           0.06,
           0.02,
           0.43,
           0,
           0,
           0,
           0,
           0.1,
           0.05,
           0.02,
           0.01,
           0.04,
           0.01,
           0.02,
           0.02,
           0.01,
           0.03,
           0.02,
           0.01,
           0.5,
           0.01,
           0.01,
           0,
           0.01,
           0.2,
           0.02,
           0.03,
           0.31,
           0.14,
           0.08,
           0.11,
           0.12,
           0.1,
           0.12,
           0.07,
           0.45,
           0.22,
           0.04,
           0.06,
           0.02,
           0.01,
           0.01,
           0.01,
           0.27,
           0.4,
           0.28,
           0.1,
           0.01,
           0.01,
           0.31,
           0.04,
           0.03,
           0.05,
           0.18,
           0.01,
           0.03,
           0.06,
           0.48,
           0.04,
           0.19,
           0.04,
           0.01,
           0.01,
           0.13,
           0.03,
           0.06,
           0.01,
           0.34,
           0.01,
           0.08,
           0.03,
           0.02,
           0.01,
           0.1,
           0.07,
           0,
           0.02,
           0,
           0.35,
           0.01,
           0.43,
           0.12,
           0.05,
           0.01,
           0.01,
           0,
           0.04,
           0.05,
           0,
           0.03,
           0.5,
           0.03,
           0.13,
           0.1,
           0.04,
           0.02,
           0.13,
           0.03,
           0.34,
           0.49,
           0.03,
           0.09,
           0.03,
           0.01,
           0.5,
           0.08,
           0.37,
           0,
           0.02,
           0.01,
           0,
           0,
           0.34,
           0.26,
           0.34,
           0.05,
           0.01,
           0,
           0.29,
           0.02,
           0.03,
           0.02,
           0.08,
           0.11,
           0.01,
           0.02,
           0.03,
           0.09,
           0.21,
           0.08,
           0.33,
           0.03,
           0.38,
           0.22,
           0.09,
           0.06,
           0.04,
           0.06,
           0.19,
           0.37,
           0.01,
           0.04,
           0.03,
           0.01,
           0.01,
           0.01,
           0,
           0,
           0,
           0.45,
           0.01,
           0.01,
           0.25,
           0.43,
           0.04,
           0.05,
           0.03,
           0.01,
           0.49,
           0.49,
           0.36,
           0.41,
           0.28,
           0.04,
           0.14,
           0.41,
           0.5,
           0.5,
           0.5,
           0,
           0.01,
           0,
           0.49,
           0.01,
           0.49,
           0,
           0,
           0,
           0.23,
           0.21,
           0.36,
           0,
           0.25,
           0.39,
           0.08,
           0.49,
           0.03,
           0.41,
           0.28,
           0.28,
           0.01,
           0.27,
           0.05,
           0.05,
           0.33,
           0.34,
           0.01,
           0.1,
           0.23,
           0.07,
           0.11,
           0.41,
           0.1,
           0.16,
           0.05,
           0.29,
           0.2,
           0.12,
           0.12,
           0.11,
           0,
           0.02,
           0.03,
           0.39,
           0.05,
           0.04,
           0.34,
           0.16,
           0.01,
           0.03,
           0.03,
           0.07,
           0.01,
           0.28,
           0.28,
           0.22,
           0.07,
           0.16,
           0.01,
           0.03,
           0.01,
           0.01,
           0.01,
           0.01,
           0.02,
           0.01,
           0.02,
           0.29,
           0.04,
           0.07,
           0.01,
           0.01,
           0.06,
           0.32,
           0,
           0,
           0.07,
           0.03,
           0.02,
           0.01,
           0.03,
           0.02,
           0.3,
           0.05,
           0.05,
           0.01,
           0,
           0.04,
           0.02,
           0.02,
           0.04,
           0.1,
           0,
           0,
           0.01,
           0,
           0.42,
           0.15,
           0.17,
           0.02,
           0.42,
           0.03,
           0.32,
           0.48,
           0.03,
           0,
           0.26,
           0.13,
           0.06,
           0.05,
           0.13,
           0.35,
           0.01,
           0.04,
           0,
           0.04,
           0.12,
           0.02,
           0.19,
           0.43,
           0.34,
           0.03,
           0.14,
           0.04,
           0.32,
           0.1,
           0.04,
           0.06,
           0.04,
           0.02,
           0.02,
           0.05,
           0.03,
           0.03,
           0.45,
           0.07,
           0.43,
           0.35,
           0.05,
           0.03,
           0,
           0,
           0.36,
           0.33,
           0.19,
           0.01,
           0.14,
           0.22,
           0.05,
           0,
           0.41,
           0.01,
           0.42,
           0.15,
           0.04,
           0.08,
           0.11
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2016-11",
          "2018-10",
          "2019-05",
          "2018-08",
          "2019-05",
          "2019-10",
          "2017-04",
          "2018-09",
          "2018-10",
          "2018-12",
          "2019-03",
          "2019-04",
          "2016-05",
          "2017-09",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-10",
          "2019-02",
          "2019-06",
          "2019-08",
          "2019-12",
          "2020-04",
          "2019-04",
          "2019-07",
          "2019-11",
          "2016-11",
          "2018-08",
          "2016-06",
          "2018-01",
          "2018-02",
          "2017-08",
          "2018-03",
          "2018-04",
          "2018-10",
          "2019-10",
          "2019-02",
          "2019-06",
          "2019-07",
          "2018-08",
          "2018-10",
          "2019-04",
          "2019-06",
          "2016-11",
          "2017-07",
          "2018-05",
          "2019-03",
          "2018-02",
          "2018-03",
          "2019-04",
          "2019-11",
          "2016-06",
          "2016-09",
          "2017-07",
          "2018-02",
          "2018-04",
          "2019-07",
          "2018-11",
          "2018-12",
          "2014-04",
          "2014-12",
          "2018-05",
          "2018-12",
          "2019-09",
          "2018-03",
          "2018-04",
          "2018-05",
          "2018-09",
          "2019-04",
          "2019-12",
          "2016-03",
          "2016-11",
          "2018-07",
          "2017-09",
          "2017-11",
          "2018-05",
          "2018-10",
          "2016-03",
          "2016-09",
          "2016-11",
          "2017-10",
          "2018-08",
          "2019-08",
          "2020-02",
          "2017-05",
          "2018-08",
          "2019-03",
          "2019-05",
          "2019-08",
          "2018-06",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-08",
          "2019-09",
          "2017-05",
          "2019-09",
          "2017-12",
          "2018-11",
          "2016-11",
          "2017-04",
          "2017-07",
          "2019-06",
          "2019-12",
          "2019-04",
          "2019-09",
          "2014-12",
          "2016-03",
          "2016-07",
          "2016-09",
          "2016-12",
          "2017-05",
          "2017-07",
          "2017-08",
          "2017-10",
          "2017-11",
          "2018-03",
          "2018-08",
          "2018-09",
          "2019-01",
          "2019-06",
          "2019-09",
          "2014-09",
          "2014-10",
          "2016-03",
          "2016-08",
          "2016-09",
          "2016-10",
          "2016-11",
          "2017-01",
          "2017-05",
          "2017-06",
          "2017-11",
          "2018-02",
          "2018-03",
          "2018-06",
          "2018-08",
          "2019-01",
          "2019-05",
          "2019-06",
          "2019-09",
          "2019-10",
          "2018-08",
          "2018-10",
          "2019-03",
          "2019-06",
          "2019-08",
          "2019-11",
          "2014-08",
          "2016-09",
          "2017-02",
          "2017-09",
          "2017-11",
          "2017-12",
          "2018-04",
          "2018-05",
          "2018-06",
          "2018-09",
          "2018-10",
          "2019-01",
          "2019-07",
          "2019-09",
          "2016-03",
          "2016-11",
          "2017-03",
          "2017-11",
          "2018-01",
          "2018-10",
          "2018-11",
          "2019-07",
          "2017-09",
          "2018-06",
          "2013-10",
          "2017-04",
          "2017-09",
          "2018-07",
          "2019-01",
          "2019-06",
          "2015-08",
          "2017-11",
          "2018-05",
          "2019-08",
          "2014-06",
          "2014-12",
          "2015-06",
          "2015-11",
          "2016-02",
          "2016-03",
          "2016-06",
          "2016-08",
          "2016-09",
          "2016-10",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-05",
          "2017-06",
          "2017-07",
          "2017-08",
          "2017-10",
          "2017-12",
          "2018-01",
          "2018-04",
          "2018-06",
          "2018-07",
          "2018-08",
          "2018-09",
          "2018-10",
          "2018-11",
          "2019-01",
          "2019-02",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09",
          "2018-06",
          "2019-05",
          "2016-01",
          "2017-07",
          "2017-09",
          "2018-07",
          "2018-08",
          "2018-09",
          "2018-10",
          "2018-12",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-09",
          "2019-11",
          "2020-03",
          "2020-04",
          "2017-04",
          "2018-10",
          "2017-12",
          "2018-02",
          "2018-05",
          "2018-10",
          "2018-03",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-09",
          "2018-10",
          "2019-03",
          "2017-07",
          "2018-07",
          "2014-06",
          "2014-08",
          "2015-02",
          "2015-06",
          "2015-11",
          "2016-02",
          "2017-02",
          "2017-07",
          "2017-08",
          "2017-12",
          "2018-01",
          "2018-02",
          "2018-04",
          "2018-05",
          "2018-10",
          "2019-01",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-09",
          "2015-04",
          "2015-11",
          "2017-02",
          "2018-03",
          "2018-05",
          "2018-07",
          "2018-08",
          "2018-09",
          "2019-01",
          "2019-02",
          "2019-05",
          "2019-09",
          "2020-02",
          "2017-05",
          "2017-09",
          "2016-02",
          "2016-06",
          "2017-06",
          "2018-07",
          "2018-08",
          "2019-04",
          "2019-05",
          "2019-10",
          "2016-12",
          "2017-10",
          "2019-03",
          "2019-04",
          "2018-10",
          "2019-01",
          "2019-02",
          "2019-05",
          "2017-09",
          "2017-11",
          "2018-09",
          "2019-02",
          "2019-04",
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09",
          "2020-02",
          "2016-03",
          "2016-06",
          "2018-02",
          "2018-05",
          "2018-11",
          "2019-05",
          "2019-09"
         ],
         "y": [
          "AMR Parsing",
          "AMR Parsing",
          "AMR Parsing",
          "Abstractive Text Summarization",
          "Abstractive Text Summarization",
          "Abstractive Text Summarization",
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval",
          "Ad-Hoc Information Retrieval",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Aspect-Based Sentiment Analysis",
          "Chinese Named Entity Recognition",
          "Chinese Named Entity Recognition",
          "Chinese Named Entity Recognition",
          "Chunking",
          "Chunking",
          "Citation Intent Classification",
          "Citation Intent Classification",
          "Citation Intent Classification",
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Constituency Grammar Induction",
          "Constituency Grammar Induction",
          "Constituency Grammar Induction",
          "Constituency Grammar Induction",
          "Constituency Parsing",
          "Constituency Parsing",
          "Constituency Parsing",
          "Constituency Parsing",
          "Conversational Response Selection",
          "Conversational Response Selection",
          "Conversational Response Selection",
          "Conversational Response Selection",
          "Coreference Resolution",
          "Coreference Resolution",
          "Coreference Resolution",
          "Coreference Resolution",
          "Coreference Resolution",
          "Coreference Resolution",
          "Cross-Lingual Bitext Mining",
          "Cross-Lingual Bitext Mining",
          "Cross-Lingual Document Classification",
          "Cross-Lingual Document Classification",
          "Cross-Lingual Document Classification",
          "Cross-Lingual Document Classification",
          "Cross-Lingual Document Classification",
          "Data-to-Text Generation",
          "Data-to-Text Generation",
          "Data-to-Text Generation",
          "Data-to-Text Generation",
          "Data-to-Text Generation",
          "Data-to-Text Generation",
          "Dependency Parsing",
          "Dependency Parsing",
          "Dependency Parsing",
          "Dialog Act Classification",
          "Dialog Act Classification",
          "Dialog State Tracking",
          "Dialog State Tracking",
          "Document Classification",
          "Document Classification",
          "Document Classification",
          "Document Classification",
          "Document Classification",
          "Document Classification",
          "Document Classification",
          "Document Summarization",
          "Document Summarization",
          "Document Summarization",
          "Document Summarization",
          "Document Summarization",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Entity Disambiguation",
          "Entity Disambiguation",
          "Fake News Detection",
          "Fake News Detection",
          "Grammatical Error Detection",
          "Grammatical Error Detection",
          "Grammatical Error Detection",
          "Intent Detection",
          "Intent Detection",
          "Joint Entity and Relation Extraction",
          "Joint Entity and Relation Extraction",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Language Modelling",
          "Linguistic Acceptability Assessment",
          "Linguistic Acceptability Assessment",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Machine Translation",
          "Named Entity Recognition",
          "Named Entity Recognition",
          "Named Entity Recognition",
          "Named Entity Recognition",
          "Named Entity Recognition",
          "Named Entity Recognition",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Natural Language Inference",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Open-Domain Question Answering",
          "Paraphrase Generation",
          "Paraphrase Generation",
          "Paraphrase Identification",
          "Paraphrase Identification",
          "Paraphrase Identification",
          "Paraphrase Identification",
          "Paraphrase Identification",
          "Paraphrase Identification",
          "Part-Of-Speech Tagging",
          "Part-Of-Speech Tagging",
          "Part-Of-Speech Tagging",
          "Part-Of-Speech Tagging",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Answering",
          "Question Generation",
          "Question Generation",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Relation Extraction",
          "Semantic Parsing",
          "Semantic Parsing",
          "Semantic Role Labeling",
          "Semantic Role Labeling",
          "Semantic Role Labeling",
          "Semantic Role Labeling",
          "Semantic Textual Similarity",
          "Semantic Textual Similarity",
          "Semantic Textual Similarity",
          "Semantic Textual Similarity",
          "Semantic Textual Similarity",
          "Sentence Classification",
          "Sentence Classification",
          "Sentence Compression",
          "Sentence Compression",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Sentiment Analysis",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Classification",
          "Text Generation",
          "Text Generation",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text Summarization",
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Text-to-Image Generation",
          "Unsupervised Machine Translation",
          "Unsupervised Machine Translation",
          "Unsupervised Machine Translation",
          "Unsupervised Machine Translation",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Dialog",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation",
          "Word Sense Disambiguation"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Word Sense Disambiguation",
          "Visual Question Answering",
          "Visual Dialog",
          "Unsupervised Machine Translation",
          "Text-to-Image Generation",
          "Text Summarization",
          "Text Generation",
          "Text Classification",
          "Sentiment Analysis",
          "Sentence Compression",
          "Sentence Classification",
          "Semantic Textual Similarity",
          "Semantic Role Labeling",
          "Semantic Parsing",
          "Relation Extraction",
          "Question Generation",
          "Question Answering",
          "Part-Of-Speech Tagging",
          "Paraphrase Identification",
          "Paraphrase Generation",
          "Open-Domain Question Answering",
          "Natural Language Inference",
          "Named Entity Recognition",
          "Machine Translation",
          "Linguistic Acceptability Assessment",
          "Language Modelling",
          "Joint Entity and Relation Extraction",
          "Intent Detection",
          "Grammatical Error Detection",
          "Fake News Detection",
          "Entity Disambiguation",
          "Emotion Recognition in Conversation",
          "Document Summarization",
          "Document Classification",
          "Dialog State Tracking",
          "Dialog Act Classification",
          "Dependency Parsing",
          "Data-to-Text Generation",
          "Cross-Lingual Document Classification",
          "Cross-Lingual Bitext Mining",
          "Coreference Resolution",
          "Conversational Response Selection",
          "Constituency Parsing",
          "Constituency Grammar Induction",
          "Common Sense Reasoning",
          "Code Generation",
          "Citation Intent Classification",
          "Chunking",
          "Chinese Named Entity Recognition",
          "Aspect-Based Sentiment Analysis",
          "Ad-Hoc Information Retrieval",
          "Abstractive Text Summarization",
          "AMR Parsing"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00141: Natural Language Processing"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"31b2eed8-557a-47de-a8cf-15a76d5fe99f\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"31b2eed8-557a-47de-a8cf-15a76d5fe99f\")) {                    Plotly.newPlot(                        \"31b2eed8-557a-47de-a8cf-15a76d5fe99f\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"AMR Parsing\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"AMR Parsing\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2018-10\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"AMR Parsing\", \"AMR Parsing\", \"AMR Parsing\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Abstractive Text Summarization\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Abstractive Text Summarization\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-08\", \"2019-05\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Abstractive Text Summarization\", \"Abstractive Text Summarization\", \"Abstractive Text Summarization\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Ad-Hoc Information Retrieval\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Ad-Hoc Information Retrieval\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-04\", \"2018-09\", \"2018-10\", \"2018-12\", \"2019-03\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Aspect-Based Sentiment Analysis\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Aspect-Based Sentiment Analysis\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-05\", \"2017-09\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-10\", \"2019-02\", \"2019-06\", \"2019-08\", \"2019-12\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Chinese Named Entity Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Chinese Named Entity Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-04\", \"2019-07\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Chinese Named Entity Recognition\", \"Chinese Named Entity Recognition\", \"Chinese Named Entity Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Chunking\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Chunking\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2018-08\"], \"xaxis\": \"x\", \"y\": [\"Chunking\", \"Chunking\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Citation Intent Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Citation Intent Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-06\", \"2018-01\", \"2018-02\"], \"xaxis\": \"x\", \"y\": [\"Citation Intent Classification\", \"Citation Intent Classification\", \"Citation Intent Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Code Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Code Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-08\", \"2018-03\", \"2018-04\", \"2018-10\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Common Sense Reasoning\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Common Sense Reasoning\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-02\", \"2019-06\", \"2019-07\"], \"xaxis\": \"x\", \"y\": [\"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Constituency Grammar Induction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Constituency Grammar Induction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-08\", \"2018-10\", \"2019-04\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"Constituency Grammar Induction\", \"Constituency Grammar Induction\", \"Constituency Grammar Induction\", \"Constituency Grammar Induction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Constituency Parsing\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Constituency Parsing\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-07\", \"2018-05\", \"2019-03\"], \"xaxis\": \"x\", \"y\": [\"Constituency Parsing\", \"Constituency Parsing\", \"Constituency Parsing\", \"Constituency Parsing\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Conversational Response Selection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Conversational Response Selection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-02\", \"2018-03\", \"2019-04\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Conversational Response Selection\", \"Conversational Response Selection\", \"Conversational Response Selection\", \"Conversational Response Selection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Coreference Resolution\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Coreference Resolution\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-06\", \"2016-09\", \"2017-07\", \"2018-02\", \"2018-04\", \"2019-07\"], \"xaxis\": \"x\", \"y\": [\"Coreference Resolution\", \"Coreference Resolution\", \"Coreference Resolution\", \"Coreference Resolution\", \"Coreference Resolution\", \"Coreference Resolution\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Cross-Lingual Bitext Mining\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Cross-Lingual Bitext Mining\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-11\", \"2018-12\"], \"xaxis\": \"x\", \"y\": [\"Cross-Lingual Bitext Mining\", \"Cross-Lingual Bitext Mining\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Cross-Lingual Document Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Cross-Lingual Document Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-04\", \"2014-12\", \"2018-05\", \"2018-12\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Cross-Lingual Document Classification\", \"Cross-Lingual Document Classification\", \"Cross-Lingual Document Classification\", \"Cross-Lingual Document Classification\", \"Cross-Lingual Document Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Data-to-Text Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Data-to-Text Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-03\", \"2018-04\", \"2018-05\", \"2018-09\", \"2019-04\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Data-to-Text Generation\", \"Data-to-Text Generation\", \"Data-to-Text Generation\", \"Data-to-Text Generation\", \"Data-to-Text Generation\", \"Data-to-Text Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Dependency Parsing\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Dependency Parsing\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-11\", \"2018-07\"], \"xaxis\": \"x\", \"y\": [\"Dependency Parsing\", \"Dependency Parsing\", \"Dependency Parsing\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Dialog Act Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Dialog Act Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-09\", \"2017-11\"], \"xaxis\": \"x\", \"y\": [\"Dialog Act Classification\", \"Dialog Act Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Dialog State Tracking\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Dialog State Tracking\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-05\", \"2018-10\"], \"xaxis\": \"x\", \"y\": [\"Dialog State Tracking\", \"Dialog State Tracking\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Document Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Document Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-09\", \"2016-11\", \"2017-10\", \"2018-08\", \"2019-08\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Document Classification\", \"Document Classification\", \"Document Classification\", \"Document Classification\", \"Document Classification\", \"Document Classification\", \"Document Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Document Summarization\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Document Summarization\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-05\", \"2018-08\", \"2019-03\", \"2019-05\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Document Summarization\", \"Document Summarization\", \"Document Summarization\", \"Document Summarization\", \"Document Summarization\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Emotion Recognition in Conversation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Emotion Recognition in Conversation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-06\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-08\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Entity Disambiguation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Entity Disambiguation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-05\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Entity Disambiguation\", \"Entity Disambiguation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Fake News Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Fake News Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-12\", \"2018-11\"], \"xaxis\": \"x\", \"y\": [\"Fake News Detection\", \"Fake News Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Grammatical Error Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Grammatical Error Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-11\", \"2017-04\", \"2017-07\"], \"xaxis\": \"x\", \"y\": [\"Grammatical Error Detection\", \"Grammatical Error Detection\", \"Grammatical Error Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Intent Detection\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Intent Detection\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-06\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Intent Detection\", \"Intent Detection\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Joint Entity and Relation Extraction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Joint Entity and Relation Extraction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-04\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Joint Entity and Relation Extraction\", \"Joint Entity and Relation Extraction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Language Modelling\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Language Modelling\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-12\", \"2016-03\", \"2016-07\", \"2016-09\", \"2016-12\", \"2017-05\", \"2017-07\", \"2017-08\", \"2017-10\", \"2017-11\", \"2018-03\", \"2018-08\", \"2018-09\", \"2019-01\"], \"xaxis\": \"x\", \"y\": [\"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Linguistic Acceptability Assessment\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Linguistic Acceptability Assessment\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-06\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Linguistic Acceptability Assessment\", \"Linguistic Acceptability Assessment\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Machine Translation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Machine Translation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-09\", \"2014-10\", \"2016-03\", \"2016-08\", \"2016-09\", \"2016-10\", \"2016-11\", \"2017-01\", \"2017-05\", \"2017-06\", \"2017-11\", \"2018-02\", \"2018-03\", \"2018-06\", \"2018-08\", \"2019-01\", \"2019-05\", \"2019-06\", \"2019-09\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Named Entity Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Named Entity Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-08\", \"2018-10\", \"2019-03\", \"2019-06\", \"2019-08\", \"2019-11\"], \"xaxis\": \"x\", \"y\": [\"Named Entity Recognition\", \"Named Entity Recognition\", \"Named Entity Recognition\", \"Named Entity Recognition\", \"Named Entity Recognition\", \"Named Entity Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Natural Language Inference\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Natural Language Inference\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-08\", \"2016-09\", \"2017-02\", \"2017-09\", \"2017-11\", \"2017-12\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-09\", \"2018-10\", \"2019-01\", \"2019-07\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Open-Domain Question Answering\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Open-Domain Question Answering\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-11\", \"2017-03\", \"2017-11\", \"2018-01\", \"2018-10\", \"2018-11\", \"2019-07\"], \"xaxis\": \"x\", \"y\": [\"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Paraphrase Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Paraphrase Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-09\", \"2018-06\"], \"xaxis\": \"x\", \"y\": [\"Paraphrase Generation\", \"Paraphrase Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Paraphrase Identification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Paraphrase Identification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2013-10\", \"2017-04\", \"2017-09\", \"2018-07\", \"2019-01\", \"2019-06\"], \"xaxis\": \"x\", \"y\": [\"Paraphrase Identification\", \"Paraphrase Identification\", \"Paraphrase Identification\", \"Paraphrase Identification\", \"Paraphrase Identification\", \"Paraphrase Identification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Part-Of-Speech Tagging\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Part-Of-Speech Tagging\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-08\", \"2017-11\", \"2018-05\", \"2019-08\"], \"xaxis\": \"x\", \"y\": [\"Part-Of-Speech Tagging\", \"Part-Of-Speech Tagging\", \"Part-Of-Speech Tagging\", \"Part-Of-Speech Tagging\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Question Answering\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Question Answering\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-06\", \"2014-12\", \"2015-06\", \"2015-11\", \"2016-02\", \"2016-03\", \"2016-06\", \"2016-08\", \"2016-09\", \"2016-10\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-06\", \"2017-07\", \"2017-08\", \"2017-10\", \"2017-12\", \"2018-01\", \"2018-04\", \"2018-06\", \"2018-07\", \"2018-08\", \"2018-09\", \"2018-10\", \"2018-11\", \"2019-01\", \"2019-02\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Question Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Question Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-06\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Question Generation\", \"Question Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Relation Extraction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Relation Extraction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-01\", \"2017-07\", \"2017-09\", \"2018-07\", \"2018-08\", \"2018-09\", \"2018-10\", \"2018-12\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\", \"2020-03\", \"2020-04\"], \"xaxis\": \"x\", \"y\": [\"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Semantic Parsing\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Semantic Parsing\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-04\", \"2018-10\"], \"xaxis\": \"x\", \"y\": [\"Semantic Parsing\", \"Semantic Parsing\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Semantic Role Labeling\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Semantic Role Labeling\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-12\", \"2018-02\", \"2018-05\", \"2018-10\"], \"xaxis\": \"x\", \"y\": [\"Semantic Role Labeling\", \"Semantic Role Labeling\", \"Semantic Role Labeling\", \"Semantic Role Labeling\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Semantic Textual Similarity\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Semantic Textual Similarity\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-03\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Semantic Textual Similarity\", \"Semantic Textual Similarity\", \"Semantic Textual Similarity\", \"Semantic Textual Similarity\", \"Semantic Textual Similarity\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Sentence Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Sentence Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-10\", \"2019-03\"], \"xaxis\": \"x\", \"y\": [\"Sentence Classification\", \"Sentence Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Sentence Compression\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Sentence Compression\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-07\", \"2018-07\"], \"xaxis\": \"x\", \"y\": [\"Sentence Compression\", \"Sentence Compression\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Sentiment Analysis\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Sentiment Analysis\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-06\", \"2014-08\", \"2015-02\", \"2015-06\", \"2015-11\", \"2016-02\", \"2017-02\", \"2017-07\", \"2017-08\", \"2017-12\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-10\", \"2019-01\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Text Classification\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Text Classification\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-04\", \"2015-11\", \"2017-02\", \"2018-03\", \"2018-05\", \"2018-07\", \"2018-08\", \"2018-09\", \"2019-01\", \"2019-02\", \"2019-05\", \"2019-09\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Text Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Text Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-05\", \"2017-09\"], \"xaxis\": \"x\", \"y\": [\"Text Generation\", \"Text Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Text Summarization\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Text Summarization\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-02\", \"2016-06\", \"2017-06\", \"2018-07\", \"2018-08\", \"2019-04\", \"2019-05\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Text-to-Image Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Text-to-Image Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-12\", \"2017-10\", \"2019-03\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Text-to-Image Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Unsupervised Machine Translation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Unsupervised Machine Translation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-10\", \"2019-01\", \"2019-02\", \"2019-05\"], \"xaxis\": \"x\", \"y\": [\"Unsupervised Machine Translation\", \"Unsupervised Machine Translation\", \"Unsupervised Machine Translation\", \"Unsupervised Machine Translation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Visual Dialog\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Visual Dialog\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-09\", \"2017-11\", \"2018-09\", \"2019-02\", \"2019-04\"], \"xaxis\": \"x\", \"y\": [\"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Visual Question Answering\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Visual Question Answering\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Word Sense Disambiguation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Word Sense Disambiguation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-06\", \"2018-02\", \"2018-05\", \"2018-11\", \"2019-05\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"AMR Parsing<BR>task: AMR Parsing<BR>date: 2016-11<BR>ratio: 0.47\", \"AMR Parsing<BR>task: AMR Parsing<BR>date: 2018-10<BR>ratio: 0.01\", \"AMR Parsing<BR>task: AMR Parsing<BR>date: 2019-05<BR>ratio: 0.01\", \"Abstractive Text Summarization<BR>task: Abstractive Text Summarization<BR>date: 2018-08<BR>ratio: 0.04\", \"Abstractive Text Summarization<BR>task: Abstractive Text Summarization<BR>date: 2019-05<BR>ratio: 0.06\", \"Abstractive Text Summarization<BR>task: Abstractive Text Summarization<BR>date: 2019-10<BR>ratio: 0.02\", \"Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2017-04<BR>ratio: 0.43\", \"Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2018-09<BR>ratio: 0.0\", \"Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2018-10<BR>ratio: 0.0\", \"Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2018-12<BR>ratio: 0.0\", \"Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2019-03<BR>ratio: 0.0\", \"Ad-Hoc Information Retrieval<BR>task: Ad-Hoc Information Retrieval<BR>date: 2019-04<BR>ratio: 0.1\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2016-05<BR>ratio: 0.05\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2017-09<BR>ratio: 0.02\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2018-02<BR>ratio: 0.01\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2018-04<BR>ratio: 0.04\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2018-05<BR>ratio: 0.01\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2018-10<BR>ratio: 0.02\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2019-02<BR>ratio: 0.02\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2019-06<BR>ratio: 0.01\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2019-08<BR>ratio: 0.03\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2019-12<BR>ratio: 0.02\", \"Aspect-Based Sentiment Analysis<BR>task: Aspect-Based Sentiment Analysis<BR>date: 2020-04<BR>ratio: 0.01\", \"Chinese Named Entity Recognition<BR>task: Chinese Named Entity Recognition<BR>date: 2019-04<BR>ratio: 0.5\", \"Chinese Named Entity Recognition<BR>task: Chinese Named Entity Recognition<BR>date: 2019-07<BR>ratio: 0.01\", \"Chinese Named Entity Recognition<BR>task: Chinese Named Entity Recognition<BR>date: 2019-11<BR>ratio: 0.01\", \"Chunking<BR>task: Chunking<BR>date: 2016-11<BR>ratio: 0.0\", \"Chunking<BR>task: Chunking<BR>date: 2018-08<BR>ratio: 0.01\", \"Citation Intent Classification<BR>task: Citation Intent Classification<BR>date: 2016-06<BR>ratio: 0.2\", \"Citation Intent Classification<BR>task: Citation Intent Classification<BR>date: 2018-01<BR>ratio: 0.02\", \"Citation Intent Classification<BR>task: Citation Intent Classification<BR>date: 2018-02<BR>ratio: 0.03\", \"Code Generation<BR>task: Code Generation<BR>date: 2017-08<BR>ratio: 0.31\", \"Code Generation<BR>task: Code Generation<BR>date: 2018-03<BR>ratio: 0.14\", \"Code Generation<BR>task: Code Generation<BR>date: 2018-04<BR>ratio: 0.08\", \"Code Generation<BR>task: Code Generation<BR>date: 2018-10<BR>ratio: 0.11\", \"Code Generation<BR>task: Code Generation<BR>date: 2019-10<BR>ratio: 0.12\", \"Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-02<BR>ratio: 0.1\", \"Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-06<BR>ratio: 0.12\", \"Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-07<BR>ratio: 0.07\", \"Constituency Grammar Induction<BR>task: Constituency Grammar Induction<BR>date: 2018-08<BR>ratio: 0.45\", \"Constituency Grammar Induction<BR>task: Constituency Grammar Induction<BR>date: 2018-10<BR>ratio: 0.22\", \"Constituency Grammar Induction<BR>task: Constituency Grammar Induction<BR>date: 2019-04<BR>ratio: 0.04\", \"Constituency Grammar Induction<BR>task: Constituency Grammar Induction<BR>date: 2019-06<BR>ratio: 0.06\", \"Constituency Parsing<BR>task: Constituency Parsing<BR>date: 2016-11<BR>ratio: 0.02\", \"Constituency Parsing<BR>task: Constituency Parsing<BR>date: 2017-07<BR>ratio: 0.01\", \"Constituency Parsing<BR>task: Constituency Parsing<BR>date: 2018-05<BR>ratio: 0.01\", \"Constituency Parsing<BR>task: Constituency Parsing<BR>date: 2019-03<BR>ratio: 0.01\", \"Conversational Response Selection<BR>task: Conversational Response Selection<BR>date: 2018-02<BR>ratio: 0.27\", \"Conversational Response Selection<BR>task: Conversational Response Selection<BR>date: 2018-03<BR>ratio: 0.4\", \"Conversational Response Selection<BR>task: Conversational Response Selection<BR>date: 2019-04<BR>ratio: 0.28\", \"Conversational Response Selection<BR>task: Conversational Response Selection<BR>date: 2019-11<BR>ratio: 0.1\", \"Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2016-06<BR>ratio: 0.01\", \"Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2016-09<BR>ratio: 0.01\", \"Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2017-07<BR>ratio: 0.31\", \"Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2018-02<BR>ratio: 0.04\", \"Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2018-04<BR>ratio: 0.03\", \"Coreference Resolution<BR>task: Coreference Resolution<BR>date: 2019-07<BR>ratio: 0.05\", \"Cross-Lingual Bitext Mining<BR>task: Cross-Lingual Bitext Mining<BR>date: 2018-11<BR>ratio: 0.18\", \"Cross-Lingual Bitext Mining<BR>task: Cross-Lingual Bitext Mining<BR>date: 2018-12<BR>ratio: 0.01\", \"Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2014-04<BR>ratio: 0.03\", \"Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2014-12<BR>ratio: 0.06\", \"Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2018-05<BR>ratio: 0.48\", \"Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2018-12<BR>ratio: 0.04\", \"Cross-Lingual Document Classification<BR>task: Cross-Lingual Document Classification<BR>date: 2019-09<BR>ratio: 0.19\", \"Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2018-03<BR>ratio: 0.04\", \"Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2018-04<BR>ratio: 0.01\", \"Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2018-05<BR>ratio: 0.01\", \"Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2018-09<BR>ratio: 0.13\", \"Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2019-04<BR>ratio: 0.03\", \"Data-to-Text Generation<BR>task: Data-to-Text Generation<BR>date: 2019-12<BR>ratio: 0.06\", \"Dependency Parsing<BR>task: Dependency Parsing<BR>date: 2016-03<BR>ratio: 0.01\", \"Dependency Parsing<BR>task: Dependency Parsing<BR>date: 2016-11<BR>ratio: 0.34\", \"Dependency Parsing<BR>task: Dependency Parsing<BR>date: 2018-07<BR>ratio: 0.01\", \"Dialog Act Classification<BR>task: Dialog Act Classification<BR>date: 2017-09<BR>ratio: 0.08\", \"Dialog Act Classification<BR>task: Dialog Act Classification<BR>date: 2017-11<BR>ratio: 0.03\", \"Dialog State Tracking<BR>task: Dialog State Tracking<BR>date: 2018-05<BR>ratio: 0.02\", \"Dialog State Tracking<BR>task: Dialog State Tracking<BR>date: 2018-10<BR>ratio: 0.01\", \"Document Classification<BR>task: Document Classification<BR>date: 2016-03<BR>ratio: 0.1\", \"Document Classification<BR>task: Document Classification<BR>date: 2016-09<BR>ratio: 0.07\", \"Document Classification<BR>task: Document Classification<BR>date: 2016-11<BR>ratio: 0.0\", \"Document Classification<BR>task: Document Classification<BR>date: 2017-10<BR>ratio: 0.02\", \"Document Classification<BR>task: Document Classification<BR>date: 2018-08<BR>ratio: 0.0\", \"Document Classification<BR>task: Document Classification<BR>date: 2019-08<BR>ratio: 0.35\", \"Document Classification<BR>task: Document Classification<BR>date: 2020-02<BR>ratio: 0.01\", \"Document Summarization<BR>task: Document Summarization<BR>date: 2017-05<BR>ratio: 0.43\", \"Document Summarization<BR>task: Document Summarization<BR>date: 2018-08<BR>ratio: 0.12\", \"Document Summarization<BR>task: Document Summarization<BR>date: 2019-03<BR>ratio: 0.05\", \"Document Summarization<BR>task: Document Summarization<BR>date: 2019-05<BR>ratio: 0.01\", \"Document Summarization<BR>task: Document Summarization<BR>date: 2019-08<BR>ratio: 0.01\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-06<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-10<BR>ratio: 0.04\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-11<BR>ratio: 0.05\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-04<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-08<BR>ratio: 0.03\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-09<BR>ratio: 0.5\", \"Entity Disambiguation<BR>task: Entity Disambiguation<BR>date: 2017-05<BR>ratio: 0.03\", \"Entity Disambiguation<BR>task: Entity Disambiguation<BR>date: 2019-09<BR>ratio: 0.13\", \"Fake News Detection<BR>task: Fake News Detection<BR>date: 2017-12<BR>ratio: 0.1\", \"Fake News Detection<BR>task: Fake News Detection<BR>date: 2018-11<BR>ratio: 0.04\", \"Grammatical Error Detection<BR>task: Grammatical Error Detection<BR>date: 2016-11<BR>ratio: 0.02\", \"Grammatical Error Detection<BR>task: Grammatical Error Detection<BR>date: 2017-04<BR>ratio: 0.13\", \"Grammatical Error Detection<BR>task: Grammatical Error Detection<BR>date: 2017-07<BR>ratio: 0.03\", \"Intent Detection<BR>task: Intent Detection<BR>date: 2019-06<BR>ratio: 0.34\", \"Intent Detection<BR>task: Intent Detection<BR>date: 2019-12<BR>ratio: 0.49\", \"Joint Entity and Relation Extraction<BR>task: Joint Entity and Relation Extraction<BR>date: 2019-04<BR>ratio: 0.03\", \"Joint Entity and Relation Extraction<BR>task: Joint Entity and Relation Extraction<BR>date: 2019-09<BR>ratio: 0.09\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2014-12<BR>ratio: 0.03\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2016-03<BR>ratio: 0.01\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2016-07<BR>ratio: 0.5\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2016-09<BR>ratio: 0.08\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2016-12<BR>ratio: 0.37\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2017-05<BR>ratio: 0.0\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2017-07<BR>ratio: 0.02\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2017-08<BR>ratio: 0.01\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2017-10<BR>ratio: 0.0\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2017-11<BR>ratio: 0.0\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2018-03<BR>ratio: 0.34\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2018-08<BR>ratio: 0.26\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2018-09<BR>ratio: 0.34\", \"Language Modelling<BR>task: Language Modelling<BR>date: 2019-01<BR>ratio: 0.05\", \"Linguistic Acceptability Assessment<BR>task: Linguistic Acceptability Assessment<BR>date: 2019-06<BR>ratio: 0.01\", \"Linguistic Acceptability Assessment<BR>task: Linguistic Acceptability Assessment<BR>date: 2019-09<BR>ratio: 0.0\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2014-09<BR>ratio: 0.29\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2014-10<BR>ratio: 0.02\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2016-03<BR>ratio: 0.03\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2016-08<BR>ratio: 0.02\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2016-09<BR>ratio: 0.08\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2016-10<BR>ratio: 0.11\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2016-11<BR>ratio: 0.01\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2017-01<BR>ratio: 0.02\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2017-05<BR>ratio: 0.03\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2017-06<BR>ratio: 0.09\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2017-11<BR>ratio: 0.21\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2018-02<BR>ratio: 0.08\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2018-03<BR>ratio: 0.33\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2018-06<BR>ratio: 0.03\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2018-08<BR>ratio: 0.38\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2019-01<BR>ratio: 0.22\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2019-05<BR>ratio: 0.09\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2019-06<BR>ratio: 0.06\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2019-09<BR>ratio: 0.04\", \"Machine Translation<BR>task: Machine Translation<BR>date: 2019-10<BR>ratio: 0.06\", \"Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2018-08<BR>ratio: 0.19\", \"Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2018-10<BR>ratio: 0.37\", \"Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2019-03<BR>ratio: 0.01\", \"Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2019-06<BR>ratio: 0.04\", \"Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2019-08<BR>ratio: 0.03\", \"Named Entity Recognition<BR>task: Named Entity Recognition<BR>date: 2019-11<BR>ratio: 0.01\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2014-08<BR>ratio: 0.01\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2016-09<BR>ratio: 0.01\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2017-02<BR>ratio: 0.0\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2017-09<BR>ratio: 0.0\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2017-11<BR>ratio: 0.0\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2017-12<BR>ratio: 0.45\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-04<BR>ratio: 0.01\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-05<BR>ratio: 0.01\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-06<BR>ratio: 0.25\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-09<BR>ratio: 0.43\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2018-10<BR>ratio: 0.04\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2019-01<BR>ratio: 0.05\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2019-07<BR>ratio: 0.03\", \"Natural Language Inference<BR>task: Natural Language Inference<BR>date: 2019-09<BR>ratio: 0.01\", \"Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2016-03<BR>ratio: 0.49\", \"Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2016-11<BR>ratio: 0.49\", \"Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2017-03<BR>ratio: 0.36\", \"Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2017-11<BR>ratio: 0.41\", \"Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2018-01<BR>ratio: 0.28\", \"Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2018-10<BR>ratio: 0.04\", \"Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2018-11<BR>ratio: 0.14\", \"Open-Domain Question Answering<BR>task: Open-Domain Question Answering<BR>date: 2019-07<BR>ratio: 0.41\", \"Paraphrase Generation<BR>task: Paraphrase Generation<BR>date: 2017-09<BR>ratio: 0.5\", \"Paraphrase Generation<BR>task: Paraphrase Generation<BR>date: 2018-06<BR>ratio: 0.5\", \"Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2013-10<BR>ratio: 0.5\", \"Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2017-04<BR>ratio: 0.0\", \"Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2017-09<BR>ratio: 0.01\", \"Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2018-07<BR>ratio: 0.0\", \"Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2019-01<BR>ratio: 0.49\", \"Paraphrase Identification<BR>task: Paraphrase Identification<BR>date: 2019-06<BR>ratio: 0.01\", \"Part-Of-Speech Tagging<BR>task: Part-Of-Speech Tagging<BR>date: 2015-08<BR>ratio: 0.49\", \"Part-Of-Speech Tagging<BR>task: Part-Of-Speech Tagging<BR>date: 2017-11<BR>ratio: 0.0\", \"Part-Of-Speech Tagging<BR>task: Part-Of-Speech Tagging<BR>date: 2018-05<BR>ratio: 0.0\", \"Part-Of-Speech Tagging<BR>task: Part-Of-Speech Tagging<BR>date: 2019-08<BR>ratio: 0.0\", \"Question Answering<BR>task: Question Answering<BR>date: 2014-06<BR>ratio: 0.23\", \"Question Answering<BR>task: Question Answering<BR>date: 2014-12<BR>ratio: 0.21\", \"Question Answering<BR>task: Question Answering<BR>date: 2015-06<BR>ratio: 0.36\", \"Question Answering<BR>task: Question Answering<BR>date: 2015-11<BR>ratio: 0.0\", \"Question Answering<BR>task: Question Answering<BR>date: 2016-02<BR>ratio: 0.25\", \"Question Answering<BR>task: Question Answering<BR>date: 2016-03<BR>ratio: 0.39\", \"Question Answering<BR>task: Question Answering<BR>date: 2016-06<BR>ratio: 0.08\", \"Question Answering<BR>task: Question Answering<BR>date: 2016-08<BR>ratio: 0.49\", \"Question Answering<BR>task: Question Answering<BR>date: 2016-09<BR>ratio: 0.03\", \"Question Answering<BR>task: Question Answering<BR>date: 2016-10<BR>ratio: 0.41\", \"Question Answering<BR>task: Question Answering<BR>date: 2016-11<BR>ratio: 0.28\", \"Question Answering<BR>task: Question Answering<BR>date: 2017-03<BR>ratio: 0.28\", \"Question Answering<BR>task: Question Answering<BR>date: 2017-04<BR>ratio: 0.01\", \"Question Answering<BR>task: Question Answering<BR>date: 2017-05<BR>ratio: 0.27\", \"Question Answering<BR>task: Question Answering<BR>date: 2017-06<BR>ratio: 0.05\", \"Question Answering<BR>task: Question Answering<BR>date: 2017-07<BR>ratio: 0.05\", \"Question Answering<BR>task: Question Answering<BR>date: 2017-08<BR>ratio: 0.33\", \"Question Answering<BR>task: Question Answering<BR>date: 2017-10<BR>ratio: 0.34\", \"Question Answering<BR>task: Question Answering<BR>date: 2017-12<BR>ratio: 0.01\", \"Question Answering<BR>task: Question Answering<BR>date: 2018-01<BR>ratio: 0.1\", \"Question Answering<BR>task: Question Answering<BR>date: 2018-04<BR>ratio: 0.23\", \"Question Answering<BR>task: Question Answering<BR>date: 2018-06<BR>ratio: 0.07\", \"Question Answering<BR>task: Question Answering<BR>date: 2018-07<BR>ratio: 0.11\", \"Question Answering<BR>task: Question Answering<BR>date: 2018-08<BR>ratio: 0.41\", \"Question Answering<BR>task: Question Answering<BR>date: 2018-09<BR>ratio: 0.1\", \"Question Answering<BR>task: Question Answering<BR>date: 2018-10<BR>ratio: 0.16\", \"Question Answering<BR>task: Question Answering<BR>date: 2018-11<BR>ratio: 0.05\", \"Question Answering<BR>task: Question Answering<BR>date: 2019-01<BR>ratio: 0.29\", \"Question Answering<BR>task: Question Answering<BR>date: 2019-02<BR>ratio: 0.2\", \"Question Answering<BR>task: Question Answering<BR>date: 2019-05<BR>ratio: 0.12\", \"Question Answering<BR>task: Question Answering<BR>date: 2019-06<BR>ratio: 0.12\", \"Question Answering<BR>task: Question Answering<BR>date: 2019-07<BR>ratio: 0.11\", \"Question Answering<BR>task: Question Answering<BR>date: 2019-08<BR>ratio: 0.0\", \"Question Answering<BR>task: Question Answering<BR>date: 2019-09<BR>ratio: 0.02\", \"Question Generation<BR>task: Question Generation<BR>date: 2018-06<BR>ratio: 0.03\", \"Question Generation<BR>task: Question Generation<BR>date: 2019-05<BR>ratio: 0.39\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2016-01<BR>ratio: 0.05\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2017-07<BR>ratio: 0.04\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2017-09<BR>ratio: 0.34\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-07<BR>ratio: 0.16\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-08<BR>ratio: 0.01\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-09<BR>ratio: 0.03\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-10<BR>ratio: 0.03\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2018-12<BR>ratio: 0.07\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-02<BR>ratio: 0.01\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-04<BR>ratio: 0.28\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-05<BR>ratio: 0.28\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-06<BR>ratio: 0.22\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-07<BR>ratio: 0.07\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-09<BR>ratio: 0.16\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2019-11<BR>ratio: 0.01\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2020-03<BR>ratio: 0.03\", \"Relation Extraction<BR>task: Relation Extraction<BR>date: 2020-04<BR>ratio: 0.01\", \"Semantic Parsing<BR>task: Semantic Parsing<BR>date: 2017-04<BR>ratio: 0.01\", \"Semantic Parsing<BR>task: Semantic Parsing<BR>date: 2018-10<BR>ratio: 0.01\", \"Semantic Role Labeling<BR>task: Semantic Role Labeling<BR>date: 2017-12<BR>ratio: 0.01\", \"Semantic Role Labeling<BR>task: Semantic Role Labeling<BR>date: 2018-02<BR>ratio: 0.02\", \"Semantic Role Labeling<BR>task: Semantic Role Labeling<BR>date: 2018-05<BR>ratio: 0.01\", \"Semantic Role Labeling<BR>task: Semantic Role Labeling<BR>date: 2018-10<BR>ratio: 0.02\", \"Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2018-03<BR>ratio: 0.29\", \"Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2019-05<BR>ratio: 0.04\", \"Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2019-06<BR>ratio: 0.07\", \"Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2019-07<BR>ratio: 0.01\", \"Semantic Textual Similarity<BR>task: Semantic Textual Similarity<BR>date: 2019-09<BR>ratio: 0.01\", \"Sentence Classification<BR>task: Sentence Classification<BR>date: 2018-10<BR>ratio: 0.06\", \"Sentence Classification<BR>task: Sentence Classification<BR>date: 2019-03<BR>ratio: 0.32\", \"Sentence Compression<BR>task: Sentence Compression<BR>date: 2017-07<BR>ratio: 0.0\", \"Sentence Compression<BR>task: Sentence Compression<BR>date: 2018-07<BR>ratio: 0.0\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2014-06<BR>ratio: 0.07\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2014-08<BR>ratio: 0.03\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2015-02<BR>ratio: 0.02\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2015-06<BR>ratio: 0.01\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2015-11<BR>ratio: 0.03\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2016-02<BR>ratio: 0.02\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2017-02<BR>ratio: 0.3\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2017-07<BR>ratio: 0.05\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2017-08<BR>ratio: 0.05\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2017-12<BR>ratio: 0.01\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-01<BR>ratio: 0.0\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-02<BR>ratio: 0.04\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-04<BR>ratio: 0.02\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-05<BR>ratio: 0.02\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2018-10<BR>ratio: 0.04\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-01<BR>ratio: 0.1\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-05<BR>ratio: 0.0\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-06<BR>ratio: 0.0\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-07<BR>ratio: 0.01\", \"Sentiment Analysis<BR>task: Sentiment Analysis<BR>date: 2019-09<BR>ratio: 0.0\", \"Text Classification<BR>task: Text Classification<BR>date: 2015-04<BR>ratio: 0.42\", \"Text Classification<BR>task: Text Classification<BR>date: 2015-11<BR>ratio: 0.15\", \"Text Classification<BR>task: Text Classification<BR>date: 2017-02<BR>ratio: 0.17\", \"Text Classification<BR>task: Text Classification<BR>date: 2018-03<BR>ratio: 0.02\", \"Text Classification<BR>task: Text Classification<BR>date: 2018-05<BR>ratio: 0.42\", \"Text Classification<BR>task: Text Classification<BR>date: 2018-07<BR>ratio: 0.03\", \"Text Classification<BR>task: Text Classification<BR>date: 2018-08<BR>ratio: 0.32\", \"Text Classification<BR>task: Text Classification<BR>date: 2018-09<BR>ratio: 0.48\", \"Text Classification<BR>task: Text Classification<BR>date: 2019-01<BR>ratio: 0.03\", \"Text Classification<BR>task: Text Classification<BR>date: 2019-02<BR>ratio: 0.0\", \"Text Classification<BR>task: Text Classification<BR>date: 2019-05<BR>ratio: 0.26\", \"Text Classification<BR>task: Text Classification<BR>date: 2019-09<BR>ratio: 0.13\", \"Text Classification<BR>task: Text Classification<BR>date: 2020-02<BR>ratio: 0.06\", \"Text Generation<BR>task: Text Generation<BR>date: 2017-05<BR>ratio: 0.05\", \"Text Generation<BR>task: Text Generation<BR>date: 2017-09<BR>ratio: 0.13\", \"Text Summarization<BR>task: Text Summarization<BR>date: 2016-02<BR>ratio: 0.35\", \"Text Summarization<BR>task: Text Summarization<BR>date: 2016-06<BR>ratio: 0.01\", \"Text Summarization<BR>task: Text Summarization<BR>date: 2017-06<BR>ratio: 0.04\", \"Text Summarization<BR>task: Text Summarization<BR>date: 2018-07<BR>ratio: 0.0\", \"Text Summarization<BR>task: Text Summarization<BR>date: 2018-08<BR>ratio: 0.04\", \"Text Summarization<BR>task: Text Summarization<BR>date: 2019-04<BR>ratio: 0.12\", \"Text Summarization<BR>task: Text Summarization<BR>date: 2019-05<BR>ratio: 0.02\", \"Text Summarization<BR>task: Text Summarization<BR>date: 2019-10<BR>ratio: 0.19\", \"Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2016-12<BR>ratio: 0.43\", \"Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2017-10<BR>ratio: 0.34\", \"Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2019-03<BR>ratio: 0.03\", \"Text-to-Image Generation<BR>task: Text-to-Image Generation<BR>date: 2019-04<BR>ratio: 0.14\", \"Unsupervised Machine Translation<BR>task: Unsupervised Machine Translation<BR>date: 2018-10<BR>ratio: 0.04\", \"Unsupervised Machine Translation<BR>task: Unsupervised Machine Translation<BR>date: 2019-01<BR>ratio: 0.32\", \"Unsupervised Machine Translation<BR>task: Unsupervised Machine Translation<BR>date: 2019-02<BR>ratio: 0.1\", \"Unsupervised Machine Translation<BR>task: Unsupervised Machine Translation<BR>date: 2019-05<BR>ratio: 0.04\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2017-09<BR>ratio: 0.06\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2017-11<BR>ratio: 0.04\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2018-09<BR>ratio: 0.02\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2019-02<BR>ratio: 0.02\", \"Visual Dialog<BR>task: Visual Dialog<BR>date: 2019-04<BR>ratio: 0.05\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-03<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-05<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-06<BR>ratio: 0.45\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-11<BR>ratio: 0.07\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-12<BR>ratio: 0.43\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-04<BR>ratio: 0.35\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-05<BR>ratio: 0.05\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-08<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-03<BR>ratio: 0.0\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-05<BR>ratio: 0.0\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-02<BR>ratio: 0.36\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-04<BR>ratio: 0.33\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-05<BR>ratio: 0.19\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-06<BR>ratio: 0.01\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-07<BR>ratio: 0.14\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-08<BR>ratio: 0.22\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-09<BR>ratio: 0.05\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2020-02<BR>ratio: 0.0\", \"Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2016-03<BR>ratio: 0.41\", \"Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2016-06<BR>ratio: 0.01\", \"Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2018-02<BR>ratio: 0.42\", \"Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2018-05<BR>ratio: 0.15\", \"Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2018-11<BR>ratio: 0.04\", \"Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2019-05<BR>ratio: 0.08\", \"Word Sense Disambiguation<BR>task: Word Sense Disambiguation<BR>date: 2019-09<BR>ratio: 0.11\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.47, 0.01, 0.01, 0.04, 0.06, 0.02, 0.43, 0.0, 0.0, 0.0, 0.0, 0.1, 0.05, 0.02, 0.01, 0.04, 0.01, 0.02, 0.02, 0.01, 0.03, 0.02, 0.01, 0.5, 0.01, 0.01, 0.0, 0.01, 0.2, 0.02, 0.03, 0.31, 0.14, 0.08, 0.11, 0.12, 0.1, 0.12, 0.07, 0.45, 0.22, 0.04, 0.06, 0.02, 0.01, 0.01, 0.01, 0.27, 0.4, 0.28, 0.1, 0.01, 0.01, 0.31, 0.04, 0.03, 0.05, 0.18, 0.01, 0.03, 0.06, 0.48, 0.04, 0.19, 0.04, 0.01, 0.01, 0.13, 0.03, 0.06, 0.01, 0.34, 0.01, 0.08, 0.03, 0.02, 0.01, 0.1, 0.07, 0.0, 0.02, 0.0, 0.35, 0.01, 0.43, 0.12, 0.05, 0.01, 0.01, 0.0, 0.04, 0.05, 0.0, 0.03, 0.5, 0.03, 0.13, 0.1, 0.04, 0.02, 0.13, 0.03, 0.34, 0.49, 0.03, 0.09, 0.03, 0.01, 0.5, 0.08, 0.37, 0.0, 0.02, 0.01, 0.0, 0.0, 0.34, 0.26, 0.34, 0.05, 0.01, 0.0, 0.29, 0.02, 0.03, 0.02, 0.08, 0.11, 0.01, 0.02, 0.03, 0.09, 0.21, 0.08, 0.33, 0.03, 0.38, 0.22, 0.09, 0.06, 0.04, 0.06, 0.19, 0.37, 0.01, 0.04, 0.03, 0.01, 0.01, 0.01, 0.0, 0.0, 0.0, 0.45, 0.01, 0.01, 0.25, 0.43, 0.04, 0.05, 0.03, 0.01, 0.49, 0.49, 0.36, 0.41, 0.28, 0.04, 0.14, 0.41, 0.5, 0.5, 0.5, 0.0, 0.01, 0.0, 0.49, 0.01, 0.49, 0.0, 0.0, 0.0, 0.23, 0.21, 0.36, 0.0, 0.25, 0.39, 0.08, 0.49, 0.03, 0.41, 0.28, 0.28, 0.01, 0.27, 0.05, 0.05, 0.33, 0.34, 0.01, 0.1, 0.23, 0.07, 0.11, 0.41, 0.1, 0.16, 0.05, 0.29, 0.2, 0.12, 0.12, 0.11, 0.0, 0.02, 0.03, 0.39, 0.05, 0.04, 0.34, 0.16, 0.01, 0.03, 0.03, 0.07, 0.01, 0.28, 0.28, 0.22, 0.07, 0.16, 0.01, 0.03, 0.01, 0.01, 0.01, 0.01, 0.02, 0.01, 0.02, 0.29, 0.04, 0.07, 0.01, 0.01, 0.06, 0.32, 0.0, 0.0, 0.07, 0.03, 0.02, 0.01, 0.03, 0.02, 0.3, 0.05, 0.05, 0.01, 0.0, 0.04, 0.02, 0.02, 0.04, 0.1, 0.0, 0.0, 0.01, 0.0, 0.42, 0.15, 0.17, 0.02, 0.42, 0.03, 0.32, 0.48, 0.03, 0.0, 0.26, 0.13, 0.06, 0.05, 0.13, 0.35, 0.01, 0.04, 0.0, 0.04, 0.12, 0.02, 0.19, 0.43, 0.34, 0.03, 0.14, 0.04, 0.32, 0.1, 0.04, 0.06, 0.04, 0.02, 0.02, 0.05, 0.03, 0.03, 0.45, 0.07, 0.43, 0.35, 0.05, 0.03, 0.0, 0.0, 0.36, 0.33, 0.19, 0.01, 0.14, 0.22, 0.05, 0.0, 0.41, 0.01, 0.42, 0.15, 0.04, 0.08, 0.11], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2016-11\", \"2018-10\", \"2019-05\", \"2018-08\", \"2019-05\", \"2019-10\", \"2017-04\", \"2018-09\", \"2018-10\", \"2018-12\", \"2019-03\", \"2019-04\", \"2016-05\", \"2017-09\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-10\", \"2019-02\", \"2019-06\", \"2019-08\", \"2019-12\", \"2020-04\", \"2019-04\", \"2019-07\", \"2019-11\", \"2016-11\", \"2018-08\", \"2016-06\", \"2018-01\", \"2018-02\", \"2017-08\", \"2018-03\", \"2018-04\", \"2018-10\", \"2019-10\", \"2019-02\", \"2019-06\", \"2019-07\", \"2018-08\", \"2018-10\", \"2019-04\", \"2019-06\", \"2016-11\", \"2017-07\", \"2018-05\", \"2019-03\", \"2018-02\", \"2018-03\", \"2019-04\", \"2019-11\", \"2016-06\", \"2016-09\", \"2017-07\", \"2018-02\", \"2018-04\", \"2019-07\", \"2018-11\", \"2018-12\", \"2014-04\", \"2014-12\", \"2018-05\", \"2018-12\", \"2019-09\", \"2018-03\", \"2018-04\", \"2018-05\", \"2018-09\", \"2019-04\", \"2019-12\", \"2016-03\", \"2016-11\", \"2018-07\", \"2017-09\", \"2017-11\", \"2018-05\", \"2018-10\", \"2016-03\", \"2016-09\", \"2016-11\", \"2017-10\", \"2018-08\", \"2019-08\", \"2020-02\", \"2017-05\", \"2018-08\", \"2019-03\", \"2019-05\", \"2019-08\", \"2018-06\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-08\", \"2019-09\", \"2017-05\", \"2019-09\", \"2017-12\", \"2018-11\", \"2016-11\", \"2017-04\", \"2017-07\", \"2019-06\", \"2019-12\", \"2019-04\", \"2019-09\", \"2014-12\", \"2016-03\", \"2016-07\", \"2016-09\", \"2016-12\", \"2017-05\", \"2017-07\", \"2017-08\", \"2017-10\", \"2017-11\", \"2018-03\", \"2018-08\", \"2018-09\", \"2019-01\", \"2019-06\", \"2019-09\", \"2014-09\", \"2014-10\", \"2016-03\", \"2016-08\", \"2016-09\", \"2016-10\", \"2016-11\", \"2017-01\", \"2017-05\", \"2017-06\", \"2017-11\", \"2018-02\", \"2018-03\", \"2018-06\", \"2018-08\", \"2019-01\", \"2019-05\", \"2019-06\", \"2019-09\", \"2019-10\", \"2018-08\", \"2018-10\", \"2019-03\", \"2019-06\", \"2019-08\", \"2019-11\", \"2014-08\", \"2016-09\", \"2017-02\", \"2017-09\", \"2017-11\", \"2017-12\", \"2018-04\", \"2018-05\", \"2018-06\", \"2018-09\", \"2018-10\", \"2019-01\", \"2019-07\", \"2019-09\", \"2016-03\", \"2016-11\", \"2017-03\", \"2017-11\", \"2018-01\", \"2018-10\", \"2018-11\", \"2019-07\", \"2017-09\", \"2018-06\", \"2013-10\", \"2017-04\", \"2017-09\", \"2018-07\", \"2019-01\", \"2019-06\", \"2015-08\", \"2017-11\", \"2018-05\", \"2019-08\", \"2014-06\", \"2014-12\", \"2015-06\", \"2015-11\", \"2016-02\", \"2016-03\", \"2016-06\", \"2016-08\", \"2016-09\", \"2016-10\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-05\", \"2017-06\", \"2017-07\", \"2017-08\", \"2017-10\", \"2017-12\", \"2018-01\", \"2018-04\", \"2018-06\", \"2018-07\", \"2018-08\", \"2018-09\", \"2018-10\", \"2018-11\", \"2019-01\", \"2019-02\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\", \"2018-06\", \"2019-05\", \"2016-01\", \"2017-07\", \"2017-09\", \"2018-07\", \"2018-08\", \"2018-09\", \"2018-10\", \"2018-12\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-09\", \"2019-11\", \"2020-03\", \"2020-04\", \"2017-04\", \"2018-10\", \"2017-12\", \"2018-02\", \"2018-05\", \"2018-10\", \"2018-03\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-09\", \"2018-10\", \"2019-03\", \"2017-07\", \"2018-07\", \"2014-06\", \"2014-08\", \"2015-02\", \"2015-06\", \"2015-11\", \"2016-02\", \"2017-02\", \"2017-07\", \"2017-08\", \"2017-12\", \"2018-01\", \"2018-02\", \"2018-04\", \"2018-05\", \"2018-10\", \"2019-01\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-09\", \"2015-04\", \"2015-11\", \"2017-02\", \"2018-03\", \"2018-05\", \"2018-07\", \"2018-08\", \"2018-09\", \"2019-01\", \"2019-02\", \"2019-05\", \"2019-09\", \"2020-02\", \"2017-05\", \"2017-09\", \"2016-02\", \"2016-06\", \"2017-06\", \"2018-07\", \"2018-08\", \"2019-04\", \"2019-05\", \"2019-10\", \"2016-12\", \"2017-10\", \"2019-03\", \"2019-04\", \"2018-10\", \"2019-01\", \"2019-02\", \"2019-05\", \"2017-09\", \"2017-11\", \"2018-09\", \"2019-02\", \"2019-04\", \"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\", \"2020-02\", \"2016-03\", \"2016-06\", \"2018-02\", \"2018-05\", \"2018-11\", \"2019-05\", \"2019-09\"], \"y\": [\"AMR Parsing\", \"AMR Parsing\", \"AMR Parsing\", \"Abstractive Text Summarization\", \"Abstractive Text Summarization\", \"Abstractive Text Summarization\", \"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\", \"Ad-Hoc Information Retrieval\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Aspect-Based Sentiment Analysis\", \"Chinese Named Entity Recognition\", \"Chinese Named Entity Recognition\", \"Chinese Named Entity Recognition\", \"Chunking\", \"Chunking\", \"Citation Intent Classification\", \"Citation Intent Classification\", \"Citation Intent Classification\", \"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\", \"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Constituency Grammar Induction\", \"Constituency Grammar Induction\", \"Constituency Grammar Induction\", \"Constituency Grammar Induction\", \"Constituency Parsing\", \"Constituency Parsing\", \"Constituency Parsing\", \"Constituency Parsing\", \"Conversational Response Selection\", \"Conversational Response Selection\", \"Conversational Response Selection\", \"Conversational Response Selection\", \"Coreference Resolution\", \"Coreference Resolution\", \"Coreference Resolution\", \"Coreference Resolution\", \"Coreference Resolution\", \"Coreference Resolution\", \"Cross-Lingual Bitext Mining\", \"Cross-Lingual Bitext Mining\", \"Cross-Lingual Document Classification\", \"Cross-Lingual Document Classification\", \"Cross-Lingual Document Classification\", \"Cross-Lingual Document Classification\", \"Cross-Lingual Document Classification\", \"Data-to-Text Generation\", \"Data-to-Text Generation\", \"Data-to-Text Generation\", \"Data-to-Text Generation\", \"Data-to-Text Generation\", \"Data-to-Text Generation\", \"Dependency Parsing\", \"Dependency Parsing\", \"Dependency Parsing\", \"Dialog Act Classification\", \"Dialog Act Classification\", \"Dialog State Tracking\", \"Dialog State Tracking\", \"Document Classification\", \"Document Classification\", \"Document Classification\", \"Document Classification\", \"Document Classification\", \"Document Classification\", \"Document Classification\", \"Document Summarization\", \"Document Summarization\", \"Document Summarization\", \"Document Summarization\", \"Document Summarization\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Entity Disambiguation\", \"Entity Disambiguation\", \"Fake News Detection\", \"Fake News Detection\", \"Grammatical Error Detection\", \"Grammatical Error Detection\", \"Grammatical Error Detection\", \"Intent Detection\", \"Intent Detection\", \"Joint Entity and Relation Extraction\", \"Joint Entity and Relation Extraction\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Language Modelling\", \"Linguistic Acceptability Assessment\", \"Linguistic Acceptability Assessment\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Machine Translation\", \"Named Entity Recognition\", \"Named Entity Recognition\", \"Named Entity Recognition\", \"Named Entity Recognition\", \"Named Entity Recognition\", \"Named Entity Recognition\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Natural Language Inference\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Open-Domain Question Answering\", \"Paraphrase Generation\", \"Paraphrase Generation\", \"Paraphrase Identification\", \"Paraphrase Identification\", \"Paraphrase Identification\", \"Paraphrase Identification\", \"Paraphrase Identification\", \"Paraphrase Identification\", \"Part-Of-Speech Tagging\", \"Part-Of-Speech Tagging\", \"Part-Of-Speech Tagging\", \"Part-Of-Speech Tagging\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Answering\", \"Question Generation\", \"Question Generation\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Relation Extraction\", \"Semantic Parsing\", \"Semantic Parsing\", \"Semantic Role Labeling\", \"Semantic Role Labeling\", \"Semantic Role Labeling\", \"Semantic Role Labeling\", \"Semantic Textual Similarity\", \"Semantic Textual Similarity\", \"Semantic Textual Similarity\", \"Semantic Textual Similarity\", \"Semantic Textual Similarity\", \"Sentence Classification\", \"Sentence Classification\", \"Sentence Compression\", \"Sentence Compression\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Sentiment Analysis\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Classification\", \"Text Generation\", \"Text Generation\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text Summarization\", \"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Text-to-Image Generation\", \"Unsupervised Machine Translation\", \"Unsupervised Machine Translation\", \"Unsupervised Machine Translation\", \"Unsupervised Machine Translation\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Dialog\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\", \"Word Sense Disambiguation\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Word Sense Disambiguation\", \"Visual Question Answering\", \"Visual Dialog\", \"Unsupervised Machine Translation\", \"Text-to-Image Generation\", \"Text Summarization\", \"Text Generation\", \"Text Classification\", \"Sentiment Analysis\", \"Sentence Compression\", \"Sentence Classification\", \"Semantic Textual Similarity\", \"Semantic Role Labeling\", \"Semantic Parsing\", \"Relation Extraction\", \"Question Generation\", \"Question Answering\", \"Part-Of-Speech Tagging\", \"Paraphrase Identification\", \"Paraphrase Generation\", \"Open-Domain Question Answering\", \"Natural Language Inference\", \"Named Entity Recognition\", \"Machine Translation\", \"Linguistic Acceptability Assessment\", \"Language Modelling\", \"Joint Entity and Relation Extraction\", \"Intent Detection\", \"Grammatical Error Detection\", \"Fake News Detection\", \"Entity Disambiguation\", \"Emotion Recognition in Conversation\", \"Document Summarization\", \"Document Classification\", \"Dialog State Tracking\", \"Dialog Act Classification\", \"Dependency Parsing\", \"Data-to-Text Generation\", \"Cross-Lingual Document Classification\", \"Cross-Lingual Bitext Mining\", \"Coreference Resolution\", \"Conversational Response Selection\", \"Constituency Parsing\", \"Constituency Grammar Induction\", \"Common Sense Reasoning\", \"Code Generation\", \"Citation Intent Classification\", \"Chunking\", \"Chinese Named Entity Recognition\", \"Aspect-Based Sentiment Analysis\", \"Ad-Hoc Information Retrieval\", \"Abstractive Text Summarization\", \"AMR Parsing\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00141: Natural Language Processing\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('31b2eed8-557a-47de-a8cf-15a76d5fe99f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00145\n",
      "Number of metrics:  29\n",
      "####### Percentage\\\\ error\n",
      "Creating ratio df for  Percentage\\\\ error ,  TIMIT - Speech Recognition benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Percentage\\\\ error ,  swb_hub_500 WER fullSWBCH - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Percentage\\\\ error ,  Switchboard + Hub500 - Speech Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ error ,  CHiME real - Noisy Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Percentage\\\\ error ,  VoxForge Indian - Accented Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Percentage\\\\ error ,  VoxForge Commonwealth - Accented Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Percentage\\\\ error ,  VoxForge American-Canadian - Accented Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Percentage\\\\ error ,  CHiME clean - Noisy Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Percentage\\\\ error ,  VoxForge European - Accented Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  10\n",
      "####### Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\)\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  WSJ eval92 - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  LibriSpeech test-clean - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  LibriSpeech test-other - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  WSJ eval93 - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  CHiME-4 real 6ch - Distant Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  Switchboard (300hr) - Speech Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  DIRHA English WSJ - Distant Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  CMUDict 0.7b - Text-To-Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  AISHELL-1 - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Word\\\\ Error\\\\ Rate\\\\ \\\\(WER\\\\) ,  Hub5\\'00 CallHome - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  18\n",
      "####### F1\n",
      "Creating ratio df for  F1 ,  A3Lab PASCAL CHiME - Acoustic Novelty Detection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  F1 ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### SI\\\\-SDRi\n",
      "Creating ratio df for  SI\\\\-SDRi ,  wsj0-2mix - Speech Separation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  MNIST - Unsupervised MNIST benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Helsinki Prosody Corpus - Prosody Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  12\n",
      "####### Accuracy\\\\ \\\\(10\\\\-fold\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(10\\\\-fold\\\\) ,  UrbanSound8k - Environmental Sound Classification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Mean\\\\ Opinion\\\\ Score\n",
      "Creating ratio df for  Mean\\\\ Opinion\\\\ Score ,  Mandarin Chinese - Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Mean\\\\ Opinion\\\\ Score ,  North American English - Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  6\n",
      "####### MAE\\\\ \\\\(Valence\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Valence\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Arousal\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Arousal\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAE\\\\ \\\\(Expectancy\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Expectancy\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\\\\ \\\\(Power\\\\)\n",
      "Creating ratio df for  MAE\\\\ \\\\(Power\\\\) ,  SEMAINE - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Weighted\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Weighted\\\\-F1 ,  MELD - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  8\n",
      "####### UA\n",
      "Creating ratio df for  UA ,  IEMOCAP - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  UA ,  IEMOCAP - Speech Emotion Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  5\n",
      "####### Macro\\\\-F1\n",
      "Creating ratio df for  Macro\\\\-F1 ,  IEMOCAP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### Log\\\\-Spectral\\\\ Distance\n",
      "Creating ratio df for  Log\\\\-Spectral\\\\ Distance ,  VCTK Multi-Speaker - Audio Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Log\\\\-Spectral\\\\ Distance ,  Piano - Audio Super-Resolution benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Log\\\\-Spectral\\\\ Distance ,  Voice Bank corpus (VCTK) - Audio Super-Resolution benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  2\n",
      "####### v2v\\\\ error\n",
      "Creating ratio df for  v2v\\\\ error ,  Expressive hands and faces dataset (EHF). - Multimodal Emotion Recognition benchmarking , ds_count= 1\n",
      "null\n",
      "####### SDR\n",
      "Creating ratio df for  SDR ,  GRID corpus (mixed-speech) - Speech Separation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SDR ,  TCD-TIMIT corpus (mixed-speech) - Speech Separation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SDR ,  AudioSet - Audio Source Separation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### PESQ\n",
      "Creating ratio df for  PESQ ,  GRID corpus (mixed-speech) - Speech Enhancement benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  PESQ ,  TCD-TIMIT corpus (mixed-speech) - Speech Enhancement benchmarking , ds_count= 1\n",
      "null\n",
      "####### Micro\\\\-F1\n",
      "Creating ratio df for  Micro\\\\-F1 ,  EC - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Micro\\\\-F1 ,  DailyDialog - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### CallHome\n",
      "Creating ratio df for  CallHome ,  Hub5\\'00 SwitchBoard - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### SwitchBoard\n",
      "Creating ratio df for  SwitchBoard ,  Hub5\\'00 SwitchBoard - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Phoneme\\\\ Error\\\\ Rate\n",
      "Creating ratio df for  Phoneme\\\\ Error\\\\ Rate ,  CMUDict 0.7b - Text-To-Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### SAR\n",
      "Creating ratio df for  SAR ,  MUSIC (multi-source) - Audio Source Separation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SAR ,  AudioSet - Audio Source Separation benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### SIR\n",
      "Creating ratio df for  SIR ,  MUSIC (multi-source) - Audio Source Separation benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  SIR ,  AudioSet - Audio Source Separation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NSDR\n",
      "Creating ratio df for  NSDR ,  AV-Bench - Wooden Horse - Audio Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NSDR ,  AV-Bench - Guitar Solo - Audio Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  NSDR ,  AV-Bench - Violin Yanni - Audio Denoising benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### Angular\\\\ Error\n",
      "Creating ratio df for  Angular\\\\ Error ,  SOFA - Direction of Arrival Estimation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Audio\\\\ Quality\\\\ MOS\n",
      "Creating ratio df for  Audio\\\\ Quality\\\\ MOS ,  LJSpeech - Text-To-Speech Synthesis benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Eval2000\n",
      "Creating ratio df for  Eval2000 ,  Hub5\\'00 SwitchBoard - Speech Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Weighted\\\\ Macro\\\\-F1\n",
      "Creating ratio df for  Weighted\\\\ Macro\\\\-F1 ,  EmoryNLP - Emotion Recognition in Conversation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Emotion Recognition in Conversation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Emotion Recognition in Conversation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-06",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-08",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Speech Recognition",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Speech Recognition",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-04",
          "2017-12",
          "2018-05",
          "2018-12",
          "2019-07",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Speech Recognition",
          "Speech Recognition",
          "Speech Recognition",
          "Speech Recognition",
          "Speech Recognition",
          "Speech Recognition"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Speech Separation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Speech Separation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-04",
          "2018-09",
          "2019-04",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Speech Separation",
          "Speech Separation",
          "Speech Separation",
          "Speech Separation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Speech Synthesis",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Speech Synthesis",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-09",
          "2017-12"
         ],
         "xaxis": "x",
         "y": [
          "Speech Synthesis",
          "Speech Synthesis"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Unsupervised MNIST",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Unsupervised MNIST",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-03",
          "2018-07"
         ],
         "xaxis": "x",
         "y": [
          "Unsupervised MNIST",
          "Unsupervised MNIST"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-06<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-10<BR>ratio: 0.04",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-11<BR>ratio: 0.05",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-04<BR>ratio: 0.0",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-08<BR>ratio: 0.03",
          "Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-09<BR>ratio: 0.0",
          "Speech Recognition<BR>task: Speech Recognition<BR>date: 2017-04<BR>ratio: 0.12",
          "Speech Recognition<BR>task: Speech Recognition<BR>date: 2017-12<BR>ratio: 0.01",
          "Speech Recognition<BR>task: Speech Recognition<BR>date: 2018-05<BR>ratio: 0.15",
          "Speech Recognition<BR>task: Speech Recognition<BR>date: 2018-12<BR>ratio: 0.26",
          "Speech Recognition<BR>task: Speech Recognition<BR>date: 2019-07<BR>ratio: 0.01",
          "Speech Recognition<BR>task: Speech Recognition<BR>date: 2020-02<BR>ratio: 0.16",
          "Speech Separation<BR>task: Speech Separation<BR>date: 2018-04<BR>ratio: 0.04",
          "Speech Separation<BR>task: Speech Separation<BR>date: 2018-09<BR>ratio: 0.1",
          "Speech Separation<BR>task: Speech Separation<BR>date: 2019-04<BR>ratio: 0.13",
          "Speech Separation<BR>task: Speech Separation<BR>date: 2019-10<BR>ratio: 0.06",
          "Speech Synthesis<BR>task: Speech Synthesis<BR>date: 2016-09<BR>ratio: 0.49",
          "Speech Synthesis<BR>task: Speech Synthesis<BR>date: 2017-12<BR>ratio: 0.03",
          "Unsupervised MNIST<BR>task: Unsupervised MNIST<BR>date: 2018-03<BR>ratio: 0.01",
          "Unsupervised MNIST<BR>task: Unsupervised MNIST<BR>date: 2018-07<BR>ratio: 0.03"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0,
           0.04,
           0.05,
           0,
           0.03,
           0,
           0.12,
           0.01,
           0.15,
           0.26,
           0.01,
           0.16,
           0.04,
           0.1,
           0.13,
           0.06,
           0.49,
           0.03,
           0.01,
           0.03
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2018-06",
          "2018-10",
          "2018-11",
          "2019-04",
          "2019-08",
          "2019-09",
          "2017-04",
          "2017-12",
          "2018-05",
          "2018-12",
          "2019-07",
          "2020-02",
          "2018-04",
          "2018-09",
          "2019-04",
          "2019-10",
          "2016-09",
          "2017-12",
          "2018-03",
          "2018-07"
         ],
         "y": [
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Emotion Recognition in Conversation",
          "Speech Recognition",
          "Speech Recognition",
          "Speech Recognition",
          "Speech Recognition",
          "Speech Recognition",
          "Speech Recognition",
          "Speech Separation",
          "Speech Separation",
          "Speech Separation",
          "Speech Separation",
          "Speech Synthesis",
          "Speech Synthesis",
          "Unsupervised MNIST",
          "Unsupervised MNIST"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Unsupervised MNIST",
          "Speech Synthesis",
          "Speech Separation",
          "Speech Recognition",
          "Emotion Recognition in Conversation"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00145: Audio process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"8a66f37a-22e8-4b87-a22a-73f69842bc70\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8a66f37a-22e8-4b87-a22a-73f69842bc70\")) {                    Plotly.newPlot(                        \"8a66f37a-22e8-4b87-a22a-73f69842bc70\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Emotion Recognition in Conversation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Emotion Recognition in Conversation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-06\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-08\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Speech Recognition\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Speech Recognition\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-04\", \"2017-12\", \"2018-05\", \"2018-12\", \"2019-07\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Speech Recognition\", \"Speech Recognition\", \"Speech Recognition\", \"Speech Recognition\", \"Speech Recognition\", \"Speech Recognition\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Speech Separation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Speech Separation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-04\", \"2018-09\", \"2019-04\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Speech Separation\", \"Speech Separation\", \"Speech Separation\", \"Speech Separation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Speech Synthesis\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Speech Synthesis\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-09\", \"2017-12\"], \"xaxis\": \"x\", \"y\": [\"Speech Synthesis\", \"Speech Synthesis\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Unsupervised MNIST\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Unsupervised MNIST\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-03\", \"2018-07\"], \"xaxis\": \"x\", \"y\": [\"Unsupervised MNIST\", \"Unsupervised MNIST\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-06<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-10<BR>ratio: 0.04\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2018-11<BR>ratio: 0.05\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-04<BR>ratio: 0.0\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-08<BR>ratio: 0.03\", \"Emotion Recognition in Conversation<BR>task: Emotion Recognition in Conversation<BR>date: 2019-09<BR>ratio: 0.0\", \"Speech Recognition<BR>task: Speech Recognition<BR>date: 2017-04<BR>ratio: 0.12\", \"Speech Recognition<BR>task: Speech Recognition<BR>date: 2017-12<BR>ratio: 0.01\", \"Speech Recognition<BR>task: Speech Recognition<BR>date: 2018-05<BR>ratio: 0.15\", \"Speech Recognition<BR>task: Speech Recognition<BR>date: 2018-12<BR>ratio: 0.26\", \"Speech Recognition<BR>task: Speech Recognition<BR>date: 2019-07<BR>ratio: 0.01\", \"Speech Recognition<BR>task: Speech Recognition<BR>date: 2020-02<BR>ratio: 0.16\", \"Speech Separation<BR>task: Speech Separation<BR>date: 2018-04<BR>ratio: 0.04\", \"Speech Separation<BR>task: Speech Separation<BR>date: 2018-09<BR>ratio: 0.1\", \"Speech Separation<BR>task: Speech Separation<BR>date: 2019-04<BR>ratio: 0.13\", \"Speech Separation<BR>task: Speech Separation<BR>date: 2019-10<BR>ratio: 0.06\", \"Speech Synthesis<BR>task: Speech Synthesis<BR>date: 2016-09<BR>ratio: 0.49\", \"Speech Synthesis<BR>task: Speech Synthesis<BR>date: 2017-12<BR>ratio: 0.03\", \"Unsupervised MNIST<BR>task: Unsupervised MNIST<BR>date: 2018-03<BR>ratio: 0.01\", \"Unsupervised MNIST<BR>task: Unsupervised MNIST<BR>date: 2018-07<BR>ratio: 0.03\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.0, 0.04, 0.05, 0.0, 0.03, 0.0, 0.12, 0.01, 0.15, 0.26, 0.01, 0.16, 0.04, 0.1, 0.13, 0.06, 0.49, 0.03, 0.01, 0.03], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2018-06\", \"2018-10\", \"2018-11\", \"2019-04\", \"2019-08\", \"2019-09\", \"2017-04\", \"2017-12\", \"2018-05\", \"2018-12\", \"2019-07\", \"2020-02\", \"2018-04\", \"2018-09\", \"2019-04\", \"2019-10\", \"2016-09\", \"2017-12\", \"2018-03\", \"2018-07\"], \"y\": [\"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Emotion Recognition in Conversation\", \"Speech Recognition\", \"Speech Recognition\", \"Speech Recognition\", \"Speech Recognition\", \"Speech Recognition\", \"Speech Recognition\", \"Speech Separation\", \"Speech Separation\", \"Speech Separation\", \"Speech Separation\", \"Speech Synthesis\", \"Speech Synthesis\", \"Unsupervised MNIST\", \"Unsupervised MNIST\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Unsupervised MNIST\", \"Speech Synthesis\", \"Speech Separation\", \"Speech Recognition\", \"Emotion Recognition in Conversation\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00145: Audio process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8a66f37a-22e8-4b87-a22a-73f69842bc70');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00310\n",
      "Number of metrics:  1\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  ImageNet (targeted PGD, max perturbation=16) - Adversarial Defense benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  ImageNet - Adversarial Defense benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CAAD 2018 - Adversarial Defense benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  CIFAR-10 - Adversarial Defense benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "https://identifiers.org/ito:ITO_00485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metrics:  9\n",
      "####### BLEU\\\\-4\n",
      "Creating ratio df for  BLEU\\\\-4 ,  WikiSQL - SQL-to-Text benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  Django - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  MNIST - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  ISOLET - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Coil-20 - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Fashion-MNIST - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Activity - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Mice Protein - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  8\n",
      "####### 14\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  100 sleep nights of 8 caregivers - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Execution\\\\ Accuracy\n",
      "Creating ratio df for  Execution\\\\ Accuracy ,  WikiSQL - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "number of sota per dataset/metric:  6\n",
      "####### Exact\\\\ Match\\\\ Accuracy\n",
      "Creating ratio df for  Exact\\\\ Match\\\\ Accuracy ,  WikiSQL - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Perplexity\n",
      "Creating ratio df for  Perplexity ,  Android Repos - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### BLEU\n",
      "Creating ratio df for  BLEU ,  CoNaLa - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  BLEU ,  CoNaLa-Ext - Code Generation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\\\\(10\\\\-fold\\\\)\n",
      "Creating ratio df for  Accuracy\\\\(10\\\\-fold\\\\) ,  Zoo - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy\\\\(10\\\\-fold\\\\) ,  Glass identification - Feature Selection benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### MRR\n",
      "Creating ratio df for  MRR ,  Py150 - Type prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  Py150 - Value prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Code Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Code Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08",
          "2018-03",
          "2018-04",
          "2018-10",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Code Generation<BR>task: Code Generation<BR>date: 2017-08<BR>ratio: 0.31",
          "Code Generation<BR>task: Code Generation<BR>date: 2018-03<BR>ratio: 0.14",
          "Code Generation<BR>task: Code Generation<BR>date: 2018-04<BR>ratio: 0.08",
          "Code Generation<BR>task: Code Generation<BR>date: 2018-10<BR>ratio: 0.11",
          "Code Generation<BR>task: Code Generation<BR>date: 2019-10<BR>ratio: 0.12"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.31,
           0.14,
           0.08,
           0.11,
           0.12
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2017-08",
          "2018-03",
          "2018-04",
          "2018-10",
          "2019-10"
         ],
         "y": [
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Code Generation"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00485: Computer code process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"677efa92-c513-405c-a37d-bc768ccd5e2f\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"677efa92-c513-405c-a37d-bc768ccd5e2f\")) {                    Plotly.newPlot(                        \"677efa92-c513-405c-a37d-bc768ccd5e2f\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Code Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Code Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-08\", \"2018-03\", \"2018-04\", \"2018-10\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Code Generation<BR>task: Code Generation<BR>date: 2017-08<BR>ratio: 0.31\", \"Code Generation<BR>task: Code Generation<BR>date: 2018-03<BR>ratio: 0.14\", \"Code Generation<BR>task: Code Generation<BR>date: 2018-04<BR>ratio: 0.08\", \"Code Generation<BR>task: Code Generation<BR>date: 2018-10<BR>ratio: 0.11\", \"Code Generation<BR>task: Code Generation<BR>date: 2019-10<BR>ratio: 0.12\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.31, 0.14, 0.08, 0.11, 0.12], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2017-08\", \"2018-03\", \"2018-04\", \"2018-10\", \"2019-10\"], \"y\": [\"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Code Generation\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00485: Computer code process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('677efa92-c513-405c-a37d-bc768ccd5e2f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00491\n",
      "Number of metrics:  17\n",
      "####### Percentage\\\\ correct\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) abstract images 1.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 1.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) abstract 1.0 multiple choice - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 2.0 open ended - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  COCO Visual Question Answering (VQA) real images 1.0 multiple choice - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual7W - Visual Question Answering benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual Genome (pairs) - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Percentage\\\\ correct ,  Visual Genome (subjects) - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  VQA v1 test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Accuracy ,  VQA v1 test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Accuracy ,  VQA v2 test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Accuracy ,  MSVD-QA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  MSRVTT-QA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  CLEVR - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  HowmanyQA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  TallyQA - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  TDIUC - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  GQA test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  GQA test-dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  VCR (QA-R) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-AR) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-A) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-AR) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (Q-A) dev - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  VCR (QA-R) test - Visual Question Answering benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  39\n",
      "####### overall\n",
      "Creating ratio df for  overall ,  VQA v2 test-std - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  overall ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  10\n",
      "####### Consistency\n",
      "Creating ratio df for  Consistency ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Plausibility\n",
      "Creating ratio df for  Plausibility ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Validity\n",
      "Creating ratio df for  Validity ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Distribution\n",
      "Creating ratio df for  Distribution ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Binary\n",
      "Creating ratio df for  Binary ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Open\n",
      "Creating ratio df for  Open ,  GQA Test2019 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Score\n",
      "Creating ratio df for  Score ,  VQA-CP - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### 14\\\\ gestures\\\\ accuracy\n",
      "Creating ratio df for  14\\\\ gestures\\\\ accuracy ,  100 sleep nights of 8 caregivers - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### number\n",
      "Creating ratio df for  number ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### unanswerable\n",
      "Creating ratio df for  unanswerable ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### yes/no\n",
      "Creating ratio df for  yes/no ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### other\n",
      "Creating ratio df for  other ,  VizWiz 2018 - Visual Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 1/4\n",
      "Creating ratio df for  1/4 ,  SUTD-TrafficQA - Video Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### 1/2\n",
      "Creating ratio df for  1/2 ,  SUTD-TrafficQA - Video Question Answering benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Visual Question Answering",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Visual Question Answering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-03<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-05<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-06<BR>ratio: 0.46",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-11<BR>ratio: 0.07",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-12<BR>ratio: 0.43",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-04<BR>ratio: 0.35",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-05<BR>ratio: 0.05",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-08<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-03<BR>ratio: 0.0",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-05<BR>ratio: 0.0",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-02<BR>ratio: 0.36",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-04<BR>ratio: 0.33",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-05<BR>ratio: 0.19",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-06<BR>ratio: 0.01",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-07<BR>ratio: 0.14",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-08<BR>ratio: 0.22",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-09<BR>ratio: 0.05",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2020-02<BR>ratio: 0.0"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.03,
           0.03,
           0.46,
           0.07,
           0.43,
           0.35,
           0.05,
           0.03,
           0,
           0,
           0.36,
           0.33,
           0.19,
           0.01,
           0.14,
           0.22,
           0.05,
           0
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09",
          "2020-02"
         ],
         "y": [
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Visual Question Answering"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00491: Question answering"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"c33f3fe7-62de-4296-95f5-a7cd0044fe8f\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c33f3fe7-62de-4296-95f5-a7cd0044fe8f\")) {                    Plotly.newPlot(                        \"c33f3fe7-62de-4296-95f5-a7cd0044fe8f\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Visual Question Answering\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Visual Question Answering\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-03<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-05<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-06<BR>ratio: 0.46\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-11<BR>ratio: 0.07\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-12<BR>ratio: 0.43\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-04<BR>ratio: 0.35\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-05<BR>ratio: 0.05\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-08<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-03<BR>ratio: 0.0\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-05<BR>ratio: 0.0\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-02<BR>ratio: 0.36\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-04<BR>ratio: 0.33\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-05<BR>ratio: 0.19\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-06<BR>ratio: 0.01\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-07<BR>ratio: 0.14\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-08<BR>ratio: 0.22\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-09<BR>ratio: 0.05\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2020-02<BR>ratio: 0.0\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.03, 0.03, 0.46, 0.07, 0.43, 0.35, 0.05, 0.03, 0.0, 0.0, 0.36, 0.33, 0.19, 0.01, 0.14, 0.22, 0.05, 0.0], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\", \"2020-02\"], \"y\": [\"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Visual Question Answering\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00491: Question answering\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c33f3fe7-62de-4296-95f5-a7cd0044fe8f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00528\n",
      "Number of metrics:  24\n",
      "####### Hits\\\\-at\\\\-10\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB15k - Link Prediction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB122 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB15k (filtered) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  WN18 (filtered) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  YAGO3-10 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  AKSW-bib - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  YAGO39K - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  DBbook2014 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  MovieLens 1M - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  MovieLens 25M - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  LiveJournal - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-10 ,  NELL-995 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  36\n",
      "####### Hits\\\\-at\\\\-5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-5 ,  FB122 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Hits\\\\-at\\\\-5 ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-5 ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### HITS@3\n",
      "Creating ratio df for  HITS@3 ,  FB122 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Hits\\\\-at\\\\-1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  AKSW-bib - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  YAGO39K - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  YAGO3-10 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-1 ,  NELL-995 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  29\n",
      "####### MRR\n",
      "Creating ratio df for  MRR ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  MRR ,  FB122 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MRR ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MRR ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  MRR ,  FB15k - Knowledge graph process benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  MRR ,  YAGO3-10 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  YAGO39K - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  LiveJournal - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  NELL-995 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  ICEWS14 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  YAGO15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MRR ,  ICEWS05-15 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  34\n",
      "####### MR\n",
      "Creating ratio df for  MR ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  MR ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  MR ,  FB15k (filtered) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MR ,  WN18 (filtered) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  MR ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MR ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MR ,  LiveJournal - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MR ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### Number\\\\ of\\\\ params\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-ppa - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-collab - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-ddi - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-biokg - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-wikikg2 - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  ogbl-citation2 - Link Property Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  6\n",
      "####### Hits\\\\-at\\\\-3\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  WN18RR - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  YAGO37 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  AKSW-bib - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  YAGO39K - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  YAGO3-10 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Hits\\\\-at\\\\-3 ,  FB15k-237 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  31\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  Cora - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  Pubmed - Link Prediction benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Citeseer - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  WordNet - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Accuracy ,  Citeseer (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Cora (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  Pubmed (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Accuracy ,  PPI - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### Mean\\\\ AP\n",
      "Creating ratio df for  Mean\\\\ AP ,  NELL-995 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### AUC\n",
      "Creating ratio df for  AUC ,  Cora - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  Citeseer - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AUC ,  Pubmed - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Cora (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Citeseer (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Pubmed (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Wiki - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Gnutella - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Cit-HepPH - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Wiki-Vote - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Douban - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  IMDb - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Yelp - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  DBLP - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AUC ,  MIT - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  ACM - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AUC ,  Citeseer (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Pubmed (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Cora (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AUC ,  Last.FM - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  20\n",
      "####### AP\n",
      "Creating ratio df for  AP ,  Cora - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  AP ,  Citeseer - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  AP ,  Pubmed - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  Cora (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  Citeseer (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  Pubmed (biased evaluation) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  ACM - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  DBLP - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  AP ,  Citeseer (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  Pubmed (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  Cora (nonstandard variant) - Link Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  AP ,  Last.FM - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  9\n",
      "####### Mean\\\\ Rank\n",
      "Creating ratio df for  Mean\\\\ Rank ,  DBbook2014 - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Mean\\\\ Rank ,  MovieLens 1M - Knowledge Graph Completion benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### training\\\\ time\\\\ \\\\(s\\\\)\n",
      "Creating ratio df for  training\\\\ time\\\\ \\\\(s\\\\) ,  FB15k-237 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  training\\\\ time\\\\ \\\\(s\\\\) ,  WN18 - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  training\\\\ time\\\\ \\\\(s\\\\) ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### nDCG\\\\-at\\\\-10\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  MovieLens 25M - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  nDCG\\\\-at\\\\-10 ,  Yelp - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### HR\\\\-at\\\\-10\n",
      "Creating ratio df for  HR\\\\-at\\\\-10 ,  Yelp - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MRR\\\\ filtered\n",
      "Creating ratio df for  MRR\\\\ filtered ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MRR\\\\ raw\n",
      "Creating ratio df for  MRR\\\\ raw ,  FB15k - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Macro\\\\ F1\n",
      "Creating ratio df for  Macro\\\\ F1 ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Micro\\\\ F1\n",
      "Creating ratio df for  Micro\\\\ F1 ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Average\\\\ Precision\n",
      "Creating ratio df for  Average\\\\ Precision ,  BioGRID (human) - Gene Interaction Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Average\\\\ Precision ,  BioGRID(yeast) - Gene Interaction Prediction benchmarking , ds_count= 1\n",
      "null\n",
      "####### ROC\\\\ AUC\n",
      "Creating ratio df for  ROC\\\\ AUC ,  Alibaba - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROC\\\\ AUC ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROC\\\\ AUC ,  Twitter - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROC\\\\ AUC ,  Alibaba-S - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ROC\\\\ AUC ,  Amazon - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### PR\\\\ AUC\n",
      "Creating ratio df for  PR\\\\ AUC ,  Alibaba - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PR\\\\ AUC ,  Twitter - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PR\\\\ AUC ,  Alibaba-S - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PR\\\\ AUC ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  PR\\\\ AUC ,  Amazon - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n",
      "####### F1\\\\-Score\n",
      "Creating ratio df for  F1\\\\-Score ,  Alibaba - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  Twitter - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  Alibaba-S - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  YouTube - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  F1\\\\-Score ,  Amazon - Link Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Link Prediction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Link Prediction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-07",
          "2015-10",
          "2016-06",
          "2017-02",
          "2017-05",
          "2017-07",
          "2017-12",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-10",
          "2018-12",
          "2019-01",
          "2019-02",
          "2019-04",
          "2019-06",
          "2019-11",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Link Prediction<BR>task: Link Prediction<BR>date: 2015-07<BR>ratio: 0.33",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2015-10<BR>ratio: 0.28",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2016-06<BR>ratio: 0.09",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-02<BR>ratio: 0.32",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-05<BR>ratio: 0.2",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-07<BR>ratio: 0.35",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-12<BR>ratio: 0.09",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-04<BR>ratio: 0.02",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-06<BR>ratio: 0.05",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-08<BR>ratio: 0.02",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-10<BR>ratio: 0.01",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-12<BR>ratio: 0.16",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-01<BR>ratio: 0.48",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-02<BR>ratio: 0.03",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-04<BR>ratio: 0.02",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-06<BR>ratio: 0.45",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-11<BR>ratio: 0.1",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-12<BR>ratio: 0.33"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.33,
           0.28,
           0.09,
           0.32,
           0.2,
           0.35,
           0.09,
           0.02,
           0.05,
           0.02,
           0.01,
           0.16,
           0.48,
           0.03,
           0.02,
           0.45,
           0.1,
           0.33
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2015-07",
          "2015-10",
          "2016-06",
          "2017-02",
          "2017-05",
          "2017-07",
          "2017-12",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-10",
          "2018-12",
          "2019-01",
          "2019-02",
          "2019-04",
          "2019-06",
          "2019-11",
          "2019-12"
         ],
         "y": [
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Link Prediction"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00528: Knowledge base process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"b675f588-0108-44f3-95cf-cba817629afe\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b675f588-0108-44f3-95cf-cba817629afe\")) {                    Plotly.newPlot(                        \"b675f588-0108-44f3-95cf-cba817629afe\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Link Prediction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Link Prediction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-07\", \"2015-10\", \"2016-06\", \"2017-02\", \"2017-05\", \"2017-07\", \"2017-12\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-10\", \"2018-12\", \"2019-01\", \"2019-02\", \"2019-04\", \"2019-06\", \"2019-11\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Link Prediction<BR>task: Link Prediction<BR>date: 2015-07<BR>ratio: 0.33\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2015-10<BR>ratio: 0.28\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2016-06<BR>ratio: 0.09\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-02<BR>ratio: 0.32\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-05<BR>ratio: 0.2\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-07<BR>ratio: 0.35\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-12<BR>ratio: 0.09\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-04<BR>ratio: 0.02\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-06<BR>ratio: 0.05\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-08<BR>ratio: 0.02\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-10<BR>ratio: 0.01\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-12<BR>ratio: 0.16\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-01<BR>ratio: 0.48\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-02<BR>ratio: 0.03\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-04<BR>ratio: 0.02\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-06<BR>ratio: 0.45\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-11<BR>ratio: 0.1\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-12<BR>ratio: 0.33\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.33, 0.28, 0.09, 0.32, 0.2, 0.35, 0.09, 0.02, 0.05, 0.02, 0.01, 0.16, 0.48, 0.03, 0.02, 0.45, 0.1, 0.33], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2015-07\", \"2015-10\", \"2016-06\", \"2017-02\", \"2017-05\", \"2017-07\", \"2017-12\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-10\", \"2018-12\", \"2019-01\", \"2019-02\", \"2019-04\", \"2019-06\", \"2019-11\", \"2019-12\"], \"y\": [\"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Link Prediction\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00528: Knowledge base process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b675f588-0108-44f3-95cf-cba817629afe');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00600\n",
      "Number of metrics:  10\n",
      "####### 5\\\\ fold\\\\ cross\\\\ validation\n",
      "Creating ratio df for  5\\\\ fold\\\\ cross\\\\ validation ,  Cornell Grasp Dataset - Robotic Grasping benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sota per dataset/metric:  4\n",
      "####### spl\n",
      "Creating ratio df for  spl ,  R2R - Visual Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  spl ,  VLN Challenge - Vision and Language Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  spl ,  Gibson PointGoal Navigation - PointGoal Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  spl ,  Cooperative Vision-and-Dialogue Navigation - Visual Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  spl ,  Help, Anna! (HANNA) - Visual Navigation benchmarking , ds_count= 1\n",
      "null\n",
      "number of sota per dataset/metric:  8\n",
      "####### Medium\\\\ Human\\\\-Normalized\\\\ Score\n",
      "Creating ratio df for  Medium\\\\ Human\\\\-Normalized\\\\ Score ,  Dmlab-30 - Visual Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### length\n",
      "Creating ratio df for  length ,  VLN Challenge - Vision and Language Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### error\n",
      "Creating ratio df for  error ,  VLN Challenge - Vision and Language Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### success\n",
      "Creating ratio df for  success ,  VLN Challenge - Vision and Language Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### oracle\\\\ success\n",
      "Creating ratio df for  oracle\\\\ success ,  VLN Challenge - Vision and Language Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Error\\\\ rate\n",
      "Creating ratio df for  Error\\\\ rate ,  ContactDB - Grasp Contact Prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### dist_to_end_reduction\n",
      "Creating ratio df for  dist_to_end_reduction ,  Cooperative Vision-and-Dialogue Navigation - Visual Navigation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### NI\n",
      "Creating ratio df for  NI ,  mtrl-auto-uav - Autonomous Flight (Dense Forest) benchmarking , ds_count= 1\n",
      "null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Robotic Grasping",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Robotic Grasping",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-12",
          "2016-11",
          "2018-10"
         ],
         "xaxis": "x",
         "y": [
          "Robotic Grasping",
          "Robotic Grasping",
          "Robotic Grasping"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Visual Navigation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Visual Navigation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-11",
          "2018-11",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Visual Navigation",
          "Visual Navigation",
          "Visual Navigation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2014-12<BR>ratio: 0.29",
          "Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2016-11<BR>ratio: 0.01",
          "Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2018-10<BR>ratio: 0.07",
          "Visual Navigation<BR>task: Visual Navigation<BR>date: 2017-11<BR>ratio: 0.35",
          "Visual Navigation<BR>task: Visual Navigation<BR>date: 2018-11<BR>ratio: 0.39",
          "Visual Navigation<BR>task: Visual Navigation<BR>date: 2020-02<BR>ratio: 0.2"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.29,
           0.01,
           0.07,
           0.35,
           0.39,
           0.2
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2014-12",
          "2016-11",
          "2018-10",
          "2017-11",
          "2018-11",
          "2020-02"
         ],
         "y": [
          "Robotic Grasping",
          "Robotic Grasping",
          "Robotic Grasping",
          "Visual Navigation",
          "Visual Navigation",
          "Visual Navigation"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Visual Navigation",
          "Robotic Grasping"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00600: Robotics process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"bf2e4006-2a1f-4efe-bdf9-e2a56e52154b\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bf2e4006-2a1f-4efe-bdf9-e2a56e52154b\")) {                    Plotly.newPlot(                        \"bf2e4006-2a1f-4efe-bdf9-e2a56e52154b\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Robotic Grasping\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Robotic Grasping\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-12\", \"2016-11\", \"2018-10\"], \"xaxis\": \"x\", \"y\": [\"Robotic Grasping\", \"Robotic Grasping\", \"Robotic Grasping\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Visual Navigation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Visual Navigation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-11\", \"2018-11\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Visual Navigation\", \"Visual Navigation\", \"Visual Navigation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2014-12<BR>ratio: 0.29\", \"Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2016-11<BR>ratio: 0.01\", \"Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2018-10<BR>ratio: 0.07\", \"Visual Navigation<BR>task: Visual Navigation<BR>date: 2017-11<BR>ratio: 0.35\", \"Visual Navigation<BR>task: Visual Navigation<BR>date: 2018-11<BR>ratio: 0.39\", \"Visual Navigation<BR>task: Visual Navigation<BR>date: 2020-02<BR>ratio: 0.2\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.29, 0.01, 0.07, 0.35, 0.39, 0.2], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2014-12\", \"2016-11\", \"2018-10\", \"2017-11\", \"2018-11\", \"2020-02\"], \"y\": [\"Robotic Grasping\", \"Robotic Grasping\", \"Robotic Grasping\", \"Visual Navigation\", \"Visual Navigation\", \"Visual Navigation\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Visual Navigation\", \"Robotic Grasping\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00600: Robotics process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('bf2e4006-2a1f-4efe-bdf9-e2a56e52154b');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00873\n",
      "Number of metrics:  10\n",
      "####### Score\n",
      "Creating ratio df for  Score ,  Atari 2600 Space Invaders - Playing Atari Games benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Score ,  Atari 2600 Atlantis - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Score ,  Atari 2600 Tennis - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Score ,  Atari 2600 Robotank - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Score ,  Atari 2600 Asterix - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Score ,  Atari 2600 Zaxxon - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Score ,  Atari 2600 Freeway - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Score ,  Atari 2600 Kung-Fu Master - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Score ,  Atari 2600 Tutankham - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Score ,  Atari 2600 Up and Down - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Score ,  Atari 2600 Ice Hockey - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Score ,  Atari 2600 Elevator Action - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Score ,  Atari 2600 Double Dunk - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Atari 2600 Seaquest - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  Score ,  Atari 2600 River Raid - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Score ,  Atari 2600 James Bond - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  Score ,  Atari 2600 Demon Attack - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Score ,  Atari 2600 Star Gunner - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  Score ,  Atari 2600 Kangaroo - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Score ,  Atari 2600 Beam Rider - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Score ,  Atari 2600 Q_Bert - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Score ,  Atari 2600 Pooyan - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Atari 2600 Assault - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Score ,  Atari 2600 Boxing - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Score ,  Atari 2600 Road Runner - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  Score ,  Atari 2600 Pong - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Atari 2600 Wizard of Wor - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Score ,  Atari 2600 Video Pinball - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Score ,  Atari 2600 Berzerk - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Score ,  Atari 2600 Bank Heist - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Score ,  Atari 2600 HERO - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 12\n",
      "Creating ratio df for  Score ,  Atari 2600 Centipede - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Score ,  Atari 2600 Gravitar - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Score ,  Atari 2600 Bowling - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Score ,  Atari 2600 Enduro - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Score ,  Atari 2600 Gopher - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Score ,  Atari 2600 Frostbite - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Score ,  Atari 2600 Amidar - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Score ,  Atari 2600 Asteroids - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Score ,  Atari 2600 Montezuma\\'s Revenge - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Score ,  Atari 2600 Crazy Climber - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 11\n",
      "Creating ratio df for  Score ,  Atari 2600 Chopper Command - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Score ,  Atari 2600 Krull - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 10\n",
      "Creating ratio df for  Score ,  Atari 2600 Ms. Pacman - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Score ,  Atari 2600 Journey Escape - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Atari 2600 Carnival - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Atari 2600 Time Pilot - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Score ,  Atari 2600 Fishing Derby - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Score ,  Atari 2600 Battle Zone - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Score ,  Atari 2600 Breakout - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 9\n",
      "Creating ratio df for  Score ,  Atari 2600 Alien - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 6\n",
      "Creating ratio df for  Score ,  Atari 2600 Venture - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Score ,  Atari 2600 Private Eye - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "Creating ratio df for  Score ,  Atari 2600 Name This Game - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 8\n",
      "Creating ratio df for  Score ,  Atari 2600 Defender - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Score ,  Atari 2600 Phoenix - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Score ,  Atari 2600 Skiing - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Score ,  Atari 2600 Yars Revenge - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Score ,  Atari 2600 Surround - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Score ,  Atari 2600 Solaris - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "Creating ratio df for  Score ,  Acrobot (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Mountain Car (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Simple Humanoid - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  2D Walker - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Cart-Pole Balancing (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Full Humanoid - Continuous Control benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Acrobot (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Mountain Car - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Score ,  Inverted Pendulum (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Acrobot - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n",
      "Creating ratio df for  Score ,  Inverted Pendulum (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Inverted Pendulum - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Mountain Car (system identifications) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Acrobot (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Hopper - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Ant + Gathering - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Mountain Car (limited sensors) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Swimmer - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Inverted Pendulum (noisy observations) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Half-Cheetah - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Ant - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  Double Inverted Pendulum - Continuous Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Score ,  F-Zero - Playing SNES Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Score ,  Mortal Kombat - Playing SNES Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Score ,  Gradius III - Playing SNES Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Score ,  Super Mario - Playing SNES Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Score ,  Wolfenstein - Playing SNES Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "Creating ratio df for  Score ,  Cart Pole (OpenAI Gym) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Lunar Lander (OpenAI Gym) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Score ,  Atari 2600 Pitfall! - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  398\n",
      "####### Medium\\\\ Human\\\\-Normalized\\\\ Score\n",
      "Creating ratio df for  Medium\\\\ Human\\\\-Normalized\\\\ Score ,  Atari-57 - Playing Atari Games benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 7\n",
      "number of sota per dataset/metric:  7\n",
      "####### Average\\\\ Score\n",
      "Creating ratio df for  Average\\\\ Score ,  ViZDoom Basic Scenario - Playing Game of Doom benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Max\\\\ Score\n",
      "Creating ratio df for  Max\\\\ Score ,  MoveToBeacon - Playing Starcraft II benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Max\\\\ Score ,  CollectMineralShards - Playing Starcraft II benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Average\\\\ Return\\\\ \\\\(NoOp\\\\)\n",
      "Creating ratio df for  Average\\\\ Return\\\\ \\\\(NoOp\\\\) ,  Atari 2600 Montezuma\\'s Revenge - Playing Montezuma\\'s Revenge benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### ELO\\\\ Rating\n",
      "Creating ratio df for  ELO\\\\ Rating ,  ELO Ratings - Playing Game of Shogi benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  ELO\\\\ Rating ,  ELO Ratings - Playing Game of Go benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### MAE\n",
      "Creating ratio df for  MAE ,  Comma.ai - Steering Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAE ,  Udacity - Steering Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  BDD100K - Steering Control benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Accuracy ,  Sudoko 9x9 - Playing Game of Suduko benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### Return\n",
      "Creating ratio df for  Return ,  DeepMind Cup Catch (Images) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Return ,  DeepMind Walker Walk (Images) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "Creating ratio df for  Return ,  DeepMind Cheetah Run (Images) - Continuous Control benchmarking , ds_count= 1\n",
      "null\n",
      "####### final\\\\ agent\\\\ reward\n",
      "Creating ratio df for  final\\\\ agent\\\\ reward ,  ParticleEnvs Cooperative Communication - Multi-Agent Reinforcement Learning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Playing Atari Games",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Playing Atari Games",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2012-07",
          "2013-12",
          "2015-07",
          "2015-09",
          "2015-11",
          "2015-12",
          "2016-02",
          "2016-06",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-06",
          "2017-07",
          "2017-10",
          "2018-02",
          "2018-03",
          "2018-06",
          "2018-10",
          "2019-05",
          "2019-11",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2012-07<BR>ratio: 0.11",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2013-12<BR>ratio: 0.11",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-07<BR>ratio: 0.04",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-09<BR>ratio: 0.09",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-11<BR>ratio: 0.03",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-12<BR>ratio: 0.08",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-02<BR>ratio: 0.08",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-06<BR>ratio: 0.18",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-11<BR>ratio: 0.0",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-03<BR>ratio: 0.04",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-04<BR>ratio: 0.08",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-06<BR>ratio: 0.17",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-07<BR>ratio: 0.14",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-10<BR>ratio: 0.14",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-02<BR>ratio: 0.1",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-03<BR>ratio: 0.11",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-06<BR>ratio: 0.21",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-10<BR>ratio: 0.18",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2019-05<BR>ratio: 0.39",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2019-11<BR>ratio: 0.25",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2020-03<BR>ratio: 0.29"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.11,
           0.11,
           0.04,
           0.09,
           0.03,
           0.08,
           0.08,
           0.18,
           0,
           0.04,
           0.08,
           0.17,
           0.14,
           0.14,
           0.1,
           0.11,
           0.21,
           0.18,
           0.39,
           0.25,
           0.29
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2012-07",
          "2013-12",
          "2015-07",
          "2015-09",
          "2015-11",
          "2015-12",
          "2016-02",
          "2016-06",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-06",
          "2017-07",
          "2017-10",
          "2018-02",
          "2018-03",
          "2018-06",
          "2018-10",
          "2019-05",
          "2019-11",
          "2020-03"
         ],
         "y": [
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Playing Atari Games"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00873: Playing Games"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"1b25e93e-d003-4569-87b7-21cd4bc31a8d\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1b25e93e-d003-4569-87b7-21cd4bc31a8d\")) {                    Plotly.newPlot(                        \"1b25e93e-d003-4569-87b7-21cd4bc31a8d\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Playing Atari Games\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Playing Atari Games\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2012-07\", \"2013-12\", \"2015-07\", \"2015-09\", \"2015-11\", \"2015-12\", \"2016-02\", \"2016-06\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-06\", \"2017-07\", \"2017-10\", \"2018-02\", \"2018-03\", \"2018-06\", \"2018-10\", \"2019-05\", \"2019-11\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2012-07<BR>ratio: 0.11\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2013-12<BR>ratio: 0.11\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-07<BR>ratio: 0.04\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-09<BR>ratio: 0.09\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-11<BR>ratio: 0.03\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-12<BR>ratio: 0.08\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-02<BR>ratio: 0.08\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-06<BR>ratio: 0.18\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-11<BR>ratio: 0.0\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-03<BR>ratio: 0.04\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-04<BR>ratio: 0.08\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-06<BR>ratio: 0.17\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-07<BR>ratio: 0.14\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-10<BR>ratio: 0.14\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-02<BR>ratio: 0.1\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-03<BR>ratio: 0.11\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-06<BR>ratio: 0.21\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-10<BR>ratio: 0.18\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2019-05<BR>ratio: 0.39\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2019-11<BR>ratio: 0.25\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2020-03<BR>ratio: 0.29\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.11, 0.11, 0.04, 0.09, 0.03, 0.08, 0.08, 0.18, 0.0, 0.04, 0.08, 0.17, 0.14, 0.14, 0.1, 0.11, 0.21, 0.18, 0.39, 0.25, 0.29], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2012-07\", \"2013-12\", \"2015-07\", \"2015-09\", \"2015-11\", \"2015-12\", \"2016-02\", \"2016-06\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-06\", \"2017-07\", \"2017-10\", \"2018-02\", \"2018-03\", \"2018-06\", \"2018-10\", \"2019-05\", \"2019-11\", \"2020-03\"], \"y\": [\"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Playing Atari Games\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00873: Playing Games\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1b25e93e-d003-4569-87b7-21cd4bc31a8d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_01532\n",
      "Number of metrics:  11\n",
      "####### APS\n",
      "Creating ratio df for  APS ,  MusicNet - Music Transcription benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Number\\\\ of\\\\ params\n",
      "Creating ratio df for  Number\\\\ of\\\\ params ,  MusicNet - Music Transcription benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### NLL\n",
      "Creating ratio df for  NLL ,  Nottingham - Music Modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  NLL ,  JSB Chorales - Music Modeling benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  3\n",
      "####### SDR\\\\ \\\\(avg\\\\)\n",
      "Creating ratio df for  SDR\\\\ \\\\(avg\\\\) ,  MUSDB18 - Music Source Separation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### SDR\\\\ \\\\(vocals\\\\)\n",
      "Creating ratio df for  SDR\\\\ \\\\(vocals\\\\) ,  MUSDB18 - Music Source Separation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### SDR\\\\ \\\\(drums\\\\)\n",
      "Creating ratio df for  SDR\\\\ \\\\(drums\\\\) ,  MUSDB18 - Music Source Separation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### SDR\\\\ \\\\(bass\\\\)\n",
      "Creating ratio df for  SDR\\\\ \\\\(bass\\\\) ,  MUSDB18 - Music Source Separation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "number of sota per dataset/metric:  4\n",
      "####### SDR\\\\ \\\\(other\\\\)\n",
      "Creating ratio df for  SDR\\\\ \\\\(other\\\\) ,  MUSDB18 - Music Source Separation benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 5\n",
      "number of sota per dataset/metric:  5\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  chords - Music Genre Recognition benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MAP\n",
      "Creating ratio df for  MAP ,  Covers80 - Cover song identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MAP ,  YouTube350 - Cover song identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  3\n",
      "####### mAP\n",
      "Creating ratio df for  mAP ,  SHS100K-TEST - Cover song identification benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Music Source Separation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Music Source Separation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-06",
          "2018-09",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Music Source Separation",
          "Music Source Separation",
          "Music Source Separation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Music Source Separation<BR>task: Music Source Separation<BR>date: 2018-06<BR>ratio: 0.47",
          "Music Source Separation<BR>task: Music Source Separation<BR>date: 2018-09<BR>ratio: 0.25",
          "Music Source Separation<BR>task: Music Source Separation<BR>date: 2019-09<BR>ratio: 0.06"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.47,
           0.25,
           0.06
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2018-06",
          "2018-09",
          "2019-09"
         ],
         "y": [
          "Music Source Separation",
          "Music Source Separation",
          "Music Source Separation"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Music Source Separation"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_01532: Art-related process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"523b0291-a32d-4e2d-b779-476400e2e060\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"523b0291-a32d-4e2d-b779-476400e2e060\")) {                    Plotly.newPlot(                        \"523b0291-a32d-4e2d-b779-476400e2e060\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Music Source Separation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Music Source Separation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-06\", \"2018-09\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Music Source Separation\", \"Music Source Separation\", \"Music Source Separation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Music Source Separation<BR>task: Music Source Separation<BR>date: 2018-06<BR>ratio: 0.47\", \"Music Source Separation<BR>task: Music Source Separation<BR>date: 2018-09<BR>ratio: 0.25\", \"Music Source Separation<BR>task: Music Source Separation<BR>date: 2019-09<BR>ratio: 0.06\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.47, 0.25, 0.06], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2018-06\", \"2018-09\", \"2019-09\"], \"y\": [\"Music Source Separation\", \"Music Source Separation\", \"Music Source Separation\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Music Source Separation\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_01532: Art-related process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('523b0291-a32d-4e2d-b779-476400e2e060');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00506x\n",
      "Number of metrics:  13\n",
      "####### Average\\\\ Cross\\\\-Ent\n",
      "Creating ratio df for  Average\\\\ Cross\\\\-Ent ,  Event2Mind dev - Common Sense Reasoning benchmarking , ds_count= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-452431eeacbb>:85: UserWarning:\n",
      "\n",
      "Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  Average\\\\ Cross\\\\-Ent ,  Event2Mind test - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  3\n",
      "####### Score\n",
      "Creating ratio df for  Score ,  Winograd Schema Challenge - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### Test\n",
      "Creating ratio df for  Test ,  SWAG - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 3\n",
      "number of sota per dataset/metric:  3\n",
      "####### Dev\n",
      "Creating ratio df for  Dev ,  SWAG - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "number of sota per dataset/metric:  2\n",
      "####### 1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Visual Dialog v0.9 - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  1\\\\ in\\\\ 10\\\\ R\\\\-at\\\\-5 ,  Visual Dialog  v0.9 - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n",
      "####### EM\n",
      "Creating ratio df for  EM ,  ReCoRD - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### F1\n",
      "Creating ratio df for  F1 ,  ReCoRD - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\n",
      "Creating ratio df for  Accuracy ,  CommonsenseQA - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 4\n",
      "Creating ratio df for  Accuracy ,  NLVR2 Dev - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 2\n",
      "Creating ratio df for  Accuracy ,  NLVR2 Test - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  7\n",
      "####### Accuracy\\\\ \\\\(Dev\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Dev\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Test\\\\-P\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\-P\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Accuracy\\\\ \\\\(Test\\\\-U\\\\)\n",
      "Creating ratio df for  Accuracy\\\\ \\\\(Test\\\\-U\\\\) ,  NLVR - Visual Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### Recall\\\\-at\\\\-10\n",
      "Creating ratio df for  Recall\\\\-at\\\\-10 ,  Visual Dialog  v0.9 - Common Sense Reasoning benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  1\n",
      "####### MRR\n",
      "Creating ratio df for  MRR ,  Py150 - Type prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "Creating ratio df for  MRR ,  Py150 - Value prediction benchmarking , ds_count= 1\n",
      "###SOTA RESULTS: 1\n",
      "number of sota per dataset/metric:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-0f184ecb192c>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Common Sense Reasoning",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Common Sense Reasoning",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-02",
          "2019-06",
          "2019-07"
         ],
         "xaxis": "x",
         "y": [
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-02<BR>ratio: 0.1",
          "Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-06<BR>ratio: 0.12",
          "Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-07<BR>ratio: 0.07"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.1,
           0.12,
           0.07
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2019-02",
          "2019-06",
          "2019-07"
         ],
         "y": [
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Common Sense Reasoning"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00506x: Reasoning"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"da3390e6-b4e1-4658-bdba-2e06bfa5fad1\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"da3390e6-b4e1-4658-bdba-2e06bfa5fad1\")) {                    Plotly.newPlot(                        \"da3390e6-b4e1-4658-bdba-2e06bfa5fad1\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Common Sense Reasoning\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Common Sense Reasoning\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-02\", \"2019-06\", \"2019-07\"], \"xaxis\": \"x\", \"y\": [\"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-02<BR>ratio: 0.1\", \"Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-06<BR>ratio: 0.12\", \"Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-07<BR>ratio: 0.07\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.1, 0.12, 0.07], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2019-02\", \"2019-06\", \"2019-07\"], \"y\": [\"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Common Sense Reasoning\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00506x: Reasoning\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('da3390e6-b4e1-4658-bdba-2e06bfa5fad1');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This block executes three steps:\n",
    "#1) Retrieves the metrics list for one selected ito (normally a top class);\n",
    "#2) Calculates the ratio dataframe for each metric to plot the trajectory (saves it as csv);\n",
    "#3) Plots the trajectory pot for the ITO.\n",
    "i=0\n",
    "while i < len(top_level[\"top_level_class\"]):\n",
    "    print(top_level[\"top_level_class\"][i])\n",
    "    selected_ito = top_level[\"top_level_class\"][i].replace(\"https://identifiers.org/\",\"\")\n",
    "    class_label = top_level[\"class_label\"][i]\n",
    "    \n",
    "    \n",
    "    #Retrieve metrics used for ito\n",
    "    metricName_df = get_metrics_df(selected_ito)     \n",
    "    #remove here metrics with problems\n",
    "    metricName_df = metricName_df[metricName_df!=\"Accuracy (pose)\"]\n",
    "    metricName_df = metricName_df[metricName_df!=\"F1 (Sequence)\"]\n",
    "    \n",
    "    #claculate ratio dataframe and save as csv\n",
    "    get_ratio_df_all_per_global = get_ratio_df_per_ito(metricName_df)\n",
    "    csv_file_name=\"get_ratio_df_all_per_global_\"+selected_ito+\".csv\"\n",
    "    csv_file_name=csv_file_name.replace(\"ito:\", \"\")\n",
    "    get_ratio_df_all_per_global.to_csv(csv_file_name)\n",
    "    \n",
    "    #plot trajectory\n",
    "    ito = selected_ito.replace(\"ito:\",\"\")\n",
    "    plot_task_trajectory(ito, class_label)\n",
    "    \n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00310\n",
      "https://identifiers.org/ito:ITO_00485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d0693b6c8945>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n",
      "<ipython-input-42-d0693b6c8945>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Code Generation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Code Generation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08",
          "2018-03",
          "2018-04",
          "2018-10",
          "2019-10"
         ],
         "xaxis": "x",
         "y": [
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Code Generation<BR>task: Code Generation<BR>date: 2017-08<BR>ratio: 0.31",
          "Code Generation<BR>task: Code Generation<BR>date: 2018-03<BR>ratio: 0.14",
          "Code Generation<BR>task: Code Generation<BR>date: 2018-04<BR>ratio: 0.08",
          "Code Generation<BR>task: Code Generation<BR>date: 2018-10<BR>ratio: 0.11",
          "Code Generation<BR>task: Code Generation<BR>date: 2019-10<BR>ratio: 0.12"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.31,
           0.14,
           0.08,
           0.11,
           0.12
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2017-08",
          "2018-03",
          "2018-04",
          "2018-10",
          "2019-10"
         ],
         "y": [
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation",
          "Code Generation"
         ]
        },
        {
         "hovertemplate": [
          "Code Generation<BR>category: Code Generation<BR>date: 2016-03<BR>ratio: 0.85",
          "SQL-to-Text<BR>category: SQL-to-Text<BR>date: 2015-11<BR>ratio: 0.91"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": "white",
          "line": {
           "color": "black",
           "width": 1
          },
          "size": 10
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2016-03",
          "2015-11"
         ],
         "y": [
          "Code Generation",
          "SQL-to-Text"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Code Generation"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00485: Computer code process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"2e765230-5de3-4652-8526-5606a518c87f\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2e765230-5de3-4652-8526-5606a518c87f\")) {                    Plotly.newPlot(                        \"2e765230-5de3-4652-8526-5606a518c87f\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Code Generation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Code Generation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-08\", \"2018-03\", \"2018-04\", \"2018-10\", \"2019-10\"], \"xaxis\": \"x\", \"y\": [\"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Code Generation<BR>task: Code Generation<BR>date: 2017-08<BR>ratio: 0.31\", \"Code Generation<BR>task: Code Generation<BR>date: 2018-03<BR>ratio: 0.14\", \"Code Generation<BR>task: Code Generation<BR>date: 2018-04<BR>ratio: 0.08\", \"Code Generation<BR>task: Code Generation<BR>date: 2018-10<BR>ratio: 0.11\", \"Code Generation<BR>task: Code Generation<BR>date: 2019-10<BR>ratio: 0.12\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.31, 0.14, 0.08, 0.11, 0.12], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2017-08\", \"2018-03\", \"2018-04\", \"2018-10\", \"2019-10\"], \"y\": [\"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\", \"Code Generation\"]}, {\"hovertemplate\": [\"Code Generation<BR>category: Code Generation<BR>date: 2016-03<BR>ratio: 0.85\", \"SQL-to-Text<BR>category: SQL-to-Text<BR>date: 2015-11<BR>ratio: 0.91\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": \"white\", \"line\": {\"color\": \"black\", \"width\": 1}, \"size\": 10}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2016-03\", \"2015-11\"], \"y\": [\"Code Generation\", \"SQL-to-Text\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Code Generation\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00485: Computer code process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2e765230-5de3-4652-8526-5606a518c87f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d0693b6c8945>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Visual Question Answering",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Visual Question Answering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-03<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-05<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-06<BR>ratio: 0.46",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-11<BR>ratio: 0.07",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-12<BR>ratio: 0.43",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-04<BR>ratio: 0.35",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-05<BR>ratio: 0.05",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-08<BR>ratio: 0.03",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-03<BR>ratio: 0.0",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-05<BR>ratio: 0.0",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-02<BR>ratio: 0.36",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-04<BR>ratio: 0.33",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-05<BR>ratio: 0.19",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-06<BR>ratio: 0.01",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-07<BR>ratio: 0.14",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-08<BR>ratio: 0.22",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-09<BR>ratio: 0.05",
          "Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2020-02<BR>ratio: 0.0"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.03,
           0.03,
           0.46,
           0.07,
           0.43,
           0.35,
           0.05,
           0.03,
           0,
           0,
           0.36,
           0.33,
           0.19,
           0.01,
           0.14,
           0.22,
           0.05,
           0
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2016-03",
          "2016-05",
          "2016-06",
          "2016-11",
          "2016-12",
          "2017-04",
          "2017-05",
          "2017-08",
          "2018-03",
          "2018-05",
          "2019-02",
          "2019-04",
          "2019-05",
          "2019-06",
          "2019-07",
          "2019-08",
          "2019-09",
          "2020-02"
         ],
         "y": [
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering"
         ]
        },
        {
         "hovertemplate": [
          "Video Question Answering<BR>category: Video Question Answering<BR>date: 2020-02<BR>ratio: 1.0",
          "Visual Question Answering<BR>category: Visual Question Answering<BR>date: 2015-11<BR>ratio: 0.91",
          "Visual Question Answering<BR>category: Visual Question Answering<BR>date: 2017-07<BR>ratio: 0.77",
          "Visual Question Answering<BR>category: Visual Question Answering<BR>date: 2018-08<BR>ratio: 0.55"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": "white",
          "line": {
           "color": "black",
           "width": 1
          },
          "size": 10
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2020-02",
          "2015-11",
          "2017-07",
          "2018-08"
         ],
         "y": [
          "Video Question Answering",
          "Visual Question Answering",
          "Visual Question Answering",
          "Visual Question Answering"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Visual Question Answering"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00491: Question answering"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"974a0ea4-544c-4cca-baa8-65ee801634a0\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"974a0ea4-544c-4cca-baa8-65ee801634a0\")) {                    Plotly.newPlot(                        \"974a0ea4-544c-4cca-baa8-65ee801634a0\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Visual Question Answering\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Visual Question Answering\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-03<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-05<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-06<BR>ratio: 0.46\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-11<BR>ratio: 0.07\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2016-12<BR>ratio: 0.43\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-04<BR>ratio: 0.35\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-05<BR>ratio: 0.05\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2017-08<BR>ratio: 0.03\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-03<BR>ratio: 0.0\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2018-05<BR>ratio: 0.0\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-02<BR>ratio: 0.36\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-04<BR>ratio: 0.33\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-05<BR>ratio: 0.19\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-06<BR>ratio: 0.01\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-07<BR>ratio: 0.14\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-08<BR>ratio: 0.22\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2019-09<BR>ratio: 0.05\", \"Visual Question Answering<BR>task: Visual Question Answering<BR>date: 2020-02<BR>ratio: 0.0\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.03, 0.03, 0.46, 0.07, 0.43, 0.35, 0.05, 0.03, 0.0, 0.0, 0.36, 0.33, 0.19, 0.01, 0.14, 0.22, 0.05, 0.0], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2016-03\", \"2016-05\", \"2016-06\", \"2016-11\", \"2016-12\", \"2017-04\", \"2017-05\", \"2017-08\", \"2018-03\", \"2018-05\", \"2019-02\", \"2019-04\", \"2019-05\", \"2019-06\", \"2019-07\", \"2019-08\", \"2019-09\", \"2020-02\"], \"y\": [\"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\"]}, {\"hovertemplate\": [\"Video Question Answering<BR>category: Video Question Answering<BR>date: 2020-02<BR>ratio: 1.0\", \"Visual Question Answering<BR>category: Visual Question Answering<BR>date: 2015-11<BR>ratio: 0.91\", \"Visual Question Answering<BR>category: Visual Question Answering<BR>date: 2017-07<BR>ratio: 0.77\", \"Visual Question Answering<BR>category: Visual Question Answering<BR>date: 2018-08<BR>ratio: 0.55\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": \"white\", \"line\": {\"color\": \"black\", \"width\": 1}, \"size\": 10}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2020-02\", \"2015-11\", \"2017-07\", \"2018-08\"], \"y\": [\"Video Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\", \"Visual Question Answering\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Visual Question Answering\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00491: Question answering\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('974a0ea4-544c-4cca-baa8-65ee801634a0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d0693b6c8945>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Link Prediction",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Link Prediction",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2015-07",
          "2015-10",
          "2016-06",
          "2017-02",
          "2017-05",
          "2017-07",
          "2017-12",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-10",
          "2018-12",
          "2019-01",
          "2019-02",
          "2019-04",
          "2019-06",
          "2019-11",
          "2019-12"
         ],
         "xaxis": "x",
         "y": [
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Link Prediction<BR>task: Link Prediction<BR>date: 2015-07<BR>ratio: 0.33",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2015-10<BR>ratio: 0.28",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2016-06<BR>ratio: 0.09",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-02<BR>ratio: 0.32",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-05<BR>ratio: 0.2",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-07<BR>ratio: 0.35",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2017-12<BR>ratio: 0.09",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-04<BR>ratio: 0.02",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-06<BR>ratio: 0.05",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-08<BR>ratio: 0.02",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-10<BR>ratio: 0.01",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2018-12<BR>ratio: 0.16",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-01<BR>ratio: 0.48",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-02<BR>ratio: 0.03",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-04<BR>ratio: 0.02",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-06<BR>ratio: 0.45",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-11<BR>ratio: 0.1",
          "Link Prediction<BR>task: Link Prediction<BR>date: 2019-12<BR>ratio: 0.33"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.33,
           0.28,
           0.09,
           0.32,
           0.2,
           0.35,
           0.09,
           0.02,
           0.05,
           0.02,
           0.01,
           0.16,
           0.48,
           0.03,
           0.02,
           0.45,
           0.1,
           0.33
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2015-07",
          "2015-10",
          "2016-06",
          "2017-02",
          "2017-05",
          "2017-07",
          "2017-12",
          "2018-04",
          "2018-06",
          "2018-08",
          "2018-10",
          "2018-12",
          "2019-01",
          "2019-02",
          "2019-04",
          "2019-06",
          "2019-11",
          "2019-12"
         ],
         "y": [
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction"
         ]
        },
        {
         "hovertemplate": [
          "Knowledge Graph Completion<BR>category: Knowledge Graph Completion<BR>date: 2019-02<BR>ratio: 1.0",
          "Knowledge Graph Completion<BR>category: Knowledge Graph Completion<BR>date: 2019-06<BR>ratio: 1.0",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2013-12<BR>ratio: 0.67",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2014-12<BR>ratio: 0.67",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2016-11<BR>ratio: 0.98",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2017-11<BR>ratio: 0.62",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2018-02<BR>ratio: 0.84",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2018-03<BR>ratio: 1.0",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2018-11<BR>ratio: 0.58",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2019-03<BR>ratio: 1.0",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2019-05<BR>ratio: 0.94",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2019-08<BR>ratio: 1.0",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2020-02<BR>ratio: 1.0",
          "Link Prediction<BR>category: Link Prediction<BR>date: 2020-04<BR>ratio: 0.51"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": "white",
          "line": {
           "color": "black",
           "width": 1
          },
          "size": 10
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2019-02",
          "2019-06",
          "2013-12",
          "2014-12",
          "2016-11",
          "2017-11",
          "2018-02",
          "2018-03",
          "2018-11",
          "2019-03",
          "2019-05",
          "2019-08",
          "2020-02",
          "2020-04"
         ],
         "y": [
          "Knowledge Graph Completion",
          "Knowledge Graph Completion",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction",
          "Link Prediction"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Link Prediction"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00528: Knowledge base process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"dd16d6e1-ca86-4bf7-b99d-c0af0f62d83a\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dd16d6e1-ca86-4bf7-b99d-c0af0f62d83a\")) {                    Plotly.newPlot(                        \"dd16d6e1-ca86-4bf7-b99d-c0af0f62d83a\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Link Prediction\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Link Prediction\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2015-07\", \"2015-10\", \"2016-06\", \"2017-02\", \"2017-05\", \"2017-07\", \"2017-12\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-10\", \"2018-12\", \"2019-01\", \"2019-02\", \"2019-04\", \"2019-06\", \"2019-11\", \"2019-12\"], \"xaxis\": \"x\", \"y\": [\"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Link Prediction<BR>task: Link Prediction<BR>date: 2015-07<BR>ratio: 0.33\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2015-10<BR>ratio: 0.28\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2016-06<BR>ratio: 0.09\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-02<BR>ratio: 0.32\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-05<BR>ratio: 0.2\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-07<BR>ratio: 0.35\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2017-12<BR>ratio: 0.09\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-04<BR>ratio: 0.02\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-06<BR>ratio: 0.05\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-08<BR>ratio: 0.02\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-10<BR>ratio: 0.01\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2018-12<BR>ratio: 0.16\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-01<BR>ratio: 0.48\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-02<BR>ratio: 0.03\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-04<BR>ratio: 0.02\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-06<BR>ratio: 0.45\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-11<BR>ratio: 0.1\", \"Link Prediction<BR>task: Link Prediction<BR>date: 2019-12<BR>ratio: 0.33\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.33, 0.28, 0.09, 0.32, 0.2, 0.35, 0.09, 0.02, 0.05, 0.02, 0.01, 0.16, 0.48, 0.03, 0.02, 0.45, 0.1, 0.33], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2015-07\", \"2015-10\", \"2016-06\", \"2017-02\", \"2017-05\", \"2017-07\", \"2017-12\", \"2018-04\", \"2018-06\", \"2018-08\", \"2018-10\", \"2018-12\", \"2019-01\", \"2019-02\", \"2019-04\", \"2019-06\", \"2019-11\", \"2019-12\"], \"y\": [\"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\"]}, {\"hovertemplate\": [\"Knowledge Graph Completion<BR>category: Knowledge Graph Completion<BR>date: 2019-02<BR>ratio: 1.0\", \"Knowledge Graph Completion<BR>category: Knowledge Graph Completion<BR>date: 2019-06<BR>ratio: 1.0\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2013-12<BR>ratio: 0.67\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2014-12<BR>ratio: 0.67\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2016-11<BR>ratio: 0.98\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2017-11<BR>ratio: 0.62\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2018-02<BR>ratio: 0.84\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2018-03<BR>ratio: 1.0\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2018-11<BR>ratio: 0.58\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2019-03<BR>ratio: 1.0\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2019-05<BR>ratio: 0.94\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2019-08<BR>ratio: 1.0\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2020-02<BR>ratio: 1.0\", \"Link Prediction<BR>category: Link Prediction<BR>date: 2020-04<BR>ratio: 0.51\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": \"white\", \"line\": {\"color\": \"black\", \"width\": 1}, \"size\": 10}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2019-02\", \"2019-06\", \"2013-12\", \"2014-12\", \"2016-11\", \"2017-11\", \"2018-02\", \"2018-03\", \"2018-11\", \"2019-03\", \"2019-05\", \"2019-08\", \"2020-02\", \"2020-04\"], \"y\": [\"Knowledge Graph Completion\", \"Knowledge Graph Completion\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\", \"Link Prediction\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Link Prediction\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00528: Knowledge base process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('dd16d6e1-ca86-4bf7-b99d-c0af0f62d83a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d0693b6c8945>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Robotic Grasping",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Robotic Grasping",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-12",
          "2016-11",
          "2018-10"
         ],
         "xaxis": "x",
         "y": [
          "Robotic Grasping",
          "Robotic Grasping",
          "Robotic Grasping"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Visual Navigation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Visual Navigation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-11",
          "2018-11",
          "2020-02"
         ],
         "xaxis": "x",
         "y": [
          "Visual Navigation",
          "Visual Navigation",
          "Visual Navigation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2014-12<BR>ratio: 0.29",
          "Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2016-11<BR>ratio: 0.01",
          "Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2018-10<BR>ratio: 0.07",
          "Visual Navigation<BR>task: Visual Navigation<BR>date: 2017-11<BR>ratio: 0.35",
          "Visual Navigation<BR>task: Visual Navigation<BR>date: 2018-11<BR>ratio: 0.39",
          "Visual Navigation<BR>task: Visual Navigation<BR>date: 2020-02<BR>ratio: 0.2"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.29,
           0.01,
           0.07,
           0.35,
           0.39,
           0.2
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2014-12",
          "2016-11",
          "2018-10",
          "2017-11",
          "2018-11",
          "2020-02"
         ],
         "y": [
          "Robotic Grasping",
          "Robotic Grasping",
          "Robotic Grasping",
          "Visual Navigation",
          "Visual Navigation",
          "Visual Navigation"
         ]
        },
        {
         "hovertemplate": [
          "Robotic Grasping<BR>category: Robotic Grasping<BR>date: 2013-01<BR>ratio: 0.63",
          "Vision and Language Navigation<BR>category: Vision and Language Navigation<BR>date: 2019-03<BR>ratio: 0.57",
          "Visual Navigation<BR>category: Visual Navigation<BR>date: 2019-07<BR>ratio: 1.0"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": "white",
          "line": {
           "color": "black",
           "width": 1
          },
          "size": 10
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2013-01",
          "2019-03",
          "2019-07"
         ],
         "y": [
          "Robotic Grasping",
          "Vision and Language Navigation",
          "Visual Navigation"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Visual Navigation",
          "Robotic Grasping"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00600: Robotics process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"45438300-daef-4e99-bacf-f466f6f2275e\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"45438300-daef-4e99-bacf-f466f6f2275e\")) {                    Plotly.newPlot(                        \"45438300-daef-4e99-bacf-f466f6f2275e\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Robotic Grasping\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Robotic Grasping\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2014-12\", \"2016-11\", \"2018-10\"], \"xaxis\": \"x\", \"y\": [\"Robotic Grasping\", \"Robotic Grasping\", \"Robotic Grasping\"], \"yaxis\": \"y\"}, {\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Visual Navigation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Visual Navigation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2017-11\", \"2018-11\", \"2020-02\"], \"xaxis\": \"x\", \"y\": [\"Visual Navigation\", \"Visual Navigation\", \"Visual Navigation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2014-12<BR>ratio: 0.29\", \"Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2016-11<BR>ratio: 0.01\", \"Robotic Grasping<BR>task: Robotic Grasping<BR>date: 2018-10<BR>ratio: 0.07\", \"Visual Navigation<BR>task: Visual Navigation<BR>date: 2017-11<BR>ratio: 0.35\", \"Visual Navigation<BR>task: Visual Navigation<BR>date: 2018-11<BR>ratio: 0.39\", \"Visual Navigation<BR>task: Visual Navigation<BR>date: 2020-02<BR>ratio: 0.2\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.29, 0.01, 0.07, 0.35, 0.39, 0.2], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2014-12\", \"2016-11\", \"2018-10\", \"2017-11\", \"2018-11\", \"2020-02\"], \"y\": [\"Robotic Grasping\", \"Robotic Grasping\", \"Robotic Grasping\", \"Visual Navigation\", \"Visual Navigation\", \"Visual Navigation\"]}, {\"hovertemplate\": [\"Robotic Grasping<BR>category: Robotic Grasping<BR>date: 2013-01<BR>ratio: 0.63\", \"Vision and Language Navigation<BR>category: Vision and Language Navigation<BR>date: 2019-03<BR>ratio: 0.57\", \"Visual Navigation<BR>category: Visual Navigation<BR>date: 2019-07<BR>ratio: 1.0\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": \"white\", \"line\": {\"color\": \"black\", \"width\": 1}, \"size\": 10}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2013-01\", \"2019-03\", \"2019-07\"], \"y\": [\"Robotic Grasping\", \"Vision and Language Navigation\", \"Visual Navigation\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Visual Navigation\", \"Robotic Grasping\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00600: Robotics process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('45438300-daef-4e99-bacf-f466f6f2275e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d0693b6c8945>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Playing Atari Games",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Playing Atari Games",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2012-07",
          "2013-12",
          "2015-07",
          "2015-09",
          "2015-11",
          "2015-12",
          "2016-02",
          "2016-06",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-06",
          "2017-07",
          "2017-10",
          "2018-02",
          "2018-03",
          "2018-06",
          "2018-10",
          "2019-05",
          "2019-11",
          "2020-03"
         ],
         "xaxis": "x",
         "y": [
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2012-07<BR>ratio: 0.11",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2013-12<BR>ratio: 0.11",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-07<BR>ratio: 0.04",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-09<BR>ratio: 0.09",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-11<BR>ratio: 0.03",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-12<BR>ratio: 0.08",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-02<BR>ratio: 0.08",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-06<BR>ratio: 0.18",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-11<BR>ratio: 0.0",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-03<BR>ratio: 0.04",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-04<BR>ratio: 0.08",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-06<BR>ratio: 0.17",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-07<BR>ratio: 0.14",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-10<BR>ratio: 0.14",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-02<BR>ratio: 0.1",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-03<BR>ratio: 0.11",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-06<BR>ratio: 0.21",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-10<BR>ratio: 0.18",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2019-05<BR>ratio: 0.39",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2019-11<BR>ratio: 0.25",
          "Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2020-03<BR>ratio: 0.29"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.11,
           0.11,
           0.04,
           0.09,
           0.03,
           0.08,
           0.08,
           0.18,
           0,
           0.04,
           0.08,
           0.17,
           0.14,
           0.14,
           0.1,
           0.11,
           0.21,
           0.18,
           0.39,
           0.25,
           0.29
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2012-07",
          "2013-12",
          "2015-07",
          "2015-09",
          "2015-11",
          "2015-12",
          "2016-02",
          "2016-06",
          "2016-11",
          "2017-03",
          "2017-04",
          "2017-06",
          "2017-07",
          "2017-10",
          "2018-02",
          "2018-03",
          "2018-06",
          "2018-10",
          "2019-05",
          "2019-11",
          "2020-03"
         ],
         "y": [
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games",
          "Playing Atari Games"
         ]
        },
        {
         "hovertemplate": [],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": "white",
          "line": {
           "color": "black",
           "width": 1
          },
          "size": 10
         },
         "mode": "markers",
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Playing Atari Games"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00873: Playing Games"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"6ed9bed6-e11c-4bc2-ad2a-5c16da9c8098\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6ed9bed6-e11c-4bc2-ad2a-5c16da9c8098\")) {                    Plotly.newPlot(                        \"6ed9bed6-e11c-4bc2-ad2a-5c16da9c8098\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Playing Atari Games\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Playing Atari Games\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2012-07\", \"2013-12\", \"2015-07\", \"2015-09\", \"2015-11\", \"2015-12\", \"2016-02\", \"2016-06\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-06\", \"2017-07\", \"2017-10\", \"2018-02\", \"2018-03\", \"2018-06\", \"2018-10\", \"2019-05\", \"2019-11\", \"2020-03\"], \"xaxis\": \"x\", \"y\": [\"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2012-07<BR>ratio: 0.11\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2013-12<BR>ratio: 0.11\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-07<BR>ratio: 0.04\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-09<BR>ratio: 0.09\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-11<BR>ratio: 0.03\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2015-12<BR>ratio: 0.08\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-02<BR>ratio: 0.08\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-06<BR>ratio: 0.18\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2016-11<BR>ratio: 0.0\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-03<BR>ratio: 0.04\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-04<BR>ratio: 0.08\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-06<BR>ratio: 0.17\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-07<BR>ratio: 0.14\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2017-10<BR>ratio: 0.14\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-02<BR>ratio: 0.1\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-03<BR>ratio: 0.11\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-06<BR>ratio: 0.21\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2018-10<BR>ratio: 0.18\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2019-05<BR>ratio: 0.39\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2019-11<BR>ratio: 0.25\", \"Playing Atari Games<BR>task: Playing Atari Games<BR>date: 2020-03<BR>ratio: 0.29\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.11, 0.11, 0.04, 0.09, 0.03, 0.08, 0.08, 0.18, 0.0, 0.04, 0.08, 0.17, 0.14, 0.14, 0.1, 0.11, 0.21, 0.18, 0.39, 0.25, 0.29], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2012-07\", \"2013-12\", \"2015-07\", \"2015-09\", \"2015-11\", \"2015-12\", \"2016-02\", \"2016-06\", \"2016-11\", \"2017-03\", \"2017-04\", \"2017-06\", \"2017-07\", \"2017-10\", \"2018-02\", \"2018-03\", \"2018-06\", \"2018-10\", \"2019-05\", \"2019-11\", \"2020-03\"], \"y\": [\"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\", \"Playing Atari Games\"]}, {\"hovertemplate\": [], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": \"white\", \"line\": {\"color\": \"black\", \"width\": 1}, \"size\": 10}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [], \"y\": []}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Playing Atari Games\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00873: Playing Games\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6ed9bed6-e11c-4bc2-ad2a-5c16da9c8098');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_01532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d0693b6c8945>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Music Source Separation",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Music Source Separation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2018-06",
          "2018-09",
          "2019-09"
         ],
         "xaxis": "x",
         "y": [
          "Music Source Separation",
          "Music Source Separation",
          "Music Source Separation"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Music Source Separation<BR>task: Music Source Separation<BR>date: 2018-06<BR>ratio: 0.47",
          "Music Source Separation<BR>task: Music Source Separation<BR>date: 2018-09<BR>ratio: 0.25",
          "Music Source Separation<BR>task: Music Source Separation<BR>date: 2019-09<BR>ratio: 0.06"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.47,
           0.25,
           0.06
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2018-06",
          "2018-09",
          "2019-09"
         ],
         "y": [
          "Music Source Separation",
          "Music Source Separation",
          "Music Source Separation"
         ]
        },
        {
         "hovertemplate": [
          "Cover song identification<BR>category: Cover song identification<BR>date: 2019-10<BR>ratio: 0.97",
          "Music Transcription<BR>category: Music Transcription<BR>date: 2017-05<BR>ratio: 0.67"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": "white",
          "line": {
           "color": "black",
           "width": 1
          },
          "size": 10
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2019-10",
          "2017-05"
         ],
         "y": [
          "Cover song identification",
          "Music Transcription"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Music Source Separation"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_01532: Art-related process"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"4ee876ec-23d8-4184-ae81-f9c94b8e28f9\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4ee876ec-23d8-4184-ae81-f9c94b8e28f9\")) {                    Plotly.newPlot(                        \"4ee876ec-23d8-4184-ae81-f9c94b8e28f9\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Music Source Separation\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Music Source Separation\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2018-06\", \"2018-09\", \"2019-09\"], \"xaxis\": \"x\", \"y\": [\"Music Source Separation\", \"Music Source Separation\", \"Music Source Separation\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Music Source Separation<BR>task: Music Source Separation<BR>date: 2018-06<BR>ratio: 0.47\", \"Music Source Separation<BR>task: Music Source Separation<BR>date: 2018-09<BR>ratio: 0.25\", \"Music Source Separation<BR>task: Music Source Separation<BR>date: 2019-09<BR>ratio: 0.06\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.47, 0.25, 0.06], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2018-06\", \"2018-09\", \"2019-09\"], \"y\": [\"Music Source Separation\", \"Music Source Separation\", \"Music Source Separation\"]}, {\"hovertemplate\": [\"Cover song identification<BR>category: Cover song identification<BR>date: 2019-10<BR>ratio: 0.97\", \"Music Transcription<BR>category: Music Transcription<BR>date: 2017-05<BR>ratio: 0.67\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": \"white\", \"line\": {\"color\": \"black\", \"width\": 1}, \"size\": 10}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2019-10\", \"2017-05\"], \"y\": [\"Cover song identification\", \"Music Transcription\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Music Source Separation\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_01532: Art-related process\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4ee876ec-23d8-4184-ae81-f9c94b8e28f9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://identifiers.org/ito:ITO_00506x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d0693b6c8945>:14: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "task=%{y}<br>date=%{x}<extra></extra>",
         "legendgroup": "Common Sense Reasoning",
         "line": {
          "color": "black",
          "dash": "solid",
          "width": 1
         },
         "marker": {
          "line": {
           "color": "black",
           "width": 1
          }
         },
         "mode": "lines",
         "name": "Common Sense Reasoning",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2019-02",
          "2019-06",
          "2019-07"
         ],
         "xaxis": "x",
         "y": [
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": [
          "Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-02<BR>ratio: 0.1",
          "Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-06<BR>ratio: 0.12",
          "Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-07<BR>ratio: 0.07"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": [
           0.1,
           0.12,
           0.07
          ],
          "colorbar": {
           "lenmode": "pixels",
           "title": {
            "text": "ratio"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(255,255,229)"
           ],
           [
            0.125,
            "rgb(247,252,185)"
           ],
           [
            0.25,
            "rgb(217,240,163)"
           ],
           [
            0.375,
            "rgb(173,221,142)"
           ],
           [
            0.5,
            "rgb(120,198,121)"
           ],
           [
            0.625,
            "rgb(65,171,93)"
           ],
           [
            0.75,
            "rgb(35,132,67)"
           ],
           [
            0.875,
            "rgb(0,104,55)"
           ],
           [
            1,
            "rgb(0,69,41)"
           ]
          ],
          "line": {
           "color": "black",
           "width": 1
          },
          "opacity": 0.7,
          "showscale": true,
          "size": 15,
          "symbol": 48
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2019-02",
          "2019-06",
          "2019-07"
         ],
         "y": [
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning"
         ]
        },
        {
         "hovertemplate": [
          "Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-05<BR>ratio: 0.51",
          "Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-06<BR>ratio: 0.9",
          "Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-08<BR>ratio: 0.67",
          "Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-10<BR>ratio: 0.66",
          "Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-11<BR>ratio: 0.73",
          "Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2019-09<BR>ratio: 0.69",
          "Visual Reasoning<BR>category: Visual Reasoning<BR>date: 2019-08<BR>ratio: 0.8"
         ],
         "line": {
          "color": "black",
          "width": 1
         },
         "marker": {
          "color": "white",
          "line": {
           "color": "black",
           "width": 1
          },
          "size": 10
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          "2018-05",
          "2018-06",
          "2018-08",
          "2018-10",
          "2018-11",
          "2019-09",
          "2019-08"
         ],
         "y": [
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Common Sense Reasoning",
          "Visual Reasoning"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "legend": {
         "title": {
          "text": "task"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed."
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "tickmode": "auto",
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "Common Sense Reasoning"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightBlue",
         "showgrid": true,
         "title": {
          "text": "ITO_00506x: Reasoning"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"f05aa0a0-7755-4e5d-857c-58c65686a36d\" class=\"plotly-graph-div\" style=\"height:2000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f05aa0a0-7755-4e5d-857c-58c65686a36d\")) {                    Plotly.newPlot(                        \"f05aa0a0-7755-4e5d-857c-58c65686a36d\",                        [{\"hovertemplate\": \"task=%{y}<br>date=%{x}<extra></extra>\", \"legendgroup\": \"Common Sense Reasoning\", \"line\": {\"color\": \"black\", \"dash\": \"solid\", \"width\": 1}, \"marker\": {\"line\": {\"color\": \"black\", \"width\": 1}}, \"mode\": \"lines\", \"name\": \"Common Sense Reasoning\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2019-02\", \"2019-06\", \"2019-07\"], \"xaxis\": \"x\", \"y\": [\"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\"], \"yaxis\": \"y\"}, {\"hovertemplate\": [\"Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-02<BR>ratio: 0.1\", \"Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-06<BR>ratio: 0.12\", \"Common Sense Reasoning<BR>task: Common Sense Reasoning<BR>date: 2019-07<BR>ratio: 0.07\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": [0.1, 0.12, 0.07], \"colorbar\": {\"lenmode\": \"pixels\", \"title\": {\"text\": \"ratio\"}}, \"colorscale\": [[0.0, \"rgb(255,255,229)\"], [0.125, \"rgb(247,252,185)\"], [0.25, \"rgb(217,240,163)\"], [0.375, \"rgb(173,221,142)\"], [0.5, \"rgb(120,198,121)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,132,67)\"], [0.875, \"rgb(0,104,55)\"], [1.0, \"rgb(0,69,41)\"]], \"line\": {\"color\": \"black\", \"width\": 1}, \"opacity\": 0.7, \"showscale\": true, \"size\": 15, \"symbol\": 48}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2019-02\", \"2019-06\", \"2019-07\"], \"y\": [\"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\"]}, {\"hovertemplate\": [\"Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-05<BR>ratio: 0.51\", \"Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-06<BR>ratio: 0.9\", \"Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-08<BR>ratio: 0.67\", \"Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-10<BR>ratio: 0.66\", \"Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2018-11<BR>ratio: 0.73\", \"Common Sense Reasoning<BR>category: Common Sense Reasoning<BR>date: 2019-09<BR>ratio: 0.69\", \"Visual Reasoning<BR>category: Visual Reasoning<BR>date: 2019-08<BR>ratio: 0.8\"], \"line\": {\"color\": \"black\", \"width\": 1}, \"marker\": {\"color\": \"white\", \"line\": {\"color\": \"black\", \"width\": 1}, \"size\": 10}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"2018-05\", \"2018-06\", \"2018-08\", \"2018-10\", \"2018-11\", \"2019-09\", \"2019-08\"], \"y\": [\"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Common Sense Reasoning\", \"Visual Reasoning\"]}],                        {\"height\": 2000, \"legend\": {\"title\": {\"text\": \"task\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Trajectory for ratio (task per year).<BR><BR>Anchor points (ratio>0.5) removed, trajectories with single arrow removed.\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"tickmode\": \"auto\", \"title\": {\"text\": \"Year\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryarray\": [\"Common Sense Reasoning\"], \"categoryorder\": \"array\", \"domain\": [0.0, 1.0], \"gridcolor\": \"lightBlue\", \"showgrid\": true, \"title\": {\"text\": \"ITO_00506x: Reasoning\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f05aa0a0-7755-4e5d-857c-58c65686a36d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Just plot the graphs (quicker)\n",
    "i=0\n",
    "while i < len(top_level[\"top_level_class\"]):\n",
    "    print(top_level[\"top_level_class\"][i])\n",
    "    selected_ito = top_level[\"top_level_class\"][i].replace(\"https://identifiers.org/\",\"\")\n",
    "    class_label = top_level[\"class_label\"][i]\n",
    "    \n",
    "    #plot trajectory\n",
    "    ito = selected_ito.replace(\"ito:\",\"\")\n",
    "    plot_task_trajectory(ito, class_label)\n",
    "    \n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important change \n",
    "this percentage has to be calculated out of the function, because it congregates the maximum obtained value across all benchmarks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
