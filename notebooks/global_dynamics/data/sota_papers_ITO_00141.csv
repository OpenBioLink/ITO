dataset_label,paper,paper_label
CMeIE,https://identifiers.org/ito:ITO_51428,CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark
DDI extraction 2013 corpus,https://identifiers.org/ito:ITO_21496,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets
DDI extraction 2013 corpus,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
2010 i2b2/VA,https://identifiers.org/ito:ITO_41517,Improving Clinical Document Understanding on COVID-19 Research with Spark NLP
2010 i2b2/VA,https://identifiers.org/ito:ITO_41526,Machine-learned solutions for three stages of clinical information extraction: the state of the art at i2b2 2010
2010 i2b2/VA,https://identifiers.org/ito:ITO_41520,Enhancing Clinical Concept Extraction with Contextual Embeddings
MIMIC-III,https://identifiers.org/ito:ITO_33364,Predicting Multiple ICD-10 Codes from Brazilian-Portuguese Clinical Notes
AS,https://identifiers.org/ito:ITO_28215,Glyce: Glyph-vectors for Chinese Character Representations
MSRA,https://identifiers.org/ito:ITO_51260,Long Short-Term Memory Neural Networks for Chinese Word Segmentation
PKU,https://identifiers.org/ito:ITO_28215,Glyce: Glyph-vectors for Chinese Character Representations
MSR,https://identifiers.org/ito:ITO_28215,Glyce: Glyph-vectors for Chinese Character Representations
MSR,https://identifiers.org/ito:ITO_09337,ZEN: Pre-training Chinese Text Encoder Enhanced by N-gram Representations
CITYU,https://identifiers.org/ito:ITO_28215,Glyce: Glyph-vectors for Chinese Character Representations
BUCC German-to-English,https://identifiers.org/ito:ITO_15798,Improving Neural Machine Translation Models with Monolingual Data
BUCC German-to-English,https://identifiers.org/ito:ITO_15796,Margin-based Parallel Corpus Mining with Multilingual Sentence Embeddings
BUCC German-to-English,https://identifiers.org/ito:ITO_12828,Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
BUCC Chinese-to-English,https://identifiers.org/ito:ITO_12828,Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
BUCC Russian-to-English,https://identifiers.org/ito:ITO_12828,Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
BUCC French-to-English,https://identifiers.org/ito:ITO_15798,Improving Neural Machine Translation Models with Monolingual Data
BUCC French-to-English,https://identifiers.org/ito:ITO_15796,Margin-based Parallel Corpus Mining with Multilingual Sentence Embeddings
BUCC French-to-English,https://identifiers.org/ito:ITO_12828,Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
MLDoc Zero-Shot English-to-German,https://identifiers.org/ito:ITO_12830,A Corpus for Multilingual Document Classification in Eight Languages
MLDoc Zero-Shot English-to-German,https://identifiers.org/ito:ITO_12828,Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
MLDoc Zero-Shot English-to-German,https://identifiers.org/ito:ITO_12835,Bridging the domain gap in cross-lingual document classification
MLDoc Zero-Shot English-to-Japanese,https://identifiers.org/ito:ITO_12830,A Corpus for Multilingual Document Classification in Eight Languages
MLDoc Zero-Shot English-to-Japanese,https://identifiers.org/ito:ITO_33518,MultiFiT: Efficient Multi-lingual Language Model Fine-tuning
MLDoc Zero-Shot English-to-Spanish,https://identifiers.org/ito:ITO_12830,A Corpus for Multilingual Document Classification in Eight Languages
MLDoc Zero-Shot English-to-Spanish,https://identifiers.org/ito:ITO_12828,Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
MLDoc Zero-Shot English-to-Spanish,https://identifiers.org/ito:ITO_12835,Bridging the domain gap in cross-lingual document classification
Reuters RCV1/RCV2 English-to-German,https://identifiers.org/ito:ITO_12854,Multilingual Distributed Representations without Word Alignment
Reuters RCV1/RCV2 English-to-German,https://identifiers.org/ito:ITO_12852,Multilingual Models for Compositional Distributed Semantics
Reuters RCV1/RCV2 English-to-German,https://identifiers.org/ito:ITO_12850,Leveraging Monolingual Data for Crosslingual Compositional Word Representations
MLDoc Zero-Shot English-to-Russian,https://identifiers.org/ito:ITO_12830,A Corpus for Multilingual Document Classification in Eight Languages
MLDoc Zero-Shot English-to-Russian,https://identifiers.org/ito:ITO_12828,Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
MLDoc Zero-Shot English-to-Russian,https://identifiers.org/ito:ITO_12835,Bridging the domain gap in cross-lingual document classification
MLDoc Zero-Shot English-to-Italian,https://identifiers.org/ito:ITO_12830,A Corpus for Multilingual Document Classification in Eight Languages
MLDoc Zero-Shot English-to-Italian,https://identifiers.org/ito:ITO_12828,Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
MLDoc Zero-Shot English-to-Italian,https://identifiers.org/ito:ITO_33518,MultiFiT: Efficient Multi-lingual Language Model Fine-tuning
MLDoc Zero-Shot English-to-French,https://identifiers.org/ito:ITO_12830,A Corpus for Multilingual Document Classification in Eight Languages
MLDoc Zero-Shot English-to-French,https://identifiers.org/ito:ITO_12828,Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
MLDoc Zero-Shot English-to-French,https://identifiers.org/ito:ITO_12835,Bridging the domain gap in cross-lingual document classification
MLDoc Zero-Shot English-to-Chinese,https://identifiers.org/ito:ITO_12830,A Corpus for Multilingual Document Classification in Eight Languages
MLDoc Zero-Shot English-to-Chinese,https://identifiers.org/ito:ITO_12835,Bridging the domain gap in cross-lingual document classification
MLDoc Zero-Shot German-to-French,https://identifiers.org/ito:ITO_12830,A Corpus for Multilingual Document Classification in Eight Languages
Reuters RCV1/RCV2 German-to-English,https://identifiers.org/ito:ITO_12854,Multilingual Distributed Representations without Word Alignment
Reuters RCV1/RCV2 German-to-English,https://identifiers.org/ito:ITO_12852,Multilingual Models for Compositional Distributed Semantics
Reuters RCV1/RCV2 German-to-English,https://identifiers.org/ito:ITO_12850,Leveraging Monolingual Data for Crosslingual Compositional Word Representations
N15News,https://identifiers.org/ito:ITO_55587,N24News: A New Dataset for Multimodal News Classification
BBC Hindi News Article Classification,https://identifiers.org/ito:ITO_49977,Does Transliteration Help Multilingual Language Modeling?
Soham News Article Classification,https://identifiers.org/ito:ITO_49979,"IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages"
Soham News Article Classification,https://identifiers.org/ito:ITO_49977,Does Transliteration Help Multilingual Language Modeling?
XNLI,https://identifiers.org/ito:ITO_26953,Rethinking embedding coupling in pre-trained language models
XNLI,https://identifiers.org/ito:ITO_49572,ByT5: Towards a token-free future with pre-trained byte-to-byte models
XNLI Zero-Shot English-to-Spanish,https://identifiers.org/ito:ITO_09641,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data
XNLI Zero-Shot English-to-Spanish,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
XNLI Zero-Shot English-to-Spanish,https://identifiers.org/ito:ITO_28641,Better Fine-Tuning by Reducing Representational Collapse
XNLI Zero-Shot English-to-French,https://identifiers.org/ito:ITO_09641,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data
XNLI Zero-Shot English-to-French,https://identifiers.org/ito:ITO_28641,Better Fine-Tuning by Reducing Representational Collapse
XNLI Zero-Shot English-to-German,https://identifiers.org/ito:ITO_09641,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data
XNLI Zero-Shot English-to-German,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
XNLI Zero-Shot English-to-German,https://identifiers.org/ito:ITO_28641,Better Fine-Tuning by Reducing Representational Collapse
NoDaLiDa Norwegian Bokmål,https://identifiers.org/ito:ITO_33490,UniTrans: Unifying Model Transfer and Data Transfer for Cross-Lingual Named Entity Recognition with Unlabeled Data
MSRA,https://identifiers.org/ito:ITO_33493,Enhanced Meta-Learning for Cross-lingual Named Entity Recognition with Minimal Resources
NER,https://identifiers.org/ito:ITO_26953,Rethinking embedding coupling in pre-trained language models
CoNLL German,https://identifiers.org/ito:ITO_33499,Multi-Source Cross-Lingual Model Transfer: Learning What to Share
CoNLL German,https://identifiers.org/ito:ITO_33497,"Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT"
CoNLL German,https://identifiers.org/ito:ITO_33493,Enhanced Meta-Learning for Cross-lingual Named Entity Recognition with Minimal Resources
CoNLL German,https://identifiers.org/ito:ITO_33487,Single-/Multi-Source Cross-Lingual NER via Teacher-Student Learning on Unlabeled Data in Target Language
CoNLL Spanish,https://identifiers.org/ito:ITO_33499,Multi-Source Cross-Lingual Model Transfer: Learning What to Share
CoNLL Spanish,https://identifiers.org/ito:ITO_33497,"Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT"
CoNLL Spanish,https://identifiers.org/ito:ITO_33493,Enhanced Meta-Learning for Cross-lingual Named Entity Recognition with Minimal Resources
CoNLL Spanish,https://identifiers.org/ito:ITO_33487,Single-/Multi-Source Cross-Lingual NER via Teacher-Student Learning on Unlabeled Data in Target Language
CoNLL Spanish,https://identifiers.org/ito:ITO_33490,UniTrans: Unifying Model Transfer and Data Transfer for Cross-Lingual Named Entity Recognition with Unlabeled Data
CoNLL Dutch,https://identifiers.org/ito:ITO_33499,Multi-Source Cross-Lingual Model Transfer: Learning What to Share
CoNLL Dutch,https://identifiers.org/ito:ITO_33497,"Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT"
CoNLL Dutch,https://identifiers.org/ito:ITO_33495,Towards Lingua Franca Named Entity Recognition with BERT
WikiAnn NER,https://identifiers.org/ito:ITO_49572,ByT5: Towards a token-free future with pre-trained byte-to-byte models
Europeana French,https://identifiers.org/ito:ITO_33493,Enhanced Meta-Learning for Cross-lingual Named Entity Recognition with Minimal Resources
XCOPA,https://identifiers.org/ito:ITO_33458,MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer
XCOPA,https://identifiers.org/ito:ITO_33456,XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning
MaRVL,https://identifiers.org/ito:ITO_55554,Visually Grounded Reasoning across Languages and Cultures
XTREME,https://identifiers.org/ito:ITO_33478,English Intermediate-Task Training Improves Zero-Shot Cross-Lingual Transfer Too
XTREME,https://identifiers.org/ito:ITO_33473,InfoXLM: An Information-Theoretic Framework for Cross-Lingual Language Model Pre-Training
XTREME,https://identifiers.org/ito:ITO_55565,ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora
XTREME,https://identifiers.org/ito:ITO_55559,XLM-E: Cross-lingual Language Model Pre-training via ELECTRA
XTREME,https://identifiers.org/ito:ITO_25462,mT5: A massively multilingual pre-trained text-to-text transformer
Linux IRC (Ch2 Kummerfeld),https://identifiers.org/ito:ITO_45413,You Talking to Me? A Corpus and Algorithm for Conversation Disentanglement
Linux IRC (Ch2 Elsner),https://identifiers.org/ito:ITO_45413,You Talking to Me? A Corpus and Algorithm for Conversation Disentanglement
irc-disentanglement,https://identifiers.org/ito:ITO_45413,You Talking to Me? A Corpus and Algorithm for Conversation Disentanglement
irc-disentanglement,https://identifiers.org/ito:ITO_21319,A Large-Scale Corpus for Conversation Disentanglement
irc-disentanglement,https://identifiers.org/ito:ITO_21317,Pre-Trained and Attention-Based Neural Networks for Building Noetic Task-Oriented Dialogue Systems
Switchboard corpus,https://identifiers.org/ito:ITO_04635,Sequential Short-Text Classification with Recurrent and Convolutional Neural Networks
Switchboard corpus,https://identifiers.org/ito:ITO_04629,Dialogue Act Sequence Labeling using Hierarchical encoder with CRF
Switchboard corpus,https://identifiers.org/ito:ITO_04627,Dialogue Act Recognition via CRF-Attentive Structured Network
Switchboard corpus,https://identifiers.org/ito:ITO_21281,A Dual-Attention Hierarchical Recurrent Neural Network for Dialogue Act Classification
Switchboard corpus,https://identifiers.org/ito:ITO_21279,Dialogue Act Classification with Context-Aware Self-Attention
Switchboard corpus,https://identifiers.org/ito:ITO_21277,Guiding attention in Sequence-to-sequence models for Dialogue Act prediction
ICSI Meeting Recorder Dialog Act (MRDA) corpus,https://identifiers.org/ito:ITO_04629,Dialogue Act Sequence Labeling using Hierarchical encoder with CRF
ICSI Meeting Recorder Dialog Act (MRDA) corpus,https://identifiers.org/ito:ITO_04627,Dialogue Act Recognition via CRF-Attentive Structured Network
ICSI Meeting Recorder Dialog Act (MRDA) corpus,https://identifiers.org/ito:ITO_21287,Hierarchical Pre-training for Sequence Labelling in Spoken Dialog
Switchboard dialogue act corpus,https://identifiers.org/ito:ITO_31231,Probabilistic Word Association for Dialogue Act Classification with Recurrent Neural Networks
CPED,https://identifiers.org/ito:ITO_53136,CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI
Amazon-5,https://identifiers.org/ito:ITO_04555,Adversarial Learning for Neural Dialogue Generation
FusedChat,https://identifiers.org/ito:ITO_45254,Fusing task-oriented and open-domain dialogues in conversational agents
WikiText-103,https://identifiers.org/ito:ITO_45258,$\infty$-former: Infinite Memory Transformer
Reddit (multi-ref),https://identifiers.org/ito:ITO_04573,Jointly Optimizing Diversity and Relevance in Neural Response Generation
Twitter Dialogue (Tense),https://identifiers.org/ito:ITO_04550,Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation
Twitter Dialogue (Noun),https://identifiers.org/ito:ITO_04550,Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation
Persona-Chat,https://identifiers.org/ito:ITO_05251,Neural Machine Translation by Jointly Learning to Align and Translate
Persona-Chat,https://identifiers.org/ito:ITO_21078,TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents
Persona-Chat,https://identifiers.org/ito:ITO_04563,You Impress Me: Dialogue Generation via Mutual Persona Perception
Persona-Chat,https://identifiers.org/ito:ITO_21083,Synthesizer: Rethinking Self-Attention in Transformer Models
Ubuntu Dialogue (Tense),https://identifiers.org/ito:ITO_04550,Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation
Ubuntu Dialogue (Entity),https://identifiers.org/ito:ITO_04550,Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation
Ubuntu Dialogue (Activity),https://identifiers.org/ito:ITO_04550,Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation
CMU-DoG,https://identifiers.org/ito:ITO_45258,$\infty$-former: Infinite Memory Transformer
Ubuntu Dialogue (Cmd),https://identifiers.org/ito:ITO_04550,Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation
OpenViDial 2.0,https://identifiers.org/ito:ITO_45278,"OpenViDial 2.0: A Larger-Scale, Open-Domain Dialogue Generation Dataset with Visual Contexts"
Wizard-of-Oz,https://identifiers.org/ito:ITO_04587,Neural Belief Tracker: Data-Driven Dialogue State Tracking
Wizard-of-Oz,https://identifiers.org/ito:ITO_04585,Global-Locally Self-Attentive Dialogue State Tracker
Wizard-of-Oz,https://identifiers.org/ito:ITO_04581,Towards Universal Dialogue State Tracking
Wizard-of-Oz,https://identifiers.org/ito:ITO_21111,A Simple but Effective BERT Model for Dialog State Tracking on Resource-Limited Systems
Wizard-of-Oz,https://identifiers.org/ito:ITO_45286,A Sequence-to-Sequence Approach to Dialogue State Tracking
Wizard-of-Oz,https://identifiers.org/ito:ITO_45284,Amendable Generation for Dialogue State Tracking
Wizard-of-Oz,https://identifiers.org/ito:ITO_21114,Toward Scalable Neural Dialogue State Tracking Model
CoSQL,https://identifiers.org/ito:ITO_45296,PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models
CoSQL,https://identifiers.org/ito:ITO_45294,RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL
Second dialogue state tracking challenge,https://identifiers.org/ito:ITO_04587,Neural Belief Tracker: Data-Driven Dialogue State Tracking
Second dialogue state tracking challenge,https://identifiers.org/ito:ITO_04585,Global-Locally Self-Attentive Dialogue State Tracker
Second dialogue state tracking challenge,https://identifiers.org/ito:ITO_04581,Towards Universal Dialogue State Tracking
Second dialogue state tracking challenge,https://identifiers.org/ito:ITO_45286,A Sequence-to-Sequence Approach to Dialogue State Tracking
YouTube News dataset (Crackling Noise),https://identifiers.org/ito:ITO_21221,Language Identification Using Deep Convolutional Recurrent Neural Networks
VOXLINGUA107,https://identifiers.org/ito:ITO_21228,VOXLINGUA107: A DATASET FOR SPOKEN LANGUAGE RECOGNITION
VoxForge Commonwealth,https://identifiers.org/ito:ITO_21232,Spoken Language Identification using ConvNets
YouTube News dataset (White Noise),https://identifiers.org/ito:ITO_21221,Language Identification Using Deep Convolutional Recurrent Neural Networks
YouTube News dataset (White Noise),https://identifiers.org/ito:ITO_45392,Is Attention always needed? A Case Study on Language Identification from Speech
YouTube News dataset (No Noise),https://identifiers.org/ito:ITO_21221,Language Identification Using Deep Convolutional Recurrent Neural Networks
YouTube News dataset (No Noise),https://identifiers.org/ito:ITO_45392,Is Attention always needed? A Case Study on Language Identification from Speech
VoxForge European,https://identifiers.org/ito:ITO_21232,Spoken Language Identification using ConvNets
LRE07,https://identifiers.org/ito:ITO_21228,VOXLINGUA107: A DATASET FOR SPOKEN LANGUAGE RECOGNITION
KALAKA-3,https://identifiers.org/ito:ITO_21228,VOXLINGUA107: A DATASET FOR SPOKEN LANGUAGE RECOGNITION
Untranscribed mixed-speech dataset,https://identifiers.org/ito:ITO_21269,Automatic Dialect Detection in Arabic Broadcast Speech
YouTube News dataset (Background Music),https://identifiers.org/ito:ITO_21221,Language Identification Using Deep Convolutional Recurrent Neural Networks
IndicTTS,https://identifiers.org/ito:ITO_45392,Is Attention always needed? A Case Study on Language Identification from Speech
Spoken-SQuAD,https://identifiers.org/ito:ITO_45354,Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition Errors on Listening Comprehension
Spoken-SQuAD,https://identifiers.org/ito:ITO_45353,Mitigating the Impact of Speech Recognition Errors on Spoken Question Answering by Adversarial Domain Adaptation
Spoken-SQuAD,https://identifiers.org/ito:ITO_45351,SpeechBERT: An Audio-and-text Jointly Learned Language Model for End-to-end Spoken Question Answering
Snips-SmartLights,https://identifiers.org/ito:ITO_45362,Spoken Language Understanding on the Edge
Snips-SmartLights,https://identifiers.org/ito:ITO_45360,Exploring Transfer Learning For End-to-End Spoken Language Understanding
Snips-SmartLights,https://identifiers.org/ito:ITO_45358,Finstreder: Simple and fast Spoken Language Understanding with Finite State Transducers using modern Speech-to-Text models
Timers and Such,https://identifiers.org/ito:ITO_45369,Timers and Such: A Practical Benchmark for Spoken Language Understanding with Numbers
Timers and Such,https://identifiers.org/ito:ITO_45368,SpeechBrain: A General-Purpose Speech Toolkit
Timers and Such,https://identifiers.org/ito:ITO_45358,Finstreder: Simple and fast Spoken Language Understanding with Finite State Transducers using modern Speech-to-Text models
Snips-SmartSpeaker,https://identifiers.org/ito:ITO_45362,Spoken Language Understanding on the Edge
Snips-SmartSpeaker,https://identifiers.org/ito:ITO_45358,Finstreder: Simple and fast Spoken Language Understanding with Finite State Transducers using modern Speech-to-Text models
Fluent Speech Commands,https://identifiers.org/ito:ITO_21215,Speech Model Pre-training for End-to-End Spoken Language Understanding
Fluent Speech Commands,https://identifiers.org/ito:ITO_45388,Improving End-to-End Speech-to-Intent Classification with Reptile
Fluent Speech Commands,https://identifiers.org/ito:ITO_45377,Two-stage Textual Knowledge Distillation for End-to-End Spoken Language Understanding
EmpatheticDialogues,https://identifiers.org/ito:ITO_45403,Emotion-Aware Transformer Encoder for Empathetic Dialogue Generation
MULTIWOZ 2.1,https://identifiers.org/ito:ITO_45408,A Simple Language Model for Task-Oriented Dialogue
MULTIWOZ 2.1,https://identifiers.org/ito:ITO_21298,A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning
MULTIWOZ 2.1,https://identifiers.org/ito:ITO_45406,GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-Supervised Learning and Explicit Policy Injection
MULTIWOZ 2.0,https://identifiers.org/ito:ITO_21306,Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context
MULTIWOZ 2.0,https://identifiers.org/ito:ITO_45411,Pretraining the Noisy Channel Model for Task-Oriented Dialogue
Kvret,https://identifiers.org/ito:ITO_21211,Incorporating Joint Embeddings into Goal-Oriented Dialogues with Multi-Task Learning
DSTC9 Track 3 - Task 2,https://identifiers.org/ito:ITO_21345,A Unified Pre-training Framework for Conversational AI
BBAI Dataset,https://identifiers.org/ito:ITO_62740,One Agent To Rule Them All: Towards Multi-agent Conversational AI
GIF Reply Dataset,https://identifiers.org/ito:ITO_45420,An animated picture says at least a thousand words: Selecting Gif-based Replies in Multimodal Dialog
USR-TopicalChat,https://identifiers.org/ito:ITO_61719,USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation
USR-TopicalChat,https://identifiers.org/ito:ITO_61715,MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue Evaluation
USR-PersonaChat,https://identifiers.org/ito:ITO_61719,USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation
KILT: Wizard of Wikipedia,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: Wizard of Wikipedia,https://identifiers.org/ito:ITO_49915,"Re2G: Retrieve, Rerank, Generate"
DeliData,https://identifiers.org/ito:ITO_45424,DeliData: A dataset for deliberation in multi-party problem solving
ArgSciChat,https://identifiers.org/ito:ITO_61809,ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers
SSD_NAME,https://identifiers.org/ito:ITO_45315,A Slot Is Not Built in One Utterance: Spoken Language Dialogs with Sub-Slots
automata,https://identifiers.org/ito:ITO_45315,A Slot Is Not Built in One Utterance: Spoken Language Dialogs with Sub-Slots
KVRET,https://identifiers.org/ito:ITO_21096,Key-Value Retrieval Networks for Task-Oriented Dialogue
KVRET,https://identifiers.org/ito:ITO_21094,Sequence-to-Sequence Learning for Task-oriented Dialogue with Dialogue State Representation
KVRET,https://identifiers.org/ito:ITO_21090,Global-to-local Memory Pointer Networks for Task-Oriented Dialogue
KVRET,https://identifiers.org/ito:ITO_21088,Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog
KVRET,https://identifiers.org/ito:ITO_45302,Contextualize Knowledge Bases with Transformer for End-to-end Task-Oriented Dialogue Systems
KVRET,https://identifiers.org/ito:ITO_45300,UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models
SGD,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
Kvret,https://identifiers.org/ito:ITO_21088,Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog
Wizard of Wikipedia,https://identifiers.org/ito:ITO_21118,Multi-Modal Open-Domain Dialogue
BlendedSkillTalk,https://identifiers.org/ito:ITO_21118,Multi-Modal Open-Domain Dialogue
ConvAI2,https://identifiers.org/ito:ITO_21118,Multi-Modal Open-Domain Dialogue
VisDial v1.0 test-std,https://identifiers.org/ito:ITO_45323,Ensemble of MRR and NDCG models for Visual Dialog
Visual Dialog v1.0 test-std,https://identifiers.org/ito:ITO_21153,Visual dialog
Visual Dialog v1.0 test-std,https://identifiers.org/ito:ITO_08715,Learning to Reason: End-to-End Module Networks for Visual Question Answering
Visual Dialog v1.0 test-std,https://identifiers.org/ito:ITO_04608,Visual Coreference Resolution in Visual Dialog using Neural Module Networks
Visual Dialog v1.0 test-std,https://identifiers.org/ito:ITO_21149,Recursive Visual Attention in Visual Dialog
Visual Dialog v1.0 test-std,https://identifiers.org/ito:ITO_04614,Making History Matter: History-Advantage Sequence Training for Visual Dialog
Visual Dialog v1.0 test-std,https://identifiers.org/ito:ITO_04603,Factor Graph Attention
Visual Dialog v1.0 test-std,https://identifiers.org/ito:ITO_45323,Ensemble of MRR and NDCG models for Visual Dialog
Visual Dialog v1.0 test-std,https://identifiers.org/ito:ITO_21166,Efficient Attention Mechanism for Visual Dialog that can Handle All the Interactions between Multiple Inputs
Visual Dialog v1.0 test-std,https://identifiers.org/ito:ITO_21200,Image-Question-Answer Synergistic Network for Visual Dialog
EmpatheticDialogues,https://identifiers.org/ito:ITO_21118,Multi-Modal Open-Domain Dialogue
VisDial v0.9 val,https://identifiers.org/ito:ITO_08759,Hierarchical Question-Image Co-Attention for Visual Question Answering
VisDial v0.9 val,https://identifiers.org/ito:ITO_21142,Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model
VisDial v0.9 val,https://identifiers.org/ito:ITO_04621,Are You Talking to Me? Reasoned Visual Dialog Generation through Adversarial Learning
VisDial v0.9 val,https://identifiers.org/ito:ITO_04608,Visual Coreference Resolution in Visual Dialog using Neural Module Networks
VisDial v0.9 val,https://identifiers.org/ito:ITO_04606,Dual Attention Networks for Visual Reference Resolution in Visual Dialog
VisDial v0.9 val,https://identifiers.org/ito:ITO_04603,Factor Graph Attention
VisDial v0.9 val,https://identifiers.org/ito:ITO_21153,Visual dialog
VisDial v0.9 val,https://identifiers.org/ito:ITO_21149,Recursive Visual Attention in Visual Dialog
VisDial v0.9 val,https://identifiers.org/ito:ITO_04623,Visual Reference Resolution using Attention Memory for Visual Dialog
VisDial v0.9 val,https://identifiers.org/ito:ITO_04614,Making History Matter: History-Advantage Sequence Training for Visual Dialog
Image-Chat,https://identifiers.org/ito:ITO_21118,Multi-Modal Open-Domain Dialogue
MIRACL-VC1,https://identifiers.org/ito:ITO_41581,AuthNet: A Deep Learning based Authentication Mechanism using Temporal Facial Feature Movements
Lip Reading in the Wild,https://identifiers.org/ito:ITO_35016,Combining Residual Networks with LSTMs for Lipreading
Lip Reading in the Wild,https://identifiers.org/ito:ITO_35012,End-to-end Audiovisual Speech Recognition
Lip Reading in the Wild,https://identifiers.org/ito:ITO_34991,Lipreading using Temporal Convolutional Networks
Lip Reading in the Wild,https://identifiers.org/ito:ITO_35003,Towards Practical Lipreading with Distilled and Efficient Models
GRID corpus (mixed-speech),https://identifiers.org/ito:ITO_35030,Lip Reading Sentences in the Wild
GRID corpus (mixed-speech),https://identifiers.org/ito:ITO_35028,LCANet: End-to-End Lipreading with Cascaded Attention-CTC
GRID corpus (mixed-speech),https://identifiers.org/ito:ITO_20979,Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis
LRS3-TED,https://identifiers.org/ito:ITO_56553,Large-Scale Visual Speech Recognition
LRS3-TED,https://identifiers.org/ito:ITO_54901,Recurrent Neural Network Transducer for Audio-Visual Speech Recognition
LRS3-TED,https://identifiers.org/ito:ITO_56548,Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction
CAS-VSR-W1k (LRW-1000),https://identifiers.org/ito:ITO_34997,LRW-1000: A Naturally-Distributed Large-Scale Benchmark for Lip Reading in the Wild
CAS-VSR-W1k (LRW-1000),https://identifiers.org/ito:ITO_34991,Lipreading using Temporal Convolutional Networks
CAS-VSR-W1k (LRW-1000),https://identifiers.org/ito:ITO_34987,Can We Read Speech Beyond the Lips? Rethinking RoI Selection for Deep Visual Speech Recognition
CAS-VSR-W1k (LRW-1000),https://identifiers.org/ito:ITO_34984,Learn an Effective Lip Reading Model without Pains
LRS2,https://identifiers.org/ito:ITO_35037,Deep Audio-Visual Speech Recognition
LRS2,https://identifiers.org/ito:ITO_35035,End-to-end Audio-visual Speech Recognition with Conformers
LRS2,https://identifiers.org/ito:ITO_45075,Sub-word Level Lip Reading With Visual Attention
CMLR,https://identifiers.org/ito:ITO_35023,A Cascade Sequence-to-Sequence Model for Chinese Mandarin Lip Reading
LRW,https://identifiers.org/ito:ITO_20979,Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis
TCD-TIMIT corpus (mixed-speech),https://identifiers.org/ito:ITO_20979,Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis
EPHOIE,https://identifiers.org/ito:ITO_55863,LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking
MusicBrainz20K,https://identifiers.org/ito:ITO_55917,Scalable Matching and Clustering of Entities with FAMER
MusicBrainz20K,https://identifiers.org/ito:ITO_55915,Graph-boosted Active Learning for Multi-Source Entity Resolution
Abt-Buy,https://identifiers.org/ito:ITO_55933,Deep Learning for Entity Matching: A Design Space Exploration
Abt-Buy,https://identifiers.org/ito:ITO_55926,Deep Entity Matching with Pre-Trained Language Models
Abt-Buy,https://identifiers.org/ito:ITO_55922,Supervised Contrastive Learning for Product Matching
WDC Watches-xlarge,https://identifiers.org/ito:ITO_55926,Deep Entity Matching with Pre-Trained Language Models
WDC Watches-xlarge,https://identifiers.org/ito:ITO_55929,Dual-Objective Fine-Tuning of BERT for Entity Matching
WDC Computers-xlarge,https://identifiers.org/ito:ITO_55926,Deep Entity Matching with Pre-Trained Language Models
WDC Computers-xlarge,https://identifiers.org/ito:ITO_55938,Intermediate Training of BERT for Product Matching
WDC Computers-xlarge,https://identifiers.org/ito:ITO_55929,Dual-Objective Fine-Tuning of BERT for Entity Matching
WDC Computers-xlarge,https://identifiers.org/ito:ITO_55922,Supervised Contrastive Learning for Product Matching
Amazon-Google,https://identifiers.org/ito:ITO_55933,Deep Learning for Entity Matching: A Design Space Exploration
Amazon-Google,https://identifiers.org/ito:ITO_55926,Deep Entity Matching with Pre-Trained Language Models
Amazon-Google,https://identifiers.org/ito:ITO_55927,Profiling Entity Matching Benchmark Tasks
Amazon-Google,https://identifiers.org/ito:ITO_55922,Supervised Contrastive Learning for Product Matching
WDC Watches-small,https://identifiers.org/ito:ITO_55926,Deep Entity Matching with Pre-Trained Language Models
WDC Watches-small,https://identifiers.org/ito:ITO_55924,Entity Resolution with Hierarchical Graph Attention Networks
WDC Computers-small,https://identifiers.org/ito:ITO_55926,Deep Entity Matching with Pre-Trained Language Models
WDC Computers-small,https://identifiers.org/ito:ITO_55938,Intermediate Training of BERT for Product Matching
DDI extraction 2013 corpus,https://identifiers.org/ito:ITO_29385,Enhancing Drug-Drug Interaction Extraction from Texts by Molecular Structure Information
DDI extraction 2013 corpus,https://identifiers.org/ito:ITO_29381,Using Drug Descriptions and Molecular Structures for Drug-Drug Interaction Extraction from Literature
DDI extraction 2013 corpus,https://identifiers.org/ito:ITO_29383,Drug–drug interaction extraction via hierarchical RNNs on sequence and shortest dependency paths
SciERC,https://identifiers.org/ito:ITO_10127,"Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction"
SciERC,https://identifiers.org/ito:ITO_04710,A General Framework for Information Extraction using Dynamic Span Graphs
SciERC,https://identifiers.org/ito:ITO_21393,Span-based Joint Entity and Relation Extraction with Transformer Pre-training
SciERC,https://identifiers.org/ito:ITO_45485,Joint Entity and Relation Extraction from Scientific Documents: Role of Linguistic Information and Entity Types
SciERC,https://identifiers.org/ito:ITO_45578,Packed Levitated Marker for Entity and Relation Extraction
SciERC,https://identifiers.org/ito:ITO_21541,A Frustratingly Easy Approach for Entity and Relation Extraction
SciERC,https://identifiers.org/ito:ITO_45500,A Partition Filter Network for Joint Entity and Relation Extraction
ACE 2005,https://identifiers.org/ito:ITO_21541,A Frustratingly Easy Approach for Entity and Relation Extraction
DocRED,https://identifiers.org/ito:ITO_45627,An End-to-end Model for Entity-level Relation Extraction using Multi-instance Learning
DocRED,https://identifiers.org/ito:ITO_45487,REBEL: Relation Extraction By End-to-end Language generation
SemEval 2022 Task 12: Symlink - Linking Mathematical Symbols to their Descriptions,https://identifiers.org/ito:ITO_45690,AIFB-WebScience at SemEval-2022 Task 12: Relation Extraction First -- Using Relation Extraction to Identify Entities
MUC-4,https://identifiers.org/ito:ITO_45707,Document-level Entity-based Extraction as Template Generation
KPTimes,https://identifiers.org/ito:ITO_41789,UCPhrase: Unsupervised Context-aware Quality Phrase Tagging
KP20k,https://identifiers.org/ito:ITO_41789,UCPhrase: Unsupervised Context-aware Quality Phrase Tagging
SemEval2017,https://identifiers.org/ito:ITO_60399,FRAKE: Fusional Real-time Automatic Keyword Extraction
SemEval2017,https://identifiers.org/ito:ITO_39657,Phraseformer: Multimodal Key-phrase Extraction using Transformer and Graph Embedding
Inspec,https://identifiers.org/ito:ITO_60399,FRAKE: Fusional Real-time Automatic Keyword Extraction
Inspec,https://identifiers.org/ito:ITO_39657,Phraseformer: Multimodal Key-phrase Extraction using Transformer and Graph Embedding
SemEval 2010 Task 8,https://identifiers.org/ito:ITO_60399,FRAKE: Fusional Real-time Automatic Keyword Extraction
SemEval 2010 Task 8,https://identifiers.org/ito:ITO_39657,Phraseformer: Multimodal Key-phrase Extraction using Transformer and Graph Embedding
OpenSubtitles,https://identifiers.org/ito:ITO_31590,A reproduction of Apple's bi-directional LSTM models for language identification in short strings
nordic_langid,https://identifiers.org/ito:ITO_54142,Discriminating Between Similar Nordic Languages
Universal Dependencies,https://identifiers.org/ito:ITO_31590,A reproduction of Apple's bi-directional LSTM models for language identification in short strings
italki NLI,https://identifiers.org/ito:ITO_54145,Fewer features perform well at Native Language Identification task
CONLL 2003 Dutch,https://identifiers.org/ito:ITO_10146,Zero-Resource Cross-Lingual Named Entity Recognition
CONLL 2003 German,https://identifiers.org/ito:ITO_10146,Zero-Resource Cross-Lingual Named Entity Recognition
Conll 2003 Spanish,https://identifiers.org/ito:ITO_10146,Zero-Resource Cross-Lingual Named Entity Recognition
OntoNotes 4,https://identifiers.org/ito:ITO_12034,Chinese NER Using Lattice LSTM
OntoNotes 4,https://identifiers.org/ito:ITO_28215,Glyce: Glyph-vectors for Chinese Character Representations
OntoNotes 4,https://identifiers.org/ito:ITO_31778,A Unified MRC Framework for Named Entity Recognition
OntoNotes 4,https://identifiers.org/ito:ITO_26144,Dice Loss for Data-imbalanced NLP Tasks
SighanNER,https://identifiers.org/ito:ITO_54410,Adversarial Transfer Learning for Chinese Named Entity Recognition with Self-Attention Mechanism
MSRA Dev,https://identifiers.org/ito:ITO_09510,ERNIE: Enhanced Representation through Knowledge Integration
MSRA Dev,https://identifiers.org/ito:ITO_08532,ERNIE 2.0: A Continual Pre-training Framework for Language Understanding
Resume NER,https://identifiers.org/ito:ITO_12034,Chinese NER Using Lattice LSTM
Resume NER,https://identifiers.org/ito:ITO_28215,Glyce: Glyph-vectors for Chinese Character Representations
Resume NER,https://identifiers.org/ito:ITO_31894,FGN: Fusion Glyph Network for Chinese Named Entity Recognition
Weibo NER,https://identifiers.org/ito:ITO_12034,Chinese NER Using Lattice LSTM
Weibo NER,https://identifiers.org/ito:ITO_28215,Glyce: Glyph-vectors for Chinese Character Representations
Weibo NER,https://identifiers.org/ito:ITO_31894,FGN: Fusion Glyph Network for Chinese Named Entity Recognition
Weibo NER,https://identifiers.org/ito:ITO_31905,CAN-NER: Convolutional Attention Network for Chinese Named Entity Recognition
OntoNotes 5.0,https://identifiers.org/ito:ITO_11917,Dependency-Guided LSTM-CRF for Named Entity Recognition
MSRA,https://identifiers.org/ito:ITO_12034,Chinese NER Using Lattice LSTM
MSRA,https://identifiers.org/ito:ITO_28215,Glyce: Glyph-vectors for Chinese Character Representations
MSRA,https://identifiers.org/ito:ITO_31778,A Unified MRC Framework for Named Entity Recognition
MSRA,https://identifiers.org/ito:ITO_26144,Dice Loss for Data-imbalanced NLP Tasks
CoNLL04,https://identifiers.org/ito:ITO_31935,Zero-Resource Cross-Domain Named Entity Recognition
Few-NERD (INTRA),https://identifiers.org/ito:ITO_54421,CONTaiNER: Few-Shot Named Entity Recognition via Contrastive Learning
Few-NERD (INTER),https://identifiers.org/ito:ITO_54421,CONTaiNER: Few-Shot Named Entity Recognition via Contrastive Learning
XGLUE,https://identifiers.org/ito:ITO_45125,mGPT: Few-Shot Learners Go Multilingual
ShARe/CLEF eHealth corpus,https://identifiers.org/ito:ITO_31932,Challenges in clinical natural language processing for automated disorder normalization
ShARe/CLEF eHealth corpus,https://identifiers.org/ito:ITO_21496,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets
ShARe/CLEF eHealth corpus,https://identifiers.org/ito:ITO_49558,BioELECTRA:Pretrained Biomedical text Encoder using Discriminators
HiNER-collapsed,https://identifiers.org/ito:ITO_54229,HiNER: A Large Hindi Named Entity Recognition Dataset
WLPC,https://identifiers.org/ito:ITO_04710,A General Framework for Information Extraction using Dynamic Span Graphs
Code-Switching English-Spanish NER,https://identifiers.org/ito:ITO_11902,Hierarchical Meta-Embeddings for Code-Switching Named Entity Recognition
French Treebank,https://identifiers.org/ito:ITO_21017,CamemBERT: a Tasty French Language Model
CoNLL 2003 (German),https://identifiers.org/ito:ITO_12048,Neural Architectures for Nested NER through Linearization
CoNLL 2003 (German),https://identifiers.org/ito:ITO_31686,Named Entity Recognition as Dependency Parsing
CoNLL 2003 (German),https://identifiers.org/ito:ITO_31689,Exploring Cross-sentence Contexts for Named Entity Recognition with BERT
CoNLL 2003 (German),https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
MasakhaNER,https://identifiers.org/ito:ITO_54258,Language Modelling with Pixels
DWIE,https://identifiers.org/ito:ITO_45471,DWIE: an entity-centric dataset for multi-task document-level information extraction
DWIE,https://identifiers.org/ito:ITO_45469,Injecting Knowledge Base Information into End-to-End Joint Entity and Relation Extraction and Coreference Resolution
Few-NERD (SUP),https://identifiers.org/ito:ITO_54268,Few-NERD: A Few-Shot Named Entity Recognition Dataset
Few-NERD (SUP),https://identifiers.org/ito:ITO_45578,Packed Levitated Marker for Entity and Relation Extraction
Few-NERD (SUP),https://identifiers.org/ito:ITO_54266,Parallel Instance Query Network for Named Entity Recognition
CoNLL 2002 (Spanish),https://identifiers.org/ito:ITO_12048,Neural Architectures for Nested NER through Linearization
CoNLL 2002 (Spanish),https://identifiers.org/ito:ITO_31686,Named Entity Recognition as Dependency Parsing
CoNLL 2002 (Spanish),https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
WNUT 2016,https://identifiers.org/ito:ITO_54272,Bidirectional LSTM for Named Entity Recognition in Twitter Messages
WNUT 2016,https://identifiers.org/ito:ITO_31727,Named Entity Recognition for Social Media Texts with Semantic Augmentation
WNUT 2016,https://identifiers.org/ito:ITO_31717,Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning
WNUT 2016,https://identifiers.org/ito:ITO_54271,Hero-Gang Neural Model For Named Entity Recognition
CMeEE,https://identifiers.org/ito:ITO_51428,CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark
LeNER-Br,https://identifiers.org/ito:ITO_31746,LeNER-Br: a Dataset for Named Entity Recognition in Brazilian Legal Text
BC5CDR-disease,https://identifiers.org/ito:ITO_21496,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets
BC5CDR-disease,https://identifiers.org/ito:ITO_21493,BioMegatron: Larger Biomedical Domain Language Model
WNUT 2020,https://identifiers.org/ito:ITO_21531,WNUT-2020 Task 1 Overview: Extracting Entities and Relations from Wet Lab Protocols
WNUT 2020,https://identifiers.org/ito:ITO_54277,mgsohrab at WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols
SciERC,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
SciERC,https://identifiers.org/ito:ITO_04773,SciBERT: A Pretrained Language Model for Scientific Text
ACE 2004,https://identifiers.org/ito:ITO_11962,Neural Segmental Hypergraphs for Overlapping Mention Recognition
ACE 2004,https://identifiers.org/ito:ITO_11975,Multi-Grained Named Entity Recognition
ACE 2004,https://identifiers.org/ito:ITO_12048,Neural Architectures for Nested NER through Linearization
ACE 2004,https://identifiers.org/ito:ITO_31839,Nested Named Entity Recognition via Second-best Sequence Learning and Decoding
ACE 2004,https://identifiers.org/ito:ITO_31686,Named Entity Recognition as Dependency Parsing
ACE 2004,https://identifiers.org/ito:ITO_21541,A Frustratingly Easy Approach for Entity and Relation Extraction
GENIA,https://identifiers.org/ito:ITO_54285,A Neural Layered Model for Nested Named Entity Recognition
GENIA,https://identifiers.org/ito:ITO_11964,Sequence-to-Nuggets: Nested Entity Mention Detection via Anchor-Region Networks
GENIA,https://identifiers.org/ito:ITO_12048,Neural Architectures for Nested NER through Linearization
GENIA,https://identifiers.org/ito:ITO_31686,Named Entity Recognition as Dependency Parsing
i2b2 De-identification Dataset,https://identifiers.org/ito:ITO_54290,MASK: A flexible framework to facilitate de-identification of clinical texts
DaNE,https://identifiers.org/ito:ITO_37159,007: Democratically Finding The Cause of Packet Drops
DaNE,https://identifiers.org/ito:ITO_45129,DaCy: A Unified Framework for Danish NLP
SoSciSoCi,https://identifiers.org/ito:ITO_54297,Investigating Software Usage in the Social Sciences: A Knowledge Graph Approach
BC5CDR-chemical,https://identifiers.org/ito:ITO_31863,An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition
BC5CDR-chemical,https://identifiers.org/ito:ITO_21496,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets
BC5CDR-chemical,https://identifiers.org/ito:ITO_31707,Biomedical Named Entity Recognition at Scale
BC5CDR,https://identifiers.org/ito:ITO_11950,CollaboNet: collaboration of deep neural networks for biomedical named entity recognition
BC5CDR,https://identifiers.org/ito:ITO_04773,SciBERT: A Pretrained Language Model for Scientific Text
BC5CDR,https://identifiers.org/ito:ITO_11952,BioFLAIR: Pretrained Pooled Contextualized Embeddings for Biomedical Sequence Labeling Tasks
BC5CDR,https://identifiers.org/ito:ITO_31707,Biomedical Named Entity Recognition at Scale
BC5CDR,https://identifiers.org/ito:ITO_21499,ELECTRAMed: a new pre-trained language representation model for biomedical NLP
BC5CDR,https://identifiers.org/ito:ITO_31717,Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning
WetLab,https://identifiers.org/ito:ITO_11933,Using Similarity Measures to Select Pretraining Data for NER
CoNLL 2002 (Dutch),https://identifiers.org/ito:ITO_12048,Neural Architectures for Nested NER through Linearization
CoNLL 2002 (Dutch),https://identifiers.org/ito:ITO_31686,Named Entity Recognition as Dependency Parsing
CoNLL 2002 (Dutch),https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
NCBI-disease,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
NCBI-disease,https://identifiers.org/ito:ITO_04771,BioBERT: a pre-trained biomedical language representation model for biomedical text mining
NCBI-disease,https://identifiers.org/ito:ITO_31707,Biomedical Named Entity Recognition at Scale
SLUE,https://identifiers.org/ito:ITO_44524,SLUE: New Benchmark Tasks for Spoken Language Understanding Evaluation on Natural Speech
Species800,https://identifiers.org/ito:ITO_31707,Biomedical Named Entity Recognition at Scale
Species800,https://identifiers.org/ito:ITO_54301,Accurate clinical and biomedical Named entity recognition at scale
ACE 2005,https://identifiers.org/ito:ITO_54285,A Neural Layered Model for Nested Named Entity Recognition
ACE 2005,https://identifiers.org/ito:ITO_11962,Neural Segmental Hypergraphs for Overlapping Mention Recognition
ACE 2005,https://identifiers.org/ito:ITO_11973,Merge and Label: A novel neural network architecture for nested NER
ACE 2005,https://identifiers.org/ito:ITO_12048,Neural Architectures for Nested NER through Linearization
ACE 2005,https://identifiers.org/ito:ITO_31839,Nested Named Entity Recognition via Second-best Sequence Learning and Decoding
ACE 2005,https://identifiers.org/ito:ITO_31778,A Unified MRC Framework for Named Entity Recognition
LINNAEUS,https://identifiers.org/ito:ITO_11952,BioFLAIR: Pretrained Pooled Contextualized Embeddings for Biomedical Sequence Labeling Tasks
BioNLP13-CG,https://identifiers.org/ito:ITO_31707,Biomedical Named Entity Recognition at Scale
BioNLP13-CG,https://identifiers.org/ito:ITO_54301,Accurate clinical and biomedical Named entity recognition at scale
CoNLL 2000,https://identifiers.org/ito:ITO_08299,Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms
IECSIL FIRE-2018 Shared Task,https://identifiers.org/ito:ITO_54324,Analysis Of Contextual and Non-Contextual Word Embedding Models For Hindi NER With Web Application For Data Collection
JNLPBA,https://identifiers.org/ito:ITO_04771,BioBERT: a pre-trained biomedical language representation model for biomedical text mining
JNLPBA,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
JNLPBA,https://identifiers.org/ito:ITO_31707,Biomedical Named Entity Recognition at Scale
JNLPBA,https://identifiers.org/ito:ITO_21416,Improving Biomedical Pretrained Language Models with Knowledge
"NEMO-Corpus (token,test)",https://identifiers.org/ito:ITO_31713,Neural Modeling for Named Entities and Morphology (NEMO^2)
"NEMO-Corpus (token,test)",https://identifiers.org/ito:ITO_31711,AlephBERT:A Hebrew Large Pre-Trained Language Model to Start-off your Hebrew NLP Application With
OntoNotes 5.0,https://identifiers.org/ito:ITO_54271,Hero-Gang Neural Model For Named Entity Recognition
BC7 NLM-Chem,https://identifiers.org/ito:ITO_54222,Chemical detection and indexing in PubMed full text articles using deep learning and rule-based methods
BC7 NLM-Chem,https://identifiers.org/ito:ITO_54220,Chemical identification and indexing in PubMed full-text articles using deep learning and heuristics
HiNER-original,https://identifiers.org/ito:ITO_54229,HiNER: A Large Hindi Named Entity Recognition Dataset
WNUT 2017,https://identifiers.org/ito:ITO_54345,Transfer Learning and Sentence Level Features for Named Entity Recognition on Tweets
WNUT 2017,https://identifiers.org/ito:ITO_31733,Modeling Noisiness to Recognize Named Entities using Multitask Neural Networks on Social Media
WNUT 2017,https://identifiers.org/ito:ITO_31729,CrossWeigh: Training Named Entity Tagger from Imperfect Annotations
WNUT 2017,https://identifiers.org/ito:ITO_31723,Robust Named Entity Recognition with Truecasing Pretraining
WNUT 2017,https://identifiers.org/ito:ITO_21023,BERTweet: A pre-trained language model for English Tweets
WNUT 2017,https://identifiers.org/ito:ITO_54342,T-NER: An All-Round Python Library for Transformer-based Named Entity Recognition
WNUT 2017,https://identifiers.org/ito:ITO_31717,Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning
WNUT 2017,https://identifiers.org/ito:ITO_31816,Why Attention? Analyze BiLSTM Deficiency and Its Remedies in the Case of NER
AnatEM,https://identifiers.org/ito:ITO_54301,Accurate clinical and biomedical Named entity recognition at scale
"NEMO-Corpus (morph,test)",https://identifiers.org/ito:ITO_31713,Neural Modeling for Named Entities and Morphology (NEMO^2)
"NEMO-Corpus (morph,test)",https://identifiers.org/ito:ITO_31711,AlephBERT:A Hebrew Large Pre-Trained Language Model to Start-off your Hebrew NLP Application With
Adverse Drug Events (ADE) Corpus,https://identifiers.org/ito:ITO_54359,Mining Adverse Drug Reactions from Unstructured Mediums at Scale
Species-800,https://identifiers.org/ito:ITO_11952,BioFLAIR: Pretrained Pooled Contextualized Embeddings for Biomedical Sequence Labeling Tasks
Species-800,https://identifiers.org/ito:ITO_31707,Biomedical Named Entity Recognition at Scale
CoNLL 2003 (English),https://identifiers.org/ito:ITO_11929,Named Entity Recognition with Bidirectional LSTM-CNNs
CoNLL 2003 (English),https://identifiers.org/ito:ITO_12017,Semi-supervised sequence tagging with bidirectional language models
CoNLL 2003 (English),https://identifiers.org/ito:ITO_07964,Deep contextualized word representations
CoNLL 2003 (English),https://identifiers.org/ito:ITO_45104,Contextual String Embeddings for Sequence Labeling
CoNLL 2003 (English),https://identifiers.org/ito:ITO_11680,Cloze-driven Pretraining of Self-attention Networks
CoNLL 2003 (English),https://identifiers.org/ito:ITO_31689,Exploring Cross-sentence Contexts for Named Entity Recognition with BERT
CoNLL 2003 (English),https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
Ontonotes v5 (English),https://identifiers.org/ito:ITO_54372,"A Joint Model for Entity Analysis: Coreference, Typing, and Linking"
Ontonotes v5 (English),https://identifiers.org/ito:ITO_11929,Named Entity Recognition with Bidirectional LSTM-CNNs
Ontonotes v5 (English),https://identifiers.org/ito:ITO_11926,Fast and Accurate Entity Recognition with Iterated Dilated Convolutions
Ontonotes v5 (English),https://identifiers.org/ito:ITO_11923,Robust Lexical Features for Improved Neural Network Named-Entity Recognition
Ontonotes v5 (English),https://identifiers.org/ito:ITO_05191,Semi-Supervised Sequence Modeling with Cross-View Training
Ontonotes v5 (English),https://identifiers.org/ito:ITO_54367,Towards Improving Neural Named Entity Recognition with Gazetteers
Ontonotes v5 (English),https://identifiers.org/ito:ITO_31778,A Unified MRC Framework for Named Entity Recognition
Ontonotes v5 (English),https://identifiers.org/ito:ITO_26144,Dice Loss for Data-imbalanced NLP Tasks
Ontonotes v5 (English),https://identifiers.org/ito:ITO_31816,Why Attention? Analyze BiLSTM Deficiency and Its Remedies in the Case of NER
Ontonotes v5 (English),https://identifiers.org/ito:ITO_45578,Packed Levitated Marker for Entity and Relation Extraction
BC2GM,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
BC2GM,https://identifiers.org/ito:ITO_31707,Biomedical Named Entity Recognition at Scale
CoNLL 2003 (German) Revised,https://identifiers.org/ito:ITO_45104,Contextual String Embeddings for Sequence Labeling
CoNLL 2003 (German) Revised,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
CoNLL 2003 (German) Revised,https://identifiers.org/ito:ITO_31891,FLERT: Document-Level Features for Named Entity Recognition
BC4CHEMD,https://identifiers.org/ito:ITO_31863,An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition
BC4CHEMD,https://identifiers.org/ito:ITO_31707,Biomedical Named Entity Recognition at Scale
BC4CHEMD,https://identifiers.org/ito:ITO_54301,Accurate clinical and biomedical Named entity recognition at scale
CoNLL++,https://identifiers.org/ito:ITO_04511,End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF
CoNLL++,https://identifiers.org/ito:ITO_07964,Deep contextualized word representations
CoNLL++,https://identifiers.org/ito:ITO_31729,CrossWeigh: Training Named Entity Tagger from Imperfect Annotations
CoNLL++,https://identifiers.org/ito:ITO_45562,Learning from Noisy Labels for Entity-Centric Information Extraction
PhoNER COVID19,https://identifiers.org/ito:ITO_54431,COVID-19 Named Entity Recognition for Vietnamese
PhoNER COVID19,https://identifiers.org/ito:ITO_54435,ViHealthBERT: Pre-trained Language Models for Vietnamese in Health Text Mining
VLSP-2016,https://identifiers.org/ito:ITO_31804,A Deep Neural Network Model for the Task of Named Entity Recognition
NNE,https://identifiers.org/ito:ITO_11962,Neural Segmental Hypergraphs for Overlapping Mention Recognition
NNE,https://identifiers.org/ito:ITO_31839,Nested Named Entity Recognition via Second-best Sequence Learning and Decoding
NNE,https://identifiers.org/ito:ITO_54388,Pyramid: A Layered Model for Nested Named Entity Recognition
GENIA,https://identifiers.org/ito:ITO_54388,Pyramid: A Layered Model for Nested Named Entity Recognition
GENIA,https://identifiers.org/ito:ITO_31780,Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition
GENIA,https://identifiers.org/ito:ITO_54393,Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition
GENIA,https://identifiers.org/ito:ITO_54366,Unified Named Entity Recognition as Word-Word Relation Classification
GENIA,https://identifiers.org/ito:ITO_54266,Parallel Instance Query Network for Named Entity Recognition
TAC-KBP 2017,https://identifiers.org/ito:ITO_54393,Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition
ACE 2004,https://identifiers.org/ito:ITO_31922,Nested Named Entity Recognition with Partially-Observed TreeCRFs
ACE 2004,https://identifiers.org/ito:ITO_31780,Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition
ACE 2004,https://identifiers.org/ito:ITO_54393,Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition
Chilean Waiting List,https://identifiers.org/ito:ITO_54405,Automatic Extraction of Nested Entities in Clinical Referrals in Spanish
ACE 2005,https://identifiers.org/ito:ITO_11970,A Neural Transition-based Model for Nested Mention Recognition
ACE 2005,https://identifiers.org/ito:ITO_31922,Nested Named Entity Recognition with Partially-Observed TreeCRFs
ACE 2005,https://identifiers.org/ito:ITO_54394,A Sequence-to-Set Network for Nested Named Entity Recognition
ACE 2005,https://identifiers.org/ito:ITO_54393,Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition
STM-corpus,https://identifiers.org/ito:ITO_12054,Domain-independent Extraction of Scientific Concepts from Research Articles
ACE 2004,https://identifiers.org/ito:ITO_11970,A Neural Transition-based Model for Nested Mention Recognition
ACE 2004,https://identifiers.org/ito:ITO_31778,A Unified MRC Framework for Named Entity Recognition
GENIA,https://identifiers.org/ito:ITO_29350,DeepEventMine: end-to-end neural nested event extraction from biomedical texts
Epigenetics and Post-translational Modifications 2011 (EPI),https://identifiers.org/ito:ITO_29350,DeepEventMine: end-to-end neural nested event extraction from biomedical texts
GENIA 2013,https://identifiers.org/ito:ITO_29350,DeepEventMine: end-to-end neural nested event extraction from biomedical texts
Pathway Curation 2013 (PC),https://identifiers.org/ito:ITO_29350,DeepEventMine: end-to-end neural nested event extraction from biomedical texts
Multi-Level Event Extraction (MLEE),https://identifiers.org/ito:ITO_29350,DeepEventMine: end-to-end neural nested event extraction from biomedical texts
Infectious Diseases 2011 (ID),https://identifiers.org/ito:ITO_29350,DeepEventMine: end-to-end neural nested event extraction from biomedical texts
Cancer Genetics 2013 (CG),https://identifiers.org/ito:ITO_29350,DeepEventMine: end-to-end neural nested event extraction from biomedical texts
BenchIE,https://identifiers.org/ito:ITO_52010,BenchIE: A Framework for Multi-Faceted Fact-Based Open Information Extraction Evaluation
CaRB OIE benchmark (Greek Use-case),https://identifiers.org/ito:ITO_23042,PENELOPIE: Enabling Open Information Extraction for the Greek Language through Machine Translation
Penn Treebank,https://identifiers.org/ito:ITO_45658,Zero-Shot Information Extraction as a Unified Text-to-Triple Translation
OIE2016,https://identifiers.org/ito:ITO_45658,Zero-Shot Information Extraction as a Unified Text-to-Triple Translation
OIE2016,https://identifiers.org/ito:ITO_29346,Span Model for Open Information Extraction on Accurate Corpus
NYT,https://identifiers.org/ito:ITO_45658,Zero-Shot Information Extraction as a Unified Text-to-Triple Translation
Web,https://identifiers.org/ito:ITO_45658,Zero-Shot Information Extraction as a Unified Text-to-Triple Translation
EBM-NLP,https://identifiers.org/ito:ITO_16257,"A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature"
EBM-NLP,https://identifiers.org/ito:ITO_04773,SciBERT: A Pretrained Language Model for Scientific Text
EBM-NLP,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
SciREX,https://identifiers.org/ito:ITO_45707,Document-level Entity-based Extraction as Template Generation
DialogRE,https://identifiers.org/ito:ITO_45697,An Embarrassingly Simple Model for Dialogue Relation Extraction
DialogRE,https://identifiers.org/ito:ITO_21697,Semantic Representation for Dialogue Modeling
DialogRE,https://identifiers.org/ito:ITO_45694,SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues
DialogRE,https://identifiers.org/ito:ITO_45693,Graph Based Network with Contextualized Representations of Turns in Dialogue
DialogRE,https://identifiers.org/ito:ITO_21703,Dialogue-Based Relation Extraction
DialogRE,https://identifiers.org/ito:ITO_21588,GDPNet: Refining Latent Multi-View Graph for Relation Extraction
DDRel,https://identifiers.org/ito:ITO_21714,DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic Dialogues
DrugProt,https://identifiers.org/ito:ITO_45711,R-BERT-CNN: Drug-target interactions extraction from biomedical literature
FREDo (cross-domain),https://identifiers.org/ito:ITO_45672,Few-Shot Document-Level Relation Extraction
DocRED,https://identifiers.org/ito:ITO_45672,Few-Shot Document-Level Relation Extraction
Discovery Dataset,https://identifiers.org/ito:ITO_45650,Mining Discourse Markers for Unsupervised Sentence Representation Learning
AbstRCT - Neoplasm,https://identifiers.org/ito:ITO_18306,Multi-Task Attentive Residual Networks for Argument Mining
MATRES,https://identifiers.org/ito:ITO_45655,Selecting Optimal Context Sentences for Event-Event Relation Extraction
FewRel,https://identifiers.org/ito:ITO_45658,Zero-Shot Information Extraction as a Unified Text-to-Triple Translation
DRI Corpus,https://identifiers.org/ito:ITO_18306,Multi-Task Attentive Residual Networks for Argument Mining
SemEval 2010 Task 8,https://identifiers.org/ito:ITO_45663,Semantic Compositionality through Recursive Matrix-Vector Spaces
SemEval 2010 Task 8,https://identifiers.org/ito:ITO_21655,Semantic Relation Classification via Convolutional Neural Networks with Simple Negative Sampling
SemEval 2010 Task 8,https://identifiers.org/ito:ITO_21653,Improved Relation Classification by Deep Recurrent Neural Networks with Data Augmentation
SemEval 2010 Task 8,https://identifiers.org/ito:ITO_45662,Bidirectional Recurrent Convolutional Neural Network for Relation Classification
TACRED,https://identifiers.org/ito:ITO_45639,Structured Prediction as Translation between Augmented Natural Languages
TACRED,https://identifiers.org/ito:ITO_45658,Zero-Shot Information Extraction as a Unified Text-to-Triple Translation
CDCP,https://identifiers.org/ito:ITO_18306,Multi-Task Attentive Residual Networks for Argument Mining
PGR,https://identifiers.org/ito:ITO_45458,Deeper Clinical Document Understanding Using Relation Extraction
SKE,https://identifiers.org/ito:ITO_45462,Revisiting the Negative Data of Distantly Supervised Relation Extraction
2012 i2b2 Temporal Relations,https://identifiers.org/ito:ITO_45458,Deeper Clinical Document Understanding Using Relation Extraction
NYT10-HRL,https://identifiers.org/ito:ITO_21528,A Hierarchical Framework for Relation Extraction with Reinforcement Learning
NYT10-HRL,https://identifiers.org/ito:ITO_21510,A Novel Cascade Binary Tagging Framework for Relational Triple Extraction
NYT10-HRL,https://identifiers.org/ito:ITO_21508,TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking
NYT10-HRL,https://identifiers.org/ito:ITO_45462,Revisiting the Negative Data of Distantly Supervised Relation Extraction
Adverse Drug Events (ADE) Corpus,https://identifiers.org/ito:ITO_04718,Joint entity recognition and relation extraction as a multi-head selection problem
Adverse Drug Events (ADE) Corpus,https://identifiers.org/ito:ITO_04716,Adversarial training for multi-context joint entity and relation extraction
Adverse Drug Events (ADE) Corpus,https://identifiers.org/ito:ITO_04792,Neural Metric Learning for Fast End-to-End Relation Extraction
Adverse Drug Events (ADE) Corpus,https://identifiers.org/ito:ITO_21393,Span-based Joint Entity and Relation Extraction with Transformer Pre-training
Adverse Drug Events (ADE) Corpus,https://identifiers.org/ito:ITO_21387,Deeper Task-Specificity Improves Joint Entity and Relation Extraction
Adverse Drug Events (ADE) Corpus,https://identifiers.org/ito:ITO_45458,Deeper Clinical Document Understanding Using Relation Extraction
Adverse Drug Events (ADE) Corpus,https://identifiers.org/ito:ITO_21391,Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders
Adverse Drug Events (ADE) Corpus,https://identifiers.org/ito:ITO_45485,Joint Entity and Relation Extraction from Scientific Documents: Role of Linguistic Information and Entity Types
2018 n2c2 (Track 2) - Adverse Drug Events and Medication Extraction,https://identifiers.org/ito:ITO_45458,Deeper Clinical Document Understanding Using Relation Extraction
Re-TACRED,https://identifiers.org/ito:ITO_45497,Position-aware Attention and Supervised Data Improve Slot Filling
Re-TACRED,https://identifiers.org/ito:ITO_04753,Graph Convolution over Pruned Dependency Trees Improves Relation Extraction
Re-TACRED,https://identifiers.org/ito:ITO_04751,SpanBERT: Improving Pre-training by Representing and Predicting Spans
Re-TACRED,https://identifiers.org/ito:ITO_21401,An Improved Baseline for Sentence-level Relation Extraction
Re-TACRED,https://identifiers.org/ito:ITO_45495,Improving Sentence-Level Relation Extraction through Curriculum Learning
ADE Corpus,https://identifiers.org/ito:ITO_45500,A Partition Filter Network for Joint Entity and Relation Extraction
NYT Corpus,https://identifiers.org/ito:ITO_45503,Multi-instance Multi-label Learning for Relation Extraction
NYT Corpus,https://identifiers.org/ito:ITO_45502,Neural Relation Extraction with Selective Attention over Instances
NYT Corpus,https://identifiers.org/ito:ITO_04812,RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information
NYT Corpus,https://identifiers.org/ito:ITO_21615,Connecting Language and Knowledge with Heterogeneous Representations for Neural Relation Extraction
NYT Corpus,https://identifiers.org/ito:ITO_21613,RECON: Relation Extraction using Knowledge Graph Context in a Graph Neural Network
NYT Corpus,https://identifiers.org/ito:ITO_21611,KGPool: Dynamic Knowledge Graph Context Selection for Relation Extraction
CDR,https://identifiers.org/ito:ITO_21450,Reasoning with Latent Structure Refinement for Document-Level Relation Extraction
CDR,https://identifiers.org/ito:ITO_21428,Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling
CDR,https://identifiers.org/ito:ITO_45513,Document-level Relation Extraction as Semantic Segmentation
CDR,https://identifiers.org/ito:ITO_45507,SAIS: Supervising and Augmenting Intermediate Steps for Document-Level Relation Extraction
NYT-single,https://identifiers.org/ito:ITO_04700,Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme
NYT-single,https://identifiers.org/ito:ITO_04726,Joint extraction of entities and overlapping relations using position-attentive sequence labeling
NYT-single,https://identifiers.org/ito:ITO_04692,Joint Extraction of Entities and Relations Based on a Novel Decomposition Strategy
Dataset: Relationship extraction for knowledge graph creation from biomedical literature (Gene-Disease relationships),https://identifiers.org/ito:ITO_45524,Relationship extraction for knowledge graph creation from biomedical literature
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_45531,Relation Classification via Convolutional Deep Neural Network
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_21639,Classifying Relations by Ranking with Convolutional Neural Networks
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_45528,Relation Classification via Multi-Level Attention CNNs
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_04738,Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_04734,Enriching Pre-trained Language Model with Entity Information for Relation Classification
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_04732,Matching the Blanks: Distributional Similarity for Relation Learning
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_04730,Improving Relation Classification by Entity Pair Graph
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_21631,Enhancing Relation Extraction Using Syntactic Indicators and Sentential Contexts
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_04685,Downstream Model Design of Pre-trained Language Model for Relation Extraction Task
SemEval-2010 Task 8,https://identifiers.org/ito:ITO_21573,Relation Classification as Two-way Span-Prediction
WebNLG,https://identifiers.org/ito:ITO_04700,Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme
WebNLG,https://identifiers.org/ito:ITO_45537,Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism
WebNLG,https://identifiers.org/ito:ITO_21510,A Novel Cascade Binary Tagging Framework for Relational Triple Extraction
WebNLG,https://identifiers.org/ito:ITO_21508,TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking
WebNLG,https://identifiers.org/ito:ITO_21504,Joint Entity and Relation Extraction with Set Prediction Networks
WebNLG,https://identifiers.org/ito:ITO_45500,A Partition Filter Network for Joint Entity and Relation Extraction
ChemProt,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
ChemProt,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
ChemProt,https://identifiers.org/ito:ITO_04771,BioBERT: a pre-trained biomedical language representation model for biomedical text mining
ChemProt,https://identifiers.org/ito:ITO_04773,SciBERT: A Pretrained Language Model for Scientific Text
ChemProt,https://identifiers.org/ito:ITO_21490,SciFive: a text-to-text transformer model for biomedical literature
NYT11-HRL,https://identifiers.org/ito:ITO_04714,End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures
NYT11-HRL,https://identifiers.org/ito:ITO_21528,A Hierarchical Framework for Relation Extraction with Reinforcement Learning
NYT11-HRL,https://identifiers.org/ito:ITO_21510,A Novel Cascade Binary Tagging Framework for Relational Triple Extraction
NYT11-HRL,https://identifiers.org/ito:ITO_21508,TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking
NYT11-HRL,https://identifiers.org/ito:ITO_45462,Revisiting the Negative Data of Distantly Supervised Relation Extraction
TACRED,https://identifiers.org/ito:ITO_45497,Position-aware Attention and Supervised Data Improve Slot Filling
TACRED,https://identifiers.org/ito:ITO_04753,Graph Convolution over Pruned Dependency Trees Improves Relation Extraction
TACRED,https://identifiers.org/ito:ITO_04734,Enriching Pre-trained Language Model with Entity Information for Relation Classification
TACRED,https://identifiers.org/ito:ITO_04732,Matching the Blanks: Distributional Similarity for Relation Learning
TACRED,https://identifiers.org/ito:ITO_21581,KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation
TACRED,https://identifiers.org/ito:ITO_21579,K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters
TACRED,https://identifiers.org/ito:ITO_21577,"DeNERT-KG: Named Entity and Relation Extraction Model Using DQN, Knowledge Graph, and BERT"
TACRED,https://identifiers.org/ito:ITO_21573,Relation Classification as Two-way Span-Prediction
TACRED,https://identifiers.org/ito:ITO_21571,Relation Classification with Entity Type Restriction
TACRED,https://identifiers.org/ito:ITO_45558,Enhancing Targeted Minority Class Prediction in Sentence-Level Relation Extraction
TACRED,https://identifiers.org/ito:ITO_45560,Label Verbalization and Entailment for Effective Zero- and Few-Shot Relation Extraction
TACRED,https://identifiers.org/ito:ITO_21575,LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention
Wikipedia-Wikidata relations,https://identifiers.org/ito:ITO_45565,Context-Aware Representations for Knowledge Base Relation Extraction
WLPC,https://identifiers.org/ito:ITO_21030,Generalizing Natural Language Analysis through Span-relation Representations
GAD,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
GAD,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
GAD,https://identifiers.org/ito:ITO_21416,Improving Biomedical Pretrained Language Models with Knowledge
MUC6,https://identifiers.org/ito:ITO_45571,Neural Relation Extraction Within and Across Sentence Boundaries
Dataset: Relationship extraction for knowledge graph creation from biomedical literature (Gene-Disease relationships) n,https://identifiers.org/ito:ITO_45524,Relationship extraction for knowledge graph creation from biomedical literature
ACE 2004,https://identifiers.org/ito:ITO_45580,Incremental Joint Extraction of Entity Mentions and Relations
ACE 2004,https://identifiers.org/ito:ITO_04714,End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures
ACE 2004,https://identifiers.org/ito:ITO_04712,Entity-Relation Extraction as Multi-Turn Question Answering
ACE 2004,https://identifiers.org/ito:ITO_45500,A Partition Filter Network for Joint Entity and Relation Extraction
ACE 2004,https://identifiers.org/ito:ITO_45578,Packed Levitated Marker for Entity and Relation Extraction
ACE 2004,https://identifiers.org/ito:ITO_45579,Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees
ACE 2004,https://identifiers.org/ito:ITO_04710,A General Framework for Information Extraction using Dynamic Span Graphs
SemEval 2018 Task 10,https://identifiers.org/ito:ITO_21481,"BomJi at SemEval-2018 Task 10: Combining Vector-, Pattern- and Graph-based Information to Identify Discriminative Attributes"
SemEval 2018 Task 10,https://identifiers.org/ito:ITO_45582,SUNNYNLP at SemEval-2018 Task 10: A Support-Vector-Machine-Based Method for Detecting Semantic Difference using Taxonomy and Word Embedding Features
GDA,https://identifiers.org/ito:ITO_21450,Reasoning with Latent Structure Refinement for Document-Level Relation Extraction
GDA,https://identifiers.org/ito:ITO_21428,Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling
GDA,https://identifiers.org/ito:ITO_45513,Document-level Relation Extraction as Semantic Segmentation
GDA,https://identifiers.org/ito:ITO_45507,SAIS: Supervising and Augmenting Intermediate Steps for Document-Level Relation Extraction
2010 i2b2/VA,https://identifiers.org/ito:ITO_45458,Deeper Clinical Document Understanding Using Relation Extraction
DuIE,https://identifiers.org/ito:ITO_21514,BiTT: Bidirectional Tree Tagging for Joint Extraction of Overlapping Entities and Relations
ACE 2005,https://identifiers.org/ito:ITO_21539,HySPA: Hybrid Span Generation for Scalable Text-to-Graph Extraction
ACE 2005,https://identifiers.org/ito:ITO_45580,Incremental Joint Extraction of Entity Mentions and Relations
ACE 2005,https://identifiers.org/ito:ITO_04714,End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures
ACE 2005,https://identifiers.org/ito:ITO_45597,End-to-End Neural Relation Extraction with Global Optimization
ACE 2005,https://identifiers.org/ito:ITO_45595,Extracting Entities and Relations with Joint Minimum Risk Training
ACE 2005,https://identifiers.org/ito:ITO_04712,Entity-Relation Extraction as Multi-Turn Question Answering
ACE 2005,https://identifiers.org/ito:ITO_21547,Asking Effective and Diverse Questions: A Machine Reading Comprehension based Framework for Joint Entity-Relation Extraction
ACE 2005,https://identifiers.org/ito:ITO_45578,Packed Levitated Marker for Entity and Relation Extraction
ACE 2005,https://identifiers.org/ito:ITO_45579,Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees
ACE 2005,https://identifiers.org/ito:ITO_21545,A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks
ACE 2005,https://identifiers.org/ito:ITO_04710,A General Framework for Information Extraction using Dynamic Span Graphs
ACE 2005,https://identifiers.org/ito:ITO_10124,"Entity, Relation, and Event Extraction with Contextualized Span Representations"
ACE 2005,https://identifiers.org/ito:ITO_21562,Improved Relation Extraction with Feature-Rich Compositional Embedding Models
ACE 2005,https://identifiers.org/ito:ITO_45599,Relation Extraction: Perspective from Convolutional Neural Networks
ACE 2005,https://identifiers.org/ito:ITO_21557,Combining Neural Networks and Log-linear Models to Improve Relation Extraction
ACE 2005,https://identifiers.org/ito:ITO_45598,Relation Extraction among Multiple Entities Using a Dual Pointer Network with a Multi-Head Attention Mechanism
ACE 2005,https://identifiers.org/ito:ITO_21553,Dual Pointer Network for Fast Extraction of Multiple Relations in a Sentence
JNLPBA,https://identifiers.org/ito:ITO_04773,SciBERT: A Pretrained Language Model for Scientific Text
NYT21,https://identifiers.org/ito:ITO_45462,Revisiting the Negative Data of Distantly Supervised Relation Extraction
DocRED,https://identifiers.org/ito:ITO_04680,DocRED: A Large-Scale Document-Level Relation Extraction Dataset
DocRED,https://identifiers.org/ito:ITO_04676,Fine-tune Bert for DocRED with Two-step Process
DocRED,https://identifiers.org/ito:ITO_04674,HIN: Hierarchical Inference Network for Document-Level Relation Extraction
DocRED,https://identifiers.org/ito:ITO_21443,Coreferential Reasoning Learning for Language Representation
DocRED,https://identifiers.org/ito:ITO_21432,Entity and Evidence Guided Relation Extraction for DocRED
DocRED,https://identifiers.org/ito:ITO_21430,Double Graph Based Reasoning for Document-level Relation Extraction
DocRED,https://identifiers.org/ito:ITO_21428,Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling
DocRED,https://identifiers.org/ito:ITO_21424,Entity Structure Within and Throughout: Modeling Mention Dependencies for Document-Level Relation Extraction
DocRED,https://identifiers.org/ito:ITO_45607,Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation
FewRel,https://identifiers.org/ito:ITO_04704,ERNIE: Enhanced Language Representation with Informative Entities
DDI,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
DDI,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
DDI,https://identifiers.org/ito:ITO_21416,Improving Biomedical Pretrained Language Models with Knowledge
NYT29,https://identifiers.org/ito:ITO_21528,A Hierarchical Framework for Relation Extraction with Reinforcement Learning
NYT29,https://identifiers.org/ito:ITO_04690,Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction
NYT24,https://identifiers.org/ito:ITO_21528,A Hierarchical Framework for Relation Extraction with Reinforcement Learning
NYT24,https://identifiers.org/ito:ITO_04690,Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction
CoNLL04,https://identifiers.org/ito:ITO_04718,Joint entity recognition and relation extraction as a multi-head selection problem
CoNLL04,https://identifiers.org/ito:ITO_04790,End-to-end neural relation extraction using deep biaffine attention
CoNLL04,https://identifiers.org/ito:ITO_21393,Span-based Joint Entity and Relation Extraction with Transformer Pre-training
CoNLL04,https://identifiers.org/ito:ITO_21387,Deeper Task-Specificity Improves Joint Entity and Relation Extraction
CoNLL04,https://identifiers.org/ito:ITO_45640,Modeling Joint Entity and Relation Extraction with Table Representation
CoNLL04,https://identifiers.org/ito:ITO_45597,End-to-End Neural Relation Extraction with Global Optimization
CoNLL04,https://identifiers.org/ito:ITO_04712,Entity-Relation Extraction as Multi-Turn Question Answering
CoNLL04,https://identifiers.org/ito:ITO_21391,Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders
CoNLL04,https://identifiers.org/ito:ITO_45487,REBEL: Relation Extraction By End-to-end Language generation
CoNLL04,https://identifiers.org/ito:ITO_45593,Named Entity Recognition and Relation Extraction using Enhanced Table Filling by Contextualized Representations
CoNLL04,https://identifiers.org/ito:ITO_45591,A Trigger-Sense Memory Flow Framework for Joint Entity and Relation Extraction
NYT,https://identifiers.org/ito:ITO_04700,Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme
NYT,https://identifiers.org/ito:ITO_45537,Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism
NYT,https://identifiers.org/ito:ITO_21510,A Novel Cascade Binary Tagging Framework for Relational Triple Extraction
NYT,https://identifiers.org/ito:ITO_45647,RH-Net: Improving Neural Relation Extraction via Reinforcement Learning and Hierarchical Relational Searching
NYT,https://identifiers.org/ito:ITO_21504,Joint Entity and Relation Extraction with Set Prediction Networks
NYT,https://identifiers.org/ito:ITO_45487,REBEL: Relation Extraction By End-to-end Language generation
NYT,https://identifiers.org/ito:ITO_45500,A Partition Filter Network for Joint Entity and Relation Extraction
NYT,https://identifiers.org/ito:ITO_45645,Adjacency List Oriented Relational Fact Extraction via Adaptive Multi-task Learning
NYT,https://identifiers.org/ito:ITO_21677,From Bag of Sentences to Document: Distantly Supervised Relation Extraction via Machine Reading Comprehension
New York Times Corpus,https://identifiers.org/ito:ITO_04820,Neural Relation Extraction via Inner-Sentence Noise Reduction and Transfer Learning
New York Times Corpus,https://identifiers.org/ito:ITO_21684,Improving Distantly-Supervised Relation Extraction through BERT-based Label & Instance Embeddings
New York Times Corpus,https://identifiers.org/ito:ITO_45702,Distantly-Supervised Long-Tailed Relation Extraction Using Constraint Graphs
New York Times Corpus,https://identifiers.org/ito:ITO_45703,Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks
New York Times Corpus,https://identifiers.org/ito:ITO_04814,Improving Distantly Supervised Relation Extraction using Word and Entity Based Attention
Wiki-ZSL,https://identifiers.org/ito:ITO_21391,Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders
Wiki-ZSL,https://identifiers.org/ito:ITO_45715,RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction
FewRel,https://identifiers.org/ito:ITO_21391,Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders
FewRel,https://identifiers.org/ito:ITO_45715,RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction
"NLP-TDMS (Exp, arXiv only)",https://identifiers.org/ito:ITO_16525,"Identification of Tasks, Datasets, Evaluation Metrics, and Numeric Scores for Scientific Leaderboards Construction"
"NLP-TDMS (Exp, arXiv only)",https://identifiers.org/ito:ITO_16523,AxCell: Automatic Extraction of Results from Machine Learning Papers
PWC Leaderboards (restricted),https://identifiers.org/ito:ITO_16523,AxCell: Automatic Extraction of Results from Machine Learning Papers
TempEval-3,https://identifiers.org/ito:ITO_52055,BERT got a Date: Introducing Transformers to Temporal Tagging
TempEval-3,https://identifiers.org/ito:ITO_52041,ClearTK-TimeML: A minimalist approach to TempEval 2013
TempEval-3,https://identifiers.org/ito:ITO_29370,A Structured Learning Approach to Temporal Relation Extraction
TimeBank,https://identifiers.org/ito:ITO_52044,Dense Event Ordering with a Multi-Pass Architecture
TimeBank,https://identifiers.org/ito:ITO_52043,CATENA: CAusal and TEmporal relation extraction from NAtural language texts
AWARE,https://identifiers.org/ito:ITO_59473,AWARE: Aspect-Based Sentiment Analysis Dataset of Apps Reviews for Requirements Elicitation
SemEval 2014 Task 4 Laptop,https://identifiers.org/ito:ITO_62673,Exploring Sequence-to-Sequence Learning in Aspect Term Extraction
TimeBank,https://identifiers.org/ito:ITO_61849,TIMEN: An Open Temporal Expression Normalisation Resource
PNT,https://identifiers.org/ito:ITO_61850,A Baseline Temporal Tagger for all Languages
PNT,https://identifiers.org/ito:ITO_61851,From Characters to Time Intervals: New Paradigms for Evaluation and Neural Parsing of Time Normalizations
TREC Robust04,https://identifiers.org/ito:ITO_12592,Neural Ranking Models with Weak Supervision
TREC Robust04,https://identifiers.org/ito:ITO_12581,From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing
TREC Robust04,https://identifiers.org/ito:ITO_12590,The Neural Hype and Comparisons Against Weak Baselines
TREC Robust04,https://identifiers.org/ito:ITO_12588,Simple Applications of BERT for Ad Hoc Document Retrieval
TREC Robust04,https://identifiers.org/ito:ITO_32880,Document Ranking with a Pretrained Sequence-to-Sequence Model
TREC Robust04,https://identifiers.org/ito:ITO_12585,A Deep Relevance Matching Model for Ad-hoc Retrieval
TREC Robust04,https://identifiers.org/ito:ITO_12574,Deep Relevance Ranking Using Enhanced Document-Query Interactions
TREC Robust04,https://identifiers.org/ito:ITO_12569,CEDR: Contextualized Embeddings for Document Ranking
TREC Robust04,https://identifiers.org/ito:ITO_12577,NPRF: A Neural Pseudo Relevance Feedback Framework for Ad-hoc Information Retrieval
DaReCzech,https://identifiers.org/ito:ITO_55185,Siamese BERT-based Model for Web Search Relevance Ranking Evaluated on a New Czech Dataset
ClueWeb09-B,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
RRS,https://identifiers.org/ito:ITO_16361,Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots
RRS,https://identifiers.org/ito:ITO_60321,Multi-Turn Response Selection for Chatbots with Deep Attention Matching Network
RRS,https://identifiers.org/ito:ITO_39566,An Effective Domain Adaptive Post-Training Method for BERT in Response Selection
RRS,https://identifiers.org/ito:ITO_39568,Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots
RRS,https://identifiers.org/ito:ITO_60316,Fine-grained Post-training for Improving Retrieval-based Dialogue Systems
RRS Ranking Test,https://identifiers.org/ito:ITO_16381,Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring
Advising Corpus,https://identifiers.org/ito:ITO_16344,Sequential Attention-based Network for Noetic End-to-End Response Selection
DSTC7 Ubuntu,https://identifiers.org/ito:ITO_16385,Building Sequential Inference Models for End-to-End Response Selection
DSTC7 Ubuntu,https://identifiers.org/ito:ITO_16344,Sequential Attention-based Network for Noetic End-to-End Response Selection
DSTC7 Ubuntu,https://identifiers.org/ito:ITO_16381,Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring
DSTC7 Ubuntu,https://identifiers.org/ito:ITO_16370,ConveRT: Efficient and Accurate Conversational Representations from Transformers
PolyAI AmazonQA,https://identifiers.org/ito:ITO_16372,A Repository of Conversational Datasets
PolyAI AmazonQA,https://identifiers.org/ito:ITO_16370,ConveRT: Efficient and Accurate Conversational Representations from Transformers
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_16366,The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_16364,Improved Deep Learning Baselines for Ubuntu Corpus Dialogs
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_60336,Multi-view Response Selection for Human-Computer Conversation
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_16361,Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_16359,Modeling Multi-turn Conversation with Deep Utterance Aggregation
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_60321,Multi-Turn Response Selection for Chatbots with Deep Attention Matching Network
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_16344,Sequential Attention-based Network for Noetic End-to-End Response Selection
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_16381,Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_39562,Learning an Effective Context-Response Matching Model with Self-Supervised Tasks for Retrieval-based Dialogues
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_60316,Fine-grained Post-training for Improving Retrieval-based Dialogue Systems
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_16347,Interactive Matching Network for Multi-Turn Response Selection in Retrieval-Based Chatbots
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_60334,One Time of Interaction May Not Be Enough: Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_39568,Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots
PolyAI Reddit,https://identifiers.org/ito:ITO_07964,Deep contextualized word representations
PolyAI Reddit,https://identifiers.org/ito:ITO_11090,Universal Sentence Encoder
PolyAI Reddit,https://identifiers.org/ito:ITO_16372,A Repository of Conversational Datasets
PolyAI Reddit,https://identifiers.org/ito:ITO_16370,ConveRT: Efficient and Accurate Conversational Representations from Transformers
PolyAI OpenSubtitles,https://identifiers.org/ito:ITO_16372,A Repository of Conversational Datasets
Douban,https://identifiers.org/ito:ITO_16361,Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots
Douban,https://identifiers.org/ito:ITO_16359,Modeling Multi-turn Conversation with Deep Utterance Aggregation
Douban,https://identifiers.org/ito:ITO_60321,Multi-Turn Response Selection for Chatbots with Deep Attention Matching Network
Douban,https://identifiers.org/ito:ITO_16347,Interactive Matching Network for Multi-Turn Response Selection in Retrieval-Based Chatbots
Douban,https://identifiers.org/ito:ITO_16381,Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring
Douban,https://identifiers.org/ito:ITO_39568,Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots
Douban,https://identifiers.org/ito:ITO_39564,Do Response Selection Models Really Know What's Next? Utterance Manipulation Strategies for Multi-turn Response Selection
Douban,https://identifiers.org/ito:ITO_60319,Dialogue Response Selection with Hierarchical Curriculum Learning
Douban,https://identifiers.org/ito:ITO_60316,Fine-grained Post-training for Improving Retrieval-based Dialogue Systems
Douban,https://identifiers.org/ito:ITO_39566,An Effective Domain Adaptive Post-Training Method for BERT in Response Selection
E-commerce,https://identifiers.org/ito:ITO_16361,Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots
E-commerce,https://identifiers.org/ito:ITO_37159,007: Democratically Finding The Cause of Packet Drops
E-commerce,https://identifiers.org/ito:ITO_39568,Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots
E-commerce,https://identifiers.org/ito:ITO_39562,Learning an Effective Context-Response Matching Model with Self-Supervised Tasks for Retrieval-based Dialogues
E-commerce,https://identifiers.org/ito:ITO_60316,Fine-grained Post-training for Improving Retrieval-based Dialogue Systems
E-commerce,https://identifiers.org/ito:ITO_60319,Dialogue Response Selection with Hierarchical Curriculum Learning
TREC-PM,https://identifiers.org/ito:ITO_16513,HPI-DHC at TREC 2018 Precision Medicine Track
MS MARCO,https://identifiers.org/ito:ITO_60493,Dimension Reduction for Efficient Dense Retrieval via Conditional Autoencoder
CQADupStack,https://identifiers.org/ito:ITO_49577,BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models
CQADupStack,https://identifiers.org/ito:ITO_49579,SGPT: GPT Sentence Embeddings for Semantic Search
BSARD,https://identifiers.org/ito:ITO_60501,A Statutory Article Retrieval Dataset in French
Ohsumed,https://identifiers.org/ito:ITO_60505,Semantic Enrichment of Pretrained Embedding Output for Unsupervised IR
ARQMath2 - Task 1,https://identifiers.org/ito:ITO_62745,Evaluating Token-Level and Passage-Level Dense Retrieval Models for Math Information Retrieval
MS MARCO,https://identifiers.org/ito:ITO_59521,Text and Code Embeddings by Contrastive Pre-Training
MSMARCO (BEIR),https://identifiers.org/ito:ITO_49577,BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models
Natural Questions,https://identifiers.org/ito:ITO_60524,Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation
Natural Questions,https://identifiers.org/ito:ITO_26321,Dense Passage Retrieval for Open-Domain Question Answering
Natural Questions,https://identifiers.org/ito:ITO_60520,Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval
Natural Questions,https://identifiers.org/ito:ITO_60516,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering
Natural Questions,https://identifiers.org/ito:ITO_60512,Domain-matched Pre-training Tasks for Dense Retrieval
Natural Questions,https://identifiers.org/ito:ITO_49899,R2-D2: A Modular Baseline for Open-Domain Question Answering
EntityQuestions,https://identifiers.org/ito:ITO_49694,Mention Memory: incorporating textual knowledge into Transformers through entity mention attention
TREC-PM,https://identifiers.org/ito:ITO_15961,Document Expansion by Query Prediction
MS MARCO,https://identifiers.org/ito:ITO_15963,Passage Re-ranking with BERT
MS MARCO,https://identifiers.org/ito:ITO_15961,Document Expansion by Query Prediction
Contract Discovery,https://identifiers.org/ito:ITO_40957,Contract Discovery: Dataset and a Few-Shot Semantic Retrieval Challenge with Competitive Baselines
LexNorm,https://identifiers.org/ito:ITO_53285,A Log-Linear Model for Unsupervised Text Normalization
LexNorm,https://identifiers.org/ito:ITO_53284,Tweet Normalization with Syllables
LexNorm,https://identifiers.org/ito:ITO_11042,MoNoise: Modeling Noise Using a Modular Normalization System
BEST-2010,https://identifiers.org/ito:ITO_40634,AttaCut: A Fast and Accurate Neural Thai Word Segmenter
BEST-2010,https://identifiers.org/ito:ITO_61219,ThaiLMCut: Unsupervised Pretraining for Thai Word Segmentation
Automatic Misogynistic Identification,https://identifiers.org/ito:ITO_12299,Hateminers : Detecting Hate speech against Women
Automatic Misogynistic Identification,https://identifiers.org/ito:ITO_29160,Deep Learning Models for Multilingual Hate Speech Detection
AbusEval,https://identifiers.org/ito:ITO_29115,HateBERT: Retraining BERT for Abusive Language Detection in English
"Waseem et al., 2018",https://identifiers.org/ito:ITO_29127,AAA: Fair Evaluation for Abuse Detection Systems Wanted
ToLD-Br,https://identifiers.org/ito:ITO_29142,Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis
HatEval,https://identifiers.org/ito:ITO_29115,HateBERT: Retraining BERT for Abusive Language Detection in English
Ethos MultiLabel,https://identifiers.org/ito:ITO_29148,ETHOS: an Online Hate Speech Detection Dataset
SHAJ,https://identifiers.org/ito:ITO_51871,Detecting Abusive Albanian
OffensEval 2019,https://identifiers.org/ito:ITO_29115,HateBERT: Retraining BERT for Abusive Language Detection in English
HateXplain,https://identifiers.org/ito:ITO_51874,HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection
bajer_danish_misogyny,https://identifiers.org/ito:ITO_51878,Annotating Online Misogyny
Ethos Binary,https://identifiers.org/ito:ITO_29148,ETHOS: an Online Hate Speech Detection Dataset
Ethos Binary,https://identifiers.org/ito:ITO_51881,Hate speech detection using static BERT embeddings
Hostility Detection Dataset in Hindi,https://identifiers.org/ito:ITO_29165,Hostility Detection in Hindi leveraging Pre-Trained Language Models
DKhate,https://identifiers.org/ito:ITO_51892,Offensive Language and Hate Speech Detection for Danish
KanHope,https://identifiers.org/ito:ITO_51897,Hope Speech detection in under-resourced Kannada language
HopeEDI,https://identifiers.org/ito:ITO_51900,"HopeEDI: A Multilingual Hope Speech Detection Dataset for Equality, Diversity, and Inclusion"
HopeEDI,https://identifiers.org/ito:ITO_51899,TeamUNCC@LT-EDI-EACL2021: Hope Speech Detection using Transfer Learning with Transformers
PlantVillage_8px,https://identifiers.org/ito:ITO_61150,Uncovering bias in the PlantVillage dataset
StereoSet,https://identifiers.org/ito:ITO_17272,StereoSet: Measuring stereotypical bias in pretrained language models
Wiki Neutrality Corpus,https://identifiers.org/ito:ITO_40591,Towards Detection of Subjective Bias using Contextualized Word Embeddings
The ARRAU Corpus,https://identifiers.org/ito:ITO_34045,A Cluster Ranking Model for Full Anaphora Resolution
OntoGUM,https://identifiers.org/ito:ITO_55897,OntoGUM: Evaluating Contextualized SOTA Coreference Resolution on 12 More Genres
CoNLL 2012,https://identifiers.org/ito:ITO_12999,End-to-end Neural Coreference Resolution
CoNLL 2012,https://identifiers.org/ito:ITO_13010,Higher-order Coreference Resolution with Coarse-to-fine Inference
CoNLL 2012,https://identifiers.org/ito:ITO_55902,Coreference Resolution with Entity Equalization
CoNLL 2012,https://identifiers.org/ito:ITO_13004,BERT for Coreference Resolution: Baselines and Analysis
CoNLL 2012,https://identifiers.org/ito:ITO_55899,CorefQA: Coreference Resolution as Query-based Span Prediction
Winograd Schema Challenge,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
Winograd Schema Challenge,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
WSC,https://identifiers.org/ito:ITO_49638,PaLM: Scaling Language Modeling with Pathways
STM-coref,https://identifiers.org/ito:ITO_34057,Coreference Resolution in Research Papers from Multiple Domains
OntoNotes,https://identifiers.org/ito:ITO_13020,Learning Global Features for Coreference Resolution
OntoNotes,https://identifiers.org/ito:ITO_13019,Improving Coreference Resolution by Learning Entity-Level Distributed Representations
OntoNotes,https://identifiers.org/ito:ITO_13017,Deep Reinforcement Learning for Mention-Ranking Coreference Models
OntoNotes,https://identifiers.org/ito:ITO_12999,End-to-end Neural Coreference Resolution
OntoNotes,https://identifiers.org/ito:ITO_07964,Deep contextualized word representations
OntoNotes,https://identifiers.org/ito:ITO_13010,Higher-order Coreference Resolution with Coarse-to-fine Inference
OntoNotes,https://identifiers.org/ito:ITO_04751,SpanBERT: Improving Pre-training by Representing and Predicting Spans
OntoNotes,https://identifiers.org/ito:ITO_55901,Word-Level Coreference Resolution
GAP,https://identifiers.org/ito:ITO_34069,PeTra: A Sparsely Supervised Memory Model for People Tracking
GAP,https://identifiers.org/ito:ITO_34067,Gendered Pronoun Resolution using BERT and an extractive question answering formulation
GAP,https://identifiers.org/ito:ITO_55911,Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by Evidence Pooling
Youtube counterspeech dataset,https://identifiers.org/ito:ITO_38441,Thou shalt not hate: Countering Online Hate Speech
RECCON,https://identifiers.org/ito:ITO_61798,Recognizing Emotion Cause in Conversations
SEED-IV,https://identifiers.org/ito:ITO_18768,EEG-Based Emotion Recognition Using Regularized Graph Neural Networks
ECE,https://identifiers.org/ito:ITO_30346,A Question Answering Approach to Emotion Cause Extraction
ECE,https://identifiers.org/ito:ITO_30342,RTHN: A RNN-Transformer Hierarchical Network for Emotion Cause Extraction
RAVDESS,https://identifiers.org/ito:ITO_53034,ERANNs: Efficient Residual Audio Neural Networks for Audio Pattern Recognition
RAVDESS,https://identifiers.org/ito:ITO_53032,Multimodal Emotion Recognition on RAVDESS Dataset Using Transfer Learning
RAVDESS,https://identifiers.org/ito:ITO_53028,A proposal for Multimodal Emotion Recognition using aural transformers and Action Units on RAVDESS dataset
SEED,https://identifiers.org/ito:ITO_30255,4D Attention-based Neural Network for EEG Emotion Recognition
MPED,https://identifiers.org/ito:ITO_18765,A Novel Bi-hemispheric Discrepancy Model for EEG Emotion Recognition
MSP-Podcast,https://identifiers.org/ito:ITO_53042,Dawn of the transformer era in speech emotion recognition: closing the valence gap
Emomusic,https://identifiers.org/ito:ITO_53048,Codified audio language modeling learns useful representations for music information retrieval
EMOTIC,https://identifiers.org/ito:ITO_30358,Context-Aware Emotion Recognition Networks
EMOTIC,https://identifiers.org/ito:ITO_30350,EmotiCon: Context-Aware Multimodal Emotion Recognition using Frege's Principle
EmoWoz,https://identifiers.org/ito:ITO_53090,EmoWOZ: A Large-Scale Corpus and Labelling Scheme for Emotion Recognition in Task-Oriented Dialogue Systems
MELD,https://identifiers.org/ito:ITO_53129,Context-Dependent Sentiment Analysis in User-Generated Videos
MELD,https://identifiers.org/ito:ITO_10888,DialogueRNN: An Attentive RNN for Emotion Detection in Conversations
MELD,https://identifiers.org/ito:ITO_30299,DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations
MELD,https://identifiers.org/ito:ITO_53126,MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations
MELD,https://identifiers.org/ito:ITO_53095,M2FNet: Multi-modal Fusion Network for Emotion Recognition in Conversation
MELD,https://identifiers.org/ito:ITO_30302,Modeling both context- and speaker-sensitive dependence for emotion detection in multi-speaker conversations
MELD,https://identifiers.org/ito:ITO_10886,DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation
MELD,https://identifiers.org/ito:ITO_10909,Knowledge-Enriched Transformer for Emotion Detection in Textual Conversations
MELD,https://identifiers.org/ito:ITO_30268,Multi-Task Learning with Auxiliary Speaker Identification for Conversational Emotion Recognition
MELD,https://identifiers.org/ito:ITO_30264,COSMIC: COmmonSense knowledge for eMotion Identification in Conversations
MELD,https://identifiers.org/ito:ITO_30286,Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection
MELD,https://identifiers.org/ito:ITO_53097,CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation
EmoryNLP,https://identifiers.org/ito:ITO_30286,Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection
EmoryNLP,https://identifiers.org/ito:ITO_53109,Contrast and Generation Make BART a Good Dialogue Emotion Recognizer
EmoryNLP,https://identifiers.org/ito:ITO_10909,Knowledge-Enriched Transformer for Emotion Detection in Textual Conversations
EmoryNLP,https://identifiers.org/ito:ITO_30268,Multi-Task Learning with Auxiliary Speaker Identification for Conversational Emotion Recognition
EmoryNLP,https://identifiers.org/ito:ITO_30264,COSMIC: COmmonSense knowledge for eMotion Identification in Conversations
EmoryNLP,https://identifiers.org/ito:ITO_53114,Directed Acyclic Graph Network for Conversational Emotion Recognition
EmoryNLP,https://identifiers.org/ito:ITO_45693,Graph Based Network with Contextualized Representations of Turns in Dialogue
CPED,https://identifiers.org/ito:ITO_09582,Convolutional Neural Networks for Sentence Classification
CPED,https://identifiers.org/ito:ITO_53139,Recurrent Convolutional Neural Networks for Text Classification
CPED,https://identifiers.org/ito:ITO_53129,Context-Dependent Sentiment Analysis in User-Generated Videos
CPED,https://identifiers.org/ito:ITO_30270,DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition
SEMAINE,https://identifiers.org/ito:ITO_53129,Context-Dependent Sentiment Analysis in User-Generated Videos
SEMAINE,https://identifiers.org/ito:ITO_53144,ICON: Interactive Conversational Memory Network for Multimodal Emotion Detection
SEMAINE,https://identifiers.org/ito:ITO_10888,DialogueRNN: An Attentive RNN for Emotion Detection in Conversations
SEMAINE,https://identifiers.org/ito:ITO_10886,DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation
SEMAINE,https://identifiers.org/ito:ITO_21287,Hierarchical Pre-training for Sequence Labelling in Spoken Dialog
SEMAINE,https://identifiers.org/ito:ITO_30299,DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations
DailyDialog,https://identifiers.org/ito:ITO_30264,COSMIC: COmmonSense knowledge for eMotion Identification in Conversations
DailyDialog,https://identifiers.org/ito:ITO_53097,CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation
DailyDialog,https://identifiers.org/ito:ITO_10909,Knowledge-Enriched Transformer for Emotion Detection in Textual Conversations
DailyDialog,https://identifiers.org/ito:ITO_53128,Contextualized Emotion Recognition in Conversation as Sequence Tagging
DailyDialog,https://identifiers.org/ito:ITO_53117,S+PAGE: A Speaker and Position-Aware Graph Neural Network Model for Emotion Recognition in Conversation
DailyDialog,https://identifiers.org/ito:ITO_30286,Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection
DailyDialog,https://identifiers.org/ito:ITO_53109,Contrast and Generation Make BART a Good Dialogue Emotion Recognizer
IEMOCAP,https://identifiers.org/ito:ITO_53129,Context-Dependent Sentiment Analysis in User-Generated Videos
IEMOCAP,https://identifiers.org/ito:ITO_53145,Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos
IEMOCAP,https://identifiers.org/ito:ITO_53144,ICON: Interactive Conversational Memory Network for Multimodal Emotion Detection
IEMOCAP,https://identifiers.org/ito:ITO_10888,DialogueRNN: An Attentive RNN for Emotion Detection in Conversations
IEMOCAP,https://identifiers.org/ito:ITO_10886,DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation
IEMOCAP,https://identifiers.org/ito:ITO_30293,BiERU: Bidirectional Emotional Recurrent Unit for Conversational Sentiment Analysis
IEMOCAP,https://identifiers.org/ito:ITO_53127,Summarize before Aggregate: A Global-to-local Heterogeneous Graph Inference Network for Conversational Emotion Recognition
IEMOCAP,https://identifiers.org/ito:ITO_53126,MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations
IEMOCAP,https://identifiers.org/ito:ITO_53095,M2FNet: Multi-modal Fusion Network for Emotion Recognition in Conversation
IEMOCAP,https://identifiers.org/ito:ITO_30286,Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection
IEMOCAP,https://identifiers.org/ito:ITO_53109,Contrast and Generation Make BART a Good Dialogue Emotion Recognizer
IEMOCAP,https://identifiers.org/ito:ITO_30299,DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations
IEMOCAP,https://identifiers.org/ito:ITO_53128,Contextualized Emotion Recognition in Conversation as Sequence Tagging
IEMOCAP,https://identifiers.org/ito:ITO_53114,Directed Acyclic Graph Network for Conversational Emotion Recognition
IEMOCAP,https://identifiers.org/ito:ITO_53104,EmoBERTa: Speaker-Aware Emotion Recognition in Conversation with RoBERTa
IEMOCAP,https://identifiers.org/ito:ITO_53148,Hybrid Curriculum Learning for Emotion Recognition in Conversation
IEMOCAP,https://identifiers.org/ito:ITO_53113,EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition
EC,https://identifiers.org/ito:ITO_10903,ANA at SemEval-2019 Task 3: Contextual Emotion detection in Conversations through hierarchical LSTMs and BERT
EC,https://identifiers.org/ito:ITO_10899,NELEC at SemEval-2019 Task 3: Think Twice Before Going Deep
EmotionPush,https://identifiers.org/ito:ITO_30279,Hierarchical Transformer Network for Utterance-level Emotion Recognition
ECPE-FanSplit,https://identifiers.org/ito:ITO_53168,Effective Inter-Clause Modeling for End-to-End Emotion-Cause Pair Extraction
ECPE,https://identifiers.org/ito:ITO_30334,Emotion-Cause Pair Extraction: A New Task to Emotion Analysis in Texts
ECPE,https://identifiers.org/ito:ITO_30332,End-to-end Emotion-Cause Pair Extraction via Learning to Link
ECPE,https://identifiers.org/ito:ITO_53168,Effective Inter-Clause Modeling for End-to-End Emotion-Cause Pair Extraction
RAVDESS,https://identifiers.org/ito:ITO_53030,Self-attention fusion for audiovisual emotion recognition with incomplete data
Expressive hands and faces dataset (EHF).,https://identifiers.org/ito:ITO_10878,Multi-Modal Emotion recognition on IEMOCAP Dataset using Deep Learning
IEMOCAP,https://identifiers.org/ito:ITO_10865,Multimodal Sentiment Analysis using Hierarchical Fusion with Context Modeling
IEMOCAP,https://identifiers.org/ito:ITO_53166,Combining deep and unsupervised features for multilingual speech emotion recognition
IEMOCAP,https://identifiers.org/ito:ITO_53164,COGMEN: COntextualized GNN based Multimodal Emotion recognitioN
EmoCause,https://identifiers.org/ito:ITO_61792,Perspective-taking and Pragmatics for Generating Empathetic Responses Focused on Emotion Causes
ShEMO,https://identifiers.org/ito:ITO_53052,Emotion Recognition In Persian Speech Using Deep Neural Networks
MSP-Podcast (Valence),https://identifiers.org/ito:ITO_53057,Contrastive Unsupervised Learning for Speech Emotion Recognition
RAVDESS,https://identifiers.org/ito:ITO_53060,Shallow over Deep Neural Networks: A empirical analysis for human emotion classification using audio data
MSP-Podcast (Dominance),https://identifiers.org/ito:ITO_53057,Contrastive Unsupervised Learning for Speech Emotion Recognition
MSP-Podcast (Activation),https://identifiers.org/ito:ITO_53057,Contrastive Unsupervised Learning for Speech Emotion Recognition
IEMOCAP,https://identifiers.org/ito:ITO_10915,Multimodal Speech Emotion Recognition and Ambiguity Resolution
IEMOCAP,https://identifiers.org/ito:ITO_10913,CNN+LSTM Architecture for Speech Emotion Recognition with Data Augmentation
IEMOCAP,https://identifiers.org/ito:ITO_53071,Empirical Interpretation of Speech Emotion Perception with Attention Based Model for Speech Emotion Recognition
IEMOCAP,https://identifiers.org/ito:ITO_53075,Speech Emotion Recognition with Multi-Task Learning
IEMOCAP,https://identifiers.org/ito:ITO_53073,Speech Emotion Recognition Using Speech Feature and Word Embedding
IEMOCAP,https://identifiers.org/ito:ITO_53069,Context-Dependent Domain Adversarial Neural Network for Multimodal Emotion Recognition
CREMA-D,https://identifiers.org/ito:ITO_53086,Visually Guided Self Supervised Learning of Speech Representations
CREMA-D,https://identifiers.org/ito:ITO_53085,Non-linear Neurons with Human-like Apical Dendrite Activations
CREMA-D,https://identifiers.org/ito:ITO_53083,Self-paced ensemble learning for speech and audio classification
CREMA-D,https://identifiers.org/ito:ITO_53081,SepTr: Separable Transformer for Audio Spectrogram Processing
CREMA-D,https://identifiers.org/ito:ITO_53079,LeRaC: Learning Rate Curriculum
Events2012 - Oct 11 to Oct 17,https://identifiers.org/ito:ITO_56044,SEDTWik: Segmentation-based Event Detection from Tweets Using Wikipedia
KILT: FEVER,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: FEVER,https://identifiers.org/ito:ITO_49915,"Re2G: Retrieve, Rerank, Generate"
FEVER,https://identifiers.org/ito:ITO_41144,GEAR: Graph-based Evidence Aggregating and Reasoning for Fact Verification
FEVER,https://identifiers.org/ito:ITO_41142,Fine-grained Fact Verification with Kernel Graph Attention Network
FEVER,https://identifiers.org/ito:ITO_26323,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
Social media,https://identifiers.org/ito:ITO_32177,Exploring Text-transformers in AAAI 2021 Shared Task: COVID-19 Fake News Detection in English
LIAR,https://identifiers.org/ito:ITO_54658,"""Liar, Liar Pants on Fire"": A New Benchmark Dataset for Fake News Detection"
Grover-Mega,https://identifiers.org/ito:ITO_32179,Defending Against Neural Fake News
Grover-Mega,https://identifiers.org/ito:ITO_32177,Exploring Text-transformers in AAAI 2021 Shared Task: COVID-19 Fake News Detection in English
COVID-19 Fake News Dataset,https://identifiers.org/ito:ITO_32173,A Heuristic-driven Ensemble Framework for COVID-19 Fake News Detection
MediaEval2016,https://identifiers.org/ito:ITO_54668,SEMI-FND: Stacked Ensemble Based Multimodal Inference For Faster Fake News Detection
Weibo NER,https://identifiers.org/ito:ITO_54668,SEMI-FND: Stacked Ensemble Based Multimodal Inference For Faster Fake News Detection
FNC-1,https://identifiers.org/ito:ITO_12266,A simple but tough-to-beat baseline for the Fake News Challenge stance detection task
FNC-1,https://identifiers.org/ito:ITO_12263,"On the Benefit of Combining Neural, Statistical and External Features for Fake News Identification"
FNC-1,https://identifiers.org/ito:ITO_54672,Exploring Summarization to Enhance Headline Stance Detection
FNC-1,https://identifiers.org/ito:ITO_09524,Combining Similarity Features and Deep Representation Learning for Stance Detection in the Context of Checking Fake News
200k Short Texts for Humor Detection,https://identifiers.org/ito:ITO_38970,XGBoost: A Scalable Tree Boosting System
200k Short Texts for Humor Detection,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
200k Short Texts for Humor Detection,https://identifiers.org/ito:ITO_38967,ColBERT: Using BERT Sentence Embedding for Humor Detection
SLURP,https://identifiers.org/ito:ITO_53913,SLURP: A Spoken Language Understanding Resource Package
SLURP,https://identifiers.org/ito:ITO_51727,"A Fine-tuned Wav2vec 2.0/HuBERT Benchmark For Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding"
KUAKE-QIC,https://identifiers.org/ito:ITO_51428,CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark
ORCAS-I,https://identifiers.org/ito:ITO_53919,ORCAS-I: Queries Annotated with Intent using Weak Supervision
MASSIVE,https://identifiers.org/ito:ITO_53923,MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages
ASOS.com user intent,https://identifiers.org/ito:ITO_12229,“Where is My Parcel?” Fast and Efficient Classifiers to Detect User Intent in Natural Language
MixATIS,https://identifiers.org/ito:ITO_32055,GL-GIN: Fast and Accurate Non-Autoregressive Model for Joint Multiple Intent Detection and Slot Filling
MixSNIPS,https://identifiers.org/ito:ITO_32055,GL-GIN: Fast and Accurate Non-Autoregressive Model for Joint Multiple Intent Detection and Slot Filling
ATIS,https://identifiers.org/ito:ITO_32116,Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling
ATIS,https://identifiers.org/ito:ITO_32058,A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling
SNIPS,https://identifiers.org/ito:ITO_54573,Slot-Gated Modeling for Joint Slot Filling and Intent Prediction
SNIPS,https://identifiers.org/ito:ITO_12217,Joint Slot Filling and Intent Detection via Capsule Neural Networks
SNIPS,https://identifiers.org/ito:ITO_12215,A Novel Bi-directional Interrelated Model for Joint Intent Detection and Slot Filling
SNIPS,https://identifiers.org/ito:ITO_32104,A Stack-Propagation Framework with Token-Level Intent Detection for Spoken Language Understanding
StackOverFlow(75%known),https://identifiers.org/ito:ITO_54578,Deep Open Intent Classification with Adaptive Decision Boundary
SNIPS (50% known),https://identifiers.org/ito:ITO_54582,Deep Unknown Intent Detection with Margin Loss
SNIPS (25% known),https://identifiers.org/ito:ITO_54582,Deep Unknown Intent Detection with Margin Loss
StackOverFlow(25%known),https://identifiers.org/ito:ITO_54578,Deep Open Intent Classification with Adaptive Decision Boundary
BANKING77 (25%known),https://identifiers.org/ito:ITO_54578,Deep Open Intent Classification with Adaptive Decision Boundary
BANKING-77 (50% known),https://identifiers.org/ito:ITO_54578,Deep Open Intent Classification with Adaptive Decision Boundary
OOS(75%known),https://identifiers.org/ito:ITO_54578,Deep Open Intent Classification with Adaptive Decision Boundary
BANKING-77 (75% known),https://identifiers.org/ito:ITO_54578,Deep Open Intent Classification with Adaptive Decision Boundary
SNIPS (75% known),https://identifiers.org/ito:ITO_54582,Deep Unknown Intent Detection with Margin Loss
ATIS (50% known),https://identifiers.org/ito:ITO_54582,Deep Unknown Intent Detection with Margin Loss
ATIS (25% known),https://identifiers.org/ito:ITO_54582,Deep Unknown Intent Detection with Margin Loss
StackOverFlow(50%known),https://identifiers.org/ito:ITO_54578,Deep Open Intent Classification with Adaptive Decision Boundary
OOS(25%known),https://identifiers.org/ito:ITO_54578,Deep Open Intent Classification with Adaptive Decision Boundary
OOS(50%known),https://identifiers.org/ito:ITO_54578,Deep Open Intent Classification with Adaptive Decision Boundary
SLAM 2018,https://identifiers.org/ito:ITO_59782,Context Based Approach for Second Language Acquisition
_sem 2012 Shared Task: Sherlock Dataset,https://identifiers.org/ito:ITO_29199,NegBERT: A Transfer Learning Approach for Negation Detection and Scope Resolution
BioScope : Full Papers,https://identifiers.org/ito:ITO_29199,NegBERT: A Transfer Learning Approach for Negation Detection and Scope Resolution
BioScope : Full Papers,https://identifiers.org/ito:ITO_10041,Resolving the Scope of Speculation and Negation using Transformer-Based Architectures
BioScope : Abstracts,https://identifiers.org/ito:ITO_29199,NegBERT: A Transfer Learning Approach for Negation Detection and Scope Resolution
BioScope : Abstracts,https://identifiers.org/ito:ITO_10041,Resolving the Scope of Speculation and Negation using Transformer-Based Architectures
SFU Review Corpus,https://identifiers.org/ito:ITO_29199,NegBERT: A Transfer Learning Approach for Negation Detection and Scope Resolution
SFU Review Corpus,https://identifiers.org/ito:ITO_10041,Resolving the Scope of Speculation and Negation using Transformer-Based Architectures
MRPC,https://identifiers.org/ito:ITO_28696,Pay Attention when Required
MSRP,https://identifiers.org/ito:ITO_53320,Discriminative Improvements to Distributional Sentence Similarity
Quora Question Pairs,https://identifiers.org/ito:ITO_09571,Bilateral Multi-Perspective Matching for Natural Language Sentences
Quora Question Pairs,https://identifiers.org/ito:ITO_13840,Neural Paraphrase Identification of Questions with Noisy Pretraining
Quora Question Pairs,https://identifiers.org/ito:ITO_09568,Natural Language Inference over Interaction Space
Quora Question Pairs,https://identifiers.org/ito:ITO_09558,Multiway Attention Networks for Modeling Sentence Pairs
Quora Question Pairs,https://identifiers.org/ito:ITO_28511,Training Complex Models with Multi-Task Weak Supervision
Quora Question Pairs,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
Quora Question Pairs,https://identifiers.org/ito:ITO_28463,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
Quora Question Pairs,https://identifiers.org/ito:ITO_51425,RealFormer: Transformer Likes Residual Attention
Quora Question Pairs,https://identifiers.org/ito:ITO_51426,Charformer: Fast Character Transformers via Gradient-based Subword Tokenization
Quora Question Pairs,https://identifiers.org/ito:ITO_44561,"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language"
Quora Question Pairs,https://identifiers.org/ito:ITO_26088,Entailment as Few-Shot Learner
Quora Question Pairs,https://identifiers.org/ito:ITO_49493,Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning
2017_test set,https://identifiers.org/ito:ITO_13842,"Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering"
WikiHop,https://identifiers.org/ito:ITO_28463,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
PIT,https://identifiers.org/ito:ITO_53358,TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning
TURL,https://identifiers.org/ito:ITO_53358,TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning
AP,https://identifiers.org/ito:ITO_53363,Improving Paraphrase Detection with the Adversarial Paraphrasing Task
WITS,https://identifiers.org/ito:ITO_54675,"When did you become so smart, oh wise one?! Sarcasm Explanation in Multi-modal Multi-party Dialogues"
SARC (all-bal),https://identifiers.org/ito:ITO_12284,A Large Self-Annotated Corpus for Sarcasm
SARC (all-bal),https://identifiers.org/ito:ITO_12289,CASCADE: Contextual Sarcasm Detection in Online Discussion Forums
SARC (pol-bal),https://identifiers.org/ito:ITO_12284,A Large Self-Annotated Corpus for Sarcasm
MUStARD++,https://identifiers.org/ito:ITO_54681,A Multimodal Corpus for Emotion Recognition in Sarcasm
SARC (pol-unbal),https://identifiers.org/ito:ITO_12284,A Large Self-Annotated Corpus for Sarcasm
FigLang 2020 Twitter Dataset,https://identifiers.org/ito:ITO_32202,Sarcasm Detection using Context Separators in Online Discourse
iSarcasm,https://identifiers.org/ito:ITO_54688,UTNLP at SemEval-2022 Task 6: A Comparative Analysis of Sarcasm Detection Using Generative-based and Mutation-based Data Augmentation
SCv1,https://identifiers.org/ito:ITO_12293,"Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm"
FigLang 2020 Reddit Dataset,https://identifiers.org/ito:ITO_32202,Sarcasm Detection using Context Separators in Online Discourse
FigLang 2020 Reddit Dataset,https://identifiers.org/ito:ITO_54684,Applying Transformers and Aspect-based Sentiment Analysis approaches on Sarcasm Detection
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_59466,Latent Aspect Detection from Online Unsolicited Customer Reviews
Citysearch,https://identifiers.org/ito:ITO_59470,Embarrassingly Simple Unsupervised Aspect Extraction
SemEval 2014 Task 4 Subtask 3,https://identifiers.org/ito:ITO_11815,Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence
SemEval-2016 Task 5 Subtask 1 (Russian),https://identifiers.org/ito:ITO_31509,Structure-Level Knowledge Distillation For Multilingual Sequence Labeling
SemEval-2016 Task 5 Subtask 1 (Russian),https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
SemEval 2016 Task 5 Sub Task 1 Slot 2,https://identifiers.org/ito:ITO_31459,Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction
SemEval-2016 Task 5 Subtask 1 (Turkish),https://identifiers.org/ito:ITO_31509,Structure-Level Knowledge Distillation For Multilingual Sequence Labeling
SemEval-2016 Task 5 Subtask 1 (Turkish),https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
SemEval-2016 Task 5 Subtask 1,https://identifiers.org/ito:ITO_31509,Structure-Level Knowledge Distillation For Multilingual Sequence Labeling
SemEval-2016 Task 5 Subtask 1,https://identifiers.org/ito:ITO_54078,Don't Eclipse Your Arts Due to Small Discrepancies: Boundary Repositioning with a Pointer Network for Aspect Extraction
SemEval-2016 Task 5 Subtask 1,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
SemEval 2015 Task 12,https://identifiers.org/ito:ITO_31459,Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction
SemEval 2015 Task 12,https://identifiers.org/ito:ITO_54078,Don't Eclipse Your Arts Due to Small Discrepancies: Boundary Repositioning with a Pointer Network for Aspect Extraction
SemEval 2015 Task 12,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
SemEval-2016 Task 5 Subtask 1 (Spanish),https://identifiers.org/ito:ITO_31509,Structure-Level Knowledge Distillation For Multilingual Sequence Labeling
SemEval-2016 Task 5 Subtask 1 (Spanish),https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
SemEval 2014 Task 4 Sub Task 1,https://identifiers.org/ito:ITO_31459,Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction
SemEval-2016 Task 5 Subtask 1 (Dutch),https://identifiers.org/ito:ITO_31509,Structure-Level Knowledge Distillation For Multilingual Sequence Labeling
SemEval-2016 Task 5 Subtask 1 (Dutch),https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_31477,Adversarial Training for Aspect-Based Sentiment Analysis with BERT
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_31475,Improving BERT Performance for Aspect-Based Sentiment Analysis
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_31459,Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_54078,Don't Eclipse Your Arts Due to Small Discrepancies: Boundary Repositioning with a Pointer Network for Aspect Extraction
Res14,https://identifiers.org/ito:ITO_31573,Grid Tagging Scheme for Aspect-oriented Fine-grained Opinion Extraction
ASTE-Data-V2,https://identifiers.org/ito:ITO_31573,Grid Tagging Scheme for Aspect-oriented Fine-grained Opinion Extraction
ASTE-Data-V2,https://identifiers.org/ito:ITO_54127,Learning Span-Level Interactions for Aspect Sentiment Triplet Extraction
ASTE-Data-V2,https://identifiers.org/ito:ITO_54125,Towards Generative Aspect-Based Sentiment Analysis
SemEval,https://identifiers.org/ito:ITO_31577,"Knowing What, How and Why: A Near Complete Solution for Aspect-based Sentiment Analysis"
SemEval,https://identifiers.org/ito:ITO_31575,Position-Aware Tagging for Aspect Sentiment Triplet Extraction
SemEval,https://identifiers.org/ito:ITO_31533,A Joint Training Dual-MRC Framework for Aspect Based Sentiment Analysis
SemEval,https://identifiers.org/ito:ITO_31531,A Unified Generative Framework for Aspect-Based Sentiment Analysis
SemEval,https://identifiers.org/ito:ITO_31394,Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification
SemEval,https://identifiers.org/ito:ITO_53966,Relation-Aware Collaborative Learning for Unified Aspect-Based Sentiment Analysis
SemEval,https://identifiers.org/ito:ITO_11767,An Interactive Multi-Task Learning Network for End-to-End Aspect-Based Sentiment Analysis
Restaurant-ACOS,https://identifiers.org/ito:ITO_54094,Aspect-Category-Opinion-Sentiment Quadruple Extraction with Implicit Aspects and Opinions
Laptop-ACOS,https://identifiers.org/ito:ITO_54094,Aspect-Category-Opinion-Sentiment Quadruple Extraction with Implicit Aspects and Opinions
Res14,https://identifiers.org/ito:ITO_54090,A More Fine-Grained Aspect-Sentiment-Opinion Triplet Extraction Task
SemEval 2014 Task 4 Sub Task 1,https://identifiers.org/ito:ITO_31461,Recursive Neural Conditional Random Fields for Aspect-based Sentiment Analysis
SemEval 2014 Task 4 Sub Task 1,https://identifiers.org/ito:ITO_11763,BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis
SemEval 2015 Task 12,https://identifiers.org/ito:ITO_11831,A Hybrid Approach for Aspect-Based Sentiment Analysis Using a Lexicalized Domain Ontology and Attentional Neural Models
SemEval 2015 Task 12,https://identifiers.org/ito:ITO_11829,A Hybrid Approach for Aspect-Based Sentiment Analysis Using Deep Contextual Word Embeddings and Hierarchical Attention
SemEval 2014 Task 4 Subtask 4,https://identifiers.org/ito:ITO_54039,SemEval-2014 Task 4: Aspect Based Sentiment Analysis
SemEval 2014 Task 4 Subtask 4,https://identifiers.org/ito:ITO_11815,Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence
Lap14,https://identifiers.org/ito:ITO_54043,Learn from Structural Scope: Improving Aspect-Level Sentiment Analysis with Hybrid Graph Convolutional Networks
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11808,Effective LSTMs for Target-Dependent Sentiment Classification
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11791,Aspect Level Sentiment Classification with Deep Memory Network
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_54053,Recurrent Attention Network on Memory for Aspect Sentiment Analysis
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11778,Left-Center-Right Separated Neural Network for Aspect-based Sentiment Analysis with Rotatory Attention
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11775,Learning Latent Opinions for Aspect-Level Sentiment Classification
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11773,Transformation Networks for Target-Oriented Sentiment Classification
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_54050,Hierarchical Attention Based Position-Aware Network for Aspect-Level Sentiment Analysis
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11666,Attentional Encoder Network for Targeted Sentiment Classification
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11761,Modeling Sentiment Dependencies with Graph Convolutional Networks for Aspect-level Sentiment Classification
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11757,Adapt or Get Left Behind: Domain Adaptation through BERT Language Model Finetuning for Aspect-Target Sentiment Classification
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11755,A Multi-task Learning Model for Chinese-oriented Aspect Polarity Classification and Aspect Term Extraction
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_54047,Back to Reality: Leveraging Pattern-driven Modeling to Enable Affordable Sentiment Dependency Learning
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_11763,BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_31472,Does syntax matter? A strong baseline for Aspect-based Sentiment Analysis with RoBERTa
MAMS,https://identifiers.org/ito:ITO_54063,A Challenge Dataset and Effective Models for Aspect-Based Sentiment Analysis
MAMS,https://identifiers.org/ito:ITO_31445,Investigating Typed Syntactic Dependencies for Targeted Sentiment Classification Using Graph Attention Neural Network
Rest15,https://identifiers.org/ito:ITO_54043,Learn from Structural Scope: Improving Aspect-Level Sentiment Analysis with Hybrid Graph Convolutional Networks
Rest14,https://identifiers.org/ito:ITO_54043,Learn from Structural Scope: Improving Aspect-Level Sentiment Analysis with Hybrid Graph Convolutional Networks
Sentihood,https://identifiers.org/ito:ITO_11825,SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods
Sentihood,https://identifiers.org/ito:ITO_31452,Recurrent Entity Networks with Delayed Memory Update for Targeted Aspect-based Sentiment Analysis
Sentihood,https://identifiers.org/ito:ITO_11815,Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence
Rest16,https://identifiers.org/ito:ITO_54043,Learn from Structural Scope: Improving Aspect-Level Sentiment Analysis with Hybrid Graph Convolutional Networks
SemEval-2016 Task 5 Subtask 1,https://identifiers.org/ito:ITO_11831,A Hybrid Approach for Aspect-Based Sentiment Analysis Using a Lexicalized Domain Ontology and Attentional Neural Models
SemEval-2016 Task 5 Subtask 1,https://identifiers.org/ito:ITO_31467,Does BERT Understand Sentiment? Leveraging Comparisons Between Contextual and Non-Contextual Embeddings to Improve Aspect-Based Sentiment Models
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_54086,Target-oriented Opinion Words Extraction with Target-fused Neural Sequence Labeling
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_31537,Latent Opinions Transfer Network for Target-Oriented Opinion Words Extraction
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_31535,Introducing Syntactic Structures into Target Opinion Word Extraction with Deep Learning
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_31533,A Joint Training Dual-MRC Framework for Aspect Based Sentiment Analysis
SemEval 2014 Task 4 Sub Task 2,https://identifiers.org/ito:ITO_31531,A Unified Generative Framework for Aspect-Based Sentiment Analysis
SemEval 2015 Task 12,https://identifiers.org/ito:ITO_11840,Review highlights: opinion mining on reviews: a hybrid model for rule selection in aspect extraction
MPQA,https://identifiers.org/ito:ITO_11863,SRL4ORL: Improving Opinion Role Labeling using Multi-task Learning with Semantic Role Labeling
MPQA,https://identifiers.org/ito:ITO_54136,Enhancing Opinion Role Labeling with Semantic-Aware Word Representations from Semantic Role Labeling
CMU-MOSI,https://identifiers.org/ito:ITO_54103,TEASEL: A Transformer-Based Speech-Prefixed Language Model
CMU-MOSI,https://identifiers.org/ito:ITO_54109,TransModality: An End2End Fusion Method with Transformer for Multimodal Sentiment Analysis
MOSI,https://identifiers.org/ito:ITO_53129,Context-Dependent Sentiment Analysis in User-Generated Videos
MOSI,https://identifiers.org/ito:ITO_54113,Contextual Inter-modal Attention for Multi-modal Sentiment Analysis
MOSI,https://identifiers.org/ito:ITO_31546,Multimodal Transformer for Unaligned Multimodal Language Sequences
MOSI,https://identifiers.org/ito:ITO_31544,Gated Mechanism for Attention Based Multimodal Sentiment Analysis
MOSI,https://identifiers.org/ito:ITO_54112,Cross-Modal BERT for Text-Audio Sentiment Analysis
B-T4SA,https://identifiers.org/ito:ITO_31561,An AutoML-based Approach to Multimodal Image Sentiment Analysis
CMU-MOSEI,https://identifiers.org/ito:ITO_54121,Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph
CMU-MOSEI,https://identifiers.org/ito:ITO_31556,Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection and Sentiment Analysis in Conversation
CMU-MOSEI,https://identifiers.org/ito:ITO_31555,A Transformer-based joint-encoding for Emotion Recognition and Sentiment Analysis
AJGT,https://identifiers.org/ito:ITO_31328,AraBERT: Transformer-based Model for Arabic Language Understanding
IITP Product Reviews Sentiment,https://identifiers.org/ito:ITO_49979,"IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages"
IITP Product Reviews Sentiment,https://identifiers.org/ito:ITO_49977,Does Transliteration Help Multilingual Language Modeling?
DBRD,https://identifiers.org/ito:ITO_31281,BERTje: A Dutch BERT Model
DBRD,https://identifiers.org/ito:ITO_31278,RobBERT: a Dutch RoBERTa-based Language Model
Financial PhraseBank,https://identifiers.org/ito:ITO_11672,FinBERT: Financial Sentiment Analysis with Pre-trained Language Models
FiQA,https://identifiers.org/ito:ITO_31240,Financial Aspect and Sentiment Predictions with Deep Neural Networks: An Ensemble Approach
FiQA,https://identifiers.org/ito:ITO_31238,Financial Aspect-Based Sentiment Analysis using Deep Representations
FiQA,https://identifiers.org/ito:ITO_11672,FinBERT: Financial Sentiment Analysis with Pre-trained Language Models
ArSAS,https://identifiers.org/ito:ITO_53946,Mazajak: An Online Arabic Sentiment Analyser
Yelp Fine-grained classification,https://identifiers.org/ito:ITO_11624,Character-level Convolutional Networks for Text Classification
Yelp Fine-grained classification,https://identifiers.org/ito:ITO_11626,Squeezed Very Deep Convolutional Neural Networks for Text Classification
SemEval 2017 Task 4-A,https://identifiers.org/ito:ITO_11718,BB_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and LSTMs
ASTD,https://identifiers.org/ito:ITO_53946,Mazajak: An Online Arabic Sentiment Analyser
HARD,https://identifiers.org/ito:ITO_31328,AraBERT: Transformer-based Model for Arabic Language Understanding
Latvian Twitter Eater Sentiment Dataset,https://identifiers.org/ito:ITO_31380,What Can We Learn From Almost a Decade of Food Tweets
SemEval 2014 Task 4 Subtask 1+2,https://identifiers.org/ito:ITO_31403,A Unified Model for Opinion Target Extraction and Target Sentiment Prediction
SemEval 2014 Task 4 Subtask 1+2,https://identifiers.org/ito:ITO_31394,Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification
SemEval 2014 Task 4 Subtask 1+2,https://identifiers.org/ito:ITO_31392,GRACE: Gradient Harmonized and Cascaded Labeling for Aspect-based Sentiment Analysis
1B Words,https://identifiers.org/ito:ITO_12293,"Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm"
CR,https://identifiers.org/ito:ITO_11576,GPU Kernels for Block-Sparse Weights
CR,https://identifiers.org/ito:ITO_26088,Entailment as Few-Shot Learner
CR,https://identifiers.org/ito:ITO_53970,Dual Contrastive Learning: Text Classification via Label-Aware Data Augmentation
IITP Movie Reviews Sentiment,https://identifiers.org/ito:ITO_49979,"IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages"
IITP Movie Reviews Sentiment,https://identifiers.org/ito:ITO_49977,Does Transliteration Help Multilingual Language Modeling?
Amazon Review Polarity,https://identifiers.org/ito:ITO_11621,Bag of Tricks for Efficient Text Classification
Amazon Review Polarity,https://identifiers.org/ito:ITO_53948,Deep Pyramid Convolutional Neural Networks for Text Categorization
Amazon Review Polarity,https://identifiers.org/ito:ITO_31287,Unsupervised Data Augmentation for Consistency Training
ChnSentiCorp Dev,https://identifiers.org/ito:ITO_53977,Pre-Training with Whole Word Masking for Chinese BERT
RuSentiment,https://identifiers.org/ito:ITO_53980,RuSentiment: An Enriched Sentiment Analysis Dataset for Social Media in Russian
RuSentiment,https://identifiers.org/ito:ITO_31321,Deep Transfer Learning Baselines for Sentiment Analysis in Russian
"LABR (2-class, unbalanced)",https://identifiers.org/ito:ITO_31328,AraBERT: Transformer-based Model for Arabic Language Understanding
Multi-Domain Sentiment Dataset,https://identifiers.org/ito:ITO_04099,Domain-Adversarial Training of Neural Networks
Multi-Domain Sentiment Dataset,https://identifiers.org/ito:ITO_11563,The Variational Fair Autoencoder
Multi-Domain Sentiment Dataset,https://identifiers.org/ito:ITO_11561,Strong Baselines for Neural Semi-supervised Learning under Domain Shift
Multi-Domain Sentiment Dataset,https://identifiers.org/ito:ITO_11559,Revisiting Distributional Correspondence Indexing: A Python Reimplementation and New Experiments
Multi-Domain Sentiment Dataset,https://identifiers.org/ito:ITO_31369,UDALM: Unsupervised Domain Adaptation through Language Modeling
Multi-Domain Sentiment Dataset,https://identifiers.org/ito:ITO_11565,Asymmetric Tri-training for Unsupervised Domain Adaptation
SST-2 Binary classification,https://identifiers.org/ito:ITO_53985,Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
SST-2 Binary classification,https://identifiers.org/ito:ITO_09582,Convolutional Neural Networks for Sentence Classification
SST-2 Binary classification,https://identifiers.org/ito:ITO_11693,Ask Me Anything: Dynamic Memory Networks for Natural Language Processing
SST-2 Binary classification,https://identifiers.org/ito:ITO_31426,Harnessing Deep Neural Networks with Logic Rules
SST-2 Binary classification,https://identifiers.org/ito:ITO_05362,Neural Semantic Encoders
SST-2 Binary classification,https://identifiers.org/ito:ITO_11682,Learning to Generate Reviews and Discovering Sentiment
SST-2 Binary classification,https://identifiers.org/ito:ITO_11576,GPU Kernels for Block-Sparse Weights
SST-2 Binary classification,https://identifiers.org/ito:ITO_28511,Training Complex Models with Multi-Task Weak Supervision
SST-2 Binary classification,https://identifiers.org/ito:ITO_28509,Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding
SST-2 Binary classification,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
SST-2 Binary classification,https://identifiers.org/ito:ITO_28463,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
SST-2 Binary classification,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
SST-2 Binary classification,https://identifiers.org/ito:ITO_51407,SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization
Amazon Review Full,https://identifiers.org/ito:ITO_11621,Bag of Tricks for Efficient Text Classification
Amazon Review Full,https://identifiers.org/ito:ITO_53948,Deep Pyramid Convolutional Neural Networks for Text Categorization
Amazon Review Full,https://identifiers.org/ito:ITO_31287,Unsupervised Data Augmentation for Consistency Training
Twitter,https://identifiers.org/ito:ITO_11666,Attentional Encoder Network for Targeted Sentiment Classification
Sogou News,https://identifiers.org/ito:ITO_11621,Bag of Tricks for Efficient Text Classification
IMDb,https://identifiers.org/ito:ITO_11582,Effective Use of Word Order for Text Categorization with Convolutional Neural Networks
IMDb,https://identifiers.org/ito:ITO_11578,Supervised and Semi-Supervised Text Categorization using LSTM for Region Embeddings
IMDb,https://identifiers.org/ito:ITO_31294,Contextual Explanation Networks
IMDb,https://identifiers.org/ito:ITO_11576,GPU Kernels for Block-Sparse Weights
IMDb,https://identifiers.org/ito:ITO_11574,Universal Language Model Fine-tuning for Text Classification
IMDb,https://identifiers.org/ito:ITO_31287,Unsupervised Data Augmentation for Consistency Training
IMDb,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
Urdu Online Reviews,https://identifiers.org/ito:ITO_54009,Sentiment analysis for Urdu online reviews using deep learning models
User and product information,https://identifiers.org/ito:ITO_54018,Learning Semantic Representations of Users and Products for Document Level Sentiment Classification
User and product information,https://identifiers.org/ito:ITO_54016,Neural Sentiment Classification with User and Product Attention
User and product information,https://identifiers.org/ito:ITO_54015,Cascading Multiway Attentions for Document-level Sentiment Classification
User and product information,https://identifiers.org/ito:ITO_54014,Improving Review Representations with User Attention and Product Attention for Sentiment Classification
User and product information,https://identifiers.org/ito:ITO_31261,Rethinking Attribute Representation and Injection for Sentiment Classification
DynaSent,https://identifiers.org/ito:ITO_31362,Arabic Multi-Dialect Segmentation: bi-LSTM-CRF vs. SVM
SST-5 Fine-grained classification,https://identifiers.org/ito:ITO_53985,Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
SST-5 Fine-grained classification,https://identifiers.org/ito:ITO_54021,"Less Grammar, More Features"
SST-5 Fine-grained classification,https://identifiers.org/ito:ITO_09585,Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks
SST-5 Fine-grained classification,https://identifiers.org/ito:ITO_08067,Learned in Translation: Contextualized Word Vectors
SST-5 Fine-grained classification,https://identifiers.org/ito:ITO_07964,Deep contextualized word representations
SST-5 Fine-grained classification,https://identifiers.org/ito:ITO_11684,Improved Sentence Modeling using Suffix Bidirectional LSTM
SST-5 Fine-grained classification,https://identifiers.org/ito:ITO_28562,Self-Explaining Structures Improve NLP Models
Yelp Binary classification,https://identifiers.org/ito:ITO_11624,Character-level Convolutional Networks for Text Classification
SemEval,https://identifiers.org/ito:ITO_11718,BB_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and LSTMs
MR,https://identifiers.org/ito:ITO_11657,All-but-the-Top: Simple and Effective Postprocessing for Word Representations
MR,https://identifiers.org/ito:ITO_11651,Sentiment Analysis by Capsules
MR,https://identifiers.org/ito:ITO_11605,A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors
MR,https://identifiers.org/ito:ITO_14674,Vector of Locally-Aggregated Word Embeddings (VLAWE): A Novel Document-level Representation
MR,https://identifiers.org/ito:ITO_12293,"Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm"
TweetEval,https://identifiers.org/ito:ITO_21023,BERTweet: A pre-trained language model for English Tweets
TweetEval,https://identifiers.org/ito:ITO_31253,TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification
TweetEval,https://identifiers.org/ito:ITO_54032,XLM-T: Multilingual Language Models in Twitter for Sentiment Analysis and Beyond
MPQA,https://identifiers.org/ito:ITO_11090,Universal Sentence Encoder
MPQA,https://identifiers.org/ito:ITO_11605,A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors
MPQA,https://identifiers.org/ito:ITO_11603,The Pupil Has Become the Master: Teacher-Student Model-Based Word Embedding Distillation with Ensemble Learning
MPQA,https://identifiers.org/ito:ITO_26088,Entailment as Few-Shot Learner
RETWEET,https://identifiers.org/ito:ITO_31570,How Will Your Tweet Be Received? Predicting the Sentiment Polarity of Tweet Replies
W-NUT 2020 Shared Task-3,https://identifiers.org/ito:ITO_32074,Leveraging Event Specific and Chunk Span features to Extract COVID Events from tweets
KILT: Zero Shot RE,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: Zero Shot RE,https://identifiers.org/ito:ITO_26225,Learning Dense Representations of Phrases at Scale
KILT: T-REx,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: T-REx,https://identifiers.org/ito:ITO_26225,Learning Dense Representations of Phrases at Scale
KILT: T-REx,https://identifiers.org/ito:ITO_49915,"Re2G: Retrieve, Rerank, Generate"
Polyvore,https://identifiers.org/ito:ITO_32051,Context-Aware Visual Compatibility Prediction
zsRE,https://identifiers.org/ito:ITO_54533,Robust Retrieval Augmented Generation for Zero-shot Slot Filling
T-REx,https://identifiers.org/ito:ITO_54533,Robust Retrieval Augmented Generation for Zero-shot Slot Filling
Twitter Stance Election 2020 - Stance detection (US election 2020,https://identifiers.org/ito:ITO_51943,Knowledge Enhanced Masked Language Model for Stance Detection
RumourEval,https://identifiers.org/ito:ITO_10069,Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM
RuStance,https://identifiers.org/ito:ITO_51938,Stance Prediction for Russian: Data and Analysis
Turkish Elections 2018,https://identifiers.org/ito:ITO_51940,Embeddings-Based Clustering for Target Specific Stances: The Case of a Polarized Turkey
Trump Midterm Elections 2018,https://identifiers.org/ito:ITO_51940,Embeddings-Based Clustering for Target Specific Stances: The Case of a Polarized Turkey
SUBJ,https://identifiers.org/ito:ITO_12607,Self-Adaptive Hierarchical Sentence Model
SUBJ,https://identifiers.org/ito:ITO_33018,An Empirical Evaluation of Word Embedding Models for Subjectivity Analysis Tasks
SUBJ,https://identifiers.org/ito:ITO_53970,Dual Contrastive Learning: Text Classification via Label-Aware Data Augmentation
Czech Subjectivity Dataset,https://identifiers.org/ito:ITO_55245,Czech Dataset for Cross-lingual Subjectivity Classification
dbp15k fr-en,https://identifiers.org/ito:ITO_31605,Visual Pivoting for (Unsupervised) Entity Alignment
dbp15k fr-en,https://identifiers.org/ito:ITO_31603,A Critical Assessment of State-of-the-Art in Entity Alignment
dbp15k fr-en,https://identifiers.org/ito:ITO_31601,Entity Alignment for Knowledge Graphs with Multi-order Convolutional Networks
dbp15k fr-en,https://identifiers.org/ito:ITO_54153,Boosting the Speed of Entity Alignment 10*: Dual Attention Matching Network with Normalized Hard Sample Mining
dbp15k fr-en,https://identifiers.org/ito:ITO_54151,"Are Negative Samples Necessary in Entity Alignment? An Approach with High Performance, Scalability and Robustness"
dbp15k fr-en,https://identifiers.org/ito:ITO_54149,From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment
dbp15k ja-en,https://identifiers.org/ito:ITO_31605,Visual Pivoting for (Unsupervised) Entity Alignment
dbp15k ja-en,https://identifiers.org/ito:ITO_31601,Entity Alignment for Knowledge Graphs with Multi-order Convolutional Networks
dbp15k ja-en,https://identifiers.org/ito:ITO_54153,Boosting the Speed of Entity Alignment 10*: Dual Attention Matching Network with Normalized Hard Sample Mining
dbp15k ja-en,https://identifiers.org/ito:ITO_54151,"Are Negative Samples Necessary in Entity Alignment? An Approach with High Performance, Scalability and Robustness"
dbp15k ja-en,https://identifiers.org/ito:ITO_54149,From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment
DBP2.0 zh-en,https://identifiers.org/ito:ITO_54160,Knowing the No-match: Entity Alignment with Dangling Cases
DBP15k zh-en,https://identifiers.org/ito:ITO_31636,Multilingual Knowledge Graph Embeddings for Cross-lingual Knowledge Alignment
DBP15k zh-en,https://identifiers.org/ito:ITO_31621,Relation-Aware Entity Alignment for Heterogeneous Knowledge Graphs
DBP15k zh-en,https://identifiers.org/ito:ITO_31616,Jointly Learning Entity and Relation Representations for Entity Alignment
DBP15k zh-en,https://identifiers.org/ito:ITO_31611,Deep Graph Matching Consensus
DBP15k zh-en,https://identifiers.org/ito:ITO_31609,Relational Reflection Entity Alignment
DBP15k zh-en,https://identifiers.org/ito:ITO_31601,Entity Alignment for Knowledge Graphs with Multi-order Convolutional Networks
DBP15k zh-en,https://identifiers.org/ito:ITO_54151,"Are Negative Samples Necessary in Entity Alignment? An Approach with High Performance, Scalability and Robustness"
DBP15k zh-en,https://identifiers.org/ito:ITO_54149,From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment
ACE2004,https://identifiers.org/ito:ITO_17202,Deep Joint Entity Disambiguation with Local Neural Attention
ACE2004,https://identifiers.org/ito:ITO_60963,Global Entity Disambiguation with BERT
WNED-WIKI,https://identifiers.org/ito:ITO_17202,Deep Joint Entity Disambiguation with Local Neural Attention
WNED-WIKI,https://identifiers.org/ito:ITO_60963,Global Entity Disambiguation with BERT
MSNBC,https://identifiers.org/ito:ITO_17202,Deep Joint Entity Disambiguation with Local Neural Attention
MSNBC,https://identifiers.org/ito:ITO_60963,Global Entity Disambiguation with BERT
Mewsli-9,https://identifiers.org/ito:ITO_60971,Entity Linking in 100 Languages
Mewsli-9,https://identifiers.org/ito:ITO_60973,Multilingual Autoregressive Entity Linking
AIDA-CoNLL,https://identifiers.org/ito:ITO_60976,Bootleg: Chasing the Tail with Self-Supervised Named Entity Disambiguation
AIDA-CoNLL,https://identifiers.org/ito:ITO_54210,Robust Disambiguation of Named Entities in Text
AIDA-CoNLL,https://identifiers.org/ito:ITO_11896,Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation
AIDA-CoNLL,https://identifiers.org/ito:ITO_11894,Learning Distributed Representations of Texts and Entities from Knowledge Base
AIDA-CoNLL,https://identifiers.org/ito:ITO_40442,DeepType: Multilingual Entity Linking by Neural Type System Evolution
AIDA-CoNLL,https://identifiers.org/ito:ITO_60963,Global Entity Disambiguation with BERT
AQUAINT,https://identifiers.org/ito:ITO_60963,Global Entity Disambiguation with BERT
WNED-CWEB,https://identifiers.org/ito:ITO_17202,Deep Joint Entity Disambiguation with Local Neural Attention
WNED-CWEB,https://identifiers.org/ito:ITO_60963,Global Entity Disambiguation with BERT
TAC2010,https://identifiers.org/ito:ITO_11896,Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation
TAC2010,https://identifiers.org/ito:ITO_11894,Learning Distributed Representations of Texts and Entities from Knowledge Base
TAC2010,https://identifiers.org/ito:ITO_40442,DeepType: Multilingual Entity Linking by Neural Type System Evolution
Rare Diseases Mentions in MIMIC-III (Text-to-UMLS),https://identifiers.org/ito:ITO_54166,Rare Disease Identification from Clinical Notes with Ontologies and Weak Supervision
Rare Diseases Mentions in MIMIC-III (Text-to-UMLS),https://identifiers.org/ito:ITO_54165,Ontology-Based and Weakly Supervised Rare Disease Phenotyping from Clinical Notes
GUM,https://identifiers.org/ito:ITO_54169,WikiGUM: Exhaustive Entity Linking for Wikification in 12 Genres
KILT: WNED-CWEB,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: WNED-CWEB,https://identifiers.org/ito:ITO_31654,Autoregressive Entity Retrieval
KILT: AIDA-YAGO2,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: AIDA-YAGO2,https://identifiers.org/ito:ITO_31654,Autoregressive Entity Retrieval
TAC-KBP 2010,https://identifiers.org/ito:ITO_40442,DeepType: Multilingual Entity Linking by Neural Type System Evolution
MedMentions,https://identifiers.org/ito:ITO_54180,Entity Linking and Discovery via Arborescence-based Supervised Clustering
Rare Diseases Mentions in MIMIC-III,https://identifiers.org/ito:ITO_54166,Rare Disease Identification from Clinical Notes with Ontologies and Weak Supervision
Rare Diseases Mentions in MIMIC-III,https://identifiers.org/ito:ITO_54165,Ontology-Based and Weakly Supervised Rare Disease Phenotyping from Clinical Notes
ZESHEL,https://identifiers.org/ito:ITO_54180,Entity Linking and Discovery via Arborescence-based Supervised Clustering
CoNLL-Aida,https://identifiers.org/ito:ITO_40442,DeepType: Multilingual Entity Linking by Neural Type System Evolution
FIGER,https://identifiers.org/ito:ITO_04704,ERNIE: Enhanced Language Representation with Informative Entities
Derczynski,https://identifiers.org/ito:ITO_11873,End-to-End Neural Entity Linking
Derczynski,https://identifiers.org/ito:ITO_31677,REL: An Entity Linker Standing on the Shoulders of Giants
Derczynski,https://identifiers.org/ito:ITO_31654,Autoregressive Entity Retrieval
WiC-TSV,https://identifiers.org/ito:ITO_31644,Word Sense Disambiguation with Transformer Models
WiC-TSV,https://identifiers.org/ito:ITO_31645,CTLR@WiC-TSV: Target Sense Verification using Marked Inputs andPre-trained Models
OKE-2016,https://identifiers.org/ito:ITO_11873,End-to-End Neural Entity Linking
MSNBC,https://identifiers.org/ito:ITO_11873,End-to-End Neural Entity Linking
MSNBC,https://identifiers.org/ito:ITO_31654,Autoregressive Entity Retrieval
MSNBC,https://identifiers.org/ito:ITO_31653,CHOLAN: A Modular Approach for Neural Entity Linking on Wikipedia and Wikidata
WebQSP-WD,https://identifiers.org/ito:ITO_11886,Mixing Context Granularities for Improved Entity Linking on Question Answering Data across Entity Categories
KILT: WNED-WIKI,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: WNED-WIKI,https://identifiers.org/ito:ITO_31654,Autoregressive Entity Retrieval
AIDA-CoNLL,https://identifiers.org/ito:ITO_11873,End-to-End Neural Entity Linking
AIDA-CoNLL,https://identifiers.org/ito:ITO_31654,Autoregressive Entity Retrieval
AIDA-CoNLL,https://identifiers.org/ito:ITO_54203,Highly Parallel Autoregressive Entity Linking with Discriminative Correction
AIDA-CoNLL,https://identifiers.org/ito:ITO_54201,EntQA: Entity Linking as Question Answering
OKE-2015,https://identifiers.org/ito:ITO_11873,End-to-End Neural Entity Linking
FUNSD,https://identifiers.org/ito:ITO_54215,Entity Relation Extraction as Dependency Parsing in Visually Rich Documents
Rare Diseases Mentions in MIMIC-III Radiology Reports (Text-to-UMLS),https://identifiers.org/ito:ITO_54165,Ontology-Based and Weakly Supervised Rare Disease Phenotyping from Clinical Notes
N3-Reuters-128,https://identifiers.org/ito:ITO_11873,End-to-End Neural Entity Linking
FIGER,https://identifiers.org/ito:ITO_60946,Ultra-fine Entity Typing with Indirect Supervision from Natural Language Inference
Open Entity,https://identifiers.org/ito:ITO_04704,ERNIE: Enhanced Language Representation with Informative Entities
Open Entity,https://identifiers.org/ito:ITO_21579,K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters
Ontonotes v5 (English),https://identifiers.org/ito:ITO_17185,Ultra-Fine Entity Typing
Ontonotes v5 (English),https://identifiers.org/ito:ITO_17183,Imposing Label-Relational Inductive Bias for Extremely Fine-Grained Entity Typing
Ontonotes v5 (English),https://identifiers.org/ito:ITO_17181,Learning to Denoise Distantly-Labeled Data for Entity Typing
Ontonotes v5 (English),https://identifiers.org/ito:ITO_60950,Ultra-Fine Entity Typing with Weak Supervision from a Masked Language Model
OntoNotes,https://identifiers.org/ito:ITO_60946,Ultra-fine Entity Typing with Indirect Supervision from Natural Language Inference
Freebase FIGER,https://identifiers.org/ito:ITO_14727,Representation Learning of Entities and Documents from Knowledge Base Descriptions
Medical domain,https://identifiers.org/ito:ITO_45740,Supervised Distributional Hypernym Discovery via Domain Adaptation
Medical domain,https://identifiers.org/ito:ITO_45738,CRIM at SemEval-2018 Task 9: A Hybrid Approach to Hypernym Discovery
General,https://identifiers.org/ito:ITO_45740,Supervised Distributional Hypernym Discovery via Domain Adaptation
General,https://identifiers.org/ito:ITO_45738,CRIM at SemEval-2018 Task 9: A Hybrid Approach to Hypernym Discovery
Music domain,https://identifiers.org/ito:ITO_45740,Supervised Distributional Hypernym Discovery via Domain Adaptation
Music domain,https://identifiers.org/ito:ITO_45738,CRIM at SemEval-2018 Task 9: A Hybrid Approach to Hypernym Discovery
60k Stack Overflow Questions,https://identifiers.org/ito:ITO_50032,Multi-View Approach to Suggest Moderation Actions in Community Question Answering Sites
LDC2015E86,https://identifiers.org/ito:ITO_53397,CMU at SemEval-2016 Task 8: Graph-based AMR Parsing with Infinite Ramp Loss
LDC2015E86,https://identifiers.org/ito:ITO_53396,Abstract Meaning Representation Parsing using LSTM Recurrent Neural Networks
LDC2015E86,https://identifiers.org/ito:ITO_30634,AMR Parsing as Graph Prediction with Latent Alignment
LDC2017T10,https://identifiers.org/ito:ITO_30639,Neural Semantic Parsing by Character-based Translation: Experiments with Abstract Meaning Representations
LDC2017T10,https://identifiers.org/ito:ITO_30634,AMR Parsing as Graph Prediction with Latent Alignment
LDC2017T10,https://identifiers.org/ito:ITO_13177,AMR Parsing as Sequence-to-Graph Transduction
LDC2017T10,https://identifiers.org/ito:ITO_30632,Broad-Coverage Semantic Parsing as Transduction
LDC2017T10,https://identifiers.org/ito:ITO_30631,AMR Parsing via Graph-Sequence Iterative Inference
LDC2017T10,https://identifiers.org/ito:ITO_30627,Improving AMR Parsing with Sequence-to-Sequence Pre-training
LDC2017T10,https://identifiers.org/ito:ITO_53413,AMR Parsing with Action-Pointer Transformer
LDC2017T10,https://identifiers.org/ito:ITO_30625,One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline
LDC2017T10,https://identifiers.org/ito:ITO_53403,Ensembling Graph Predictions for AMR Parsing
LDC2017T10,https://identifiers.org/ito:ITO_53401,Maximum Bayes Smatch Ensemble Distillation for AMR Parsing
LDC2014T12:,https://identifiers.org/ito:ITO_53421,Noise reduction and targeted exploration in imitation learning for Abstract Meaning Representation parsing
LDC2014T12:,https://identifiers.org/ito:ITO_53420,AMR Parsing with an Incremental Joint Model
LDC2014T12:,https://identifiers.org/ito:ITO_13179,An AMR Aligner Tuned by Transition-based Parser
LDC2014T12:,https://identifiers.org/ito:ITO_13177,AMR Parsing as Sequence-to-Graph Transduction
LDC2014T12,https://identifiers.org/ito:ITO_53423,Boosting Transition-based AMR Parsing with Refined Actions and Auxiliary Analyzers
LDC2014T12,https://identifiers.org/ito:ITO_53420,AMR Parsing with an Incremental Joint Model
LDC2014T12,https://identifiers.org/ito:ITO_13179,An AMR Aligner Tuned by Transition-based Parser
LDC2014T12,https://identifiers.org/ito:ITO_53424,Getting the Most out of AMR Parsing
LDC2014T12,https://identifiers.org/ito:ITO_13177,AMR Parsing as Sequence-to-Graph Transduction
LDC2014T12,https://identifiers.org/ito:ITO_30632,Broad-Coverage Semantic Parsing as Transduction
LDC2014T12,https://identifiers.org/ito:ITO_30631,AMR Parsing via Graph-Sequence Iterative Inference
LDC2014T12,https://identifiers.org/ito:ITO_30629,Pushing the Limits of AMR Parsing with Self-Learning
New3,https://identifiers.org/ito:ITO_30625,One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline
New3,https://identifiers.org/ito:ITO_53403,Ensembling Graph Predictions for AMR Parsing
New3,https://identifiers.org/ito:ITO_53406,Graph Pre-training for AMR Parsing and Generation
Bio,https://identifiers.org/ito:ITO_30625,One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline
Bio,https://identifiers.org/ito:ITO_53403,Ensembling Graph Predictions for AMR Parsing
Bio,https://identifiers.org/ito:ITO_53406,Graph Pre-training for AMR Parsing and Generation
LDC2020T02,https://identifiers.org/ito:ITO_53413,AMR Parsing with Action-Pointer Transformer
LDC2020T02,https://identifiers.org/ito:ITO_30625,One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline
LDC2020T02,https://identifiers.org/ito:ITO_53403,Ensembling Graph Predictions for AMR Parsing
LDC2020T02,https://identifiers.org/ito:ITO_53401,Maximum Bayes Smatch Ensemble Distillation for AMR Parsing
The Little Prince,https://identifiers.org/ito:ITO_30625,One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline
The Little Prince,https://identifiers.org/ito:ITO_53403,Ensembling Graph Predictions for AMR Parsing
The Little Prince,https://identifiers.org/ito:ITO_53406,Graph Pre-training for AMR Parsing and Generation
PMB-3.0.0,https://identifiers.org/ito:ITO_30716,Exploring Neural Methods for Parsing Discourse Representation Structures
PMB-3.0.0,https://identifiers.org/ito:ITO_53444,Linguistic Information in Neural Semantic Parsing with Multiple Encoders
PMB-3.0.0,https://identifiers.org/ito:ITO_30710,Character-level Representations Improve DRS-based Semantic Parsing Even in the Age of BERT
PMB-2.2.0,https://identifiers.org/ito:ITO_30716,Exploring Neural Methods for Parsing Discourse Representation Structures
PMB-2.2.0,https://identifiers.org/ito:ITO_53446,Discourse Representation Structure Parsing with Recurrent Neural Networks and the Transformer Model
PMB-2.2.0,https://identifiers.org/ito:ITO_30710,Character-level Representations Improve DRS-based Semantic Parsing Even in the Age of BERT
PAS,https://identifiers.org/ito:ITO_30680,Simpler but More Accurate Semantic Dependency Parsing
PAS,https://identifiers.org/ito:ITO_30678,Second-Order Semantic Dependency Parsing with End-to-End Neural Networks
PAS,https://identifiers.org/ito:ITO_53435,Transition-based Semantic Dependency Parsing with Pointer Networks
PAS,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
DM,https://identifiers.org/ito:ITO_30680,Simpler but More Accurate Semantic Dependency Parsing
DM,https://identifiers.org/ito:ITO_30678,Second-Order Semantic Dependency Parsing with End-to-End Neural Networks
DM,https://identifiers.org/ito:ITO_53435,Transition-based Semantic Dependency Parsing with Pointer Networks
DM,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
PSD,https://identifiers.org/ito:ITO_30680,Simpler but More Accurate Semantic Dependency Parsing
PSD,https://identifiers.org/ito:ITO_30678,Second-Order Semantic Dependency Parsing with End-to-End Neural Networks
PSD,https://identifiers.org/ito:ITO_53435,Transition-based Semantic Dependency Parsing with Pointer Networks
PSD,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
WebQuestionsSP,https://identifiers.org/ito:ITO_53365,The Value of Semantic Parse Labeling for Knowledge Base Question Answering
WebQuestionsSP,https://identifiers.org/ito:ITO_26938,Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals
"AMR (chinese, MRP 2020)",https://identifiers.org/ito:ITO_30556,HUJI-KU at MRP~2020: Two Transition-based Neural Parsers
"AMR (chinese, MRP 2020)",https://identifiers.org/ito:ITO_30554,ÚFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN
ATIS,https://identifiers.org/ito:ITO_11110,Type-Driven Incremental Semantic Parsing with Polymorphism
ATIS,https://identifiers.org/ito:ITO_11108,Abstract Syntax Networks for Code Generation and Semantic Parsing
ATIS,https://identifiers.org/ito:ITO_09137,TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation
Geo,https://identifiers.org/ito:ITO_11097,Coarse-to-Fine Decoding for Neural Semantic Parsing
spider,https://identifiers.org/ito:ITO_11104,Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task
spider,https://identifiers.org/ito:ITO_53372,RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers
spider,https://identifiers.org/ito:ITO_30589,GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing
spider,https://identifiers.org/ito:ITO_30587,Learning Contextual Representations for Semantic Parsing with Generation-Augmented Pre-Training
spider,https://identifiers.org/ito:ITO_45296,PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models
"PTG (czech, MRP 2020)",https://identifiers.org/ito:ITO_30556,HUJI-KU at MRP~2020: Two Transition-based Neural Parsers
"PTG (czech, MRP 2020)",https://identifiers.org/ito:ITO_30554,ÚFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN
"PTG (czech, MRP 2020)",https://identifiers.org/ito:ITO_53374,"RobeCzech: Czech RoBERTa, a monolingual contextualized language representation model"
"DRG (english, MRP 2020)",https://identifiers.org/ito:ITO_30556,HUJI-KU at MRP~2020: Two Transition-based Neural Parsers
"DRG (english, MRP 2020)",https://identifiers.org/ito:ITO_30554,ÚFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN
"DRG (german, MRP 2020)",https://identifiers.org/ito:ITO_30556,HUJI-KU at MRP~2020: Two Transition-based Neural Parsers
"DRG (german, MRP 2020)",https://identifiers.org/ito:ITO_30554,ÚFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN
"EDS (english, MRP 2020)",https://identifiers.org/ito:ITO_30556,HUJI-KU at MRP~2020: Two Transition-based Neural Parsers
"EDS (english, MRP 2020)",https://identifiers.org/ito:ITO_30554,ÚFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN
"PTG (english, MRP 2020)",https://identifiers.org/ito:ITO_30556,HUJI-KU at MRP~2020: Two Transition-based Neural Parsers
"PTG (english, MRP 2020)",https://identifiers.org/ito:ITO_30554,ÚFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN
"UCCA (english, MRP 2020)",https://identifiers.org/ito:ITO_30556,HUJI-KU at MRP~2020: Two Transition-based Neural Parsers
"UCCA (english, MRP 2020)",https://identifiers.org/ito:ITO_30554,ÚFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN
"AMR (english, MRP 2020)",https://identifiers.org/ito:ITO_30556,HUJI-KU at MRP~2020: Two Transition-based Neural Parsers
"AMR (english, MRP 2020)",https://identifiers.org/ito:ITO_30554,ÚFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN
HotpotQA,https://identifiers.org/ito:ITO_49698,ReasonBERT: Pre-trained to Reason with Distant Supervision
SQA,https://identifiers.org/ito:ITO_30572,TAPAS: Weakly Supervised Table Parsing via Pre-training
SQA,https://identifiers.org/ito:ITO_53386,TAPEX: Table Pre-training via Learning a Neural SQL Executor
"UCCA (german, MRP 2020)",https://identifiers.org/ito:ITO_30556,HUJI-KU at MRP~2020: Two Transition-based Neural Parsers
"UCCA (german, MRP 2020)",https://identifiers.org/ito:ITO_30554,ÚFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN
WikiTableQuestions,https://identifiers.org/ito:ITO_30570,Learning Semantic Parsers from Denotations with Latent Structured Alignments and Abstract Programs
WikiTableQuestions,https://identifiers.org/ito:ITO_30568,TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data
WikiTableQuestions,https://identifiers.org/ito:ITO_53386,TAPEX: Table Pre-training via Learning a Neural SQL Executor
WikiTableQuestions,https://identifiers.org/ito:ITO_30572,TAPAS: Weakly Supervised Table Parsing via Pre-training
WikiSQL,https://identifiers.org/ito:ITO_11100,Content Enhanced BERT-based Text-to-SQL Generation
WikiSQL,https://identifiers.org/ito:ITO_30572,TAPAS: Weakly Supervised Table Parsing via Pre-training
WikiSQL,https://identifiers.org/ito:ITO_53386,TAPEX: Table Pre-training via Learning a Neural SQL Executor
complexWebQuestions-V1.0,https://identifiers.org/ito:ITO_53392,Complex Question Decomposition for Semantic Parsing
GraphQuestions,https://identifiers.org/ito:ITO_49698,ReasonBERT: Pre-trained to Reason with Distant Supervision
CoNLL 2019,https://identifiers.org/ito:ITO_53439,HIT-SCIR at MRP 2019: A Unified Pipeline for Meaning Representation Parsing via Efficient Training and Effective Encoding
CoNLL 2019,https://identifiers.org/ito:ITO_53440,TUPA at MRP 2019: A Multi-Task Baseline System
SemEval 2019 Task 1,https://identifiers.org/ito:ITO_30695,A Transition-Based Directed Acyclic Graph Parser for UCCA
SemEval 2019 Task 1,https://identifiers.org/ito:ITO_30693,Multitask Parsing Across Semantic Representations
SemEval 2019 Task 1,https://identifiers.org/ito:ITO_53442,HLT@SUDA at SemEval-2019 Task 1: UCCA Graph Parsing as Constituent Tree Parsing
VG graph-text,https://identifiers.org/ito:ITO_30726,An Unsupervised Joint System for Text Generation from Knowledge Graphs and Semantic Parsing
WebNLG v2.1,https://identifiers.org/ito:ITO_30726,An Unsupervised Joint System for Text Generation from Knowledge Graphs and Semantic Parsing
CoNLL 2005,https://identifiers.org/ito:ITO_53296,Deep Semantic Role Labeling: What Works and What's Next
CoNLL 2005,https://identifiers.org/ito:ITO_11064,Linguistically-Informed Self-Attention for Semantic Role Labeling
CoNLL 2012,https://identifiers.org/ito:ITO_11064,Linguistically-Informed Self-Attention for Semantic Role Labeling
OntoNotes,https://identifiers.org/ito:ITO_53296,Deep Semantic Role Labeling: What Works and What's Next
OntoNotes,https://identifiers.org/ito:ITO_11058,Deep Semantic Role Labeling with Self-Attention
OntoNotes,https://identifiers.org/ito:ITO_11066,Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling
OntoNotes,https://identifiers.org/ito:ITO_11051,A Span Selection Model for Semantic Role Labeling
OntoNotes,https://identifiers.org/ito:ITO_53295,Constraining Linear-chain CRFs to Regular Languages
OntoNotes,https://identifiers.org/ito:ITO_53293,An MRC Framework for Semantic Role Labeling
OntoNotes,https://identifiers.org/ito:ITO_53291,Semantic Role Labeling as Dependency Parsing: Exploring Latent Tree Structures Inside Arguments
CoNLL-2009,https://identifiers.org/ito:ITO_53301,End-to-end Semantic Role Labeling with Neural Transition-based Model
CoNLL 2005,https://identifiers.org/ito:ITO_11051,A Span Selection Model for Semantic Role Labeling
CoNLL 2005,https://identifiers.org/ito:ITO_30465,Syntax-Aware Graph-to-Graph Transformer for Semantic Role Labelling
CoNLL 2005,https://identifiers.org/ito:ITO_53293,An MRC Framework for Semantic Role Labeling
Q2Q Arabic Benchmark,https://identifiers.org/ito:ITO_16239,Tha3aroon at NSURL-2019 Task 8: Semantic Question Similarity in Arabic
Q2Q Arabic Benchmark,https://identifiers.org/ito:ITO_16237,The Inception Team at NSURL-2019 Task 8: Semantic Question Similarity in Arabic
MRPC Dev,https://identifiers.org/ito:ITO_26155,TinyBERT: Distilling BERT for Natural Language Understanding
MRPC Dev,https://identifiers.org/ito:ITO_21083,Synthesizer: Rethinking Self-Attention in Transformer Models
MRPC,https://identifiers.org/ito:ITO_53320,Discriminative Improvements to Distributional Sentence Similarity
MRPC,https://identifiers.org/ito:ITO_04704,ERNIE: Enhanced Language Representation with Informative Entities
MRPC,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
MRPC,https://identifiers.org/ito:ITO_07499,RoBERTa: A Robustly Optimized BERT Pretraining Approach
MRPC,https://identifiers.org/ito:ITO_08310,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
MRPC,https://identifiers.org/ito:ITO_51407,SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization
MRPC,https://identifiers.org/ito:ITO_28463,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
MRPC,https://identifiers.org/ito:ITO_49493,Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning
SentEval,https://identifiers.org/ito:ITO_09641,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data
SentEval,https://identifiers.org/ito:ITO_09526,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning
STS13,https://identifiers.org/ito:ITO_30486,Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
STS13,https://identifiers.org/ito:ITO_53331,SimCSE: Simple Contrastive Learning of Sentence Embeddings
STS13,https://identifiers.org/ito:ITO_53327,Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations
STS13,https://identifiers.org/ito:ITO_53325,Deep Continuous Prompt for Contrastive Learning of Sentence Embeddings
STS15,https://identifiers.org/ito:ITO_30486,Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
STS15,https://identifiers.org/ito:ITO_53331,SimCSE: Simple Contrastive Learning of Sentence Embeddings
STS15,https://identifiers.org/ito:ITO_53327,Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations
STS12,https://identifiers.org/ito:ITO_30486,Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
STS12,https://identifiers.org/ito:ITO_53331,SimCSE: Simple Contrastive Learning of Sentence Embeddings
STS12,https://identifiers.org/ito:ITO_53327,Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations
STS12,https://identifiers.org/ito:ITO_53325,Deep Continuous Prompt for Contrastive Learning of Sentence Embeddings
STS Benchmark,https://identifiers.org/ito:ITO_11090,Universal Sentence Encoder
STS Benchmark,https://identifiers.org/ito:ITO_04704,ERNIE: Enhanced Language Representation with Informative Entities
STS Benchmark,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
STS Benchmark,https://identifiers.org/ito:ITO_28463,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
STS Benchmark,https://identifiers.org/ito:ITO_51407,SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization
STS Benchmark,https://identifiers.org/ito:ITO_53346,MNet-Sim: A Multi-layered Semantic Similarity Network to Evaluate Sentence Similarity
SICK,https://identifiers.org/ito:ITO_30486,Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
SICK,https://identifiers.org/ito:ITO_53331,SimCSE: Simple Contrastive Learning of Sentence Embeddings
SICK,https://identifiers.org/ito:ITO_53325,Deep Continuous Prompt for Contrastive Learning of Sentence Embeddings
STS14,https://identifiers.org/ito:ITO_30486,Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
STS14,https://identifiers.org/ito:ITO_53331,SimCSE: Simple Contrastive Learning of Sentence Embeddings
STS14,https://identifiers.org/ito:ITO_53325,Deep Continuous Prompt for Contrastive Learning of Sentence Embeddings
STS16,https://identifiers.org/ito:ITO_30486,Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
STS16,https://identifiers.org/ito:ITO_30493,On the Sentence Embeddings from Pre-trained Language Models
STS16,https://identifiers.org/ito:ITO_53331,SimCSE: Simple Contrastive Learning of Sentence Embeddings
STS16,https://identifiers.org/ito:ITO_53327,Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations
Annotated corpus for semantic similarity of clinical trial outcomes (original corpus),https://identifiers.org/ito:ITO_28878,Measuring semantic similarity of clinical trial outcomes using deep pre-trained language representations
MedSTS,https://identifiers.org/ito:ITO_21496,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets
SICK,https://identifiers.org/ito:ITO_09585,Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks
ClinicalSTS,https://identifiers.org/ito:ITO_21501,CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters
Annotated corpus for semantic similarity of clinical trial outcomes (expanded corpus),https://identifiers.org/ito:ITO_28878,Measuring semantic similarity of clinical trial outcomes using deep pre-trained language representations
BIOSSES,https://identifiers.org/ito:ITO_21496,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets
BIOSSES,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
CHIP-STS,https://identifiers.org/ito:ITO_51428,CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark
ASAP,https://identifiers.org/ito:ITO_61143,Flexible Domain Adaptation for Automated Essay Scoring Using Correlated Linear Regression
ASAP,https://identifiers.org/ito:ITO_61142,Automatic Features for Essay Scoring -- An Empirical Study
ASAP,https://identifiers.org/ito:ITO_61138,SkipFlow: Incorporating Neural Coherence Features for End-to-End Automatic Text Scoring
ASAP,https://identifiers.org/ito:ITO_61136,Automated essay scoring with string kernels and word embeddings
ASAP,https://identifiers.org/ito:ITO_61132,On the Use of BERT for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation
ACL-ARC,https://identifiers.org/ito:ITO_58026,Purpose and Polarity of Citation: Towards NLP-based Bibliometrics
ACL-ARC,https://identifiers.org/ito:ITO_58025,Hierarchical Attention Networks for Document Classification
ACL-ARC,https://identifiers.org/ito:ITO_57995,Measuring the Evolution of a Scientific Field through Citation Frames
ACL-ARC,https://identifiers.org/ito:ITO_07964,Deep contextualized word representations
ACL-ARC,https://identifiers.org/ito:ITO_14785,Structural Scaffolds for Citation Intent Classification in Scientific Publications
SciCite,https://identifiers.org/ito:ITO_04773,SciBERT: A Pretrained Language Model for Scientific Text
GCDC + RST - Accuracy,https://identifiers.org/ito:ITO_36747,"Discourse Coherence in the Wild: A Dataset, Evaluation and Methods"
GCDC + RST - Accuracy,https://identifiers.org/ito:ITO_36745,Neural RST-based Evaluation of Discourse Coherence
GCDC + RST - Accuracy,https://identifiers.org/ito:ITO_58022,Transformer Models for Text Coherence Assessment
GCDC + RST - F1,https://identifiers.org/ito:ITO_36747,"Discourse Coherence in the Wild: A Dataset, Evaluation and Methods"
GCDC + RST - F1,https://identifiers.org/ito:ITO_36745,Neural RST-based Evaluation of Discourse Coherence
Traditional and Context-specific Spam Twitter,https://identifiers.org/ito:ITO_62896,Traditional and context-specific spam detection in low resource settings
Recipe,https://identifiers.org/ito:ITO_14732,Rep the Set: Neural Networks for Learning Set Representations
Reuters En-De,https://identifiers.org/ito:ITO_14742,BilBOWA: Fast Bilingual Distributed Representations without Word Alignments
Classic,https://identifiers.org/ito:ITO_14732,Rep the Set: Neural Networks for Learning Set Representations
Classic,https://identifiers.org/ito:ITO_36585,Speeding up Word Mover's Distance and its variants via properties of distances between embeddings
WOS-5736,https://identifiers.org/ito:ITO_14753,HDLTex: Hierarchical Deep Learning for Text Classification
Yelp-14,https://identifiers.org/ito:ITO_14689,DocBERT: BERT for Document Classification
AAPD,https://identifiers.org/ito:ITO_14689,DocBERT: BERT for Document Classification
SciDocs (MAG),https://identifiers.org/ito:ITO_56741,SPECTER: Document-level Representation Learning using Citation-informed Transformers
SciDocs (MeSH),https://identifiers.org/ito:ITO_56741,SPECTER: Document-level Representation Learning using Citation-informed Transformers
SciDocs (MeSH),https://identifiers.org/ito:ITO_56739,Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings
Reuters De-En,https://identifiers.org/ito:ITO_14742,BilBOWA: Fast Bilingual Distributed Representations without Word Alignments
Reuters-21578,https://identifiers.org/ito:ITO_14732,Rep the Set: Neural Networks for Learning Set Representations
Reuters-21578,https://identifiers.org/ito:ITO_11647,Message Passing Attention Networks for Document Understanding
Reuters-21578,https://identifiers.org/ito:ITO_14674,Vector of Locally-Aggregated Word Embeddings (VLAWE): A Novel Document-level Representation
Reuters-21578,https://identifiers.org/ito:ITO_12785,MAGNET: Multi-Label Text Classification using Attention-based Graph Neural Network
HOC,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
HOC,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
HOC,https://identifiers.org/ito:ITO_21496,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets
Twitter,https://identifiers.org/ito:ITO_14732,Rep the Set: Neural Networks for Learning Set Representations
Cora,https://identifiers.org/ito:ITO_14767,DeepWalk: Online Learning of Social Representations
Cora,https://identifiers.org/ito:ITO_14765,Revisiting Semi-Supervised Learning with Graph Embeddings
Cora,https://identifiers.org/ito:ITO_06709,Semi-Supervised Classification with Graph Convolutional Networks
Cora,https://identifiers.org/ito:ITO_14762,Geometric deep learning on graphs and manifolds using mixture model CNNs
Cora,https://identifiers.org/ito:ITO_06834,Graph Attention Networks
Cora,https://identifiers.org/ito:ITO_14760,Large-Scale Learnable Graph Convolutional Networks
Cora,https://identifiers.org/ito:ITO_06231,Adaptively Connected Neural Networks
BBCSport,https://identifiers.org/ito:ITO_14732,Rep the Set: Neural Networks for Learning Set Representations
BBCSport,https://identifiers.org/ito:ITO_11647,Message Passing Attention Networks for Document Understanding
WOS-46985,https://identifiers.org/ito:ITO_14753,HDLTex: Hierarchical Deep Learning for Text Classification
WOS-11967,https://identifiers.org/ito:ITO_14753,HDLTex: Hierarchical Deep Learning for Text Classification
IMDb-M,https://identifiers.org/ito:ITO_57800,Rethinking Complex Neural Network Architectures for Document Classification
IMDb-M,https://identifiers.org/ito:ITO_36614,Improving Document-Level Sentiment Classification Using Importance of Sentences
MPQA,https://identifiers.org/ito:ITO_11647,Message Passing Attention Networks for Document Understanding
Amazon,https://identifiers.org/ito:ITO_14732,Rep the Set: Neural Networks for Learning Set Representations
Tobacco-3482,https://identifiers.org/ito:ITO_41730,Light-Weighted CNN for Text Classification
Food-101,https://identifiers.org/ito:ITO_36866,Image and Text fusion for UPMC Food-101 \\using BERT and CNNs
Tobacco small-3482,https://identifiers.org/ito:ITO_41730,Light-Weighted CNN for Text Classification
CUB-200-2011,https://identifiers.org/ito:ITO_37979,Are These Birds Similar: Learning Branched Networks for Fine-grained Representations
BabelDomains,https://identifiers.org/ito:ITO_41546,Ask2Transformers: Zero-Shot Domain labelling with Pre-trained Language Models
EWALK,https://identifiers.org/ito:ITO_36727,ProxEmo: Gait-based Emotion Learning and Multi-view Proxemic Fusion for Socially-Aware Robot Navigation
MFA,https://identifiers.org/ito:ITO_58011,The Many Faces of Anger: A Multicultural Video Dataset of Negative Emotions in the Wild (MFA-Wild)
ROCStories,https://identifiers.org/ito:ITO_36723,Modeling Naive Psychology of Characters in Simple Commonsense Stories
ROCStories,https://identifiers.org/ito:ITO_36721,Modeling Label Semantics for Predicting Emotional Reactions
GoEmotions,https://identifiers.org/ito:ITO_36717,GoEmotions: A Dataset of Fine-Grained Emotions
SemEval 2018 Task 1E-c,https://identifiers.org/ito:ITO_58016,Improving Multi-label Emotion Classification by Integrating both General and Domain-specific Knowledge
SemEval 2018 Task 1E-c,https://identifiers.org/ito:ITO_36710,SpanEmo: Casting Multi-label Emotion Classification as Span-prediction
SemEval 2018 Task 1E-c,https://identifiers.org/ito:ITO_11686,Practical Text Classification With Large Pre-Trained Language Models
SemEval 2018 Task 1E-c,https://identifiers.org/ito:ITO_36714,EmoGraph: Capturing Emotion Correlations using Graph Networks
ODIC 5-way (5-shot),https://identifiers.org/ito:ITO_62345,Induction Networks for Few-Shot Text Classification
ODIC 5-way (10-shot),https://identifiers.org/ito:ITO_62345,Induction Networks for Few-Shot Text Classification
ODIC 10-way (5-shot),https://identifiers.org/ito:ITO_62345,Induction Networks for Few-Shot Text Classification
ODIC 10-way (10-shot),https://identifiers.org/ito:ITO_62345,Induction Networks for Few-Shot Text Classification
RAFT,https://identifiers.org/ito:ITO_62367,RAFT: A Real-World Few-Shot Text Classification Benchmark
RAFT,https://identifiers.org/ito:ITO_62365,Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning
ANIMAL,https://identifiers.org/ito:ITO_38341,SELFIE: Refurbishing Unclean Samples for Robust Deep Learning
ANIMAL,https://identifiers.org/ito:ITO_38339,Learning with Feature-Dependent Label Noise: A Progressive Approach
ANIMAL,https://identifiers.org/ito:ITO_37120,Boosting Co-teaching with Compression Regularization for Label Noise
ANIMAL,https://identifiers.org/ito:ITO_58476,S3: Supervised Self-supervised Learning under Label Noise
Chaoyang,https://identifiers.org/ito:ITO_58785,Hard Sample Aware Noise Robust Learning for Histopathology Image Classification
CIFAR-10N-Random3,https://identifiers.org/ito:ITO_36831,Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach
CIFAR-10N-Random3,https://identifiers.org/ito:ITO_36827,Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels
CIFAR-10N-Random3,https://identifiers.org/ito:ITO_36810,Early-Learning Regularization Prevents Memorization of Noisy Labels
CIFAR-10N-Random3,https://identifiers.org/ito:ITO_37144,Learning with Instance-Dependent Label Noise: A Sample Sieve Approach
CIFAR-10N-Random2,https://identifiers.org/ito:ITO_36831,Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach
CIFAR-10N-Random2,https://identifiers.org/ito:ITO_36827,Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels
CIFAR-10N-Random2,https://identifiers.org/ito:ITO_36814,DivideMix: Learning with Noisy Labels as Semi-supervised Learning
CIFAR-10N-Random2,https://identifiers.org/ito:ITO_36810,Early-Learning Regularization Prevents Memorization of Noisy Labels
CIFAR-10N-Random2,https://identifiers.org/ito:ITO_37144,Learning with Instance-Dependent Label Noise: A Sample Sieve Approach
CIFAR-10N-Worst,https://identifiers.org/ito:ITO_36831,Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach
CIFAR-10N-Worst,https://identifiers.org/ito:ITO_36827,Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels
CIFAR-10N-Worst,https://identifiers.org/ito:ITO_36814,DivideMix: Learning with Noisy Labels as Semi-supervised Learning
CIFAR-10N-Random1,https://identifiers.org/ito:ITO_36831,Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach
CIFAR-10N-Random1,https://identifiers.org/ito:ITO_36827,Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels
CIFAR-10N-Random1,https://identifiers.org/ito:ITO_36810,Early-Learning Regularization Prevents Memorization of Noisy Labels
CIFAR-10N-Random1,https://identifiers.org/ito:ITO_37144,Learning with Instance-Dependent Label Noise: A Sample Sieve Approach
CIFAR-10N-Aggregate,https://identifiers.org/ito:ITO_36831,Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach
CIFAR-10N-Aggregate,https://identifiers.org/ito:ITO_36827,Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels
CIFAR-10N-Aggregate,https://identifiers.org/ito:ITO_59121,Does label smoothing mitigate label noise?
CIFAR-10N-Aggregate,https://identifiers.org/ito:ITO_36810,Early-Learning Regularization Prevents Memorization of Noisy Labels
CIFAR-10N-Aggregate,https://identifiers.org/ito:ITO_37144,Learning with Instance-Dependent Label Noise: A Sample Sieve Approach
CIFAR-100N,https://identifiers.org/ito:ITO_36831,Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach
CIFAR-100N,https://identifiers.org/ito:ITO_36827,Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels
CIFAR-100N,https://identifiers.org/ito:ITO_36814,DivideMix: Learning with Noisy Labels as Semi-supervised Learning
Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China,https://identifiers.org/ito:ITO_33382,Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China
Amazon-12K,https://identifiers.org/ito:ITO_12797,Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification
MIMIC-III-50,https://identifiers.org/ito:ITO_42513,Explainable Automated Coding of Clinical Notes using Hierarchical Label-wise Attention Networks and Label Embedding Initialisation
MIMIC-III-50,https://identifiers.org/ito:ITO_55482,Medical Code Prediction from Discharge Summary: Document to Sequence BERT using Sequence Attention
LF-AmzonTitles-131K,https://identifiers.org/ito:ITO_55487,ECLARE: Extreme Classification with Label Graph Correlations
Reuters-21578,https://identifiers.org/ito:ITO_55490,Balancing Methods for Multi-label Text Classification with Long-Tailed Class Distribution
LF-AmazonTitles-131K,https://identifiers.org/ito:ITO_55487,ECLARE: Extreme Classification with Label Graph Correlations
RCV1-v2,https://identifiers.org/ito:ITO_12785,MAGNET: Multi-Label Text Classification using Attention-based Graph Neural Network
Wiki-30K,https://identifiers.org/ito:ITO_12797,Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification
SVICTOR (theme),https://identifiers.org/ito:ITO_55498,VICTOR: a Dataset for Brazilian Legal Documents Classification
MIMIC-III,https://identifiers.org/ito:ITO_42513,Explainable Automated Coding of Clinical Notes using Hierarchical Label-wise Attention Networks and Label Embedding Initialisation
MIMIC-III,https://identifiers.org/ito:ITO_33403,An Empirical Evaluation of Deep Learning for ICD-9 Code Assignment using MIMIC-III Clinical Notes
USPTO-3M,https://identifiers.org/ito:ITO_33407,PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT Model
Slashdot,https://identifiers.org/ito:ITO_12785,MAGNET: Multi-Label Text Classification using Attention-based Graph Neural Network
Kan-Shan Cup,https://identifiers.org/ito:ITO_12797,Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification
AAPD,https://identifiers.org/ito:ITO_33369,Label-Wise Document Pre-Training for Multi-Label Text Classification
AAPD,https://identifiers.org/ito:ITO_12797,Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification
AAPD,https://identifiers.org/ito:ITO_55505,Label-Specific Document Representation for Multi-Label Text Classification
AAPD,https://identifiers.org/ito:ITO_12785,MAGNET: Multi-Label Text Classification using Attention-based Graph Neural Network
MVICTOR (theme),https://identifiers.org/ito:ITO_55498,VICTOR: a Dataset for Brazilian Legal Documents Classification
Freecode,https://identifiers.org/ito:ITO_33373,Tag Recommendation for Online Q&A Communities based on BERT Pre-Training Technique
BVICTOR,https://identifiers.org/ito:ITO_55498,VICTOR: a Dataset for Brazilian Legal Documents Classification
RCV1,https://identifiers.org/ito:ITO_55511,Joint Learning of Hyperbolic Label Embeddings for Hierarchical Multi-label Classification
EUR-Lex,https://identifiers.org/ito:ITO_12794,Large-Scale Multi-Label Text Classification on EU Legislation
EUR-Lex,https://identifiers.org/ito:ITO_12797,Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification
EUR-Lex,https://identifiers.org/ito:ITO_08328,Towards Scalable and Reliable Capsule Networks for Challenging NLP Applications
PCD,https://identifiers.org/ito:ITO_41627,Learning meters of Arabic and English poems with Recurrent Neural Networks: a step forward for language understanding and synthesis
Persian Twitter,https://identifiers.org/ito:ITO_61077,Tracking Legislators’ Expressed Policy Agendas in Real Time
Sepehr_RumTel01,https://identifiers.org/ito:ITO_56667,A Speech Act Classifier for Persian Texts and its Application in Identifying Rumors
Sepehr_RumTel01,https://identifiers.org/ito:ITO_56665,A Model to Measure the Spread Power of Rumors
Sepehr_RumTel01,https://identifiers.org/ito:ITO_56661,A Deep Content-Based Model for Persian Rumor Verification
Yahoo! Answers (800 Labels),https://identifiers.org/ito:ITO_36733,Semi-Supervised Learning with Normalizing Flows
AG News (200 Labels),https://identifiers.org/ito:ITO_36733,Semi-Supervised Learning with Normalizing Flows
SciCite,https://identifiers.org/ito:ITO_57995,Measuring the Evolution of a Scientific Field through Citation Frames
SciCite,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
PubMed 20k RCT,https://identifiers.org/ito:ITO_14792,Hierarchical Neural Networks for Sequential Sentence Classification in Medical Scientific Abstracts
Paper Field,https://identifiers.org/ito:ITO_04773,SciBERT: A Pretrained Language Model for Scientific Text
ACL-ARC,https://identifiers.org/ito:ITO_04773,SciBERT: A Pretrained Language Model for Scientific Text
ACL-ARC,https://identifiers.org/ito:ITO_36696,Improving Self-supervised Pre-training via a Fully-Explored Masked Language Model
ScienceCite,https://identifiers.org/ito:ITO_04773,SciBERT: A Pretrained Language Model for Scientific Text
CHIP-CTC,https://identifiers.org/ito:ITO_51428,CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark
Terms of Service,https://identifiers.org/ito:ITO_26260,When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset
TREC-6,https://identifiers.org/ito:ITO_14671,Discriminative Neural Sentence Modeling by Tree-Based Convolution
TREC-6,https://identifiers.org/ito:ITO_11653,A C-LSTM Neural Network for Text Classification
TREC-6,https://identifiers.org/ito:ITO_11657,All-but-the-Top: Simple and Effective Postprocessing for Word Representations
TREC-6,https://identifiers.org/ito:ITO_11700,Investigating Capsule Networks with Dynamic Routing for Text Classification
TREC-6,https://identifiers.org/ito:ITO_11605,A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors
TREC-6,https://identifiers.org/ito:ITO_54027,Enhancing Interpretable Clauses Semantically using Pretrained Word Representation
AG News,https://identifiers.org/ito:ITO_11624,Character-level Convolutional Networks for Text Classification
AG News,https://identifiers.org/ito:ITO_36537,Abstractive Text Classification Using Sequence-to-convolution Neural Networks
AG News,https://identifiers.org/ito:ITO_53986,Task-oriented Word Embedding for Text Classification
Amazon-5,https://identifiers.org/ito:ITO_31287,Unsupervised Data Augmentation for Consistency Training
BLURB,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
BLURB,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
MuLD (Character Type),https://identifiers.org/ito:ITO_49552,MuLD: The Multitask Long Document Benchmark
TREC-50,https://identifiers.org/ito:ITO_36652,Improving Question Classification by Feature Extraction and Selection
SILICONE Benchmark,https://identifiers.org/ito:ITO_21287,Hierarchical Pre-training for Sequence Labelling in Spoken Dialog
RusAge: Corpus for Age-Based Text Classification,https://identifiers.org/ito:ITO_36564,A Comparative Study of Feature Types for Age-Based Text Classification
Facebook Media,https://identifiers.org/ito:ITO_36541,A Unified System for Aggression Identification in English Code-Mixed and Uni-Lingual Texts
DODF Data,https://identifiers.org/ito:ITO_36556,Inferring the source of official texts: can SVM beat ULMFiT?
Ohsumed,https://identifiers.org/ito:ITO_11589,On the Role of Text Preprocessing in Neural Network Architectures: An Evaluation Study on Text Categorization and Sentiment Analysis
Ohsumed,https://identifiers.org/ito:ITO_11727,Graph Convolutional Networks for Text Classification
Ohsumed,https://identifiers.org/ito:ITO_04763,Simplifying Graph Convolutional Networks
Ohsumed,https://identifiers.org/ito:ITO_57797,Text Level Graph Neural Network for Text Classification
Ohsumed,https://identifiers.org/ito:ITO_36582,Text classification with word embedding regularization and soft similarity measure
MR,https://identifiers.org/ito:ITO_36547,Simple Spectral Graph Convolution
MR,https://identifiers.org/ito:ITO_57795,BertGCN: Transductive Text Classification by Combining GCN and BERT
Yelp-5,https://identifiers.org/ito:ITO_14682,Hierarchical Attentional Hybrid Neural Networks for Document Classification
Amazon-2,https://identifiers.org/ito:ITO_31287,Unsupervised Data Augmentation for Consistency Training
Amazon-2,https://identifiers.org/ito:ITO_14661,Sampling Bias in Deep Active Classification: An Empirical Study
Amazon-2,https://identifiers.org/ito:ITO_31376,"Heavy-tailed Representations, Text Polarity Classification & Data Augmentation"
arXiv,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
An Amharic News Text classification Dataset,https://identifiers.org/ito:ITO_36638,An Amharic News Text classification Dataset
MVICTOR (type),https://identifiers.org/ito:ITO_55498,VICTOR: a Dataset for Brazilian Legal Documents Classification
20NEWS,https://identifiers.org/ito:ITO_14685,RMDL: Random Multimodel Deep Learning for Classification
20NEWS,https://identifiers.org/ito:ITO_04763,Simplifying Graph Convolutional Networks
20NEWS,https://identifiers.org/ito:ITO_36547,Simple Spectral Graph Convolution
20NEWS,https://identifiers.org/ito:ITO_57795,BertGCN: Transductive Text Classification by Combining GCN and BERT
20NEWS,https://identifiers.org/ito:ITO_14738,Improving Document Classification with Multi-Sense Embeddings
20NEWS,https://identifiers.org/ito:ITO_36619,An Explainable Probabilistic Classifier for Categorical Data Inspired to Quantum Physics
20NEWS,https://identifiers.org/ito:ITO_14727,Representation Learning of Entities and Documents from Knowledge Base Descriptions
20NEWS,https://identifiers.org/ito:ITO_14725,Neural Attentive Bag-of-Entities Model for Text Classification
SVICTOR (type),https://identifiers.org/ito:ITO_55498,VICTOR: a Dataset for Brazilian Legal Documents Classification
R52,https://identifiers.org/ito:ITO_11727,Graph Convolutional Networks for Text Classification
R52,https://identifiers.org/ito:ITO_04763,Simplifying Graph Convolutional Networks
R52,https://identifiers.org/ito:ITO_02729,Graph Star Net for Generalized Multi-Task Learning
R52,https://identifiers.org/ito:ITO_57795,BertGCN: Transductive Text Classification by Combining GCN and BERT
OneStopEnglish (Readability Assessment),https://identifiers.org/ito:ITO_57815,OneStopEnglish corpus: A new corpus for automatic readability assessment and text simplification
OneStopEnglish (Readability Assessment),https://identifiers.org/ito:ITO_36572,Supervised and Unsupervised Neural Approaches to Text Readability
OneStopEnglish (Readability Assessment),https://identifiers.org/ito:ITO_57812,Pushing on Text Readability Assessment: A Transformer Meets Handcrafted Linguistic Features
Yelp-2,https://identifiers.org/ito:ITO_31287,Unsupervised Data Augmentation for Consistency Training
Yelp-2,https://identifiers.org/ito:ITO_14668,How to Fine-Tune BERT for Text Classification?
Yelp-2,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
Sogou News,https://identifiers.org/ito:ITO_53950,Compositional Coding Capsule Network with K-Means Routing for Text Classification
Sogou News,https://identifiers.org/ito:ITO_14668,How to Fine-Tune BERT for Text Classification?
DBpedia,https://identifiers.org/ito:ITO_11624,Character-level Convolutional Networks for Text Classification
DBpedia,https://identifiers.org/ito:ITO_36537,Abstractive Text Classification Using Sequence-to-convolution Neural Networks
WeeBit (Readability Assessment),https://identifiers.org/ito:ITO_36594,Text Readability Assessment for Second Language Learners
WeeBit (Readability Assessment),https://identifiers.org/ito:ITO_36572,Supervised and Unsupervised Neural Approaches to Text Readability
WeeBit (Readability Assessment),https://identifiers.org/ito:ITO_57812,Pushing on Text Readability Assessment: A Transformer Meets Handcrafted Linguistic Features
RCV1,https://identifiers.org/ito:ITO_11578,Supervised and Semi-Supervised Text Categorization using LSTM for Region Embeddings
RCV1,https://identifiers.org/ito:ITO_14706,Hierarchical Text Classification with Reinforced Label Assignment
RCV1,https://identifiers.org/ito:ITO_12785,MAGNET: Multi-Label Text Classification using Attention-based Graph Neural Network
RCV1,https://identifiers.org/ito:ITO_08328,Towards Scalable and Reliable Capsule Networks for Challenging NLP Applications
Patents,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
WNUT-2020 Task 2,https://identifiers.org/ito:ITO_36530,NutCracker at WNUT-2020 Task 2: Robustly Identifying Informative COVID-19 Tweets using Ensembling and Adversarial Training
TRAC2-English. Task2.,https://identifiers.org/ito:ITO_57829,"BERT of all trades, master of some"
AffCon 2020 Emotion Detection,https://identifiers.org/ito:ITO_36568,BERT-based Ensembles for Modeling Disclosure and Support in Conversational Social Media Text
Twitter-US,https://identifiers.org/ito:ITO_36541,A Unified System for Aggression Identification in English Code-Mixed and Uni-Lingual Texts
Overruling,https://identifiers.org/ito:ITO_26260,When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset
R8,https://identifiers.org/ito:ITO_14727,Representation Learning of Entities and Documents from Knowledge Base Descriptions
R8,https://identifiers.org/ito:ITO_11727,Graph Convolutional Networks for Text Classification
R8,https://identifiers.org/ito:ITO_04763,Simplifying Graph Convolutional Networks
R8,https://identifiers.org/ito:ITO_02729,Graph Star Net for Generalized Multi-Task Learning
R8,https://identifiers.org/ito:ITO_14725,Neural Attentive Bag-of-Entities Model for Text Classification
R8,https://identifiers.org/ito:ITO_57795,BertGCN: Transductive Text Classification by Combining GCN and BERT
Hyperpartisan,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
TRAC2-Benghali. Task 2.,https://identifiers.org/ito:ITO_57829,"BERT of all trades, master of some"
GLUE RTE,https://identifiers.org/ito:ITO_51450,TRANS-BLSTM: Transformer with Bidirectional LSTM for Language Understanding
Yahoo! Answers,https://identifiers.org/ito:ITO_11621,Bag of Tricks for Efficient Text Classification
Yahoo! Answers,https://identifiers.org/ito:ITO_08299,Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms
Yahoo! Answers,https://identifiers.org/ito:ITO_53949,Disconnected Recurrent Neural Networks for Text Categorization
Yahoo! Answers,https://identifiers.org/ito:ITO_14668,How to Fine-Tune BERT for Text Classification?
GLUE COLA,https://identifiers.org/ito:ITO_51450,TRANS-BLSTM: Transformer with Bidirectional LSTM for Language Understanding
GLUE SST2,https://identifiers.org/ito:ITO_51450,TRANS-BLSTM: Transformer with Bidirectional LSTM for Language Understanding
GLUE MRPC,https://identifiers.org/ito:ITO_51450,TRANS-BLSTM: Transformer with Bidirectional LSTM for Language Understanding
GLUE STSB,https://identifiers.org/ito:ITO_51450,TRANS-BLSTM: Transformer with Bidirectional LSTM for Language Understanding
IMDb,https://identifiers.org/ito:ITO_08304,Distributed Representations of Sentences and Documents
IMDb,https://identifiers.org/ito:ITO_14682,Hierarchical Attentional Hybrid Neural Networks for Document Classification
IMDb,https://identifiers.org/ito:ITO_57943,ERNIE-Doc: A Retrospective Long-Document Modeling Transformer
IMDb,https://identifiers.org/ito:ITO_14689,DocBERT: BERT for Document Classification
IMDb,https://identifiers.org/ito:ITO_36614,Improving Document-Level Sentiment Classification Using Importance of Sentences
LOCAL DATASET,https://identifiers.org/ito:ITO_14685,RMDL: Random Multimodel Deep Learning for Classification
Topic modeling topic coverage dataset - news,https://identifiers.org/ito:ITO_57965,A Topic Coverage Approach to Evaluation of Topic Models
Topic modeling topic coverage dataset - bio,https://identifiers.org/ito:ITO_57965,A Topic Coverage Approach to Evaluation of Topic Models
Topic modeling topic coverage dataset,https://identifiers.org/ito:ITO_57965,A Topic Coverage Approach to Evaluation of Topic Models
NYT,https://identifiers.org/ito:ITO_36659,Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding
arXiv,https://identifiers.org/ito:ITO_36659,Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding
arXiv,https://identifiers.org/ito:ITO_36663,TopicEq: A Joint Topic and Mathematical Equation Model for Scientific Texts
20 Newsgroups,https://identifiers.org/ito:ITO_08295,Neural Variational Inference for Text Processing
20 Newsgroups,https://identifiers.org/ito:ITO_15745,Learning document embeddings along with their uncertainties
GermEval 2021 - Toxic Comments test set,https://identifiers.org/ito:ITO_58031,"FHAC at GermEval 2021: Identifying German toxic, engaging, and fact-claiming comments with ensemble learning"
THYME-2016,https://identifiers.org/ito:ITO_41610,Ontology-driven weak supervision for clinical entity classification in electronic health records
ShARe/CLEF 2014: Task 2 Disorders,https://identifiers.org/ito:ITO_41610,Ontology-driven weak supervision for clinical entity classification in electronic health records
SNIPS,https://identifiers.org/ito:ITO_55222,Discovering New Intents via Constrained Deep Adaptive Clustering with Cluster Refinement
Stackoverflow,https://identifiers.org/ito:ITO_55222,Discovering New Intents via Constrained Deep Adaptive Clustering with Cluster Refinement
BANKING77,https://identifiers.org/ito:ITO_55227,Discovering New Intents with Deep Aligned Clustering
ATIS,https://identifiers.org/ito:ITO_55222,Discovering New Intents via Constrained Deep Adaptive Clustering with Cluster Refinement
CLINC150,https://identifiers.org/ito:ITO_55227,Discovering New Intents with Deep Aligned Clustering
GoogleNews-T,https://identifiers.org/ito:ITO_32969,Supporting Clustering with Contrastive Learning
Searchsnippets,https://identifiers.org/ito:ITO_32973,Self-Taught Convolutional Neural Networks for Short Text Clustering
Searchsnippets,https://identifiers.org/ito:ITO_55209,A Self-Training Approach for Short Text Clustering
Searchsnippets,https://identifiers.org/ito:ITO_32969,Supporting Clustering with Contrastive Learning
GoogleNews-S,https://identifiers.org/ito:ITO_32969,Supporting Clustering with Contrastive Learning
Tweet,https://identifiers.org/ito:ITO_32969,Supporting Clustering with Contrastive Learning
AG News,https://identifiers.org/ito:ITO_32969,Supporting Clustering with Contrastive Learning
Biomedical,https://identifiers.org/ito:ITO_32973,Self-Taught Convolutional Neural Networks for Short Text Clustering
Biomedical,https://identifiers.org/ito:ITO_32969,Supporting Clustering with Contrastive Learning
GoogleNews-TS,https://identifiers.org/ito:ITO_32969,Supporting Clustering with Contrastive Learning
20 Newsgroups,https://identifiers.org/ito:ITO_32965,Neural Topic Modeling with Bidirectional Adversarial Training
RR,https://identifiers.org/ito:ITO_45768,Argument Pair Extraction via Attention-guided Multi-Layer Multi-Cross Encoding
IAM Dataset,https://identifiers.org/ito:ITO_45774,IAM: A Comprehensive and Large-Scale Dataset for Integrated Argument Mining Tasks
SensEval 3 Task 1,https://identifiers.org/ito:ITO_09393,Semi-supervised Word Sense Disambiguation with Neural Models
SensEval 3 Task 1,https://identifiers.org/ito:ITO_09389,Sense Vocabulary Compression through the Semantic Knowledge of WordNet for Neural Word Sense Disambiguation
Knowledge-based:,https://identifiers.org/ito:ITO_51330,Entity Linking meets Word Sense Disambiguation: a Unified Approach
Knowledge-based:,https://identifiers.org/ito:ITO_51332,Random Walks for Knowledge-Based Word Sense Disambiguation
Knowledge-based:,https://identifiers.org/ito:ITO_28345,Word Sense Disambiguation: A comprehensive knowledge exploitation framework
Knowledge-based:,https://identifiers.org/ito:ITO_51331,Word Sense Disambiguation: A Unified Evaluation Framework and Empirical Comparison
Knowledge-based:,https://identifiers.org/ito:ITO_09424,Knowledge-based Word Sense Disambiguation using Topic Models
SensEval 2 Lexical Sample,https://identifiers.org/ito:ITO_09444,Semi-Supervised Word Sense Disambiguation Using Word Embeddings in General and Specific Domains
SensEval 2 Lexical Sample,https://identifiers.org/ito:ITO_09442,Word Sense Disambiguation using a Bidirectional LSTM
SensEval 2 Lexical Sample,https://identifiers.org/ito:ITO_09398,Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings
SemEval 2015 Task 13,https://identifiers.org/ito:ITO_09432,Incorporating Glosses into Neural Word Sense Disambiguation
SemEval 2015 Task 13,https://identifiers.org/ito:ITO_09391,Improving the Coverage and the Generalization Ability of Neural Word Sense Disambiguation through Hypernymy and Hyponymy Relationships
SemEval 2015 Task 13,https://identifiers.org/ito:ITO_09389,Sense Vocabulary Compression through the Semantic Knowledge of WordNet for Neural Word Sense Disambiguation
SensEval 3 Lexical Sample,https://identifiers.org/ito:ITO_09444,Semi-Supervised Word Sense Disambiguation Using Word Embeddings in General and Specific Domains
SensEval 3 Lexical Sample,https://identifiers.org/ito:ITO_09398,Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings
Supervised:,https://identifiers.org/ito:ITO_51348,Neural Sequence Learning Models for Word Sense Disambiguation
Supervised:,https://identifiers.org/ito:ITO_09432,Incorporating Glosses into Neural Word Sense Disambiguation
Supervised:,https://identifiers.org/ito:ITO_09391,Improving the Coverage and the Generalization Ability of Neural Word Sense Disambiguation through Hypernymy and Hyponymy Relationships
Supervised:,https://identifiers.org/ito:ITO_09389,Sense Vocabulary Compression through the Semantic Knowledge of WordNet for Neural Word Sense Disambiguation
Supervised:,https://identifiers.org/ito:ITO_51344,Breaking Through the 80\% Glass Ceiling: Raising the State of the Art in Word Sense Disambiguation by Incorporating Knowledge Graph Information
Supervised:,https://identifiers.org/ito:ITO_51343,ESC: Redesigning WSD with Extractive Sense Comprehension
Supervised:,https://identifiers.org/ito:ITO_07964,Deep contextualized word representations
SensEval 2,https://identifiers.org/ito:ITO_09393,Semi-supervised Word Sense Disambiguation with Neural Models
SensEval 2,https://identifiers.org/ito:ITO_09391,Improving the Coverage and the Generalization Ability of Neural Word Sense Disambiguation through Hypernymy and Hyponymy Relationships
SensEval 2,https://identifiers.org/ito:ITO_09389,Sense Vocabulary Compression through the Semantic Knowledge of WordNet for Neural Word Sense Disambiguation
SemEval 2007 Task 7,https://identifiers.org/ito:ITO_09393,Semi-supervised Word Sense Disambiguation with Neural Models
SemEval 2007 Task 7,https://identifiers.org/ito:ITO_09391,Improving the Coverage and the Generalization Ability of Neural Word Sense Disambiguation through Hypernymy and Hyponymy Relationships
SemEval 2007 Task 7,https://identifiers.org/ito:ITO_09389,Sense Vocabulary Compression through the Semantic Knowledge of WordNet for Neural Word Sense Disambiguation
SemEval 2007 Task 17,https://identifiers.org/ito:ITO_09393,Semi-supervised Word Sense Disambiguation with Neural Models
SemEval 2007 Task 17,https://identifiers.org/ito:ITO_09391,Improving the Coverage and the Generalization Ability of Neural Word Sense Disambiguation through Hypernymy and Hyponymy Relationships
SemEval 2007 Task 17,https://identifiers.org/ito:ITO_09389,Sense Vocabulary Compression through the Semantic Knowledge of WordNet for Neural Word Sense Disambiguation
SemEval 2013 Task 12,https://identifiers.org/ito:ITO_09393,Semi-supervised Word Sense Disambiguation with Neural Models
SemEval 2013 Task 12,https://identifiers.org/ito:ITO_09391,Improving the Coverage and the Generalization Ability of Neural Word Sense Disambiguation through Hypernymy and Hyponymy Relationships
SemEval 2013 Task 12,https://identifiers.org/ito:ITO_09389,Sense Vocabulary Compression through the Semantic Knowledge of WordNet for Neural Word Sense Disambiguation
RUSSE,https://identifiers.org/ito:ITO_25466,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
WiC-TSV,https://identifiers.org/ito:ITO_28332,GlossBERT: BERT for Word Sense Disambiguation with Gloss Knowledge
WiC-TSV,https://identifiers.org/ito:ITO_28334,WiC-TSV: An Evaluation Benchmark for Target Sense Verification of Words in Context
Words in Context,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
Words in Context,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
Words in Context,https://identifiers.org/ito:ITO_28342,Fine-Tuning Pre-trained Language Model with Weak Supervision: A Contrastive-Regularized Self-Training Approach
SemEval 2013,https://identifiers.org/ito:ITO_51362,AI-KU: Using Substitute Vectors and Co-Occurrence Modeling For Word Sense Induction and Disambiguation
SemEval 2013,https://identifiers.org/ito:ITO_51361,A Sense-Topic Model for Word Sense Induction with Unsupervised Data Enrichment
SemEval 2013,https://identifiers.org/ito:ITO_51360,Structured Generative Models of Continuous Features for Word Sense Induction
SemEval 2013,https://identifiers.org/ito:ITO_28402,Word Sense Induction with Neural biLM and Symmetric Patterns
SemEval 2013,https://identifiers.org/ito:ITO_28388,Towards better substitution-based word sense induction
SemEval 2013,https://identifiers.org/ito:ITO_28390,AutoSense Model for Word Sense Induction
SemEval 2010 WSI,https://identifiers.org/ito:ITO_51364,Unsupervised Word Sense Induction using Distributional Statistics
SemEval 2010 WSI,https://identifiers.org/ito:ITO_28390,AutoSense Model for Word Sense Induction
SemEval 2010 WSI,https://identifiers.org/ito:ITO_28388,Towards better substitution-based word sense induction
SemEval 2010 WSI,https://identifiers.org/ito:ITO_51365,Inducing Word Sense with Automatically Learned Hidden Concepts
SemEval 2010 WSI,https://identifiers.org/ito:ITO_28394,Sense Embedding Learning for Word Sense Induction
Google Dataset,https://identifiers.org/ito:ITO_56211,Sentence Compression by Deletion with LSTMs
Google Dataset,https://identifiers.org/ito:ITO_56210,Higher-Order Syntactic Attention Network for Longer Sentence Compression
Google Dataset,https://identifiers.org/ito:ITO_56209,A Language Model based Evaluator for Sentence Compression
Google Dataset,https://identifiers.org/ito:ITO_34501,Syntactically Look-Ahead Attention Network for Sentence Compression
Google Dataset,https://identifiers.org/ito:ITO_56212,Can Syntax Help? Improving an LSTM-based Sentence Compression Model for New Domains
MedSTS,https://identifiers.org/ito:ITO_34508,BioSentVec: creating sentence embeddings for biomedical texts
BIOSSES,https://identifiers.org/ito:ITO_34514,BIOSSES: A Semantic Sentence Similarity Estimation System for the Biomedical Domain
BIOSSES,https://identifiers.org/ito:ITO_34508,BioSentVec: creating sentence embeddings for biomedical texts
BIOSSES,https://identifiers.org/ito:ITO_56216,Neural sentence embedding models for semantic similarity estimation in the biomedical domain
The ARRAU Corpus,https://identifiers.org/ito:ITO_16040,A Mention-Ranking Model for Abstract Anaphora Resolution
CoNLL 2000,https://identifiers.org/ito:ITO_04505,Robust Multilingual Part-of-Speech Tagging via Adversarial Training
CoNLL 2000,https://identifiers.org/ito:ITO_34519,Cross-View Training for Semi-Supervised Learning
CoNLL 2000,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
CoNLL 2003 (English),https://identifiers.org/ito:ITO_34526,"More Embeddings, Better Sequence Labelers?"
CoNLL 2003 (German),https://identifiers.org/ito:ITO_34526,"More Embeddings, Better Sequence Labelers?"
Penn Treebank,https://identifiers.org/ito:ITO_56228,Deep multi-task learning with low level tasks supervised at lower layers
Penn Treebank,https://identifiers.org/ito:ITO_13168,A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks
Penn Treebank,https://identifiers.org/ito:ITO_45104,Contextual String Embeddings for Sequence Labeling
Penn Treebank,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
CCGbank,https://identifiers.org/ito:ITO_60532,LSTM CCG Parsing
CCGbank,https://identifiers.org/ito:ITO_05191,Semi-Supervised Sequence Modeling with Cross-View Training
CCGbank,https://identifiers.org/ito:ITO_60531,Geometry-Aware Supertagging with Heterogeneous Dynamic Convolutions
PTB,https://identifiers.org/ito:ITO_13222,Neural Language Modeling by Jointly Learning Syntax and Lexicon
PTB,https://identifiers.org/ito:ITO_13219,Unsupervised Learning of Syntactic Structure with Invertible Neural Projections
PTB,https://identifiers.org/ito:ITO_13217,Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks
PTB,https://identifiers.org/ito:ITO_56248,Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders
PTB,https://identifiers.org/ito:ITO_34565,PCFGs Can Do Better: Inducing Probabilistic Context-Free Grammars with Many Symbols
PTB,https://identifiers.org/ito:ITO_34563,Neural Bi-Lexicalized PCFG Induction
PTB,https://identifiers.org/ito:ITO_56247,Co-training an Unsupervised Constituency Parser with Weak Supervision
PTB,https://identifiers.org/ito:ITO_56245,Dynamic Programming in Rank Space: Scaling Structured Inference with Low-Rank HMMs and PCFGs
PTB,https://identifiers.org/ito:ITO_13225,Unsupervised Recurrent Neural Network Grammars
PTB,https://identifiers.org/ito:ITO_13213,Compound Probabilistic Context-Free Grammars for Grammar Induction
CTB7,https://identifiers.org/ito:ITO_34539,Fast and Accurate Neural CRF Constituency Parsing
Penn Treebank,https://identifiers.org/ito:ITO_34554,Effective Self-Training for Parsing
Penn Treebank,https://identifiers.org/ito:ITO_56235,Syntactic Parse Fusion
Penn Treebank,https://identifiers.org/ito:ITO_56234,Parsing as Language Modeling
Penn Treebank,https://identifiers.org/ito:ITO_13190,Improving Neural Parsing by Disentangling Model Combination and Reranking Effects
Penn Treebank,https://identifiers.org/ito:ITO_13188,Constituency Parsing with a Self-Attentive Encoder
Penn Treebank,https://identifiers.org/ito:ITO_11680,Cloze-driven Pretraining of Self-attention Networks
Penn Treebank,https://identifiers.org/ito:ITO_30792,Head-Driven Phrase Structure Grammar Parsing on Penn Treebank
Penn Treebank,https://identifiers.org/ito:ITO_30789,Rethinking Self-Attention: Towards Interpretability in Neural Parsing
CTB5,https://identifiers.org/ito:ITO_13188,Constituency Parsing with a Self-Attentive Encoder
CTB5,https://identifiers.org/ito:ITO_56240,Multilingual Constituency Parsing with Self-Attention and Pre-Training
CTB5,https://identifiers.org/ito:ITO_34539,Fast and Accurate Neural CRF Constituency Parsing
CTB5,https://identifiers.org/ito:ITO_34536,Strongly Incremental Constituency Parsing with Graph Neural Networks
Universal Dependency Treebank,https://identifiers.org/ito:ITO_30845,"Many Languages, One Parser"
Universal Dependency Treebank,https://identifiers.org/ito:ITO_30843,"Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing"
Universal Dependency Treebank,https://identifiers.org/ito:ITO_30847,A Representation Learning Framework for Multi-Source Transfer Parsing
WSJ,https://identifiers.org/ito:ITO_30836,Second-Order Unsupervised Neural Dependency Parsing
WSJ10,https://identifiers.org/ito:ITO_53508,Enhancing Unsupervised Generative Dependency Parser with Contextual Information
WSJ10,https://identifiers.org/ito:ITO_30836,Second-Order Unsupervised Neural Dependency Parsing
Chinese Treebank,https://identifiers.org/ito:ITO_30793,Second-Order Neural Dependency Parsing with Message Passing and End-to-End Training
UD2.5 test,https://identifiers.org/ito:ITO_45114,Trankit: A Light-Weight Transformer-based Toolkit for Multilingual Natural Language Processing
Universal Dependencies,https://identifiers.org/ito:ITO_30819,"Towards Better UD Parsing: Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation"
Universal Dependencies,https://identifiers.org/ito:ITO_30781,"75 Languages, 1 Model: Parsing Universal Dependencies Universally"
Universal Dependencies,https://identifiers.org/ito:ITO_30817,"Evaluating Contextualized Embeddings on 54 Languages in POS Tagging, Lemmatization and Dependency Parsing"
Universal Dependencies,https://identifiers.org/ito:ITO_53484,UDPipe 2.0 Prototype at CoNLL 2018 UD Shared Task
Universal Dependencies,https://identifiers.org/ito:ITO_30821,Universal Dependency Parsing from Scratch
Universal Dependencies,https://identifiers.org/ito:ITO_53483,Turku Neural Parser Pipeline: An End-to-End System for the CoNLL 2018 Shared Task
ParTUT,https://identifiers.org/ito:ITO_30781,"75 Languages, 1 Model: Parsing Universal Dependencies Universally"
ParTUT,https://identifiers.org/ito:ITO_21017,CamemBERT: a Tasty French Language Model
NLPCC-2019,https://identifiers.org/ito:ITO_30785,Efficient Second-Order TreeCRF for Neural Dependency Parsing
Sequoia Treebank,https://identifiers.org/ito:ITO_30781,"75 Languages, 1 Model: Parsing Universal Dependencies Universally"
Sequoia Treebank,https://identifiers.org/ito:ITO_21017,CamemBERT: a Tasty French Language Model
Penn Treebank,https://identifiers.org/ito:ITO_11179,Structured Training for Neural Network Transition-Based Parsing
Penn Treebank,https://identifiers.org/ito:ITO_11173,Globally Normalized Transition-Based Neural Networks
Penn Treebank,https://identifiers.org/ito:ITO_11171,Deep Biaffine Attention for Neural Dependency Parsing
Penn Treebank,https://identifiers.org/ito:ITO_11181,Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations
Penn Treebank,https://identifiers.org/ito:ITO_11175,An improved neural network model for joint POS tagging and dependency parsing
CoNLL-2009,https://identifiers.org/ito:ITO_11171,Deep Biaffine Attention for Neural Dependency Parsing
CoNLL-2009,https://identifiers.org/ito:ITO_30785,Efficient Second-Order TreeCRF for Neural Dependency Parsing
GENIA - UAS,https://identifiers.org/ito:ITO_11162,From POS tagging to dependency parsing for biomedical event extraction
Spoken Corpus,https://identifiers.org/ito:ITO_30781,"75 Languages, 1 Model: Parsing Universal Dependencies Universally"
Spoken Corpus,https://identifiers.org/ito:ITO_21017,CamemBERT: a Tasty French Language Model
GENIA - LAS,https://identifiers.org/ito:ITO_11162,From POS tagging to dependency parsing for biomedical event extraction
French GSD,https://identifiers.org/ito:ITO_30781,"75 Languages, 1 Model: Parsing Universal Dependencies Universally"
French GSD,https://identifiers.org/ito:ITO_21017,CamemBERT: a Tasty French Language Model
Penn Treebank,https://identifiers.org/ito:ITO_53505,Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency
Penn Treebank,https://identifiers.org/ito:ITO_53504,Shared Logistic Normal Distributions for Soft Parameter Tying in Unsupervised Grammar Induction
Penn Treebank,https://identifiers.org/ito:ITO_53503,Unsupervised Induction of Tree Substitution Grammars for Dependency Parsing
Penn Treebank,https://identifiers.org/ito:ITO_53502,Breaking Out of Local Optima with Count Transforms and Model Recombination: A Study in Grammar Induction
Penn Treebank,https://identifiers.org/ito:ITO_30850,Unsupervised Dependency Parsing: Let's Use Supervised Parsers
SIGHAN 2015,https://identifiers.org/ito:ITO_41783,"Read, Listen, and See: Leveraging Multimodal Information Helps Chinese Spell Checking"
SIGHAN 2015,https://identifiers.org/ito:ITO_62124,PHMOSpell: Phonological and Morphological Knowledge Guided Chinese Spelling Check
Unrestricted,https://identifiers.org/ito:ITO_11129,Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study
CoNLL-2014 Shared Task (10 annotations),https://identifiers.org/ito:ITO_11124,A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction
CoNLL-2014 Shared Task (10 annotations),https://identifiers.org/ito:ITO_30750,Near Human-Level Performance in Grammatical Error Correction with Hybrid Machine Translation
BEA-2019 (test),https://identifiers.org/ito:ITO_30735,Learning to combine Grammatical Error Corrections
BEA-2019 (test),https://identifiers.org/ito:ITO_30733,"GECToR -- Grammatical Error Correction: Tag, Not Rewrite"
CoNLL-2014 Shared Task,https://identifiers.org/ito:ITO_11115,Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data
CoNLL-2014 Shared Task,https://identifiers.org/ito:ITO_30733,"GECToR -- Grammatical Error Correction: Tag, Not Rewrite"
CoNLL-2014 Shared Task,https://identifiers.org/ito:ITO_53457,Stronger Baselines for Grammatical Error Correction Using Pretrained Encoder-Decoder Model
CoNLL-2014 Shared Task,https://identifiers.org/ito:ITO_11124,A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction
CoNLL-2014 Shared Task,https://identifiers.org/ito:ITO_30750,Near Human-Level Performance in Grammatical Error Correction with Hybrid Machine Translation
CoNLL-2014 Shared Task,https://identifiers.org/ito:ITO_53458,Neural Quality Estimation of Grammatical Error Correction
CoNLL-2014 Shared Task,https://identifiers.org/ito:ITO_30738,An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction
CoNLL-2014 Shared Task,https://identifiers.org/ito:ITO_53456,A Simple Recipe for Multilingual Grammatical Error Correction
GMEG-wiki,https://identifiers.org/ito:ITO_53452,LM-Critic: Language Models for Unsupervised Grammatical Error Correction
JFLEG,https://identifiers.org/ito:ITO_11124,A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction
JFLEG,https://identifiers.org/ito:ITO_30750,Near Human-Level Performance in Grammatical Error Correction with Hybrid Machine Translation
JFLEG,https://identifiers.org/ito:ITO_30740,Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction
JFLEG,https://identifiers.org/ito:ITO_30744,Neural Quality Estimation with Multiple Hypotheses for Grammatical Error Correction
Falko-MERLIN,https://identifiers.org/ito:ITO_53469,Using Wikipedia Edits in Low Resource Grammatical Error Correction
Falko-MERLIN,https://identifiers.org/ito:ITO_53466,Grammatical Error Correction in Low-Resource Scenarios
Falko-MERLIN,https://identifiers.org/ito:ITO_53456,A Simple Recipe for Multilingual Grammatical Error Correction
GMEG-yahoo,https://identifiers.org/ito:ITO_53452,LM-Critic: Language Models for Unsupervised Grammatical Error Correction
CoNLL-2014 A1,https://identifiers.org/ito:ITO_11140,Compositional Sequence Labeling Models for Error Detection in Learner Writing
CoNLL-2014 A1,https://identifiers.org/ito:ITO_11138,Auxiliary Objectives for Neural Error Detection Models
CoNLL-2014 A1,https://identifiers.org/ito:ITO_30744,Neural Quality Estimation with Multiple Hypotheses for Grammatical Error Correction
FCE,https://identifiers.org/ito:ITO_11140,Compositional Sequence Labeling Models for Error Detection in Learner Writing
FCE,https://identifiers.org/ito:ITO_04524,Attending to Characters in Neural Sequence Labeling Models
FCE,https://identifiers.org/ito:ITO_04519,Semi-supervised Multitask Learning for Sequence Labeling
FCE,https://identifiers.org/ito:ITO_11142,Artificial Error Generation with Machine Translation and Syntactic Patterns
FCE,https://identifiers.org/ito:ITO_11144,Jointly Learning to Label Sentences and Tokens
FCE,https://identifiers.org/ito:ITO_30744,Neural Quality Estimation with Multiple Hypotheses for Grammatical Error Correction
JFLEG,https://identifiers.org/ito:ITO_11144,Jointly Learning to Label Sentences and Tokens
CoNLL-2014 A2,https://identifiers.org/ito:ITO_11140,Compositional Sequence Labeling Models for Error Detection in Learner Writing
CoNLL-2014 A2,https://identifiers.org/ito:ITO_11138,Auxiliary Objectives for Neural Error Detection Models
CoNLL-2014 A2,https://identifiers.org/ito:ITO_30744,Neural Quality Estimation with Multiple Hypotheses for Grammatical Error Correction
CoLA,https://identifiers.org/ito:ITO_09517,Multi-Task Deep Neural Networks for Natural Language Understanding
CoLA,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
CoLA,https://identifiers.org/ito:ITO_28463,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
CoLA,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
CoLA,https://identifiers.org/ito:ITO_26088,Entailment as Few-Shot Learner
CoLA Dev,https://identifiers.org/ito:ITO_26155,TinyBERT: Distilling BERT for Natural Language Understanding
CoLA Dev,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
ANTILLES,https://identifiers.org/ito:ITO_45100,ANTILLES: An Open French Linguistically Enriched Part-of-Speech Corpus
Penn Treebank,https://identifiers.org/ito:ITO_04501,Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation
Penn Treebank,https://identifiers.org/ito:ITO_04497,Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings
Penn Treebank,https://identifiers.org/ito:ITO_45103,Sequence Alignment Ensemble with a Single Neural Network for Sequence Labeling
Penn Treebank,https://identifiers.org/ito:ITO_45107,Sequential Alignment Methods for Ensemble Part-of-Speech Tagging
Social media,https://identifiers.org/ito:ITO_45111,Twitter Part-of-Speech Tagging for All: Overcoming Sparse and Noisy Data
Social media,https://identifiers.org/ito:ITO_21053,Joint Learning of Pre-Trained and Random Units for Domain Adaptation in Part-of-Speech Tagging
Ritter,https://identifiers.org/ito:ITO_45118,Part-of-Speech Tagging for Twitter with Adversarial Neural Networks
Ritter,https://identifiers.org/ito:ITO_45117,Transferring from Formal Newswire Domain with Hypernet for Twitter POS Tagging
Ritter,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
ARK,https://identifiers.org/ito:ITO_45110,Improved Part-of-Speech Tagging for Online Conversational Text with Word Clusters
ARK,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
UD,https://identifiers.org/ito:ITO_04525,Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss
UD,https://identifiers.org/ito:ITO_04505,Robust Multilingual Part-of-Speech Tagging via Adversarial Training
UD,https://identifiers.org/ito:ITO_04503,Hierarchically-Refined Label Attention Network for Sequence Labeling
Tweebank,https://identifiers.org/ito:ITO_45118,Part-of-Speech Tagging for Twitter with Adversarial Neural Networks
Tweebank,https://identifiers.org/ito:ITO_21023,BERTweet: A pre-trained language model for English Tweets
Tweebank,https://identifiers.org/ito:ITO_21010,Automated Concatenation of Embeddings for Structured Prediction
Query Wellformedness,https://identifiers.org/ito:ITO_16210,Identifying Well-formed Natural Language Questions
Tashkeela,https://identifiers.org/ito:ITO_17259,Arabic Text Diacritization Using Deep Neural Networks
Tashkeela,https://identifiers.org/ito:ITO_17257,Neural Arabic Text Diacritization: State of the Art Results and a Novel Approach for Machine Translation
Tashkeela,https://identifiers.org/ito:ITO_40565,Effective Deep Learning Models for Automatic Diacritization of Arabic Text
Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems,https://identifiers.org/ito:ITO_62450,Diacritics Restoration using BERT with Analysis on Czech language
Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems,https://identifiers.org/ito:ITO_62452,Diacritics Restoration Using Neural Networks
APW,https://identifiers.org/ito:ITO_61854,Labeling Documents with Timestamps: Learning from their Time Expressions
APW,https://identifiers.org/ito:ITO_41589,Dating Documents using Graph Convolution Networks
NYT,https://identifiers.org/ito:ITO_61854,Labeling Documents with Timestamps: Learning from their Time Expressions
NYT,https://identifiers.org/ito:ITO_41589,Dating Documents using Graph Convolution Networks
ToughTables-WD,https://identifiers.org/ito:ITO_61535,DAGOBAH: Table and Graph Contexts for Eﬀicient Semantic Annotation of Tabular Data
WikiTables-TURL-CEA,https://identifiers.org/ito:ITO_61529,TURL: Table Understanding through Representation Learning
ToughTables-DBP,https://identifiers.org/ito:ITO_61535,DAGOBAH: Table and Graph Contexts for Eﬀicient Semantic Annotation of Tabular Data
WikipediaGS,https://identifiers.org/ito:ITO_61529,TURL: Table Understanding through Representation Learning
WikiTables-TURL-CTA,https://identifiers.org/ito:ITO_61529,TURL: Table Understanding through Representation Learning
GitTables-SemTab-SCH,https://identifiers.org/ito:ITO_61535,DAGOBAH: Table and Graph Contexts for Eﬀicient Semantic Annotation of Tabular Data
VizNet-Sato-Full,https://identifiers.org/ito:ITO_61539,Sato: Contextual Semantic Type Detection in Tables
VizNet-Sato-Full,https://identifiers.org/ito:ITO_61531,Annotating Columns with Pre-trained Language Models
VizNet-Sato-Full,https://identifiers.org/ito:ITO_61541,TABBIE: Pretrained Representations of Tabular Data
VizNet-Sato-MultiColumn,https://identifiers.org/ito:ITO_61539,Sato: Contextual Semantic Type Detection in Tables
VizNet-Sato-MultiColumn,https://identifiers.org/ito:ITO_61531,Annotating Columns with Pre-trained Language Models
WikipediaGS-CTA,https://identifiers.org/ito:ITO_61552,Learning Semantic Annotations for Tabular Data
WikipediaGS-CTA,https://identifiers.org/ito:ITO_61529,TURL: Table Understanding through Representation Learning
GitTables-SemTab-DBP,https://identifiers.org/ito:ITO_61535,DAGOBAH: Table and Graph Contexts for Eﬀicient Semantic Annotation of Tabular Data
ToughTables-DBP,https://identifiers.org/ito:ITO_61549,JenTab Meets SemTab 2021's New Challenges
T2Dv2,https://identifiers.org/ito:ITO_61552,Learning Semantic Annotations for Tabular Data
T2Dv2,https://identifiers.org/ito:ITO_61563,ColNet: Embedding the Semantics of Web Tables for Column Type Prediction
T2Dv2,https://identifiers.org/ito:ITO_61572,Matching web tables to DBpedia-A feature utility study
WikiTables-TURL-CPA,https://identifiers.org/ito:ITO_61529,TURL: Table Understanding through Representation Learning
Multi-Rewrite,https://identifiers.org/ito:ITO_41016,SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete Utterance Restoration
Multi-Rewrite,https://identifiers.org/ito:ITO_41014,Incomplete Utterance Rewriting as Semantic Segmentation
CANARD,https://identifiers.org/ito:ITO_41016,SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete Utterance Restoration
Rewrite,https://identifiers.org/ito:ITO_41014,Incomplete Utterance Rewriting as Semantic Segmentation
CLEVR-X,https://identifiers.org/ito:ITO_62866,CLEVR-X: A Visual Reasoning Dataset for Natural Language Explanations
Hindi Visual Genome (Challenge Set),https://identifiers.org/ito:ITO_55020,An encoder-decoder based framework for hindi image caption generation
Hindi Visual Genome (Test Set),https://identifiers.org/ito:ITO_55020,An encoder-decoder based framework for hindi image caption generation
nocaps-val-in-domain,https://identifiers.org/ito:ITO_27227,VinVL: Revisiting Visual Representations in Vision-Language Models
nocaps-val-in-domain,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
nocaps-val-in-domain,https://identifiers.org/ito:ITO_54910,Scaling Up Vision-Language Pre-training for Image Captioning
nocaps-val-in-domain,https://identifiers.org/ito:ITO_54918,Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts
nocaps-val-near-domain,https://identifiers.org/ito:ITO_27227,VinVL: Revisiting Visual Representations in Vision-Language Models
nocaps-val-near-domain,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
nocaps-val-near-domain,https://identifiers.org/ito:ITO_54910,Scaling Up Vision-Language Pre-training for Image Captioning
nocaps in-domain,https://identifiers.org/ito:ITO_32556,VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning
COCO Captions test,https://identifiers.org/ito:ITO_54941,From Captions to Visual Concepts and Back
COCO Captions test,https://identifiers.org/ito:ITO_08723,Unified Vision-Language Pre-Training for Image Captioning and VQA
nocaps-val-overall,https://identifiers.org/ito:ITO_27227,VinVL: Revisiting Visual Representations in Vision-Language Models
nocaps-val-overall,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
nocaps-val-overall,https://identifiers.org/ito:ITO_54910,Scaling Up Vision-Language Pre-training for Image Captioning
COCO Captions Karpathy Test,https://identifiers.org/ito:ITO_50176,Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation
COCO Captions Karpathy Test,https://identifiers.org/ito:ITO_50174,Language Models are General-Purpose Interfaces
nocaps-val-out-domain,https://identifiers.org/ito:ITO_27227,VinVL: Revisiting Visual Representations in Vision-Language Models
nocaps-val-out-domain,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
nocaps-val-out-domain,https://identifiers.org/ito:ITO_54912,BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation
nocaps-val-out-domain,https://identifiers.org/ito:ITO_54910,Scaling Up Vision-Language Pre-training for Image Captioning
BanglaLekhaImageCaptions,https://identifiers.org/ito:ITO_32514,Improved Bengali Image Captioning via deep convolutional neural network based encoder-decoder model
Conceptual Captions,https://identifiers.org/ito:ITO_54935,ClipCap: CLIP Prefix for Image Captioning
FlickrStyle10K,https://identifiers.org/ito:ITO_54958,MemCap: Memorizing Style Knowledge for Image Captioning
Localized Narratives,https://identifiers.org/ito:ITO_32535,Connecting Vision and Language with Localized Narratives
Localized Narratives,https://identifiers.org/ito:ITO_54961,Control Image Captioning Spatially and Temporally
nocaps near-domain,https://identifiers.org/ito:ITO_32556,VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning
Flickr30k Captions test,https://identifiers.org/ito:ITO_12821,Deep Visual-Semantic Alignments for Generating Image Descriptions
Flickr30k Captions test,https://identifiers.org/ito:ITO_54966,Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention
Flickr30k Captions test,https://identifiers.org/ito:ITO_08723,Unified Vision-Language Pre-Training for Image Captioning and VQA
AIC-ICC,https://identifiers.org/ito:ITO_32519,WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training
SCICAP,https://identifiers.org/ito:ITO_54974,SciCap: Generating Captions for Scientific Figures
COCO,https://identifiers.org/ito:ITO_04317,CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features
COCO,https://identifiers.org/ito:ITO_54985,UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning
COCO,https://identifiers.org/ito:ITO_32539,Reflective Decoding Network for Image Captioning
COCO,https://identifiers.org/ito:ITO_32538,Meshed-Memory Transformer for Image Captioning
nocaps out-of-domain,https://identifiers.org/ito:ITO_32556,VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning
nocaps out-of-domain,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
nocaps entire,https://identifiers.org/ito:ITO_32556,VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning
nocaps-XD out-of-domain,https://identifiers.org/ito:ITO_32556,VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning
nocaps-XD out-of-domain,https://identifiers.org/ito:ITO_54991,GIT: A Generative Image-to-text Transformer for Vision and Language
nocaps-XD entire,https://identifiers.org/ito:ITO_32556,VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning
nocaps-XD entire,https://identifiers.org/ito:ITO_54910,Scaling Up Vision-Language Pre-training for Image Captioning
nocaps-XD entire,https://identifiers.org/ito:ITO_54991,GIT: A Generative Image-to-text Transformer for Vision and Language
COCO Captions,https://identifiers.org/ito:ITO_37159,007: Democratically Finding The Cause of Packet Drops
COCO Captions,https://identifiers.org/ito:ITO_54926,GRIT: Faster and Better Image captioning Transformer Using Dual Visual Features
COCO Captions,https://identifiers.org/ito:ITO_54941,From Captions to Visual Concepts and Back
COCO Captions,https://identifiers.org/ito:ITO_27072,Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks
COCO Captions,https://identifiers.org/ito:ITO_54910,Scaling Up Vision-Language Pre-training for Image Captioning
COCO Captions,https://identifiers.org/ito:ITO_50108,"OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"
COCO Captions,https://identifiers.org/ito:ITO_55004,X-Linear Attention Networks for Image Captioning
COCO Captions,https://identifiers.org/ito:ITO_27227,VinVL: Revisiting Visual Representations in Vision-Language Models
COCO Captions,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
COCO Captions,https://identifiers.org/ito:ITO_32539,Reflective Decoding Network for Image Captioning
COCO Captions,https://identifiers.org/ito:ITO_27078,Visual Commonsense R-CNN
nocaps val,https://identifiers.org/ito:ITO_50194,Unifying Vision-and-Language Tasks via Text Generation
nocaps val,https://identifiers.org/ito:ITO_54969,A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models
nocaps val,https://identifiers.org/ito:ITO_50174,Language Models are General-Purpose Interfaces
nocaps-XD near-domain,https://identifiers.org/ito:ITO_32556,VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning
nocaps-XD near-domain,https://identifiers.org/ito:ITO_54991,GIT: A Generative Image-to-text Transformer for Vision and Language
nocaps-XD in-domain,https://identifiers.org/ito:ITO_32556,VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning
nocaps-XD in-domain,https://identifiers.org/ito:ITO_54991,GIT: A Generative Image-to-text Transformer for Vision and Language
Flickr30k,https://identifiers.org/ito:ITO_13983,Multi-level Multimodal Common Semantic Space for Image-Phrase Grounding
Visual Genome,https://identifiers.org/ito:ITO_13983,Multi-level Multimodal Common Semantic Space for Image-Phrase Grounding
ReferIt,https://identifiers.org/ito:ITO_08685,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
ReferIt,https://identifiers.org/ito:ITO_13983,Multi-level Multimodal Common Semantic Space for Image-Phrase Grounding
Flickr30k Entities Test,https://identifiers.org/ito:ITO_08685,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
Flickr30k Entities Test,https://identifiers.org/ito:ITO_35408,Grounding of Textual Phrases in Images by Reconstruction
Flickr30k Entities Test,https://identifiers.org/ito:ITO_56894,Rethinking Diversified and Discriminative Proposal Generation for Visual Grounding
Flickr30k Entities Test,https://identifiers.org/ito:ITO_56892,Phrase Grounding by Soft-Label Chain Conditional Random Field
Flickr30k Entities Test,https://identifiers.org/ito:ITO_56890,Learning Cross-modal Context Graph for Visual Grounding
Flickr30k Entities Test,https://identifiers.org/ito:ITO_50086,MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding
Flickr30k Entities Test,https://identifiers.org/ito:ITO_56886,Grounded Language-Image Pre-training
Flickr30k Entities Test,https://identifiers.org/ito:ITO_56882,GLIPv2: Unifying Localization and Vision-Language Understanding
Flickr30k Entities Test,https://identifiers.org/ito:ITO_08698,Bilinear Attention Networks
Flickr30k Entities Test,https://identifiers.org/ito:ITO_08694,VisualBERT: A Simple and Performant Baseline for Vision and Language
Flickr30k Entities Dev,https://identifiers.org/ito:ITO_08694,VisualBERT: A Simple and Performant Baseline for Vision and Language
Flickr30k Entities Dev,https://identifiers.org/ito:ITO_50151,PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models
Flickr30k Entities Dev,https://identifiers.org/ito:ITO_56884,Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone
relational captioning dataset,https://identifiers.org/ito:ITO_32656,Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning
relational captioning dataset,https://identifiers.org/ito:ITO_55014,Dense Relational Image Captioning via Multi-task Triple-Stream Networks
COCO,https://identifiers.org/ito:ITO_55017,"Perturb, Predict & Paraphrase: Semi-Supervised Learning using Noisy Student for Image Captioning"
MultiNews val,https://identifiers.org/ito:ITO_51634,CDLM: Cross-Document Language Modeling
MultiNews test,https://identifiers.org/ito:ITO_51634,CDLM: Cross-Document Language Modeling
WikiText-103,https://identifiers.org/ito:ITO_09870,Language Modeling with Gated Convolutional Networks
WikiText-103,https://identifiers.org/ito:ITO_09899,Fast Parametric Learning with Activation Memorization
WikiText-103,https://identifiers.org/ito:ITO_09860,Adaptive Input Representations for Neural Language Modeling
WikiText-103,https://identifiers.org/ito:ITO_09735,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context
WikiText-103,https://identifiers.org/ito:ITO_07879,Language Models are Unsupervised Multitask Learners
WikiText-103,https://identifiers.org/ito:ITO_09798,Dynamic Evaluation of Transformer Language Models
WikiText-103,https://identifiers.org/ito:ITO_09881,Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism
WikiText-103,https://identifiers.org/ito:ITO_28786,How much complexity does an RNN architecture need to learn syntax-sensitive dependencies?
WikiText-103,https://identifiers.org/ito:ITO_09786,An Analysis of Neural Language Modeling at Multiple Scales
WikiText-103,https://identifiers.org/ito:ITO_51484,GLM: General Language Model Pretraining with Autoregressive Blank Infilling
WikiText-103,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
enwiki8,https://identifiers.org/ito:ITO_28696,Pay Attention when Required
GitHub,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
Penn Treebank (Character Level),https://identifiers.org/ito:ITO_09827,HyperNetworks
Penn Treebank (Character Level),https://identifiers.org/ito:ITO_09749,Neural Architecture Search with Reinforcement Learning
Penn Treebank (Character Level),https://identifiers.org/ito:ITO_09790,Fast-Slow Recurrent Neural Networks
Penn Treebank (Character Level),https://identifiers.org/ito:ITO_09759,An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling
Penn Treebank (Character Level),https://identifiers.org/ito:ITO_09809,Discrete Flows: Invertible Generative Models of Discrete Data
USPTO Backgrounds,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
100 sleep nights of 8 caregivers,https://identifiers.org/ito:ITO_37159,007: Democratically Finding The Cause of Packet Drops
Wiki-40B,https://identifiers.org/ito:ITO_46400,Combiner: Full Attention Transformer with Sparse Computation Cost
Wiki-40B,https://identifiers.org/ito:ITO_51506,Transformer Quality in Linear Time
OpenWebtext2,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
Penn Treebank (Word Level),https://identifiers.org/ito:ITO_05438,Recurrent Neural Network Regularization
Penn Treebank (Word Level),https://identifiers.org/ito:ITO_09756,A Theoretically Grounded Application of Dropout in Recurrent Neural Networks
Penn Treebank (Word Level),https://identifiers.org/ito:ITO_09751,Recurrent Highway Networks
Penn Treebank (Word Level),https://identifiers.org/ito:ITO_09749,Neural Architecture Search with Reinforcement Learning
Penn Treebank (Word Level),https://identifiers.org/ito:ITO_28838,Gradual Learning of Recurrent Neural Networks
Penn Treebank (Word Level),https://identifiers.org/ito:ITO_07879,Language Models are Unsupervised Multitask Learners
Penn Treebank (Word Level),https://identifiers.org/ito:ITO_28757,Language Models with Transformers
Penn Treebank (Word Level),https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
Penn Treebank (Word Level),https://identifiers.org/ito:ITO_09715,Direct Output Connection for a High-Rank Language Model
PTB,https://identifiers.org/ito:ITO_51516,Improved Differentiable Architecture Search for Language Modeling and Named Entity Recognition
LAMBADA,https://identifiers.org/ito:ITO_28713,Broad Context Language Modeling as Reading Comprehension
LAMBADA,https://identifiers.org/ito:ITO_05335,Universal Transformers
LAMBADA,https://identifiers.org/ito:ITO_07879,Language Models are Unsupervised Multitask Learners
LAMBADA,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
LAMBADA,https://identifiers.org/ito:ITO_51519,"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"
LAMBADA,https://identifiers.org/ito:ITO_49638,PaLM: Scaling Language Modeling with Pathways
Pile CC,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
One Billion Word,https://identifiers.org/ito:ITO_09860,Adaptive Input Representations for Neural Language Modeling
One Billion Word,https://identifiers.org/ito:ITO_51533,H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for Sequences
One Billion Word,https://identifiers.org/ito:ITO_51486,When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute
One Billion Word,https://identifiers.org/ito:ITO_09875,One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling
One Billion Word,https://identifiers.org/ito:ITO_09867,Exploring the Limits of Language Modeling
One Billion Word,https://identifiers.org/ito:ITO_09735,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context
One Billion Word,https://identifiers.org/ito:ITO_22839,OmniNet: Omnidirectional Representations from Transformers
enwik8,https://identifiers.org/ito:ITO_09751,Recurrent Highway Networks
enwik8,https://identifiers.org/ito:ITO_09790,Fast-Slow Recurrent Neural Networks
enwik8,https://identifiers.org/ito:ITO_09782,Character-Level Language Modeling with Deeper Self-Attention
enwik8,https://identifiers.org/ito:ITO_09735,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context
enwik8,https://identifiers.org/ito:ITO_07879,Language Models are Unsupervised Multitask Learners
enwik8,https://identifiers.org/ito:ITO_28823,Generating Sequences With Recurrent Neural Networks
PubMed Cognitive Control Abstracts,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
Bookcorpus2,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
HackerNews,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
The Pile,https://identifiers.org/ito:ITO_07879,Language Models are Unsupervised Multitask Learners
FreeLaw,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
DM Mathematics,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
Ubuntu IRC,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
PubMed Central,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
Hutter Prize,https://identifiers.org/ito:ITO_09751,Recurrent Highway Networks
Hutter Prize,https://identifiers.org/ito:ITO_09790,Fast-Slow Recurrent Neural Networks
Hutter Prize,https://identifiers.org/ito:ITO_09782,Character-Level Language Modeling with Deeper Self-Attention
Hutter Prize,https://identifiers.org/ito:ITO_09735,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context
OpenSubtitles,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
C4,https://identifiers.org/ito:ITO_51561,Primer: Searching for Efficient Transformers for Language Modeling
Books3,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
Text8,https://identifiers.org/ito:ITO_09813,Recurrent Batch Normalization
Text8,https://identifiers.org/ito:ITO_09788,Multiplicative LSTM for sequence modelling
Text8,https://identifiers.org/ito:ITO_09782,Character-Level Language Modeling with Deeper Self-Attention
Text8,https://identifiers.org/ito:ITO_09735,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context
Text8,https://identifiers.org/ito:ITO_07879,Language Models are Unsupervised Multitask Learners
Text8,https://identifiers.org/ito:ITO_09816,Architectural Complexity Measures of Recurrent Neural Networks
WikiText-2,https://identifiers.org/ito:ITO_09753,Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling
WikiText-2,https://identifiers.org/ito:ITO_09771,Improving Neural Language Models with a Continuous Cache
WikiText-2,https://identifiers.org/ito:ITO_09769,On the State of the Art of Evaluation in Neural Language Models
WikiText-2,https://identifiers.org/ito:ITO_28838,Gradual Learning of Recurrent Neural Networks
WikiText-2,https://identifiers.org/ito:ITO_09717,Improved Language Modeling by Decoding the Past
WikiText-2,https://identifiers.org/ito:ITO_05234,FRAGE: Frequency-Agnostic Word Representation
WikiText-2,https://identifiers.org/ito:ITO_07879,Language Models are Unsupervised Multitask Learners
WikiText-2,https://identifiers.org/ito:ITO_09715,Direct Output Connection for a High-Rank Language Model
enwik8 dev,https://identifiers.org/ito:ITO_51537,Long-Short Transformer: Efficient Transformers for Language and Vision
Curation Corpus,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
PhilPapers,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
arXiv,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
Gutenberg PG-19,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
NIH ExPorter,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
language-modeling-recommendation,https://identifiers.org/ito:ITO_51582,Zero-Shot Recommendation as Language Modeling
StackExchange,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
Text8 dev,https://identifiers.org/ito:ITO_51537,Long-Short Transformer: Efficient Transformers for Language and Vision
SCROLLS,https://identifiers.org/ito:ITO_50956,LongT5: Efficient Text-To-Text Transformer for Long Sequences
SCROLLS,https://identifiers.org/ito:ITO_51600,Unifying Language Learning Paradigms
LRA,https://identifiers.org/ito:ITO_51618,Long Range Arena: A Benchmark for Efficient Transformers
LRA,https://identifiers.org/ito:ITO_51615,Sparse Factorization of Large Square Matrices
LRA,https://identifiers.org/ito:ITO_51489,Efficiently Modeling Long Sequences with Structured State Spaces
LRA,https://identifiers.org/ito:ITO_51613,Classification of Long Sequential Data using Circular Dilated Convolutional Neural Networks
LRA,https://identifiers.org/ito:ITO_51611,Diagonal State Spaces are as Effective as Structured State Spaces
VoxForge European,https://identifiers.org/ito:ITO_04366,Deep Speech: Scaling up end-to-end speech recognition
VoxForge European,https://identifiers.org/ito:ITO_04403,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
VoxForge Commonwealth,https://identifiers.org/ito:ITO_04366,Deep Speech: Scaling up end-to-end speech recognition
VoxForge Commonwealth,https://identifiers.org/ito:ITO_04403,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
VoxForge Indian,https://identifiers.org/ito:ITO_04366,Deep Speech: Scaling up end-to-end speech recognition
VoxForge Indian,https://identifiers.org/ito:ITO_04403,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
VoxForge American-Canadian,https://identifiers.org/ito:ITO_04366,Deep Speech: Scaling up end-to-end speech recognition
VoxForge American-Canadian,https://identifiers.org/ito:ITO_04403,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
DIRHA English WSJ,https://identifiers.org/ito:ITO_04408,The PyTorch-Kaldi Speech Recognition Toolkit
CHiME-4 real 6ch,https://identifiers.org/ito:ITO_04479,Building state-of-the-art distant speech recognition using the CHiME-4 challenge with a setup of speech enhancement baseline
CHiME real,https://identifiers.org/ito:ITO_04366,Deep Speech: Scaling up end-to-end speech recognition
CHiME real,https://identifiers.org/ito:ITO_04403,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
CHiME real,https://identifiers.org/ito:ITO_04479,Building state-of-the-art distant speech recognition using the CHiME-4 challenge with a setup of speech enhancement baseline
CHiME clean,https://identifiers.org/ito:ITO_04366,Deep Speech: Scaling up end-to-end speech recognition
CHiME clean,https://identifiers.org/ito:ITO_04403,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
Lip2Wav (DL),https://identifiers.org/ito:ITO_20979,Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis
Lip2Wav (DL),https://identifiers.org/ito:ITO_45082,Speech Reconstruction with Reminiscent Sound via Visual Voice Memory
Lip2Wav (Chess),https://identifiers.org/ito:ITO_20979,Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis
Lip2Wav (Chess),https://identifiers.org/ito:ITO_45082,Speech Reconstruction with Reminiscent Sound via Visual Voice Memory
Lip2Wav (EH),https://identifiers.org/ito:ITO_20979,Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis
Lip2Wav (EH),https://identifiers.org/ito:ITO_45082,Speech Reconstruction with Reminiscent Sound via Visual Voice Memory
GRID corpus (mixed-speech),https://identifiers.org/ito:ITO_45082,Speech Reconstruction with Reminiscent Sound via Visual Voice Memory
Lip2Wav (HS),https://identifiers.org/ito:ITO_20979,Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis
Lip2Wav (HS),https://identifiers.org/ito:ITO_45082,Speech Reconstruction with Reminiscent Sound via Visual Voice Memory
Lip2Wav (Chem),https://identifiers.org/ito:ITO_20979,Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis
Lip2Wav (Chem),https://identifiers.org/ito:ITO_45082,Speech Reconstruction with Reminiscent Sound via Visual Voice Memory
GigaSpeech DEV,https://identifiers.org/ito:ITO_44456,"GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio"
Common Voice,https://identifiers.org/ito:ITO_20648,SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network
Common Voice Spanish,https://identifiers.org/ito:ITO_44476,"VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation"
Common Voice Spanish,https://identifiers.org/ito:ITO_44474,Scribosermo: Fast Speech-to-Text models for German and other Languages
AISHELL-1,https://identifiers.org/ito:ITO_20727,End-to-end Speech Recognition with Adaptive Computation Steps
AISHELL-1,https://identifiers.org/ito:ITO_04388,A Comparative Study on Transformer vs RNN in Speech Applications
AISHELL-1,https://identifiers.org/ito:ITO_20626,CAT: A CTC-CRF based ASR Toolkit Bridging the Hybrid and the End-to-end Approaches towards Data Efficiency and Low Latency
AISHELL-1,https://identifiers.org/ito:ITO_44481,Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition
Libri-Light test-other,https://identifiers.org/ito:ITO_20711,Libri-Light: A Benchmark for ASR with Limited or No Supervision
Libri-Light test-other,https://identifiers.org/ito:ITO_20646,wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
Libri-Light test-other,https://identifiers.org/ito:ITO_20715,Improving Unsupervised Sparsespeech Acoustic Models with Categorical Reparameterization
Tedlium,https://identifiers.org/ito:ITO_20648,SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network
Google Speech Commands - Musan,https://identifiers.org/ito:ITO_44498,ImportantAug: a data augmentation agent for speech
Switchboard CallHome,https://identifiers.org/ito:ITO_20648,SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network
Hub5'00 CallHome,https://identifiers.org/ito:ITO_04339,Espresso: A Fast End-to-end Neural Speech Recognition Toolkit
GigaSpeech TEST,https://identifiers.org/ito:ITO_44456,"GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio"
AMI SDM1,https://identifiers.org/ito:ITO_20648,SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network
Switchboard + Hub500,https://identifiers.org/ito:ITO_04373,Building DNN Acoustic Models for Large Vocabulary Speech Recognition
Switchboard + Hub500,https://identifiers.org/ito:ITO_04366,Deep Speech: Scaling up end-to-end speech recognition
Switchboard + Hub500,https://identifiers.org/ito:ITO_04356,The IBM 2015 English Conversational Telephone Speech Recognition System
Switchboard + Hub500,https://identifiers.org/ito:ITO_04351,The IBM 2016 English Conversational Telephone Speech Recognition System
Switchboard + Hub500,https://identifiers.org/ito:ITO_04348,The Microsoft 2016 Conversational Speech Recognition System
Switchboard + Hub500,https://identifiers.org/ito:ITO_04346,Achieving Human Parity in Conversational Speech Recognition
Switchboard + Hub500,https://identifiers.org/ito:ITO_04344,English Conversational Telephone Speech Recognition by Humans and Machines
Switchboard + Hub500,https://identifiers.org/ito:ITO_20837,Single headed attention based sequence-to-sequence model for state-of-the-art results on Switchboard
Switchboard + Hub500,https://identifiers.org/ito:ITO_20835,On the limit of English conversational speech recognition
LibriSpeech test-clean,https://identifiers.org/ito:ITO_04403,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
LibriSpeech test-clean,https://identifiers.org/ito:ITO_04401,Letter-Based Speech Recognition with Gated ConvNets
LibriSpeech test-clean,https://identifiers.org/ito:ITO_04392,Neural Network Language Modeling with Letter-based Features and Importance Sampling
LibriSpeech test-clean,https://identifiers.org/ito:ITO_04336,SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition
LibriSpeech test-clean,https://identifiers.org/ito:ITO_04385,RWTH ASR Systems for LibriSpeech: Hybrid vs Attention -- w/o Data Augmentation
LibriSpeech test-clean,https://identifiers.org/ito:ITO_04383,State-of-the-Art Speech Recognition Using Multi-Stream Self-Attention With Dilated 1D Convolutions
LibriSpeech test-clean,https://identifiers.org/ito:ITO_20660,End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures
LibriSpeech test-clean,https://identifiers.org/ito:ITO_20650,Improved Noisy Student Training for Automatic Speech Recognition
LibriSpeech test-clean,https://identifiers.org/ito:ITO_44539,Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition
WSJ eval93,https://identifiers.org/ito:ITO_04403,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
Hub5'00 SwitchBoard,https://identifiers.org/ito:ITO_04334,Jasper: An End-to-End Convolutional Neural Acoustic Model
Hub5'00 SwitchBoard,https://identifiers.org/ito:ITO_20626,CAT: A CTC-CRF based ASR Toolkit Bridging the Hybrid and the End-to-end Approaches towards Data Efficiency and Low Latency
Hub5'00 SwitchBoard,https://identifiers.org/ito:ITO_04339,Espresso: A Fast End-to-end Neural Speech Recognition Toolkit
Hub5'00 FISHER-SWBD,https://identifiers.org/ito:ITO_20626,CAT: A CTC-CRF based ASR Toolkit Bridging the Hybrid and the End-to-end Approaches towards Data Efficiency and Low Latency
LibriSpeech test-other,https://identifiers.org/ito:ITO_04403,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
LibriSpeech test-other,https://identifiers.org/ito:ITO_04392,Neural Network Language Modeling with Letter-based Features and Importance Sampling
LibriSpeech test-other,https://identifiers.org/ito:ITO_04336,SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition
LibriSpeech test-other,https://identifiers.org/ito:ITO_04385,RWTH ASR Systems for LibriSpeech: Hybrid vs Attention -- w/o Data Augmentation
LibriSpeech test-other,https://identifiers.org/ito:ITO_20670,Transformer-based Acoustic Modeling for Hybrid Speech Recognition
LibriSpeech test-other,https://identifiers.org/ito:ITO_20660,End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures
LibriSpeech test-other,https://identifiers.org/ito:ITO_20650,Improved Noisy Student Training for Automatic Speech Recognition
LibriSpeech test-other,https://identifiers.org/ito:ITO_20646,wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
LibriSpeech test-other,https://identifiers.org/ito:ITO_44539,Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition
LibriSpeech test-other,https://identifiers.org/ito:ITO_44541,W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training
LibriSpeech train-clean-100 test-clean,https://identifiers.org/ito:ITO_20644,Self-training and Pre-training are Complementary for Speech Recognition
LibriSpeech train-clean-100 test-other,https://identifiers.org/ito:ITO_20644,Self-training and Pre-training are Complementary for Speech Recognition
Switchboard (300hr),https://identifiers.org/ito:ITO_04424,End-to-end speech recognition using lattice-free MMI
SPGISpeech,https://identifiers.org/ito:ITO_20918,"SPGISpeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition"
MediaSpeech,https://identifiers.org/ito:ITO_20788,MediaSpeech: Multilanguage ASR Benchmark and Dataset
Libri-Light test-clean,https://identifiers.org/ito:ITO_20711,Libri-Light: A Benchmark for ASR with Limited or No Supervision
Libri-Light test-clean,https://identifiers.org/ito:ITO_20646,wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
Libri-Light test-clean,https://identifiers.org/ito:ITO_20715,Improving Unsupervised Sparsespeech Acoustic Models with Categorical Reparameterization
swb_hub_500 WER fullSWBCH,https://identifiers.org/ito:ITO_04373,Building DNN Acoustic Models for Large Vocabulary Speech Recognition
swb_hub_500 WER fullSWBCH,https://identifiers.org/ito:ITO_04366,Deep Speech: Scaling up end-to-end speech recognition
swb_hub_500 WER fullSWBCH,https://identifiers.org/ito:ITO_04351,The IBM 2016 English Conversational Telephone Speech Recognition System
swb_hub_500 WER fullSWBCH,https://identifiers.org/ito:ITO_04348,The Microsoft 2016 Conversational Speech Recognition System
swb_hub_500 WER fullSWBCH,https://identifiers.org/ito:ITO_04344,English Conversational Telephone Speech Recognition by Humans and Machines
swb_hub_500 WER fullSWBCH,https://identifiers.org/ito:ITO_20837,Single headed attention based sequence-to-sequence model for state-of-the-art results on Switchboard
swb_hub_500 WER fullSWBCH,https://identifiers.org/ito:ITO_20835,On the limit of English conversational speech recognition
TUDA,https://identifiers.org/ito:ITO_44587,Open Source German Distant Speech Recognition: Corpus and Acoustic Model
Common Voice vi,https://identifiers.org/ito:ITO_44594,Vietnamese end-to-end speech recognition using wav2vec 2.0
AMI IMH,https://identifiers.org/ito:ITO_20648,SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network
WenetSpeech,https://identifiers.org/ito:ITO_44611,WenetSpeech: A 10000+ Hours Multi-domain Mandarin Corpus for Speech Recognition
CHiME-6 dev_gss12,https://identifiers.org/ito:ITO_20721,Towards a Competitive End-to-End Speech Recognition for CHiME-6 Dinner Party Transcription
CHiME-6 dev_gss12,https://identifiers.org/ito:ITO_20648,SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network
CHiME-6 eval,https://identifiers.org/ito:ITO_20648,SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network
WSJ eval92,https://identifiers.org/ito:ITO_04426,Deep Recurrent Neural Networks for Acoustic Modelling
WSJ eval92,https://identifiers.org/ito:ITO_04422,Purely sequence-trained neural networks for ASR based on lattice-free MMI
WSJ eval92,https://identifiers.org/ito:ITO_20648,SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network
Switchboard SWBD,https://identifiers.org/ito:ITO_20648,SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network
Common Voice French,https://identifiers.org/ito:ITO_44476,"VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation"
Common Voice French,https://identifiers.org/ito:ITO_44474,Scribosermo: Fast Speech-to-Text models for German and other Languages
TIMIT,https://identifiers.org/ito:ITO_04462,Speech Recognition with Deep Recurrent Neural Networks
TIMIT,https://identifiers.org/ito:ITO_04460,Attention-Based Models for Speech Recognition
TIMIT,https://identifiers.org/ito:ITO_04458,Segmental Recurrent Neural Networks for End-to-end Speech Recognition
TIMIT,https://identifiers.org/ito:ITO_04450,Light Gated Recurrent Units for Speech Recognition
TIMIT,https://identifiers.org/ito:ITO_04408,The PyTorch-Kaldi Speech Recognition Toolkit
TIMIT,https://identifiers.org/ito:ITO_20798,vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations
TIMIT,https://identifiers.org/ito:ITO_20646,wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
Fongbe  audio,https://identifiers.org/ito:ITO_20702,First Automatic Fongbe Continuous Speech Recognition System: Development of Acoustic Models and Language Models
VIVOS,https://identifiers.org/ito:ITO_44594,Vietnamese end-to-end speech recognition using wav2vec 2.0
VIVOS,https://identifiers.org/ito:ITO_44592,Wav2vec2 Base Vietnamese 160h
Common Voice Portuguese,https://identifiers.org/ito:ITO_44958,XLSR53 Wav2Vec2 Portuguese by Orlem Santos
Common Voice German,https://identifiers.org/ito:ITO_44476,"VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation"
Common Voice German,https://identifiers.org/ito:ITO_44964,TEVR: Improving Speech Recognition by Token Entropy Variance Reduction
Common Voice Italian,https://identifiers.org/ito:ITO_44474,Scribosermo: Fast Speech-to-Text models for German and other Languages
MuST-C EN->ES,https://identifiers.org/ito:ITO_61822,Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation
MuST-C EN->ES,https://identifiers.org/ito:ITO_61818,Lightweight Adapter Tuning for Multilingual Speech Translation
MuST-C,https://identifiers.org/ito:ITO_61822,Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation
MuST-C,https://identifiers.org/ito:ITO_61818,Lightweight Adapter Tuning for Multilingual Speech Translation
MuST-C EN->FR,https://identifiers.org/ito:ITO_61822,Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation
MuST-C EN->DE,https://identifiers.org/ito:ITO_61827,End-to-End Offline Speech Translation System for IWSLT 2020 using Modality Agnostic Meta-Learning
MuST-C EN->DE,https://identifiers.org/ito:ITO_41563,End-to-End Speech Translation with Pre-trained Models and Adapters: UPC at IWSLT 2021
MuST-C EN->DE,https://identifiers.org/ito:ITO_41561,TASK AWARE MULTI-TASK LEARNING FOR SPEECH TO TEXT TASKS
libri-trans,https://identifiers.org/ito:ITO_41556,NeurST: Neural Speech Translation Toolkit
MuST-C EN->NL,https://identifiers.org/ito:ITO_61820,Speechformer: Reducing Information Loss in Direct Speech Translation
LRS3-TED,https://identifiers.org/ito:ITO_45075,Sub-word Level Lip Reading With Visual Attention
Umsuka,https://identifiers.org/ito:ITO_47027,Geographical Distance Is The New Hyperparameter: A Case Study Of Finding The Optimal Pre-trained Language For English-isiZulu Machine Translation
WMT 2017 Latvian-English,https://identifiers.org/ito:ITO_46891,Tilde's Machine Translation Systems for WMT 2017
WMT 2017 Latvian-English,https://identifiers.org/ito:ITO_05370,Impact of Corpora Quality on Neural Machine Translation
WMT2014 French-English,https://identifiers.org/ito:ITO_05277,Unsupervised Statistical Machine Translation
WMT2014 French-English,https://identifiers.org/ito:ITO_46894,Finetuned Language Models Are Zero-Shot Learners
WMT2016 German-English,https://identifiers.org/ito:ITO_05263,Edinburgh Neural Machine Translation Systems for WMT 16
WMT2016 German-English,https://identifiers.org/ito:ITO_46894,Finetuned Language Models Are Zero-Shot Learners
WMT2016 German-English,https://identifiers.org/ito:ITO_46896,Exploiting Monolingual Data at Scale for Neural Machine Translation
WMT2016 English-French,https://identifiers.org/ito:ITO_22975,DeLighT: Deep and Light-weight Transformer
WMT2016 Romanian-English,https://identifiers.org/ito:ITO_05263,Edinburgh Neural Machine Translation Systems for WMT 16
WMT2016 Romanian-English,https://identifiers.org/ito:ITO_05381,Cross-lingual Language Model Pretraining
WMT2016 Romanian-English,https://identifiers.org/ito:ITO_22857,Language Models not just for Pre-training: Fast Online Neural Noisy Channel Modeling
WMT2016 Russian-English,https://identifiers.org/ito:ITO_05263,Edinburgh Neural Machine Translation Systems for WMT 16
WMT 2017 English-Chinese,https://identifiers.org/ito:ITO_05219,Achieving Human Parity on Automatic Chinese to English News Translation
WMT 2017 English-Chinese,https://identifiers.org/ito:ITO_05216,Pay Less Attention with Lightweight and Dynamic Convolutions
ACCURAT balanced test corpus for under resourced languages Russian-Estonian,https://identifiers.org/ito:ITO_46902,Training and Adapting Multilingual NMT for Less-resourced and Morphologically Rich Languages
IWSLT2014 English-German,https://identifiers.org/ito:ITO_23021,Sequence Generation with Mixed Representations
IWSLT2014 English-German,https://identifiers.org/ito:ITO_23019,UniDrop: A Simple yet Effective Technique to Improve Transformer without Extra Cost
IWSLT2014 English-German,https://identifiers.org/ito:ITO_46905,Bi-SimCut: A Simple Strategy for Boosting Neural Machine Translation
IWSLT2015 English-Vietnamese,https://identifiers.org/ito:ITO_05199,Stanford Neural Machine Translation Systems for Spoken Language Domains
IWSLT2015 English-Vietnamese,https://identifiers.org/ito:ITO_05197,Deconvolution-Based Global Decoding for Neural Machine Translation
IWSLT2015 English-Vietnamese,https://identifiers.org/ito:ITO_05193,Learning When to Concentrate or Divert Attention: Self-Adaptive Attention Temperature for Neural Machine Translation
IWSLT2015 English-Vietnamese,https://identifiers.org/ito:ITO_05191,Semi-Supervised Sequence Modeling with Cross-View Training
IWSLT2015 English-Vietnamese,https://identifiers.org/ito:ITO_05185,BPE-Dropout: Simple and Effective Subword Regularization
IWSLT2015 English-Vietnamese,https://identifiers.org/ito:ITO_23102,Better Translation for Vietnamese
IWSLT2015 English-Vietnamese,https://identifiers.org/ito:ITO_46909,MTet: Multi-domain Translation for English-Vietnamese
IWSLT2015 English-Vietnamese,https://identifiers.org/ito:ITO_46911,No Language Left Behind: Scaling Human-Centered Machine Translation
WMT2017 Finnish-English,https://identifiers.org/ito:ITO_05295,The University of Sydney's Machine Translation System for WMT19
IWSLT2015 Chinese-English,https://identifiers.org/ito:ITO_05223,BP-Transformer: Modelling Long-Range Context via Binary Partitioning
V_A (trained on T_H),https://identifiers.org/ito:ITO_22933,On Automatic Parsing of Log Records
Business Scene Dialogue EN-JA,https://identifiers.org/ito:ITO_22944,Designing the Business Conversation Corpus
WMT2016 Finnish-English,https://identifiers.org/ito:ITO_05295,The University of Sydney's Machine Translation System for WMT19
WMT2014 English-French,https://identifiers.org/ito:ITO_05436,Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation
WMT2014 English-French,https://identifiers.org/ito:ITO_05432,Sequence to Sequence Learning with Neural Networks
WMT2014 English-French,https://identifiers.org/ito:ITO_05430,Addressing the Rare Word Problem in Neural Machine Translation
WMT2014 English-French,https://identifiers.org/ito:ITO_05358,Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation
WMT2014 English-French,https://identifiers.org/ito:ITO_05348,Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation
WMT2014 English-French,https://identifiers.org/ito:ITO_05352,Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer
WMT2014 English-French,https://identifiers.org/ito:ITO_05241,Convolutional Sequence to Sequence Learning
WMT2014 English-French,https://identifiers.org/ito:ITO_05333,Weighted Transformer Network for Machine Translation
WMT2014 English-French,https://identifiers.org/ito:ITO_05328,Self-Attention with Relative Position Representations
WMT2014 English-French,https://identifiers.org/ito:ITO_05323,Scaling Neural Machine Translation
WMT2014 English-French,https://identifiers.org/ito:ITO_05306,Understanding Back-Translation at Scale
WMT2014 English-French,https://identifiers.org/ito:ITO_22871,Very Deep Transformers for Neural Machine Translation
WMT2019 Finnish-English,https://identifiers.org/ito:ITO_05295,The University of Sydney's Machine Translation System for WMT19
Itihasa,https://identifiers.org/ito:ITO_46936,Itihasa: A large-scale corpus for Sanskrit to English translation
WMT2019 English-German,https://identifiers.org/ito:ITO_05366,Facebook FAIR's WMT19 News Translation Task Submission
WMT2019 English-German,https://identifiers.org/ito:ITO_46896,Exploiting Monolingual Data at Scale for Neural Machine Translation
WMT 2018 English-Estonian,https://identifiers.org/ito:ITO_46940,Tilde's Machine Translation Systems for WMT 2018
IWSLT2015 Thai-English,https://identifiers.org/ito:ITO_05360,Sequence-Level Knowledge Distillation
WMT2015 English-German,https://identifiers.org/ito:ITO_05209,Neural Machine Translation of Rare Words with Subword Units
WMT2015 English-German,https://identifiers.org/ito:ITO_05207,A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation
WMT2015 English-German,https://identifiers.org/ito:ITO_05204,Neural Machine Translation in Linear Time
WMT2016 English-German,https://identifiers.org/ito:ITO_05263,Edinburgh Neural Machine Translation Systems for WMT 16
WMT2016 English-German,https://identifiers.org/ito:ITO_05404,Multi-Agent Dual Learning
WMT2016 English-German,https://identifiers.org/ito:ITO_46896,Exploiting Monolingual Data at Scale for Neural Machine Translation
WMT 2017 English-Latvian,https://identifiers.org/ito:ITO_05370,Impact of Corpora Quality on Neural Machine Translation
IWSLT2015 English-German,https://identifiers.org/ito:ITO_05247,An Actor-Critic Algorithm for Sequence Prediction
IWSLT2015 English-German,https://identifiers.org/ito:ITO_05241,Convolutional Sequence to Sequence Learning
IWSLT2015 English-German,https://identifiers.org/ito:ITO_05230,Attention Is All You Need
IWSLT2015 English-German,https://identifiers.org/ito:ITO_46947,Self-Knowledge Distillation with Progressive Refinement of Targets
IWSLT2017 English-Arabic,https://identifiers.org/ito:ITO_46911,No Language Left Behind: Scaling Human-Centered Machine Translation
IWSLT2017 English-Arabic,https://identifiers.org/ito:ITO_05185,BPE-Dropout: Simple and Effective Subword Regularization
WMT2019 English-Japanese,https://identifiers.org/ito:ITO_22958,Parallel Corpus Filtering via Pre-trained Language Models
WMT 2018 English-Finnish,https://identifiers.org/ito:ITO_05370,Impact of Corpora Quality on Neural Machine Translation
WMT 2018 Estonian-English,https://identifiers.org/ito:ITO_46940,Tilde's Machine Translation Systems for WMT 2018
WMT2017 English-Finnish,https://identifiers.org/ito:ITO_22839,OmniNet: Omnidirectional Representations from Transformers
WMT2017 Russian-English,https://identifiers.org/ito:ITO_22839,OmniNet: Omnidirectional Representations from Transformers
WMT2016 English-Russian,https://identifiers.org/ito:ITO_05263,Edinburgh Neural Machine Translation Systems for WMT 16
V_B (trained on T_H),https://identifiers.org/ito:ITO_22933,On Automatic Parsing of Log Records
WMT2014 German-English,https://identifiers.org/ito:ITO_05275,Non-Autoregressive Neural Machine Translation
WMT2014 German-English,https://identifiers.org/ito:ITO_05239,Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement
WMT2014 German-English,https://identifiers.org/ito:ITO_05253,FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow
WMT2014 German-English,https://identifiers.org/ito:ITO_22998,Wide-minima Density Hypothesis and the Explore-Exploit Learning Rate Schedule
WMT2014 German-English,https://identifiers.org/ito:ITO_22862,Incorporating a Local Translation Mechanism into Non-autoregressive Translation
WMT2014 German-English,https://identifiers.org/ito:ITO_46958,"BERT, mBERT, or BiBERT? A Study on Contextualized Embeddings for Neural Machine Translation"
WMT2014 German-English,https://identifiers.org/ito:ITO_46905,Bi-SimCut: A Simple Strategy for Boosting Neural Machine Translation
WMT2014 English-Czech,https://identifiers.org/ito:ITO_05316,The Evolved Transformer
WMT2016 English-Romanian,https://identifiers.org/ito:ITO_05263,Edinburgh Neural Machine Translation Systems for WMT 16
WMT2016 English-Romanian,https://identifiers.org/ito:ITO_46963,The QT21/HimL Combined Machine Translation System
WMT2016 English-Romanian,https://identifiers.org/ito:ITO_05241,Convolutional Sequence to Sequence Learning
WMT2016 English-Romanian,https://identifiers.org/ito:ITO_05253,FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow
WMT2016 English-Romanian,https://identifiers.org/ito:ITO_22975,DeLighT: Deep and Light-weight Transformer
IWSLT2017 Arabic-English,https://identifiers.org/ito:ITO_46911,No Language Left Behind: Scaling Human-Centered Machine Translation
IWSLT2017 Arabic-English,https://identifiers.org/ito:ITO_05185,BPE-Dropout: Simple and Effective Subword Regularization
WMT2019 German-English,https://identifiers.org/ito:ITO_46896,Exploiting Monolingual Data at Scale for Neural Machine Translation
Arba Sicula,https://identifiers.org/ito:ITO_46973,Sicilian Translator: A Recipe for Low-Resource NMT
IWSLT2017 French-English,https://identifiers.org/ito:ITO_46911,No Language Left Behind: Scaling Human-Centered Machine Translation
IWSLT2017 French-English,https://identifiers.org/ito:ITO_05185,BPE-Dropout: Simple and Effective Subword Regularization
WMT 2018 Finnish-English,https://identifiers.org/ito:ITO_05370,Impact of Corpora Quality on Neural Machine Translation
WMT 2018 Finnish-English,https://identifiers.org/ito:ITO_05295,The University of Sydney's Machine Translation System for WMT19
WMT2014 English-German,https://identifiers.org/ito:ITO_05291,Effective Approaches to Attention-based Neural Machine Translation
WMT2014 English-German,https://identifiers.org/ito:ITO_05348,Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation
WMT2014 English-German,https://identifiers.org/ito:ITO_05241,Convolutional Sequence to Sequence Learning
WMT2014 English-German,https://identifiers.org/ito:ITO_05230,Attention Is All You Need
WMT2014 English-German,https://identifiers.org/ito:ITO_05333,Weighted Transformer Network for Machine Translation
WMT2014 English-German,https://identifiers.org/ito:ITO_05328,Self-Attention with Relative Position Representations
WMT2014 English-German,https://identifiers.org/ito:ITO_05323,Scaling Neural Machine Translation
WMT2014 English-German,https://identifiers.org/ito:ITO_05306,Understanding Back-Translation at Scale
WMT2014 English-German,https://identifiers.org/ito:ITO_46978,Lessons on Parameter Sharing across Layers in Transformers
WMT2014 English-German,https://identifiers.org/ito:ITO_23023,Mask Attention Networks: Rethinking and Strengthen Transformer
WMT2015 English-Russian,https://identifiers.org/ito:ITO_05209,Neural Machine Translation of Rare Words with Subword Units
WMT2017 English-French,https://identifiers.org/ito:ITO_22839,OmniNet: Omnidirectional Representations from Transformers
IWSLT2014 German-English,https://identifiers.org/ito:ITO_05247,An Actor-Critic Algorithm for Sequence Prediction
IWSLT2014 German-English,https://identifiers.org/ito:ITO_05230,Attention Is All You Need
IWSLT2014 German-English,https://identifiers.org/ito:ITO_05216,Pay Less Attention with Lightweight and Dynamic Convolutions
IWSLT2014 German-English,https://identifiers.org/ito:ITO_05318,Joint Source-Target Self Attention with Locality Constraints
IWSLT2014 German-English,https://identifiers.org/ito:ITO_23017,Data Diversification: A Simple Strategy For Neural Machine Translation
IWSLT2014 German-English,https://identifiers.org/ito:ITO_22998,Wide-minima Density Hypothesis and the Explore-Exploit Learning Rate Schedule
IWSLT2014 German-English,https://identifiers.org/ito:ITO_46929,R-Drop: Regularized Dropout for Neural Networks
IWSLT2014 German-English,https://identifiers.org/ito:ITO_46958,"BERT, mBERT, or BiBERT? A Study on Contextualized Embeddings for Neural Machine Translation"
IWSLT2014 German-English,https://identifiers.org/ito:ITO_23023,Mask Attention Networks: Rethinking and Strengthen Transformer
WMT2016 English-Czech,https://identifiers.org/ito:ITO_05263,Edinburgh Neural Machine Translation Systems for WMT 16
WMT2016 Czech-English,https://identifiers.org/ito:ITO_05263,Edinburgh Neural Machine Translation Systems for WMT 16
WMT2017 Chinese-English,https://identifiers.org/ito:ITO_46930,Finetuning Pretrained Transformers into RNNs
20NEWS,https://identifiers.org/ito:ITO_05291,Effective Approaches to Attention-based Neural Machine Translation
20NEWS,https://identifiers.org/ito:ITO_05289,Neural Machine Translation
Tatoeba (EN-to-EL),https://identifiers.org/ito:ITO_23042,PENELOPIE: Enabling Open Information Extraction for the Greek Language through Machine Translation
Tatoeba (EL-to-EN),https://identifiers.org/ito:ITO_23042,PENELOPIE: Enabling Open Information Extraction for the Greek Language through Machine Translation
V_C (trained on T_H),https://identifiers.org/ito:ITO_22933,On Automatic Parsing of Log Records
IWSLT2015 German-English,https://identifiers.org/ito:ITO_05251,Neural Machine Translation by Jointly Learning to Align and Translate
IWSLT2015 German-English,https://identifiers.org/ito:ITO_05247,An Actor-Critic Algorithm for Sequence Prediction
IWSLT2015 German-English,https://identifiers.org/ito:ITO_05243,A Convolutional Encoder Model for Neural Machine Translation
IWSLT2015 German-English,https://identifiers.org/ito:ITO_05241,Convolutional Sequence to Sequence Learning
IWSLT2015 German-English,https://identifiers.org/ito:ITO_05236,Classical Structured Prediction Losses for Sequence to Sequence Learning
IWSLT2015 German-English,https://identifiers.org/ito:ITO_05232,Pervasive Attention: 2D Convolutional Neural Networks for Sequence-to-Sequence Prediction
IWSLT2015 German-English,https://identifiers.org/ito:ITO_46947,Self-Knowledge Distillation with Progressive Refinement of Targets
Business Scene Dialogue JA-EN,https://identifiers.org/ito:ITO_22944,Designing the Business Conversation Corpus
WMT2017 English-German,https://identifiers.org/ito:ITO_22839,OmniNet: Omnidirectional Representations from Transformers
ACCURAT balanced test corpus for under resourced languages Estonian-Russian,https://identifiers.org/ito:ITO_46902,Training and Adapting Multilingual NMT for Less-resourced and Morphologically Rich Languages
IWSLT2017 English-French,https://identifiers.org/ito:ITO_46911,No Language Left Behind: Scaling Human-Centered Machine Translation
IWSLT2017 English-French,https://identifiers.org/ito:ITO_05185,BPE-Dropout: Simple and Effective Subword Regularization
MultiSubs English-Portuguese,https://identifiers.org/ito:ITO_47020,MultiSubs: A Large-scale Multimodal and Multilingual Dataset
MultiSubs English-French,https://identifiers.org/ito:ITO_47020,MultiSubs: A Large-scale Multimodal and Multilingual Dataset
MultiSubs English-German,https://identifiers.org/ito:ITO_47020,MultiSubs: A Large-scale Multimodal and Multilingual Dataset
Hindi Visual Genome (Challenge Set),https://identifiers.org/ito:ITO_47012,ViTA: Visual-Linguistic Translation by Aligning Object Tags
Multi30K,https://identifiers.org/ito:ITO_23150,Incorporating Global Visual Features into Attention-Based Neural Machine Translation
Multi30K,https://identifiers.org/ito:ITO_23148,Latent Variable Model for Multi-modal Translation
Multi30K,https://identifiers.org/ito:ITO_23146,Distilling Translations with Visual Awareness
Multi30K,https://identifiers.org/ito:ITO_23138,Multimodal Machine Translation through Visuals and Speech
Multi30K,https://identifiers.org/ito:ITO_23136,Dynamic Context-guided Capsule Network for Multimodal Machine Translation
Multi30K,https://identifiers.org/ito:ITO_23154,A Visual Attention Grounding Neural Model for Multimodal Machine Translation
Multi30K,https://identifiers.org/ito:ITO_05230,Attention Is All You Need
Multi30K,https://identifiers.org/ito:ITO_46947,Self-Knowledge Distillation with Progressive Refinement of Targets
Hindi Visual Genome (Test Set),https://identifiers.org/ito:ITO_47012,ViTA: Visual-Linguistic Translation by Aligning Object Tags
WMT2016 German-English,https://identifiers.org/ito:ITO_05265,Phrase-Based & Neural Unsupervised Machine Translation
WMT2016 German-English,https://identifiers.org/ito:ITO_05466,Unsupervised Neural Machine Translation Initialized by Unsupervised Statistical Machine Translation
WMT2016 German-English,https://identifiers.org/ito:ITO_05381,Cross-lingual Language Model Pretraining
WMT2016 German-English,https://identifiers.org/ito:ITO_05462,An Effective Approach to Unsupervised Machine Translation
WMT2016 German-English,https://identifiers.org/ito:ITO_05459,MASS: Masked Sequence to Sequence Pre-training for Language Generation
WMT2016 German-English,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
WMT2014 German-English,https://identifiers.org/ito:ITO_05464,Unsupervised Neural Machine Translation with SMT as Posterior Regularization
WMT2014 German-English,https://identifiers.org/ito:ITO_05462,An Effective Approach to Unsupervised Machine Translation
WMT2016 English--Romanian,https://identifiers.org/ito:ITO_05381,Cross-lingual Language Model Pretraining
WMT2016 English--Romanian,https://identifiers.org/ito:ITO_22881,Incorporating BERT into Neural Machine Translation
WMT2016 Romanian-English,https://identifiers.org/ito:ITO_05459,MASS: Masked Sequence to Sequence Pre-training for Language Generation
WMT2016 Romanian-English,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
WMT2016 English-German,https://identifiers.org/ito:ITO_05265,Phrase-Based & Neural Unsupervised Machine Translation
WMT2016 English-German,https://identifiers.org/ito:ITO_05381,Cross-lingual Language Model Pretraining
WMT2016 English-German,https://identifiers.org/ito:ITO_05462,An Effective Approach to Unsupervised Machine Translation
WMT2016 English-German,https://identifiers.org/ito:ITO_05459,MASS: Masked Sequence to Sequence Pre-training for Language Generation
WMT2016 English-German,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
WMT2014 English-German,https://identifiers.org/ito:ITO_05464,Unsupervised Neural Machine Translation with SMT as Posterior Regularization
WMT2014 English-German,https://identifiers.org/ito:ITO_05462,An Effective Approach to Unsupervised Machine Translation
WMT2014 French-English,https://identifiers.org/ito:ITO_05265,Phrase-Based & Neural Unsupervised Machine Translation
WMT2014 French-English,https://identifiers.org/ito:ITO_05464,Unsupervised Neural Machine Translation with SMT as Posterior Regularization
WMT2014 French-English,https://identifiers.org/ito:ITO_05462,An Effective Approach to Unsupervised Machine Translation
WMT2014 French-English,https://identifiers.org/ito:ITO_05459,MASS: Masked Sequence to Sequence Pre-training for Language Generation
WMT2014 French-English,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
WMT2016 English-Romanian,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
WMT2014 English-French,https://identifiers.org/ito:ITO_05265,Phrase-Based & Neural Unsupervised Machine Translation
WMT2014 English-French,https://identifiers.org/ito:ITO_05381,Cross-lingual Language Model Pretraining
WMT2014 English-French,https://identifiers.org/ito:ITO_05462,An Effective Approach to Unsupervised Machine Translation
WMT2014 English-French,https://identifiers.org/ito:ITO_05459,MASS: Masked Sequence to Sequence Pre-training for Language Generation
WMT2014 English-French,https://identifiers.org/ito:ITO_22881,Incorporating BERT into Neural Machine Translation
es-en,https://identifiers.org/ito:ITO_02808,Word Translation Without Parallel Data
es-en,https://identifiers.org/ito:ITO_18533,Unsupervised Multilingual Alignment using Wasserstein Barycenter
MUSE en-de,https://identifiers.org/ito:ITO_18533,Unsupervised Multilingual Alignment using Wasserstein Barycenter
en-fr,https://identifiers.org/ito:ITO_02808,Word Translation Without Parallel Data
en-fr,https://identifiers.org/ito:ITO_18533,Unsupervised Multilingual Alignment using Wasserstein Barycenter
fr-en,https://identifiers.org/ito:ITO_02808,Word Translation Without Parallel Data
fr-en,https://identifiers.org/ito:ITO_18533,Unsupervised Multilingual Alignment using Wasserstein Barycenter
en-it,https://identifiers.org/ito:ITO_18533,Unsupervised Multilingual Alignment using Wasserstein Barycenter
MUSE en-pt,https://identifiers.org/ito:ITO_18533,Unsupervised Multilingual Alignment using Wasserstein Barycenter
en-es,https://identifiers.org/ito:ITO_02808,Word Translation Without Parallel Data
en-es,https://identifiers.org/ito:ITO_18533,Unsupervised Multilingual Alignment using Wasserstein Barycenter
MultiSubs,https://identifiers.org/ito:ITO_47020,MultiSubs: A Large-scale Multimodal and Multilingual Dataset
"Ubuntu Dialogue (v2, Ranking)",https://identifiers.org/ito:ITO_08580,Learning to Rank Question-Answer Pairs using Hierarchical Recurrent Encoder with Latent Topic Clustering
CICERO,https://identifiers.org/ito:ITO_49929,CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues
"Ubuntu Dialogue (v1, Ranking)",https://identifiers.org/ito:ITO_08580,Learning to Rank Question-Answer Pairs using Hierarchical Recurrent Encoder with Latent Topic Clustering
Quora Question Pairs,https://identifiers.org/ito:ITO_49923,What Do Questions Exactly Ask? MFAE: Duplicate Question Identification with Multi-Fusion Asking Emphasis
XQuAD,https://identifiers.org/ito:ITO_26953,Rethinking embedding coupling in pre-trained language models
XQuAD,https://identifiers.org/ito:ITO_49572,ByT5: Towards a token-free future with pre-trained byte-to-byte models
XQuAD,https://identifiers.org/ito:ITO_50023,mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models
TyDiQA-GoldP,https://identifiers.org/ito:ITO_26953,Rethinking embedding coupling in pre-trained language models
TyDiQA-GoldP,https://identifiers.org/ito:ITO_49572,ByT5: Towards a token-free future with pre-trained byte-to-byte models
MLQA,https://identifiers.org/ito:ITO_26953,Rethinking embedding coupling in pre-trained language models
MLQA,https://identifiers.org/ito:ITO_49572,ByT5: Towards a token-free future with pre-trained byte-to-byte models
CoQA,https://identifiers.org/ito:ITO_08210,CoQA: A Conversational Question Answering Challenge
CoQA,https://identifiers.org/ito:ITO_13313,Unified Language Model Pre-training for Natural Language Understanding and Generation
CoQA,https://identifiers.org/ito:ITO_26946,ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation
GQA,https://identifiers.org/ito:ITO_41698,GraghVQA: Language-Guided Graph Neural Networks for Graph-based Visual Question Answering
MSVD-QA,https://identifiers.org/ito:ITO_08676,TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering
MSVD-QA,https://identifiers.org/ito:ITO_08674,Motion-Appearance Co-Memory Networks for Video Question Answering
MSVD-QA,https://identifiers.org/ito:ITO_08672,Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering
MSVD-QA,https://identifiers.org/ito:ITO_08670,Hierarchical Conditional Relation Networks for Video Question Answering
MSVD-QA,https://identifiers.org/ito:ITO_49450,Just Ask: Learning to Answer Questions from Millions of Narrated Videos
MSVD-QA,https://identifiers.org/ito:ITO_48437,All in One: Exploring Unified Video-Language Pre-training
GQA test-std,https://identifiers.org/ito:ITO_08745,GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering
GQA test-std,https://identifiers.org/ito:ITO_27112,Language-Conditioned Graph Networks for Relational Reasoning
GQA test-std,https://identifiers.org/ito:ITO_08743,Learning by Abstraction: The Neural State Machine
GQA test-std,https://identifiers.org/ito:ITO_50085,ProTo: Program-Guided Transformer for Program-Guided Tasks
VizWiz 2018,https://identifiers.org/ito:ITO_08704,Towards VQA Models That Can Read
VizWiz 2018,https://identifiers.org/ito:ITO_08700,LXMERT: Learning Cross-Modality Encoder Representations from Transformers
VizWiz 2018,https://identifiers.org/ito:ITO_27292,Decoupled Box Proposal and Featurization with Ultrafine-Grained Semantic Labels Improve Image Captioning and Visual Question Answering
VCR (QA-R) dev,https://identifiers.org/ito:ITO_08691,VL-BERT: Pre-training of Generic Visual-Linguistic Representations
COCO Visual Question Answering (VQA) abstract images 1.0 open ended,https://identifiers.org/ito:ITO_08798,VQA: Visual Question Answering
COCO Visual Question Answering (VQA) abstract images 1.0 open ended,https://identifiers.org/ito:ITO_08806,Graph-Structured Representations for Visual Question Answering
VQA-CE,https://identifiers.org/ito:ITO_50096,Beyond Question-Based Biases: Assessing Multimodal Shortcut Learning in Visual Question Answering
DocVQA val,https://identifiers.org/ito:ITO_27187,DocVQA: A Dataset for VQA on Document Images
DocVQA,https://identifiers.org/ito:ITO_27137,Going Full-TILT Boogie on Document Understanding with Text-Image-Layout Transformer
COCO Visual Question Answering (VQA) abstract 1.0 multiple choice,https://identifiers.org/ito:ITO_08798,VQA: Visual Question Answering
COCO Visual Question Answering (VQA) abstract 1.0 multiple choice,https://identifiers.org/ito:ITO_08806,Graph-Structured Representations for Visual Question Answering
VQA v2 test-dev,https://identifiers.org/ito:ITO_08685,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
VQA v2 test-dev,https://identifiers.org/ito:ITO_08715,Learning to Reason: End-to-End Module Networks for Visual Question Answering
VQA v2 test-dev,https://identifiers.org/ito:ITO_08712,MUTAN: Multimodal Tucker Fusion for Visual Question Answering
VQA v2 test-dev,https://identifiers.org/ito:ITO_08702,Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge
VQA v2 test-dev,https://identifiers.org/ito:ITO_08698,Bilinear Attention Networks
VQA v2 test-dev,https://identifiers.org/ito:ITO_08696,Deep Modular Co-Attention Networks for Visual Question Answering
VQA v2 test-dev,https://identifiers.org/ito:ITO_08691,VL-BERT: Pre-training of Generic Visual-Linguistic Representations
VQA v2 test-dev,https://identifiers.org/ito:ITO_27051,UNITER: UNiversal Image-TExt Representation Learning
VQA v2 test-dev,https://identifiers.org/ito:ITO_27072,Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks
VQA v2 test-dev,https://identifiers.org/ito:ITO_50114,Align before Fuse: Vision and Language Representation Learning with Momentum Distillation
VQA v2 test-dev,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
VQA v2 test-dev,https://identifiers.org/ito:ITO_50106,VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts
IconQA,https://identifiers.org/ito:ITO_50138,IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning
VQA v1 test-dev,https://identifiers.org/ito:ITO_08762,Neural Module Networks
VQA v1 test-dev,https://identifiers.org/ito:ITO_08760,Dynamic Memory Networks for Visual and Textual Question Answering
VQA v1 test-dev,https://identifiers.org/ito:ITO_08759,Hierarchical Question-Image Co-Attention for Visual Question Answering
VQA v1 test-dev,https://identifiers.org/ito:ITO_08685,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
VQA v1 test-dev,https://identifiers.org/ito:ITO_08754,Dual Attention Networks for Multimodal Reasoning and Matching
VQA v1 test-dev,https://identifiers.org/ito:ITO_08752,"Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering"
CLEVR,https://identifiers.org/ito:ITO_27118,Inferring and Executing Programs for Visual Reasoning
CLEVR,https://identifiers.org/ito:ITO_27114,FiLM: Visual Reasoning with a General Conditioning Layer
CLEVR,https://identifiers.org/ito:ITO_27103,Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning
CLEVR,https://identifiers.org/ito:ITO_27097,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding
GQA,https://identifiers.org/ito:ITO_50153,RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning
GQA,https://identifiers.org/ito:ITO_50151,PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models
COCO Visual Question Answering (VQA) real images 1.0 open ended,https://identifiers.org/ito:ITO_08798,VQA: Visual Question Answering
COCO Visual Question Answering (VQA) real images 1.0 open ended,https://identifiers.org/ito:ITO_08796,Stacked Attention Networks for Image Question Answering
COCO Visual Question Answering (VQA) real images 1.0 open ended,https://identifiers.org/ito:ITO_08760,Dynamic Memory Networks for Visual and Textual Question Answering
COCO Visual Question Answering (VQA) real images 1.0 open ended,https://identifiers.org/ito:ITO_08759,Hierarchical Question-Image Co-Attention for Visual Question Answering
COCO Visual Question Answering (VQA) real images 1.0 open ended,https://identifiers.org/ito:ITO_08685,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
DocVQA test,https://identifiers.org/ito:ITO_27187,DocVQA: A Dataset for VQA on Document Images
PlotQA-D2,https://identifiers.org/ito:ITO_50168,Answering Questions about Data Visualizations using Efficient Bimodal Fusion
PlotQA-D2,https://identifiers.org/ito:ITO_50166,PlotQA: Reasoning over Scientific Plots
PlotQA-D2,https://identifiers.org/ito:ITO_50164,Classification-Regression for Chart Comprehension
Visual Genome (subjects),https://identifiers.org/ito:ITO_08681,Modeling Relationships in Referential Expressions with Compositional Modular Networks
VQA v2 val,https://identifiers.org/ito:ITO_50178,Multimodal Few-Shot Learning with Frozen Language Models
VQA v2 val,https://identifiers.org/ito:ITO_50176,Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation
VQA v2 val,https://identifiers.org/ito:ITO_50174,Language Models are General-Purpose Interfaces
Visual Genome (pairs),https://identifiers.org/ito:ITO_08681,Modeling Relationships in Referential Expressions with Compositional Modular Networks
COCO Visual Question Answering (VQA) real images 1.0 multiple choice,https://identifiers.org/ito:ITO_08798,VQA: Visual Question Answering
COCO Visual Question Answering (VQA) real images 1.0 multiple choice,https://identifiers.org/ito:ITO_08795,A Focused Dynamic Attention Model for Visual Question Answering
COCO Visual Question Answering (VQA) real images 1.0 multiple choice,https://identifiers.org/ito:ITO_08759,Hierarchical Question-Image Co-Attention for Visual Question Answering
COCO Visual Question Answering (VQA) real images 1.0 multiple choice,https://identifiers.org/ito:ITO_08685,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
GRIT,https://identifiers.org/ito:ITO_50108,"OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"
GRIT,https://identifiers.org/ito:ITO_50186,"Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks"
GRIT,https://identifiers.org/ito:ITO_50188,Webly Supervised Concept Expansion for General Purpose Vision Models
VCR (Q-A) dev,https://identifiers.org/ito:ITO_08691,VL-BERT: Pre-training of Generic Visual-Linguistic Representations
VCR (Q-AR) test,https://identifiers.org/ito:ITO_08691,VL-BERT: Pre-training of Generic Visual-Linguistic Representations
VCR (Q-AR) test,https://identifiers.org/ito:ITO_27051,UNITER: UNiversal Image-TExt Representation Learning
VCR (Q-AR) test,https://identifiers.org/ito:ITO_27049,ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph
VCR (QA-R) test,https://identifiers.org/ito:ITO_08691,VL-BERT: Pre-training of Generic Visual-Linguistic Representations
VCR (QA-R) test,https://identifiers.org/ito:ITO_27051,UNITER: UNiversal Image-TExt Representation Learning
VCR (QA-R) test,https://identifiers.org/ito:ITO_27049,ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph
CLEVR-Humans,https://identifiers.org/ito:ITO_27118,Inferring and Executing Programs for Visual Reasoning
CLEVR-Humans,https://identifiers.org/ito:ITO_27114,FiLM: Visual Reasoning with a General Conditioning Layer
CLEVR-Humans,https://identifiers.org/ito:ITO_27107,Compositional Attention Networks for Machine Reasoning
CLEVR-Humans,https://identifiers.org/ito:ITO_50086,MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding
ZS-F-VQA,https://identifiers.org/ito:ITO_50200,Zero-shot Visual Question Answering using Knowledge Graph
TDIUC,https://identifiers.org/ito:ITO_08708,MUREL: Multimodal Relational Reasoning for Visual Question Answering
VQA-CP,https://identifiers.org/ito:ITO_08823,Learning Visual Question Answering by Bootstrapping Hard Attention
VQA-CP,https://identifiers.org/ito:ITO_08708,MUREL: Multimodal Relational Reasoning for Visual Question Answering
VQA-CP,https://identifiers.org/ito:ITO_08820,Self-Critical Reasoning for Robust Visual Question Answering
VQA-CP,https://identifiers.org/ito:ITO_08818,Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases
VQA-CP,https://identifiers.org/ito:ITO_27214,Counterfactual Samples Synthesizing for Robust Visual Question Answering
Visual7W,https://identifiers.org/ito:ITO_08685,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
Visual7W,https://identifiers.org/ito:ITO_08681,Modeling Relationships in Referential Expressions with Compositional Modular Networks
VCR (Q-AR) dev,https://identifiers.org/ito:ITO_08691,VL-BERT: Pre-training of Generic Visual-Linguistic Representations
OK-VQA,https://identifiers.org/ito:ITO_50178,Multimodal Few-Shot Learning with Frozen Language Models
OK-VQA,https://identifiers.org/ito:ITO_50176,Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation
OK-VQA,https://identifiers.org/ito:ITO_50174,Language Models are General-Purpose Interfaces
FigureQA - test 1,https://identifiers.org/ito:ITO_50212,FigureQA: An Annotated Figure Dataset for Visual Reasoning
FigureQA - test 1,https://identifiers.org/ito:ITO_50168,Answering Questions about Data Visualizations using Efficient Bimodal Fusion
VCR (Q-A) test,https://identifiers.org/ito:ITO_08691,VL-BERT: Pre-training of Generic Visual-Linguistic Representations
VCR (Q-A) test,https://identifiers.org/ito:ITO_27051,UNITER: UNiversal Image-TExt Representation Learning
VCR (Q-A) test,https://identifiers.org/ito:ITO_27049,ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph
GQA Test2019,https://identifiers.org/ito:ITO_08725,Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering
GQA Test2019,https://identifiers.org/ito:ITO_27233,Bilinear Graph Networks for Visual Question Answering
GQA Test2019,https://identifiers.org/ito:ITO_08700,LXMERT: Learning Cross-Modality Encoder Representations from Transformers
GQA Test2019,https://identifiers.org/ito:ITO_27227,VinVL: Revisiting Visual Representations in Vision-Language Models
QLEVR,https://identifiers.org/ito:ITO_50225,QLEVR: A Diagnostic Dataset for Quantificational Language and Elementary Visual Reasoning
VQA v1 test-std,https://identifiers.org/ito:ITO_08796,Stacked Attention Networks for Image Question Answering
VQA v1 test-std,https://identifiers.org/ito:ITO_08760,Dynamic Memory Networks for Visual and Textual Question Answering
VQA v1 test-std,https://identifiers.org/ito:ITO_08759,Hierarchical Question-Image Co-Attention for Visual Question Answering
VQA v1 test-std,https://identifiers.org/ito:ITO_08757,Training Recurrent Answering Units with Joint Loss Minimization for VQA
VQA v1 test-std,https://identifiers.org/ito:ITO_08752,"Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering"
MSRVTT-QA,https://identifiers.org/ito:ITO_08676,TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering
MSRVTT-QA,https://identifiers.org/ito:ITO_08674,Motion-Appearance Co-Memory Networks for Video Question Answering
MSRVTT-QA,https://identifiers.org/ito:ITO_08672,Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering
MSRVTT-QA,https://identifiers.org/ito:ITO_08670,Hierarchical Conditional Relation Networks for Video Question Answering
MSRVTT-QA,https://identifiers.org/ito:ITO_49450,Just Ask: Learning to Answer Questions from Millions of Narrated Videos
MSRVTT-QA,https://identifiers.org/ito:ITO_50082,Align and Prompt: Video-and-Language Pre-training with Entity Prompts
MSRVTT-QA,https://identifiers.org/ito:ITO_48437,All in One: Exploring Unified Video-Language Pre-training
GQA test-dev,https://identifiers.org/ito:ITO_27112,Language-Conditioned Graph Networks for Relational Reasoning
GQA test-dev,https://identifiers.org/ito:ITO_08743,Learning by Abstraction: The Neural State Machine
GQA test-dev,https://identifiers.org/ito:ITO_50116,Coarse-to-Fine Reasoning for Visual Question Answering
PlotQA-D1,https://identifiers.org/ito:ITO_50168,Answering Questions about Data Visualizations using Efficient Bimodal Fusion
PlotQA-D1,https://identifiers.org/ito:ITO_50164,Classification-Regression for Chart Comprehension
COCO Visual Question Answering (VQA) real images 2.0 open ended,https://identifiers.org/ito:ITO_08798,VQA: Visual Question Answering
VQA v2 test-std,https://identifiers.org/ito:ITO_08729,Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering
VQA v2 test-std,https://identifiers.org/ito:ITO_08712,MUTAN: Multimodal Tucker Fusion for Visual Question Answering
VQA v2 test-std,https://identifiers.org/ito:ITO_08725,Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering
VQA v2 test-std,https://identifiers.org/ito:ITO_08698,Bilinear Attention Networks
VQA v2 test-std,https://identifiers.org/ito:ITO_08696,Deep Modular Co-Attention Networks for Visual Question Answering
VQA v2 test-std,https://identifiers.org/ito:ITO_27233,Bilinear Graph Networks for Visual Question Answering
VQA v2 test-std,https://identifiers.org/ito:ITO_27227,VinVL: Revisiting Visual Representations in Vision-Language Models
VQA v2 test-std,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
VQA v2 test-std,https://identifiers.org/ito:ITO_50106,VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts
VQA v2 test-std,https://identifiers.org/ito:ITO_50108,"OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"
ReClor,https://identifiers.org/ito:ITO_25532,ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning
BIOMRC,https://identifiers.org/ito:ITO_49078,Contextual embedding and model weighting by fusing domain knowledge on Biomedical Question Answering
UQuAD,https://identifiers.org/ito:ITO_49081,UQuAD1.0: Development of an Urdu Question Answering Training Data for Machine Reading Comprehension
QALD-9-Plus,https://identifiers.org/ito:ITO_49935,QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia and Wikidata Translated by Native Speakers
WebQuestionsSP,https://identifiers.org/ito:ITO_49896,UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering
WebQuestionsSP,https://identifiers.org/ito:ITO_49951,ReTraCk: A Flexible and Efficient Framework for Knowledge Base Question Answering
ComplexWebQuestions,https://identifiers.org/ito:ITO_26938,Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals
ComplexWebQuestions,https://identifiers.org/ito:ITO_49954,Case-based Reasoning for Natural Language Queries over Knowledge Bases
GrailQA,https://identifiers.org/ito:ITO_49951,ReTraCk: A Flexible and Efficient Framework for Knowledge Base Question Answering
WebQSP-WD,https://identifiers.org/ito:ITO_26943,Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering
Math23K,https://identifiers.org/ito:ITO_50002,Modeling Intra-Relation in Math Word Problems with Different Functional Multi-Head Attentions
Math23K,https://identifiers.org/ito:ITO_26983,A Goal-Driven Tree-Structured Neural Model for Math Word Problems
Math23K,https://identifiers.org/ito:ITO_50001,Graph-to-Tree Learning for Solving Math Word Problems
Math23K,https://identifiers.org/ito:ITO_50004,Learning by Fixing: Solving Math Word Problems with Weak Supervision
MATH,https://identifiers.org/ito:ITO_50014,Measuring Mathematical Problem Solving With the MATH Dataset
MATH,https://identifiers.org/ito:ITO_49535,Solving Quantitative Reasoning Problems with Language Models
SVAMP,https://identifiers.org/ito:ITO_26963,Are NLP Models really able to Solve Simple Math Word Problems?
Geometry3K,https://identifiers.org/ito:ITO_49990,Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning
GeoS,https://identifiers.org/ito:ITO_49998,Solving Geometry Problems: Combining Text and Diagram Interpretation
GeoS,https://identifiers.org/ito:ITO_49990,Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning
MemexQA,https://identifiers.org/ito:ITO_15921,Focal Visual-Text Attention for Visual Question Answering
Extended XQuAD,https://identifiers.org/ito:ITO_26998,BERT Based Multilingual Machine Comprehension in English and Hindi
MedMCQA (with Context),https://identifiers.org/ito:ITO_49970,MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering
IndicGLUE WSTP Pa,https://identifiers.org/ito:ITO_49979,"IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages"
IndicGLUE WSTP Pa,https://identifiers.org/ito:ITO_49977,Does Transliteration Help Multilingual Language Modeling?
MedMCQA (w/o Context),https://identifiers.org/ito:ITO_49970,MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering
SQuAD1.1,https://identifiers.org/ito:ITO_08061,Dynamic Coattention Networks For Question Answering
SQuAD1.1,https://identifiers.org/ito:ITO_08076,Reading Wikipedia to Answer Open-Domain Questions
WebQuestions,https://identifiers.org/ito:ITO_49896,UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering
Natural Questions,https://identifiers.org/ito:ITO_49896,UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering
SQuAD1.1 dev,https://identifiers.org/ito:ITO_26889,End-to-End Open-Domain Question Answering with BERTserini
SQuAD1.1 dev,https://identifiers.org/ito:ITO_26888,Data Augmentation for BERT Fine-Tuning in Open-Domain Question Answering
SQuAD1.1 dev,https://identifiers.org/ito:ITO_26886,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval
TriviaQA,https://identifiers.org/ito:ITO_26011,UnitedQA: A Hybrid Approach for Open Domain Question Answering
Quasar,https://identifiers.org/ito:ITO_07821,Gated-Attention Readers for Text Comprehension
Quasar,https://identifiers.org/ito:ITO_26880,R$^3$: Reinforced Reader-Ranker for Open-Domain Question Answering
Quasar,https://identifiers.org/ito:ITO_08560,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering
Quasar,https://identifiers.org/ito:ITO_07825,Bidirectional Attention Flow for Machine Comprehension
TQA,https://identifiers.org/ito:ITO_49896,UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering
SearchQA,https://identifiers.org/ito:ITO_26880,R$^3$: Reinforced Reader-Ranker for Open-Domain Question Answering
SearchQA,https://identifiers.org/ito:ITO_49605,Denoising Distantly Supervised Open-Domain Question Answering
SearchQA,https://identifiers.org/ito:ITO_04751,SpanBERT: Improving Pre-training by Representing and Predicting Spans
SearchQA,https://identifiers.org/ito:ITO_08076,Reading Wikipedia to Answer Open-Domain Questions
SearchQA,https://identifiers.org/ito:ITO_08268,Densely Connected Attention Propagation for Reading Comprehension
SearchQA,https://identifiers.org/ito:ITO_22318,Generating Long Sequences with Sparse Transformers
SearchQA,https://identifiers.org/ito:ITO_26298,Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering
SearchQA,https://identifiers.org/ito:ITO_26295,Reformer: The Efficient Transformer
SearchQA,https://identifiers.org/ito:ITO_26293,Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding
SearchQA,https://identifiers.org/ito:ITO_07829,Text Understanding with the Attention Sum Reader Network
SearchQA,https://identifiers.org/ito:ITO_08270,A Question-Focused Multi-Factor Attention Network for Question Answering
SearchQA,https://identifiers.org/ito:ITO_49717,Multi-Granular Sequence Encoding via Dilated Compositional Units for Reading Comprehension
DuReader,https://identifiers.org/ito:ITO_08532,ERNIE 2.0: A Continual Pre-training Framework for Language Understanding
KILT: HotpotQA,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: Natural Questions,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: Natural Questions,https://identifiers.org/ito:ITO_49915,"Re2G: Retrieve, Rerank, Generate"
Natural Questions (short),https://identifiers.org/ito:ITO_49600,End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering
KILT: TriviaQA,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: TriviaQA,https://identifiers.org/ito:ITO_49915,"Re2G: Retrieve, Rerank, Generate"
KILT: ELI5,https://identifiers.org/ito:ITO_26914,KILT: a Benchmark for Knowledge Intensive Language Tasks
KILT: ELI5,https://identifiers.org/ito:ITO_26925,Hurdles to Progress in Long-form Question Answering
MuLD (HotpotQA),https://identifiers.org/ito:ITO_49552,MuLD: The Multitask Long Document Benchmark
SWAG,https://identifiers.org/ito:ITO_49555,DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing
PubMedQA,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
PubMedQA,https://identifiers.org/ito:ITO_49558,BioELECTRA:Pretrained Biomedical text Encoder using Discriminators
PubMedQA,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
Aristo Kaggle Allen AI 8th grade questions,https://identifiers.org/ito:ITO_49562,Moving Beyond the Turing Test with the Allen AI Science Challenge
BioASQ,https://identifiers.org/ito:ITO_45543,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing
BioASQ,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
MedQA-USMLE,https://identifiers.org/ito:ITO_04771,BioBERT: a pre-trained biomedical language representation model for biomedical text mining
MedQA-USMLE,https://identifiers.org/ito:ITO_49567,QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering
MedQA-USMLE,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
TweetQA,https://identifiers.org/ito:ITO_49572,ByT5: Towards a token-free future with pre-trained byte-to-byte models
CommonsenseQA,https://identifiers.org/ito:ITO_26001,UnifiedQA: Crossing Format Boundaries With a Single QA System
NQ (BEIR),https://identifiers.org/ito:ITO_49577,BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models
NQ (BEIR),https://identifiers.org/ito:ITO_49576,No Parameter Left Behind: How Distillation and Model Size Affect Zero-Shot Retrieval
OTT-QA,https://identifiers.org/ito:ITO_49584,Open Question Answering over Tables and Text
OTT-QA,https://identifiers.org/ito:ITO_49586,Reasoning over Hybrid Chain for Table-and-Text Open Domain QA
FinQA,https://identifiers.org/ito:ITO_49591,FinQA: A Dataset of Numerical Reasoning over Financial Data
EfficientQA dev,https://identifiers.org/ito:ITO_26011,UnitedQA: A Hybrid Approach for Open Domain Question Answering
Natural Questions (short),https://identifiers.org/ito:ITO_08076,Reading Wikipedia to Answer Open-Domain Questions
Natural Questions (short),https://identifiers.org/ito:ITO_08542,A BERT Baseline for the Natural Questions
Natural Questions (short),https://identifiers.org/ito:ITO_22318,Generating Long Sequences with Sparse Transformers
Natural Questions (short),https://identifiers.org/ito:ITO_26339,Frustratingly Easy Natural Question Answering
Natural Questions (short),https://identifiers.org/ito:ITO_26347,REALM: Retrieval-Augmented Language Model Pre-Training
Natural Questions (short),https://identifiers.org/ito:ITO_26321,Dense Passage Retrieval for Open-Domain Question Answering
Natural Questions (short),https://identifiers.org/ito:ITO_26323,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
Natural Questions (short),https://identifiers.org/ito:ITO_26319,Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering
Natural Questions (short),https://identifiers.org/ito:ITO_49598,Distilling Knowledge from Reader to Retriever for Question Answering
SberQuAD,https://identifiers.org/ito:ITO_26047,SberQuAD -- Russian Reading Comprehension Dataset: Description and Analysis
Quasart-T,https://identifiers.org/ito:ITO_08076,Reading Wikipedia to Answer Open-Domain Questions
Quasart-T,https://identifiers.org/ito:ITO_49605,Denoising Distantly Supervised Open-Domain Question Answering
Quasart-T,https://identifiers.org/ito:ITO_22318,Generating Long Sequences with Sparse Transformers
Quasart-T,https://identifiers.org/ito:ITO_26295,Reformer: The Efficient Transformer
Quasart-T,https://identifiers.org/ito:ITO_26293,Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding
AI2 Kaggle Dataset,https://identifiers.org/ito:ITO_49607,Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification
EfficientQA test,https://identifiers.org/ito:ITO_26011,UnitedQA: A Hybrid Approach for Open Domain Question Answering
StepGame,https://identifiers.org/ito:ITO_49612,StepGame: A New Benchmark for Robust Multi-Hop Spatial Reasoning in Texts
RecipeQA,https://identifiers.org/ito:ITO_26331,Latent Alignment of Procedural Concepts in Multimodal Recipes
HybridQA,https://identifiers.org/ito:ITO_49623,HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data
HybridQA,https://identifiers.org/ito:ITO_49621,Iterative Hierarchical Attention for Answering Complex Questions over Long Documents
HybridQA,https://identifiers.org/ito:ITO_49619,MATE: Multi-view Attention for Table Transformer Efficiency
HybridQA,https://identifiers.org/ito:ITO_49617,Multi-Instance Training for Question Answering Across Table and Linked Text
SCDE,https://identifiers.org/ito:ITO_07902,SCDE: Sentence Cloze Dataset with High Quality Distractors From Examinations
QASPER,https://identifiers.org/ito:ITO_26043,A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers
MuLD (NarrativeQA),https://identifiers.org/ito:ITO_49552,MuLD: The Multitask Long Document Benchmark
SimpleQuestions,https://identifiers.org/ito:ITO_07862,Large-scale Simple Question Answering with Memory Networks
NewsQA,https://identifiers.org/ito:ITO_08072,Making Neural QA as Simple as Possible but not Simpler
NewsQA,https://identifiers.org/ito:ITO_08270,A Question-Focused Multi-Factor Attention Network for Question Answering
NewsQA,https://identifiers.org/ito:ITO_08268,Densely Connected Attention Propagation for Reading Comprehension
NewsQA,https://identifiers.org/ito:ITO_04751,SpanBERT: Improving Pre-training by Representing and Predicting Spans
NewsQA,https://identifiers.org/ito:ITO_08272,Efficient and Robust Question Answering from Minimal Context over Documents
StoryCloze,https://identifiers.org/ito:ITO_46894,Finetuned Language Models Are Zero-Shot Learners
Natural Questions (long),https://identifiers.org/ito:ITO_08076,Reading Wikipedia to Answer Open-Domain Questions
Natural Questions (long),https://identifiers.org/ito:ITO_08542,A BERT Baseline for the Natural Questions
Natural Questions (long),https://identifiers.org/ito:ITO_22318,Generating Long Sequences with Sparse Transformers
Natural Questions (long),https://identifiers.org/ito:ITO_26295,Reformer: The Efficient Transformer
Natural Questions (long),https://identifiers.org/ito:ITO_26293,Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding
Natural Questions (long),https://identifiers.org/ito:ITO_26225,Learning Dense Representations of Phrases at Scale
MS MARCO,https://identifiers.org/ito:ITO_07825,Bidirectional Attention Flow for Machine Comprehension
MS MARCO,https://identifiers.org/ito:ITO_08196,Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification
MS MARCO,https://identifiers.org/ito:ITO_08194,A Deep Cascade Model for Multi-Document Reading Comprehension
MS MARCO,https://identifiers.org/ito:ITO_08192,Multi-style Generative Reading Comprehension
COPA,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
COPA,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
COPA,https://identifiers.org/ito:ITO_49638,PaLM: Scaling Language Modeling with Pathways
FQuAD,https://identifiers.org/ito:ITO_26161,FQuAD: French Question Answering Dataset
HotpotQA (BEIR),https://identifiers.org/ito:ITO_49577,BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models
HotpotQA (BEIR),https://identifiers.org/ito:ITO_49576,No Parameter Left Behind: How Distillation and Model Size Affect Zero-Shot Retrieval
FairytaleQA,https://identifiers.org/ito:ITO_49648,Fantastic Questions and Where to Find Them: FairytaleQA -- An Authentic Dataset for Narrative Comprehension
MultiRC,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
MultiRC,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
MultiRC,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
MultiRC,https://identifiers.org/ito:ITO_49638,PaLM: Scaling Language Modeling with Pathways
ARC-c,https://identifiers.org/ito:ITO_46894,Finetuned Language Models Are Zero-Shot Learners
Molweni,https://identifiers.org/ito:ITO_49662,DADgraph: A Discourse-aware Dialogue Graph Neural Network for Multiparty Dialogue Machine Reading Comprehension
Molweni,https://identifiers.org/ito:ITO_49659,Self- and Pseudo-self-supervised Prediction of Speaker and Key-utterance for Multi-party Dialogue Reading Comprehension
Molweni,https://identifiers.org/ito:ITO_49657,Enhanced Speaker-aware Multi-party Multi-turn Dialogue Comprehension
CaseHOLD,https://identifiers.org/ito:ITO_26260,When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset
QASent,https://identifiers.org/ito:ITO_08304,Distributed Representations of Sentences and Documents
QASent,https://identifiers.org/ito:ITO_08301,Deep Learning for Answer Sentence Selection
QASent,https://identifiers.org/ito:ITO_08295,Neural Variational Inference for Text Processing
TruthfulQA,https://identifiers.org/ito:ITO_49675,TruthfulQA: Measuring How Models Mimic Human Falsehoods
CoQA,https://identifiers.org/ito:ITO_08208,"A Qualitative Comparison of CoQA, SQuAD 2.0 and QuAC"
CoQA,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
CoQA,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
TrecQA,https://identifiers.org/ito:ITO_08301,Deep Learning for Answer Sentence Selection
TrecQA,https://identifiers.org/ito:ITO_49681,Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement
TrecQA,https://identifiers.org/ito:ITO_08183,Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering
TrecQA,https://identifiers.org/ito:ITO_08283,A Compare-Aggregate Model with Latent Clustering for Answer Selection
TrecQA,https://identifiers.org/ito:ITO_26052,TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection
DROP Test,https://identifiers.org/ito:ITO_26135,DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs
DROP Test,https://identifiers.org/ito:ITO_26123,Giving BERT a Calculator: Finding Operations and Arguments with Reading Comprehension
DROP Test,https://identifiers.org/ito:ITO_26121,Question Directed Graph Attention Network for Numerical Reasoning over Text
TriviaQA,https://identifiers.org/ito:ITO_07955,Reinforced Mnemonic Reader for Machine Reading Comprehension
TriviaQA,https://identifiers.org/ito:ITO_08340,Dynamic Integration of Background Knowledge in Neural NLU Systems
TriviaQA,https://identifiers.org/ito:ITO_08056,Simple and Effective Multi-Paragraph Reading Comprehension
TriviaQA,https://identifiers.org/ito:ITO_49692,MemoReader: Large-Scale Reading Comprehension through Neural Memory Controller
TriviaQA,https://identifiers.org/ito:ITO_04751,SpanBERT: Improving Pre-training by Representing and Predicting Spans
TriviaQA,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
TriviaQA,https://identifiers.org/ito:ITO_49598,Distilling Knowledge from Reader to Retriever for Question Answering
TriviaQA,https://identifiers.org/ito:ITO_49688,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts
TriviaQA,https://identifiers.org/ito:ITO_49638,PaLM: Scaling Language Modeling with Pathways
Children's Book Test,https://identifiers.org/ito:ITO_07829,Text Understanding with the Attention Sum Reader Network
Children's Book Test,https://identifiers.org/ito:ITO_07821,Gated-Attention Readers for Text Comprehension
Children's Book Test,https://identifiers.org/ito:ITO_37159,007: Democratically Finding The Cause of Packet Drops
ComplexWebQuestions,https://identifiers.org/ito:ITO_49694,Mention Memory: incorporating textual knowledge into Transformers through entity mention attention
DaNetQA,https://identifiers.org/ito:ITO_25466,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
WikiQA,https://identifiers.org/ito:ITO_08304,Distributed Representations of Sentences and Documents
WikiQA,https://identifiers.org/ito:ITO_08301,Deep Learning for Answer Sentence Selection
WikiQA,https://identifiers.org/ito:ITO_08295,Neural Variational Inference for Text Processing
WikiQA,https://identifiers.org/ito:ITO_08291,Sentence Similarity Learning by Lexical Decomposition and Composition
WikiQA,https://identifiers.org/ito:ITO_08289,Key-Value Memory Networks for Directly Reading Documents
WikiQA,https://identifiers.org/ito:ITO_08183,Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering
WikiQA,https://identifiers.org/ito:ITO_08283,A Compare-Aggregate Model with Latent Clustering for Answer Selection
WikiQA,https://identifiers.org/ito:ITO_26052,TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection
WikiQA,https://identifiers.org/ito:ITO_49681,Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement
catbAbI LM-mode,https://identifiers.org/ito:ITO_49709,Learning Associative Inference Using Fast Weight Memory
NarrativeQA,https://identifiers.org/ito:ITO_07825,Bidirectional Attention Flow for Machine Comprehension
NarrativeQA,https://identifiers.org/ito:ITO_07913,Commonsense for Generative Multi-Hop Question Answering Tasks
NarrativeQA,https://identifiers.org/ito:ITO_49716,Cut to the Chase: A Context Zoom-in Network for Reading Comprehension
NarrativeQA,https://identifiers.org/ito:ITO_08192,Multi-style Generative Reading Comprehension
NarrativeQA,https://identifiers.org/ito:ITO_08268,Densely Connected Attention Propagation for Reading Comprehension
MRQA out-of-domain,https://identifiers.org/ito:ITO_49721,Cooperative Self-training of Machine Reading Comprehension
bAbi,https://identifiers.org/ito:ITO_08164,End-To-End Memory Networks
bAbi,https://identifiers.org/ito:ITO_08158,Query-Reduction Networks for Question Answering
bAbi,https://identifiers.org/ito:ITO_26277,Self-Attentive Associative Memory
WikiHop,https://identifiers.org/ito:ITO_07914,Constructing Datasets for Multi-hop Reading Comprehension Across Documents
WikiHop,https://identifiers.org/ito:ITO_07911,Neural Models for Reasoning over Multiple Mentions using Coreference
WikiHop,https://identifiers.org/ito:ITO_07909,Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks
WikiHop,https://identifiers.org/ito:ITO_07907,Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering
WikiHop,https://identifiers.org/ito:ITO_26216,Multi-hop Question Answering via Reasoning Chains
WikiHop,https://identifiers.org/ito:ITO_26214,Longformer: The Long-Document Transformer
WikiHop,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
MCTest-500,https://identifiers.org/ito:ITO_08276,A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data
Mathematics Dataset,https://identifiers.org/ito:ITO_26211,Analysing Mathematical Reasoning Abilities of Neural Models
Mathematics Dataset,https://identifiers.org/ito:ITO_26210,Enhancing the Transformer with Explicit Relational Encoding for Math Problem Solving
Mathematics Dataset,https://identifiers.org/ito:ITO_49728,Logic Embeddings for Complex Query Answering
SQuAD2.0 dev,https://identifiers.org/ito:ITO_08320,Read + Verify: Machine Reading Comprehension with Unanswerable Questions
SQuAD2.0 dev,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
SQuAD2.0 dev,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
FiQA-2018 (BEIR),https://identifiers.org/ito:ITO_49577,BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models
FiQA-2018 (BEIR),https://identifiers.org/ito:ITO_49579,SGPT: GPT Sentence Embeddings for Semantic Search
FiQA-2018 (BEIR),https://identifiers.org/ito:ITO_49576,No Parameter Left Behind: How Distillation and Model Size Affect Zero-Shot Retrieval
ChAII - Hindi and Tamil Question Answering,https://identifiers.org/ito:ITO_49736,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages
BoolQ,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
BoolQ,https://identifiers.org/ito:ITO_49739,ST-MoE: Designing Stable and Transferable Sparse Expert Models
JD Product Question Answer,https://identifiers.org/ito:ITO_08124,Product-Aware Answer Generation in E-Commerce Question-Answering
TAT-QA,https://identifiers.org/ito:ITO_49745,TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance
Quora Question Pairs,https://identifiers.org/ito:ITO_08299,Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms
CliCR,https://identifiers.org/ito:ITO_26632,CliCR: A Dataset of Clinical Case Reports for Machine Reading Comprehension
JaQuAD,https://identifiers.org/ito:ITO_49752,JaQuAD: Japanese Question Answering Dataset for Machine Reading Comprehension
catbAbI QA-mode,https://identifiers.org/ito:ITO_49709,Learning Associative Inference Using Fast Weight Memory
NaturalQA,https://identifiers.org/ito:ITO_04751,SpanBERT: Improving Pre-training by Representing and Predicting Spans
NaturalQA,https://identifiers.org/ito:ITO_26321,Dense Passage Retrieval for Open-Domain Question Answering
Reverb,https://identifiers.org/ito:ITO_07866,Open Question Answering with Weakly Supervised Embedding Models
YahooCQA,https://identifiers.org/ito:ITO_08185,Attentive Pooling Networks
YahooCQA,https://identifiers.org/ito:ITO_08183,Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering
YahooCQA,https://identifiers.org/ito:ITO_26636,SentenceMIM: A Latent Variable Language Model
CronQuestions,https://identifiers.org/ito:ITO_49767,Question Answering Over Temporal Knowledge Graphs
CronQuestions,https://identifiers.org/ito:ITO_49761,TempoQR: Temporal Question Reasoning over Knowledge Graphs
COMPLEXQUESTIONS,https://identifiers.org/ito:ITO_08215,Evaluating Semantic Parsing against a Simple Web-based Question Answering Model
CNN / Daily Mail,https://identifiers.org/ito:ITO_07841,Teaching Machines to Read and Comprehend
CNN / Daily Mail,https://identifiers.org/ito:ITO_07829,Text Understanding with the Attention Sum Reader Network
CNN / Daily Mail,https://identifiers.org/ito:ITO_07821,Gated-Attention Readers for Text Comprehension
CNN / Daily Mail,https://identifiers.org/ito:ITO_07819,Linguistic Knowledge as Memory for Recurrent Neural Networks
RACE,https://identifiers.org/ito:ITO_08148,Multi-range Reasoning for Machine Comprehension
RACE,https://identifiers.org/ito:ITO_09554,Improving Language Understanding by Generative Pre-Training
RACE,https://identifiers.org/ito:ITO_26547,Dual Co-Matching Network for Multi-choice Reading Comprehension
RACE,https://identifiers.org/ito:ITO_26545,Option Comparison Network for Multiple-choice Reading Comprehension
RACE,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
HotpotQA,https://identifiers.org/ito:ITO_26624,"HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"
HotpotQA,https://identifiers.org/ito:ITO_07849,Dynamically Fused Graph Network for Multi-hop Reasoning
HotpotQA,https://identifiers.org/ito:ITO_26579,Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering
HotpotQA,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
HotpotQA,https://identifiers.org/ito:ITO_26572,Answering Any-hop Open-domain Questions with Iterative Document Reranking
HotpotQA,https://identifiers.org/ito:ITO_49777,Answering Open-Domain Questions of Varying Reasoning Steps from Text
HotpotQA,https://identifiers.org/ito:ITO_26560,HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions
HotpotQA,https://identifiers.org/ito:ITO_49776,Adaptive Information Seeking for Open-Domain Question Answering
HotpotQA,https://identifiers.org/ito:ITO_26586,Hierarchical Graph Network for Multi-hop Question Answering
HotpotQA,https://identifiers.org/ito:ITO_26569,Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval
QuAC,https://identifiers.org/ito:ITO_07855,FlowQA: Grasping Flow in History for Conversational Machine Comprehension
CODAH,https://identifiers.org/ito:ITO_08128,CODAH: An Adversarially Authored Question-Answer Dataset for Common Sense
CODAH,https://identifiers.org/ito:ITO_26031,Generative Data Augmentation for Commonsense Reasoning
OpenBookQA,https://identifiers.org/ito:ITO_26038,Careful Selection of Knowledge to solve Open Book Question Answering
OpenBookQA,https://identifiers.org/ito:ITO_49567,QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering
PIQA,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
Story Cloze Test,https://identifiers.org/ito:ITO_49790,UNIMELB at SemEval-2016 Tasks 4A and 4B: An Ensemble of Neural Networks and a Word2Vec Based Model for Sentiment Classification
Story Cloze Test,https://identifiers.org/ito:ITO_09554,Improving Language Understanding by Generative Pre-Training
Story Cloze Test,https://identifiers.org/ito:ITO_26023,Improving Machine Reading Comprehension with General Reading Strategies
Torque,https://identifiers.org/ito:ITO_49797,TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions
Torque,https://identifiers.org/ito:ITO_49796,ECONET: Effective Continual Pretraining of Language Models for Event Temporal Reasoning
Natural Questions,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
Natural Questions,https://identifiers.org/ito:ITO_49688,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts
Natural Questions,https://identifiers.org/ito:ITO_49638,PaLM: Scaling Language Modeling with Pathways
Natural Questions,https://identifiers.org/ito:ITO_08542,A BERT Baseline for the Natural Questions
Natural Questions,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
MRQA,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
MRQA,https://identifiers.org/ito:ITO_45542,LinkBERT: Pretraining Language Models with Document Links
OBQA,https://identifiers.org/ito:ITO_46894,Finetuned Language Models Are Zero-Shot Learners
WebQuestions,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
WebQuestions,https://identifiers.org/ito:ITO_07866,Open Question Answering with Weakly Supervised Embedding Models
WebQuestions,https://identifiers.org/ito:ITO_07864,Question Answering with Subgraph Embeddings
WebQuestions,https://identifiers.org/ito:ITO_07862,Large-scale Simple Question Answering with Memory Networks
WebQuestions,https://identifiers.org/ito:ITO_49696,Latent Retrieval for Weakly Supervised Open Domain Question Answering
WebQuestions,https://identifiers.org/ito:ITO_26347,REALM: Retrieval-Augmented Language Model Pre-Training
WebQuestions,https://identifiers.org/ito:ITO_26321,Dense Passage Retrieval for Open-Domain Question Answering
WebQuestions,https://identifiers.org/ito:ITO_26323,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
MCTest-160,https://identifiers.org/ito:ITO_08276,A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data
SQuAD1.1 dev,https://identifiers.org/ito:ITO_08091,Machine Comprehension Using Match-LSTM and Answer Pointer
SQuAD1.1 dev,https://identifiers.org/ito:ITO_08110,End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension
SQuAD1.1 dev,https://identifiers.org/ito:ITO_07825,Bidirectional Attention Flow for Machine Comprehension
SQuAD1.1 dev,https://identifiers.org/ito:ITO_08076,Reading Wikipedia to Answer Open-Domain Questions
SQuAD1.1 dev,https://identifiers.org/ito:ITO_08078,Ruminating Reader: Reasoning with Gated Multi-Hop Attention
SQuAD1.1 dev,https://identifiers.org/ito:ITO_07955,Reinforced Mnemonic Reader for Machine Reading Comprehension
SQuAD1.1 dev,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
SQuAD1.1 dev,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
SQuAD1.1 dev,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
SQuAD1.1 dev,https://identifiers.org/ito:ITO_26144,Dice Loss for Data-imbalanced NLP Tasks
SQuAD1.1 dev,https://identifiers.org/ito:ITO_08072,Making Neural QA as Simple as Possible but not Simpler
SemEvalCQA,https://identifiers.org/ito:ITO_08548,Convolutional Neural Network Architectures for Matching Natural Language Sentences
SemEvalCQA,https://identifiers.org/ito:ITO_08185,Attentive Pooling Networks
SemEvalCQA,https://identifiers.org/ito:ITO_08183,Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering
SemEvalCQA,https://identifiers.org/ito:ITO_49826,KeLP at SemEval-2016 Task 3: Learning Semantic Relations between Questions and Answers
SQuAD1.1,https://identifiers.org/ito:ITO_08091,Machine Comprehension Using Match-LSTM and Answer Pointer
SQuAD1.1,https://identifiers.org/ito:ITO_07831,ReasoNet: Learning to Stop Reading in Machine Comprehension
SQuAD1.1,https://identifiers.org/ito:ITO_07955,Reinforced Mnemonic Reader for Machine Reading Comprehension
SQuAD1.1,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
SQuAD1.1,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
SQuAD1.1,https://identifiers.org/ito:ITO_21575,LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention
SQuAD2.0,https://identifiers.org/ito:ITO_07988,FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension
SQuAD2.0,https://identifiers.org/ito:ITO_07979,Stochastic Answer Networks for Machine Reading Comprehension
SQuAD2.0,https://identifiers.org/ito:ITO_08320,Read + Verify: Machine Reading Comprehension with Unanswerable Questions
SQuAD2.0,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
SQuAD2.0,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
SQuAD2.0,https://identifiers.org/ito:ITO_08312,SG-Net: Syntax-Guided Machine Reading Comprehension
SQuAD2.0,https://identifiers.org/ito:ITO_08310,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
SQuAD2.0,https://identifiers.org/ito:ITO_26654,Retrospective Reader for Machine Reading Comprehension
ARC-e,https://identifiers.org/ito:ITO_46894,Finetuned Language Models Are Zero-Shot Learners
FriendsQA,https://identifiers.org/ito:ITO_49856,Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering
FriendsQA,https://identifiers.org/ito:ITO_49657,Enhanced Speaker-aware Multi-party Multi-turn Dialogue Comprehension
SQuAD,https://identifiers.org/ito:ITO_26319,Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering
SQuAD,https://identifiers.org/ito:ITO_26321,Dense Passage Retrieval for Open-Domain Question Answering
SQuAD,https://identifiers.org/ito:ITO_26275,Fine-tune the Entire RAG Architecture (including DPR retriever) for Question-Answering
QC-Science,https://identifiers.org/ito:ITO_62473,TagRec: Automated Tagging of Questions with Hierarchical Learning Taxonomy
NExT-QA,https://identifiers.org/ito:ITO_48129,Flamingo: a Visual Language Model for Few-Shot Learning
Howto100M-QA,https://identifiers.org/ito:ITO_25003,HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training
SUTD-TrafficQA,https://identifiers.org/ito:ITO_27436,Exploring Models and Data for Image Question Answering
SUTD-TrafficQA,https://identifiers.org/ito:ITO_27434,"TVQA: Localized, Compositional Video Question Answering"
SUTD-TrafficQA,https://identifiers.org/ito:ITO_08670,Hierarchical Conditional Relation Networks for Video Question Answering
SUTD-TrafficQA,https://identifiers.org/ito:ITO_27432,SUTD-TrafficQA: A Question Answering Benchmark and an Efficient Network for Video Reasoning over Traffic Events
MSRVTT-QA,https://identifiers.org/ito:ITO_48414,Revealing Single Frame Bias for Video-and-Language Learning
ActivityNet-QA,https://identifiers.org/ito:ITO_50246,ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering
ActivityNet-QA,https://identifiers.org/ito:ITO_49450,Just Ask: Learning to Answer Questions from Millions of Narrated Videos
ActivityNet-QA,https://identifiers.org/ito:ITO_48414,Revealing Single Frame Bias for Video-and-Language Learning
MSRVTT-MC,https://identifiers.org/ito:ITO_48414,Revealing Single Frame Bias for Video-and-Language Learning
TVQA,https://identifiers.org/ito:ITO_27442,TVQA+: Spatio-Temporal Grounding for Video Question Answering
TVQA,https://identifiers.org/ito:ITO_25003,HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training
TVQA,https://identifiers.org/ito:ITO_27440,iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video Captioning and Video Question Answering
iVQA,https://identifiers.org/ito:ITO_49450,Just Ask: Learning to Answer Questions from Millions of Narrated Videos
SQuAD1.1,https://identifiers.org/ito:ITO_13852,Neural Question Generation from Text: A Preliminary Study
SQuAD1.1,https://identifiers.org/ito:ITO_61488,Leveraging Context Information for Natural Question Generation
SQuAD1.1,https://identifiers.org/ito:ITO_13313,Unified Language Model Pre-training for Natural Language Understanding and Generation
SQuAD1.1,https://identifiers.org/ito:ITO_26946,ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation
Natural Questions,https://identifiers.org/ito:ITO_41060,Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs
Visual Question Generation,https://identifiers.org/ito:ITO_13855,Multimodal Differential Network for Visual Question Generation
TriviaQA,https://identifiers.org/ito:ITO_41060,Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs
SQuAD,https://identifiers.org/ito:ITO_41060,Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs
COCO Visual Question Answering (VQA) real images 1.0 open ended,https://identifiers.org/ito:ITO_12821,Deep Visual-Semantic Alignments for Generating Image Descriptions
COCO Visual Question Answering (VQA) real images 1.0 open ended,https://identifiers.org/ito:ITO_13855,Multimodal Differential Network for Visual Question Generation
CodeXGLUE - CT-maxmin,https://identifiers.org/ito:ITO_59509,CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation
CodeXGLUE - CT-all,https://identifiers.org/ito:ITO_59509,CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation
HONEST,https://identifiers.org/ito:ITO_62859,HONEST: Measuring Hurtful Sentence Completion in Language Models
HellaSwag,https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
HellaSwag,https://identifiers.org/ito:ITO_26086,Muppet: Massive Multi-task Representations with Pre-Finetuning
COCO Captions,https://identifiers.org/ito:ITO_27881,Fake News Detection as Natural Language Inference
MLB Dataset (Relation Generation),https://identifiers.org/ito:ITO_27761,Data-to-text Generation with Macro Planning
MLB Dataset (Relation Generation),https://identifiers.org/ito:ITO_50843,Data-to-text Generation with Variational Sequential Planning
Czech Restaurant NLG,https://identifiers.org/ito:ITO_50847,Neural Generation for Czech: Data and Baselines
Czech Restaurant NLG,https://identifiers.org/ito:ITO_27791,Machine Translation Pre-training for Data-to-Text Generation -- A Case Study in Czech
ViGGO,https://identifiers.org/ito:ITO_09063,ViGGO: A Video Game Corpus for Data-To-Text Generation in Open-Domain Conversation
ViGGO,https://identifiers.org/ito:ITO_27769,Have Your Text and Use It Too! End-to-End Neural Data-to-Text Generation with Semantic Fidelity
E2E NLG Challenge,https://identifiers.org/ito:ITO_09099,Technical Report for E2E NLG Challenge
E2E NLG Challenge,https://identifiers.org/ito:ITO_09097,Attention Regularized Sequence-to-Sequence Learning for E2E NLG Challenge
E2E NLG Challenge,https://identifiers.org/ito:ITO_09095,"TNT-NLG, System 1: Using a statistical NLG to massively augment crowd-sourced data for neural generation"
E2E NLG Challenge,https://identifiers.org/ito:ITO_09091,A Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence Natural Language Generation
E2E NLG Challenge,https://identifiers.org/ito:ITO_09087,Pragmatically Informative Text Generation
E2E NLG Challenge,https://identifiers.org/ito:ITO_50850,E2E NLG Challenge: Neural Models vs. Templates
Rotowire (Content Selection),https://identifiers.org/ito:ITO_09053,Challenges in Data-to-Document Generation
Rotowire (Content Selection),https://identifiers.org/ito:ITO_09051,Data-to-Text Generation with Content Selection and Planning
Rotowire (Content Selection),https://identifiers.org/ito:ITO_09049,A Hierarchical Model for Data-to-Text Generation
Rotowire (Content Selection),https://identifiers.org/ito:ITO_27761,Data-to-text Generation with Macro Planning
RotoWire (Relation Generation),https://identifiers.org/ito:ITO_09053,Challenges in Data-to-Document Generation
RotoWire (Relation Generation),https://identifiers.org/ito:ITO_09051,Data-to-Text Generation with Content Selection and Planning
RotoWire (Relation Generation),https://identifiers.org/ito:ITO_09049,A Hierarchical Model for Data-to-Text Generation
RotoWire (Relation Generation),https://identifiers.org/ito:ITO_27761,Data-to-text Generation with Macro Planning
RotoWire (Relation Generation),https://identifiers.org/ito:ITO_50843,Data-to-text Generation with Variational Sequential Planning
SR11Deep,https://identifiers.org/ito:ITO_09081,Deep Graph Convolutional Encoders for Structured Data to Text Generation
SR11Deep,https://identifiers.org/ito:ITO_27801,Transition-Based Deep Input Linearization
AMR3.0,https://identifiers.org/ito:ITO_50858,Structural Adapters in Pretrained Language Models for AMR-to-text Generation
WebNLG Full,https://identifiers.org/ito:ITO_09074,Neural data-to-text generation: A comparison between pipeline and end-to-end architectures
WebNLG Full,https://identifiers.org/ito:ITO_27769,Have Your Text and Use It Too! End-to-End Neural Data-to-Text Generation with Semantic Fidelity
WebNLG Full,https://identifiers.org/ito:ITO_27740,Text-to-Text Pre-Training for Data-to-Text Tasks
WebNLG Full,https://identifiers.org/ito:ITO_50863,Investigating Pretrained Language Models for Graph-to-Text Generation
WebNLG Full,https://identifiers.org/ito:ITO_27739,Stage-wise Fine-tuning for Graph-to-Text Generation
WebNLG Full,https://identifiers.org/ito:ITO_50612,Control Prefixes for Parameter-Efficient Text Generation
RotoWire (Content Ordering),https://identifiers.org/ito:ITO_09053,Challenges in Data-to-Document Generation
RotoWire (Content Ordering),https://identifiers.org/ito:ITO_09051,Data-to-Text Generation with Content Selection and Planning
RotoWire (Content Ordering),https://identifiers.org/ito:ITO_09049,A Hierarchical Model for Data-to-Text Generation
MLB Dataset (Content Ordering),https://identifiers.org/ito:ITO_27761,Data-to-text Generation with Macro Planning
MLB Dataset (Content Ordering),https://identifiers.org/ito:ITO_50843,Data-to-text Generation with Variational Sequential Planning
WebNLG ru,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
MLB Dataset (Content Selection),https://identifiers.org/ito:ITO_27761,Data-to-text Generation with Macro Planning
MLB Dataset (Content Selection),https://identifiers.org/ito:ITO_50845,May the Force Be with Your Copy Mechanism: Enhanced Supervised-Copy Method for Natural Language Generation
WebNLG,https://identifiers.org/ito:ITO_50876,GTR-LSTM: A Triple Encoder for Sentence Generation from RDF Data
WebNLG,https://identifiers.org/ito:ITO_27742,Modeling Global and Local Node Contexts for Text Generation from Knowledge Graphs
WebNLG,https://identifiers.org/ito:ITO_27740,Text-to-Text Pre-Training for Data-to-Text Tasks
WebNLG,https://identifiers.org/ito:ITO_50863,Investigating Pretrained Language Models for Graph-to-Text Generation
WebNLG,https://identifiers.org/ito:ITO_27739,Stage-wise Fine-tuning for Graph-to-Text Generation
WebNLG,https://identifiers.org/ito:ITO_50612,Control Prefixes for Parameter-Efficient Text Generation
RotoWire,https://identifiers.org/ito:ITO_09053,Challenges in Data-to-Document Generation
RotoWire,https://identifiers.org/ito:ITO_09051,Data-to-Text Generation with Content Selection and Planning
RotoWire,https://identifiers.org/ito:ITO_09049,A Hierarchical Model for Data-to-Text Generation
RotoWire,https://identifiers.org/ito:ITO_50881,Improving Encoder by Auxiliary Supervision Tasks for Table-to-Text Generation
MULTIWOZ 2.1,https://identifiers.org/ito:ITO_27757,Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention
MULTIWOZ 2.1,https://identifiers.org/ito:ITO_27755,Few-shot Natural Language Generation for Task-Oriented Dialog
MULTIWOZ 2.1,https://identifiers.org/ito:ITO_27752,Template Guided Text Generation for Task-Oriented Dialogue
MULTIWOZ 2.1,https://identifiers.org/ito:ITO_27740,Text-to-Text Pre-Training for Data-to-Text Tasks
MLB Dataset,https://identifiers.org/ito:ITO_50884,Data-to-text Generation with Entity Modeling
MLB Dataset,https://identifiers.org/ito:ITO_27761,Data-to-text Generation with Macro Planning
MLB Dataset,https://identifiers.org/ito:ITO_50843,Data-to-text Generation with Variational Sequential Planning
Cleaned E2E NLG Challenge,https://identifiers.org/ito:ITO_09059,Semantic Noise Matters for Neural Natural Language Generation
Cleaned E2E NLG Challenge,https://identifiers.org/ito:ITO_27769,Have Your Text and Use It Too! End-to-End Neural Data-to-Text Generation with Semantic Fidelity
Cleaned E2E NLG Challenge,https://identifiers.org/ito:ITO_50612,Control Prefixes for Parameter-Efficient Text Generation
Cleaned E2E NLG Challenge,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
Wikipedia Person and Animal Dataset,https://identifiers.org/ito:ITO_50889,Towards Faithful Neural Table-to-Text Generation with Content-Matching Constraints
WebNLG en,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
ToTTo,https://identifiers.org/ito:ITO_27775,ToTTo: A Controlled Table-To-Text Generation Dataset
ToTTo,https://identifiers.org/ito:ITO_27740,Text-to-Text Pre-Training for Data-to-Text Tasks
ToTTo,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
PathQuestion,https://identifiers.org/ito:ITO_50896,Toward Subgraph Guided Knowledge Graph Question Generation with Graph Neural Networks
PathQuestion,https://identifiers.org/ito:ITO_41960,JointGT: Graph-Text Joint Representation Learning for Text Generation from Knowledge Graphs
WebNLG 2.0 (Constrained),https://identifiers.org/ito:ITO_50900,Handling Rare Items in Data-to-Text Generation
WebNLG 2.0 (Constrained),https://identifiers.org/ito:ITO_41960,JointGT: Graph-Text Joint Representation Learning for Text Generation from Knowledge Graphs
WikiGraphs,https://identifiers.org/ito:ITO_50908,WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset
WebNLG (Seen),https://identifiers.org/ito:ITO_50863,Investigating Pretrained Language Models for Graph-to-Text Generation
WebNLG (All),https://identifiers.org/ito:ITO_50863,Investigating Pretrained Language Models for Graph-to-Text Generation
ENT-DESC,https://identifiers.org/ito:ITO_50921,ENT-DESC: Entity Description Generation by Exploring Knowledge Graph
WebNLG (Unseen),https://identifiers.org/ito:ITO_50863,Investigating Pretrained Language Models for Graph-to-Text Generation
WebNLG 2.0 (Unconstrained),https://identifiers.org/ito:ITO_50900,Handling Rare Items in Data-to-Text Generation
WebNLG 2.0 (Unconstrained),https://identifiers.org/ito:ITO_50927,KGPT: Knowledge-Grounded Pre-Training for Data-to-Text Generation
WebNLG 2.0 (Unconstrained),https://identifiers.org/ito:ITO_41960,JointGT: Graph-Text Joint Representation Learning for Text Generation from Knowledge Graphs
WebQuestions,https://identifiers.org/ito:ITO_50896,Toward Subgraph Guided Knowledge Graph Question Generation with Graph Neural Networks
WebQuestions,https://identifiers.org/ito:ITO_41960,JointGT: Graph-Text Joint Representation Learning for Text Generation from Knowledge Graphs
AGENDA,https://identifiers.org/ito:ITO_50935,Text Generation from Knowledge Graphs with Graph Transformers
AGENDA,https://identifiers.org/ito:ITO_27742,Modeling Global and Local Node Contexts for Text Generation from Knowledge Graphs
AGENDA,https://identifiers.org/ito:ITO_50863,Investigating Pretrained Language Models for Graph-to-Text Generation
GenWiki (Fine),https://identifiers.org/ito:ITO_50940,GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation
GenWiki (Full),https://identifiers.org/ito:ITO_50940,GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation
VIST,https://identifiers.org/ito:ITO_27822,No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling
RACE,https://identifiers.org/ito:ITO_27876,A BERT-based Distractor Generation Scheme with Multi-tasking and Negative Answer Training Strategies
WebEdit,https://identifiers.org/ito:ITO_27889,Fact-based text editing
RotoEdit,https://identifiers.org/ito:ITO_27889,Fact-based text editing
LDC2015E86:,https://identifiers.org/ito:ITO_09044,A Graph-to-Sequence Model for AMR-to-Text Generation
DUC 2004,https://identifiers.org/ito:ITO_27826,Graph-based Neural Multi-Document Summarization
WCEP,https://identifiers.org/ito:ITO_50953,PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization
Multi-News,https://identifiers.org/ito:ITO_50953,PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization
Multi-News,https://identifiers.org/ito:ITO_13377,Bottom-Up Abstractive Summarization
Multi-News,https://identifiers.org/ito:ITO_50958,Multi-Document Summarization withDeterminantal Point Process Attention
Multi-News,https://identifiers.org/ito:ITO_27836,Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model
review,https://identifiers.org/ito:ITO_27830,Solar Cell Surface Defect Inspection Based on Multispectral Convolutional Neural Network
map2seq,https://identifiers.org/ito:ITO_51010,Generating Landmark Navigation Instructions from Maps as a Graph-to-Text Problem
ACL Title and Abstract Dataset,https://identifiers.org/ito:ITO_09133,Paper Abstract Writing through Editing Mechanism
Quora Question Pairs,https://identifiers.org/ito:ITO_50964,Hierarchical Sketch Induction for Paraphrase Generation
Quora Question Pairs,https://identifiers.org/ito:ITO_27863,Factorising Meaning and Form for Intent-Preserving Paraphrasing
Paralex,https://identifiers.org/ito:ITO_50964,Hierarchical Sketch Induction for Paraphrase Generation
Paralex,https://identifiers.org/ito:ITO_27863,Factorising Meaning and Form for Intent-Preserving Paraphrasing
MSCOCO,https://identifiers.org/ito:ITO_50964,Hierarchical Sketch Induction for Paraphrase Generation
TVMegaSite test,https://identifiers.org/ito:ITO_50970,TVRecap: A Dataset for Generating Stories with Character Descriptions
TVMegaSite dev,https://identifiers.org/ito:ITO_50970,TVRecap: A Dataset for Generating Stories with Character Descriptions
Fandom test,https://identifiers.org/ito:ITO_50970,TVRecap: A Dataset for Generating Stories with Character Descriptions
Fandom dev,https://identifiers.org/ito:ITO_50970,TVRecap: A Dataset for Generating Stories with Character Descriptions
Wikipedia Person and Animal Dataset,https://identifiers.org/ito:ITO_09128,Describing a Knowledge Base
WebNLG (Unseen),https://identifiers.org/ito:ITO_50865,HTLM: Hyper-Text Pre-Training and Prompting of Language Models
WikiBio,https://identifiers.org/ito:ITO_09124,Neural Text Generation from Structured Data with Application to the Biography Domain
WikiBio,https://identifiers.org/ito:ITO_09121,Table-to-text Generation by Structure-aware Seq2seq Learning
WikiBio,https://identifiers.org/ito:ITO_27871,Controlling Hallucinations at Word Level in Data-to-Text Generation
WebNLG (Seen),https://identifiers.org/ito:ITO_50865,HTLM: Hyper-Text Pre-Training and Prompting of Language Models
E2E,https://identifiers.org/ito:ITO_50865,HTLM: Hyper-Text Pre-Training and Prompting of Language Models
WebNLG (All),https://identifiers.org/ito:ITO_50865,HTLM: Hyper-Text Pre-Training and Prompting of Language Models
Wikipedia Person and Animal Dataset,https://identifiers.org/ito:ITO_50993,Variational Template Machine for Data-to-Text Generation
DART,https://identifiers.org/ito:ITO_50865,HTLM: Hyper-Text Pre-Training and Prompting of Language Models
CNN/Daily Mail,https://identifiers.org/ito:ITO_50563,PALM: Pre-training an Autoencoding&Autoregressive Language Model for Context-conditioned Generation
CMU-SE,https://identifiers.org/ito:ITO_27725,Generating Text through Adversarial Training using Skip-Thought Vectors
CommonGen,https://identifiers.org/ito:ITO_27713,CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning
CommonGen,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
One Billion Word,https://identifiers.org/ito:ITO_22368,Refining Deep Generative Models via Discriminator Gradient Flow
COCO Captions,https://identifiers.org/ito:ITO_09008,SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient
COCO Captions,https://identifiers.org/ito:ITO_09010,Adversarial Ranking for Language Generation
COCO Captions,https://identifiers.org/ito:ITO_09006,Long Text Generation via Adversarial Training with Leaked Information
Chinese Poems,https://identifiers.org/ito:ITO_09008,SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient
Chinese Poems,https://identifiers.org/ito:ITO_09010,Adversarial Ranking for Language Generation
LDC2016E25,https://identifiers.org/ito:ITO_09044,A Graph-to-Sequence Model for AMR-to-Text Generation
DART,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
DART,https://identifiers.org/ito:ITO_50612,Control Prefixes for Parameter-Efficient Text Generation
EMNLP2017 WMT,https://identifiers.org/ito:ITO_09008,SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient
EMNLP2017 WMT,https://identifiers.org/ito:ITO_09006,Long Text Generation via Adversarial Training with Leaked Information
EMNLP2017 WMT,https://identifiers.org/ito:ITO_09010,Adversarial Ranking for Language Generation
EMNLP2017 WMT,https://identifiers.org/ito:ITO_22372,Improving GAN Training with Probability Ratio Clipping and Sample Reweighting
Czech restaurant information,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
DailyDialog,https://identifiers.org/ito:ITO_09035,An Auto-Encoder Matching Model for Learning Utterance-Level Semantic Dependency in Dialogue Generation
Yahoo Questions,https://identifiers.org/ito:ITO_09025,Improved Variational Autoencoders for Text Modeling using Dilated Convolutions
Yahoo Questions,https://identifiers.org/ito:ITO_09023,Semi-Amortized Variational Autoencoders
Yahoo Questions,https://identifiers.org/ito:ITO_09021,Lagging Inference Networks and Posterior Collapse in Variational Autoencoders
Yelp Review Dataset (Small),https://identifiers.org/ito:ITO_27850,Style Transfer from Non-Parallel Text by Cross-Alignment
Yelp Review Dataset (Small),https://identifiers.org/ito:ITO_27849,Style Transfer in Text: Exploration and Evaluation
Yelp Review Dataset (Small),https://identifiers.org/ito:ITO_27846,"Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer"
Yelp Review Dataset (Small),https://identifiers.org/ito:ITO_27842,"Style Transfer for Texts: Retrain, Report Errors, Compare with Rewrites"
Yelp Review Dataset (Large),https://identifiers.org/ito:ITO_27855,A Novel Estimator of Mutual Information for Learning to Disentangle Textual Representations
Yelp Review Dataset (Large),https://identifiers.org/ito:ITO_27844,SentiInc: Incorporating Sentiment Information into Sentiment Transfer Without Parallel Data
ASSET,https://identifiers.org/ito:ITO_32943,MUSS: Multilingual Unsupervised Sentence Simplification by Mining Paraphrases
ASSET,https://identifiers.org/ito:ITO_55193,Sentence Simplification by Monolingual Machine Translation
ASSET,https://identifiers.org/ito:ITO_32919,Sentence Simplification with Deep Reinforcement Learning
ASSET,https://identifiers.org/ito:ITO_32921,Integrating Transformer and Paraphrase Rules for Sentence Simplification
ASSET,https://identifiers.org/ito:ITO_32945,Controllable Sentence Simplification
ASSET,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
ASSET,https://identifiers.org/ito:ITO_50612,Control Prefixes for Parameter-Efficient Text Generation
TurkCorpus,https://identifiers.org/ito:ITO_32919,Sentence Simplification with Deep Reinforcement Learning
TurkCorpus,https://identifiers.org/ito:ITO_55196,Exploring Neural Text Simplification Models
TurkCorpus,https://identifiers.org/ito:ITO_32916,Sentence Simplification with Memory-Augmented Neural Networks
TurkCorpus,https://identifiers.org/ito:ITO_55193,Sentence Simplification by Monolingual Machine Translation
TurkCorpus,https://identifiers.org/ito:ITO_55195,Optimizing Statistical Machine Translation for Text Simplification
TurkCorpus,https://identifiers.org/ito:ITO_32921,Integrating Transformer and Paraphrase Rules for Sentence Simplification
TurkCorpus,https://identifiers.org/ito:ITO_32945,Controllable Sentence Simplification
TurkCorpus,https://identifiers.org/ito:ITO_32943,MUSS: Multilingual Unsupervised Sentence Simplification by Mining Paraphrases
TurkCorpus,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
TurkCorpus,https://identifiers.org/ito:ITO_50612,Control Prefixes for Parameter-Efficient Text Generation
Newsela,https://identifiers.org/ito:ITO_32919,Sentence Simplification with Deep Reinforcement Learning
Newsela,https://identifiers.org/ito:ITO_32916,Sentence Simplification with Memory-Augmented Neural Networks
Newsela,https://identifiers.org/ito:ITO_32908,Dynamic Multi-Level Multi-Task Learning for Sentence Simplification
Newsela,https://identifiers.org/ito:ITO_55200,Neural CRF Model for Sentence Alignment in Text Simplification
PWKP / WikiSmall,https://identifiers.org/ito:ITO_32934,Unsupervised Sentence Simplification Using Deep Semantics
PWKP / WikiSmall,https://identifiers.org/ito:ITO_32916,Sentence Simplification with Memory-Augmented Neural Networks
PWKP / WikiSmall,https://identifiers.org/ito:ITO_32919,Sentence Simplification with Deep Reinforcement Learning
PWKP / WikiSmall,https://identifiers.org/ito:ITO_32910,EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing
PWKP / WikiSmall,https://identifiers.org/ito:ITO_32937,Text Simplification by Tagging
EurekaAlert,https://identifiers.org/ito:ITO_55205,HTSS: A Novel Hybrid Text Summarisation and Simplification Architecture
AESLC,https://identifiers.org/ito:ITO_34915,This Email Could Save Your Life: Introducing the Task of Email Subject Line Generation
AESLC,https://identifiers.org/ito:ITO_34763,PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization
DaNewsroom,https://identifiers.org/ito:ITO_56428,DaNewsroom: A Large-scale Danish Summarisation Dataset
MLSUM de,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
CNN / Daily Mail,https://identifiers.org/ito:ITO_13324,Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond
CNN / Daily Mail,https://identifiers.org/ito:ITO_34890,Deep Communicating Agents for Abstractive Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_34748,Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting
CNN / Daily Mail,https://identifiers.org/ito:ITO_34888,Pretraining-Based Natural Language Generation for Text Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_13313,Unified Language Model Pre-training for Natural Language Understanding and Generation
CNN / Daily Mail,https://identifiers.org/ito:ITO_08259,"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"
CNN / Daily Mail,https://identifiers.org/ito:ITO_34763,PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_26946,ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation
CNN / Daily Mail,https://identifiers.org/ito:ITO_56377,BRIO: Bringing Order to Abstractive Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_28641,Better Fine-Tuning by Reducing Representational Collapse
CNN / Daily Mail,https://identifiers.org/ito:ITO_26086,Muppet: Massive Multi-task Representations with Pre-Finetuning
CNN / Daily Mail,https://identifiers.org/ito:ITO_51484,GLM: General Language Model Pretraining with Autoregressive Blank Infilling
CNN / Daily Mail,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
CNN / Daily Mail,https://identifiers.org/ito:ITO_46929,R-Drop: Regularized Dropout for Neural Networks
MLSum-it,https://identifiers.org/ito:ITO_56436,Two New Datasets for Italian-Language Abstractive Text Summarization
Abstractive Text Summarization from Fanpage,https://identifiers.org/ito:ITO_56436,Two New Datasets for Italian-Language Abstractive Text Summarization
vietnews,https://identifiers.org/ito:ITO_56446,BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese
vietnews,https://identifiers.org/ito:ITO_54433,ViT5: Pretrained Text-to-Text Transformer for Vietnamese Language Generation
Abstractive Text Summarization from Il Post,https://identifiers.org/ito:ITO_56436,Two New Datasets for Italian-Language Abstractive Text Summarization
MLSUM es,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
How2 300h,https://identifiers.org/ito:ITO_34923,MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention
RASG,https://identifiers.org/ito:ITO_13369,Abstractive Text Summarization by Incorporating Reader Comments
MTS,https://identifiers.org/ito:ITO_13365,Learning towards Abstractive Timeline Summarization
BBC XSum,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
arXiv,https://identifiers.org/ito:ITO_56387,Sparsifying Transformer Models with Trainable Representation Pooling
HowSumm-Step,https://identifiers.org/ito:ITO_56476,HowSumm: A Multi-Document Summarization Dataset Derived from WikiHow Articles
arXiv Summarization Dataset,https://identifiers.org/ito:ITO_56387,Sparsifying Transformer Models with Trainable Representation Pooling
CNN / Daily Mail,https://identifiers.org/ito:ITO_13360,Get To The Point: Summarization with Pointer-Generator Networks
CNN / Daily Mail,https://identifiers.org/ito:ITO_13379,A Deep Reinforced Model for Abstractive Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_13377,Bottom-Up Abstractive Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_13391,Fine-tune BERT for Extractive Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
CNN / Daily Mail,https://identifiers.org/ito:ITO_49051,Hierarchical Learning for Generation with Long Source Sequences
CNN / Daily Mail,https://identifiers.org/ito:ITO_56379,SummaReranker: A Multi-Task Mixture-of-Experts Re-ranking Framework for Abstractive Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_56491,Coarse-to-Fine Attention Models for Document Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_13356,Text Summarization with Pretrained Encoders
CNN / Daily Mail,https://identifiers.org/ito:ITO_34718,Extractive Summarization as Text Matching
HowSumm-Method,https://identifiers.org/ito:ITO_56476,HowSumm: A Multi-Document Summarization Dataset Derived from WikiHow Articles
EmailSum (long),https://identifiers.org/ito:ITO_56508,EmailSum: Abstractive Email Thread Summarization
EmailSum (short),https://identifiers.org/ito:ITO_56508,EmailSum: Abstractive Email Thread Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_34961,Ranking Sentences for Extractive Summarization with Reinforcement Learning
CNN / Daily Mail,https://identifiers.org/ito:ITO_34955,Neural Document Summarization by Jointly Learning to Score and Select Sentences
CNN / Daily Mail,https://identifiers.org/ito:ITO_34953,HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization
CNN / Daily Mail,https://identifiers.org/ito:ITO_34951,Searching for Effective Neural Extractive Summarization: What Works and What's Next
CNN / Daily Mail,https://identifiers.org/ito:ITO_34885,Summary Level Training of Sentence Rewriting for Abstractive Summarization
DebateSum,https://identifiers.org/ito:ITO_34943,DebateSum: A large-scale argument mining and summarization dataset
DUC 2004 Task 1,https://identifiers.org/ito:ITO_13352,A Neural Attention Model for Abstractive Sentence Summarization
XSum,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
GEM-XSum,https://identifiers.org/ito:ITO_49572,ByT5: Towards a token-free future with pre-trained byte-to-byte models
GEM-XSum,https://identifiers.org/ito:ITO_21102,"The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"
TLDR9+,https://identifiers.org/ito:ITO_62244,TLDR9+: A Large Scale Resource for Extreme Summarization of Social Media Posts
CiteSum,https://identifiers.org/ito:ITO_62250,CiteSum: Citation Text-guided Scientific Extreme Summarization and Low-resource Domain Adaptation
Debatepedia,https://identifiers.org/ito:ITO_13397,Diversity driven Attention Model for Query-based Abstractive Summarization
Debatepedia,https://identifiers.org/ito:ITO_13395,"Query Focused Abstractive Summarization: Incorporating Query Relevance, Multi-Document Coverage, and Summary Length Constraints into seq2seq Models"
BIG-bench,https://identifiers.org/ito:ITO_49516,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
BIG-bench,https://identifiers.org/ito:ITO_49514,Training Compute-Optimal Large Language Models
GSM8K,https://identifiers.org/ito:ITO_62932,Self-Consistency Improves Chain of Thought Reasoning in Language Models
GSM8K,https://identifiers.org/ito:ITO_49535,Solving Quantitative Reasoning Problems with Language Models
MultiArith,https://identifiers.org/ito:ITO_62935,Large Language Models are Zero-Shot Reasoners
HolStep (Conditional),https://identifiers.org/ito:ITO_13231,HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving
HolStep (Conditional),https://identifiers.org/ito:ITO_13229,Premise Selection for Theorem Proving by Deep Graph Embedding
HolStep (Conditional),https://identifiers.org/ito:ITO_34578,Improving Graph Neural Network Representations of Logical Formulae with Subgraph Pooling
CompCert,https://identifiers.org/ito:ITO_34587,Generating Correctness Proofs with Neural Networks
Metamath set.mm,https://identifiers.org/ito:ITO_13253,Holophrasm: a neural Automated Theorem Prover for higher-order logic
miniF2F-test,https://identifiers.org/ito:ITO_56263,MiniF2F: a cross-system benchmark for formal Olympiad-level mathematics
miniF2F-test,https://identifiers.org/ito:ITO_56261,Formal Mathematics Statement Curriculum Learning
miniF2F-test,https://identifiers.org/ito:ITO_56257,Autoformalization with Large Language Models
miniF2F-test,https://identifiers.org/ito:ITO_56267,HyperTree Proof Search for Neural Theorem Proving
CoqGym,https://identifiers.org/ito:ITO_13263,Learning to Prove Theorems via Interacting with Proof Assistants
miniF2F-valid,https://identifiers.org/ito:ITO_56263,MiniF2F: a cross-system benchmark for formal Olympiad-level mathematics
HolStep (Unconditional),https://identifiers.org/ito:ITO_13231,HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving
HolStep (Unconditional),https://identifiers.org/ito:ITO_13229,Premise Selection for Theorem Proving by Deep Graph Embedding
HOList benchmark,https://identifiers.org/ito:ITO_13238,HOList: An Environment for Machine Learning of Higher-Order Theorem Proving
HOList benchmark,https://identifiers.org/ito:ITO_13236,Graph Representations for Higher-Order Logic and Theorem Proving
Event2Mind dev,https://identifiers.org/ito:ITO_09376,"Event2Mind: Commonsense Inference on Events, Intents, and Reactions"
WSC273,https://identifiers.org/ito:ITO_46894,Finetuned Language Models Are Zero-Shot Learners
Winograd Schema Challenge,https://identifiers.org/ito:ITO_09381,A Simple Method for Commonsense Reasoning
Winograd Schema Challenge,https://identifiers.org/ito:ITO_07879,Language Models are Unsupervised Multitask Learners
Winograd Schema Challenge,https://identifiers.org/ito:ITO_28250,A Surprisingly Robust Trick for Winograd Schema Challenge
Winograd Schema Challenge,https://identifiers.org/ito:ITO_28248,A Hybrid Neural Network Model for Commonsense Reasoning
PARus,https://identifiers.org/ito:ITO_25466,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
ARC (Easy),https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
ARC (Easy),https://identifiers.org/ito:ITO_49688,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts
ARC (Easy),https://identifiers.org/ito:ITO_49739,ST-MoE: Designing Stable and Transferable Sparse Expert Models
ARC (Challenge),https://identifiers.org/ito:ITO_23113,Language Models are Few-Shot Learners
ARC (Challenge),https://identifiers.org/ito:ITO_49739,ST-MoE: Designing Stable and Transferable Sparse Expert Models
Event2Mind test,https://identifiers.org/ito:ITO_09376,"Event2Mind: Commonsense Inference on Events, Intents, and Reactions"
Russian Event2Mind,https://identifiers.org/ito:ITO_28227,Event2Mind for Russian: Understanding Emotions and Intents in Texts. Corpus and Model for Evaluation
SWAG,https://identifiers.org/ito:ITO_08133,SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference
SWAG,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
SWAG,https://identifiers.org/ito:ITO_07499,RoBERTa: A Robustly Optimized BERT Pretraining Approach
SWAG,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
Visual Dialog  v0.9,https://identifiers.org/ito:ITO_09355,Probabilistic framework for solving Visual Dialog
RuCoS,https://identifiers.org/ito:ITO_25466,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
Visual Dialog v0.9,https://identifiers.org/ito:ITO_04608,Visual Coreference Resolution in Visual Dialog using Neural Module Networks
CommonsenseQA,https://identifiers.org/ito:ITO_09371,CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge
CommonsenseQA,https://identifiers.org/ito:ITO_09367,Explain Yourself! Leveraging Language Models for Commonsense Reasoning
CommonsenseQA,https://identifiers.org/ito:ITO_07499,RoBERTa: A Robustly Optimized BERT Pretraining Approach
CommonsenseQA,https://identifiers.org/ito:ITO_08310,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
CommonsenseQA,https://identifiers.org/ito:ITO_51288,Fusing Context Into Knowledge Graph for Commonsense Question Answering
CommonsenseQA,https://identifiers.org/ito:ITO_51286,Human Parity on CommonsenseQA: Augmenting Self-Attention with External Attention
RWSD,https://identifiers.org/ito:ITO_25466,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
ReCoRD,https://identifiers.org/ito:ITO_46894,Finetuned Language Models Are Zero-Shot Learners
ReCoRD,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
ReCoRD,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
ReCoRD,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
ReCoRD,https://identifiers.org/ito:ITO_49638,PaLM: Scaling Language Modeling with Pathways
CrowdSpeech test-clean,https://identifiers.org/ito:ITO_62454,CrowdSpeech and VoxDIY: Benchmark Datasets for Crowdsourced Audio Transcription
CrowdSpeech test-other,https://identifiers.org/ito:ITO_62454,CrowdSpeech and VoxDIY: Benchmark Datasets for Crowdsourced Audio Transcription
Obstacle Tower (Weak Gen) fixed,https://identifiers.org/ito:ITO_40741,"Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning"
Obstacle Tower (No Gen) fixed,https://identifiers.org/ito:ITO_40741,"Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning"
Obstacle Tower (Strong Gen) fixed,https://identifiers.org/ito:ITO_40741,"Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning"
Obstacle Tower (No Gen) varied,https://identifiers.org/ito:ITO_40741,"Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning"
Obstacle Tower (Strong Gen) varied,https://identifiers.org/ito:ITO_40741,"Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning"
Obstacle Tower (Weak Gen) varied,https://identifiers.org/ito:ITO_40741,"Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning"
Pascal-50S,https://identifiers.org/ito:ITO_63178,CLIPScore: A Reference-free Evaluation Metric for Image Captioning
Pascal-50S,https://identifiers.org/ito:ITO_63176,Mutual Information Divergence: A Unified Metric for Multimodal Generative Models
Flickr8k-CF,https://identifiers.org/ito:ITO_63178,CLIPScore: A Reference-free Evaluation Metric for Image Captioning
Flickr8k-CF,https://identifiers.org/ito:ITO_63176,Mutual Information Divergence: A Unified Metric for Multimodal Generative Models
Flickr8k-Expert,https://identifiers.org/ito:ITO_63178,CLIPScore: A Reference-free Evaluation Metric for Image Captioning
Flickr8k-Expert,https://identifiers.org/ito:ITO_63176,Mutual Information Divergence: A Unified Metric for Multimodal Generative Models
SciTail,https://identifiers.org/ito:ITO_09537,"Compare, Compress and Propagate: Enhancing Neural Architectures with Alignment Factorization for Natural Language Inference"
SciTail,https://identifiers.org/ito:ITO_09554,Improving Language Understanding by Generative Pre-Training
SciTail,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
SciTail,https://identifiers.org/ito:ITO_09517,Multi-Task Deep Neural Networks for Natural Language Understanding
SciTail,https://identifiers.org/ito:ITO_51407,SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization
SciTail,https://identifiers.org/ito:ITO_51406,Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data
XNLI Chinese,https://identifiers.org/ito:ITO_09510,ERNIE: Enhanced Representation through Knowledge Integration
XNLI Chinese,https://identifiers.org/ito:ITO_08532,ERNIE 2.0: A Continual Pre-training Framework for Language Understanding
TERRa,https://identifiers.org/ito:ITO_25466,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
MultiNLI Dev,https://identifiers.org/ito:ITO_26155,TinyBERT: Distilling BERT for Natural Language Understanding
MRPC,https://identifiers.org/ito:ITO_49555,DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing
XNLI French,https://identifiers.org/ito:ITO_09670,XNLI: Evaluating Cross-lingual Sentence Representations
XNLI French,https://identifiers.org/ito:ITO_05381,Cross-lingual Language Model Pretraining
XNLI French,https://identifiers.org/ito:ITO_21017,CamemBERT: a Tasty French Language Model
XNLI French,https://identifiers.org/ito:ITO_51414,FlauBERT: Unsupervised Language Model Pre-training for French
SICK,https://identifiers.org/ito:ITO_28466,NeuralLog: Natural Language Inference with Joint Neural and Logical Reasoning
V-SNLI,https://identifiers.org/ito:ITO_09541,Grounded Textual Entailment
V-SNLI,https://identifiers.org/ito:ITO_51419,Supervised Multimodal Bitransformers for Classifying Images and Text
MED,https://identifiers.org/ito:ITO_28466,NeuralLog: Natural Language Inference with Joint Neural and Logical Reasoning
MultiNLI,https://identifiers.org/ito:ITO_09526,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning
MultiNLI,https://identifiers.org/ito:ITO_09522,GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding
MultiNLI,https://identifiers.org/ito:ITO_09554,Improving Language Understanding by Generative Pre-Training
MultiNLI,https://identifiers.org/ito:ITO_28511,Training Complex Models with Multi-Task Weak Supervision
MultiNLI,https://identifiers.org/ito:ITO_28509,Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding
MultiNLI,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
MultiNLI,https://identifiers.org/ito:ITO_28463,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
MultiNLI,https://identifiers.org/ito:ITO_08310,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
MultiNLI,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
MultiNLI,https://identifiers.org/ito:ITO_07499,RoBERTa: A Robustly Optimized BERT Pretraining Approach
KUAKE-QQR,https://identifiers.org/ito:ITO_51428,CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark
RCB,https://identifiers.org/ito:ITO_25466,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
FarsTail,https://identifiers.org/ito:ITO_28546,FarsTail: A Persian Natural Language Inference Dataset
WNLI,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
WNLI,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
WNLI,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
Quora Question Pairs,https://identifiers.org/ito:ITO_09520,Attention Boosted Sequential Inference Model
MRPC Dev,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
CommitmentBank,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
CommitmentBank,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
CommitmentBank,https://identifiers.org/ito:ITO_49638,PaLM: Scaling Language Modeling with Pathways
RTE,https://identifiers.org/ito:ITO_04704,ERNIE: Enhanced Language Representation with Informative Entities
RTE,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
RTE,https://identifiers.org/ito:ITO_07499,RoBERTa: A Robustly Optimized BERT Pretraining Approach
RTE,https://identifiers.org/ito:ITO_28463,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
RTE,https://identifiers.org/ito:ITO_08310,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
RTE,https://identifiers.org/ito:ITO_22884,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
RTE,https://identifiers.org/ito:ITO_49050,DeBERTa: Decoding-enhanced BERT with Disentangled Attention
RTE,https://identifiers.org/ito:ITO_49638,PaLM: Scaling Language Modeling with Pathways
LiDiRus,https://identifiers.org/ito:ITO_25466,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
XWINO,https://identifiers.org/ito:ITO_45125,mGPT: Few-Shot Learners Go Multilingual
QNLI,https://identifiers.org/ito:ITO_04704,ERNIE: Enhanced Language Representation with Informative Entities
QNLI,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
QNLI,https://identifiers.org/ito:ITO_07499,RoBERTa: A Robustly Optimized BERT Pretraining Approach
QNLI,https://identifiers.org/ito:ITO_28463,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
KUAKE-QTR,https://identifiers.org/ito:ITO_51428,CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark
SNLI,https://identifiers.org/ito:ITO_09597,A Convolutional Neural Network for Modelling Sentences
SNLI,https://identifiers.org/ito:ITO_09582,Convolutional Neural Networks for Sentence Classification
SNLI,https://identifiers.org/ito:ITO_09574,Enhanced LSTM for Natural Language Inference
SNLI,https://identifiers.org/ito:ITO_09571,Bilateral Multi-Perspective Matching for Natural Language Sentences
SNLI,https://identifiers.org/ito:ITO_09568,Natural Language Inference over Interaction Space
SNLI,https://identifiers.org/ito:ITO_09564,Neural Natural Language Inference Models Enhanced with External Knowledge
SNLI,https://identifiers.org/ito:ITO_09537,"Compare, Compress and Propagate: Enhancing Neural Architectures with Alignment Factorization for Natural Language Inference"
SNLI,https://identifiers.org/ito:ITO_09552,Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information
SNLI,https://identifiers.org/ito:ITO_09550,Explicit Contextual Semantics for Text Comprehension
SNLI,https://identifiers.org/ito:ITO_09517,Multi-Task Deep Neural Networks for Natural Language Understanding
SNLI,https://identifiers.org/ito:ITO_08315,Semantics-aware BERT for Language Understanding
SNLI,https://identifiers.org/ito:ITO_51406,Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data
SNLI,https://identifiers.org/ito:ITO_28562,Self-Explaining Structures Improve NLP Models
SNLI,https://identifiers.org/ito:ITO_26088,Entailment as Few-Shot Learner
SNLI,https://identifiers.org/ito:ITO_09657,A large annotated corpus for learning natural language inference
SNLI,https://identifiers.org/ito:ITO_09644,Reasoning about Entailment with Neural Attention
SNLI,https://identifiers.org/ito:ITO_09652,Order-Embeddings of Images and Language
SNLI,https://identifiers.org/ito:ITO_09641,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data
SNLI,https://identifiers.org/ito:ITO_09560,DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference
SNLI,https://identifiers.org/ito:ITO_09554,Improving Language Understanding by Generative Pre-Training
MedNLI,https://identifiers.org/ito:ITO_51459,Saama Research at MEDIQA 2019: Pre-trained BioBERT with Attention Visualisation for Medical Natural Language Inference
MedNLI,https://identifiers.org/ito:ITO_21501,CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters
MedNLI,https://identifiers.org/ito:ITO_21490,SciFive: a text-to-text transformer model for biomedical literature
MedNLI,https://identifiers.org/ito:ITO_21496,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets
XNLI Chinese Dev,https://identifiers.org/ito:ITO_09510,ERNIE: Enhanced Representation through Knowledge Integration
XNLI Chinese Dev,https://identifiers.org/ito:ITO_08532,ERNIE 2.0: A Continual Pre-training Framework for Language Understanding
ANLI test,https://identifiers.org/ito:ITO_07497,XLNet: Generalized Autoregressive Pretraining for Language Understanding
ANLI test,https://identifiers.org/ito:ITO_07499,RoBERTa: A Robustly Optimized BERT Pretraining Approach
ANLI test,https://identifiers.org/ito:ITO_28525,InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective
ANLI test,https://identifiers.org/ito:ITO_28528,Adversarial Training for Large Neural Language Models
Walker2d,https://identifiers.org/ito:ITO_61246,Particle Based Stochastic Policy Optimization
Physical Audiovisual CommonSense,https://identifiers.org/ito:ITO_51309,PACS: A Dataset for Physical Audiovisual CommonSense Reasoning
DeepFix,https://identifiers.org/ito:ITO_33297,Deep Reinforcement Learning for Programming Language Correction
DeepFix,https://identifiers.org/ito:ITO_55437,SampleFix: Learning to Generate Functionally Diverse Fixes
DeepFix,https://identifiers.org/ito:ITO_33282,"Graph-based, Self-Supervised Program Repair from Diagnostic Feedback"
DeepFix,https://identifiers.org/ito:ITO_33293,Break-It-Fix-It: Unsupervised Learning for Program Repair
GitHub-Python,https://identifiers.org/ito:ITO_33293,Break-It-Fix-It: Unsupervised Learning for Program Repair
HumanEval,https://identifiers.org/ito:ITO_55423,A Conversational Paradigm for Program Synthesis
SPoC TestW,https://identifiers.org/ito:ITO_33284,SPoC: Search-based Pseudocode to Code
SPoC TestW,https://identifiers.org/ito:ITO_33282,"Graph-based, Self-Supervised Program Repair from Diagnostic Feedback"
AlgoLisp,https://identifiers.org/ito:ITO_27936,CodeTrans: Towards Cracking the Language of Silicon's Code Through Self-Supervised Deep Learning and High Performance Computing
SPoC TestP,https://identifiers.org/ito:ITO_33284,SPoC: Search-based Pseudocode to Code
SPoC TestP,https://identifiers.org/ito:ITO_33282,"Graph-based, Self-Supervised Program Repair from Diagnostic Feedback"
Py150,https://identifiers.org/ito:ITO_12731,Code Prediction by Feeding Trees to Transformers
DeepTyper,https://identifiers.org/ito:ITO_55427,Contrastive Code Representation Learning
ManyTypes4TypeScript,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
ManyTypes4TypeScript,https://identifiers.org/ito:ITO_07499,RoBERTa: A Robustly Optimized BERT Pretraining Approach
ManyTypes4TypeScript,https://identifiers.org/ito:ITO_27938,CodeBERT: A Pre-Trained Model for Programming and Natural Languages
ManyTypes4TypeScript,https://identifiers.org/ito:ITO_55431,GraphCodeBERT: Pre-training Code Representations with Data Flow
SNLI-VE val,https://identifiers.org/ito:ITO_51474,Visual Entailment: A Novel Task for Fine-Grained Image Understanding
SNLI-VE val,https://identifiers.org/ito:ITO_27051,UNITER: UNiversal Image-TExt Representation Learning
SNLI-VE val,https://identifiers.org/ito:ITO_51472,Large-Scale Adversarial Training for Vision-and-Language Representation Learning
SNLI-VE val,https://identifiers.org/ito:ITO_51208,Seeing Out of tHe bOx: End-to-End Pre-training for Vision-Language Representation Learning
SNLI-VE val,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
SNLI-VE val,https://identifiers.org/ito:ITO_50108,"OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"
SNLI-VE test,https://identifiers.org/ito:ITO_51474,Visual Entailment: A Novel Task for Fine-Grained Image Understanding
SNLI-VE test,https://identifiers.org/ito:ITO_27051,UNITER: UNiversal Image-TExt Representation Learning
SNLI-VE test,https://identifiers.org/ito:ITO_51208,Seeing Out of tHe bOx: End-to-End Pre-training for Vision-Language Representation Learning
SNLI-VE test,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
SNLI-VE test,https://identifiers.org/ito:ITO_50108,"OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"
VCR (QA-R) dev,https://identifiers.org/ito:ITO_50151,PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models
VCR (Q-A) test,https://identifiers.org/ito:ITO_50151,PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models
VCR (Q-A) dev,https://identifiers.org/ito:ITO_50151,PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models
VCR (Q-AR) dev,https://identifiers.org/ito:ITO_50151,PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models
VCR (Q-AR) test,https://identifiers.org/ito:ITO_50151,PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models
VCR (QA-R) test,https://identifiers.org/ito:ITO_50151,PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models
GD-VCR,https://identifiers.org/ito:ITO_51224,Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning
NLVR,https://identifiers.org/ito:ITO_08694,VisualBERT: A Simple and Performant Baseline for Vision and Language
PHYRE-1B-Within,https://identifiers.org/ito:ITO_28133,PHYRE: A New Benchmark for Physical Reasoning
PHYRE-1B-Within,https://identifiers.org/ito:ITO_28129,Forward Prediction for Physical Reasoning
PHYRE-1B-Within,https://identifiers.org/ito:ITO_28127,Learning Long-term Visual Dynamics with Region Proposal Interaction Networks
NLVR2 Test,https://identifiers.org/ito:ITO_08700,LXMERT: Learning Cross-Modality Encoder Representations from Transformers
NLVR2 Test,https://identifiers.org/ito:ITO_27051,UNITER: UNiversal Image-TExt Representation Learning
NLVR2 Test,https://identifiers.org/ito:ITO_50114,Align before Fuse: Vision and Language Representation Learning with Momentum Distillation
NLVR2 Test,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
NLVR2 Test,https://identifiers.org/ito:ITO_50106,VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts
NLVR2 Test,https://identifiers.org/ito:ITO_47854,CoCa: Contrastive Captioners are Image-Text Foundation Models
NLVR2 Dev,https://identifiers.org/ito:ITO_08700,LXMERT: Learning Cross-Modality Encoder Representations from Transformers
NLVR2 Dev,https://identifiers.org/ito:ITO_27076,ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision
NLVR2 Dev,https://identifiers.org/ito:ITO_51208,Seeing Out of tHe bOx: End-to-End Pre-training for Vision-Language Representation Learning
NLVR2 Dev,https://identifiers.org/ito:ITO_50114,Align before Fuse: Vision and Language Representation Learning with Momentum Distillation
NLVR2 Dev,https://identifiers.org/ito:ITO_50110,SimVLM: Simple Visual Language Model Pretraining with Weak Supervision
NLVR2 Dev,https://identifiers.org/ito:ITO_50106,VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts
NLVR2 Dev,https://identifiers.org/ito:ITO_47854,CoCa: Contrastive Captioners are Image-Text Foundation Models
VSR,https://identifiers.org/ito:ITO_51212,Visual Spatial Reasoning
PHYRE-1B-Cross,https://identifiers.org/ito:ITO_28133,PHYRE: A New Benchmark for Physical Reasoning
PHYRE-1B-Cross,https://identifiers.org/ito:ITO_28129,Forward Prediction for Physical Reasoning
PHYRE-1B-Cross,https://identifiers.org/ito:ITO_28127,Learning Long-term Visual Dynamics with Region Proposal Interaction Networks
BigPatent,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
BigPatent,https://identifiers.org/ito:ITO_50956,LongT5: Efficient Text-To-Text Transformer for Long Sequences
BillSum,https://identifiers.org/ito:ITO_56359,BillSum: A Corpus for Automatic Summarization of US Legislation
DUC 2004 Task 1,https://identifiers.org/ito:ITO_13324,Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond
DUC 2004 Task 1,https://identifiers.org/ito:ITO_34800,Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization
DUC 2004 Task 1,https://identifiers.org/ito:ITO_13348,Positional Encoding to Control Output Sequence Length
DUC 2004 Task 1,https://identifiers.org/ito:ITO_56362,Abstractive Sentence Summarization with Attentive Recurrent Neural Networks
DUC 2004 Task 1,https://identifiers.org/ito:ITO_23026,Rethinking Perturbations in Encoder-Decoders for Fast Training
DUC 2004 Task 1,https://identifiers.org/ito:ITO_34802,Deep Recurrent Generative Decoder for Abstractive Text Summarization
DUC 2004 Task 1,https://identifiers.org/ito:ITO_34804,A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization
DUC 2004 Task 1,https://identifiers.org/ito:ITO_56364,Sample Efficient Text Summarization Using a Single Pre-Trained Transformer
Webis-Snippet-20 Corpus,https://identifiers.org/ito:ITO_34793,Abstractive Snippet Generation
WikiHow,https://identifiers.org/ito:ITO_34730,WikiHow: A Large Scale Text Summarization Dataset
WikiHow,https://identifiers.org/ito:ITO_34718,Extractive Summarization as Text Matching
WikiHow,https://identifiers.org/ito:ITO_34725,Abstractive Summarization of Spoken andWritten Instructions with BERT
CNN / Daily Mail (Anonymized),https://identifiers.org/ito:ITO_13324,Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond
CNN / Daily Mail (Anonymized),https://identifiers.org/ito:ITO_34750,SummaRuNNer: A Recurrent Neural Network based Sequence Model for Extractive Summarization of Documents
CNN / Daily Mail (Anonymized),https://identifiers.org/ito:ITO_13379,A Deep Reinforced Model for Abstractive Summarization
CNN / Daily Mail (Anonymized),https://identifiers.org/ito:ITO_34742,Learning to Extract Coherent Summary via Deep Reinforcement Learning
CNN / Daily Mail (Anonymized),https://identifiers.org/ito:ITO_34745,Generative Adversarial Network for Abstractive Text Summarization
CNN / Daily Mail (Anonymized),https://identifiers.org/ito:ITO_34738,A Hierarchical Structured Self-Attentive Model for Extractive Document Summarization (HSSAS)
X-Sum,https://identifiers.org/ito:ITO_56379,SummaReranker: A Multi-Task Mixture-of-Experts Re-ranking Framework for Abstractive Summarization
X-Sum,https://identifiers.org/ito:ITO_34829,"Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"
X-Sum,https://identifiers.org/ito:ITO_13356,Text Summarization with Pretrained Encoders
X-Sum,https://identifiers.org/ito:ITO_08259,"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"
X-Sum,https://identifiers.org/ito:ITO_34763,PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization
X-Sum,https://identifiers.org/ito:ITO_56377,BRIO: Bringing Order to Abstractive Summarization
X-Sum,https://identifiers.org/ito:ITO_50612,Control Prefixes for Parameter-Efficient Text Generation
OrangeSum,https://identifiers.org/ito:ITO_34821,BARThez: a Skilled Pretrained French Sequence-to-Sequence Model
arXiv,https://identifiers.org/ito:ITO_34761,A Divide-and-Conquer Approach to the Summarization of Long Documents
arXiv,https://identifiers.org/ito:ITO_49051,Hierarchical Learning for Generation with Long Source Sequences
arXiv,https://identifiers.org/ito:ITO_50956,LongT5: Efficient Text-To-Text Transformer for Long Sequences
arXiv,https://identifiers.org/ito:ITO_56385,Long Document Summarization with Top-down and Bottom-up Inference
arXiv,https://identifiers.org/ito:ITO_13360,Get To The Point: Summarization with Pointer-Generator Networks
arXiv,https://identifiers.org/ito:ITO_34775,A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents
arXiv,https://identifiers.org/ito:ITO_34768,Extractive Summarization of Long Documents by Combining Global and Local Context
arXiv,https://identifiers.org/ito:ITO_34763,PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization
Pubmed,https://identifiers.org/ito:ITO_34761,A Divide-and-Conquer Approach to the Summarization of Long Documents
Pubmed,https://identifiers.org/ito:ITO_50956,LongT5: Efficient Text-To-Text Transformer for Long Sequences
Pubmed,https://identifiers.org/ito:ITO_13360,Get To The Point: Summarization with Pointer-Generator Networks
Pubmed,https://identifiers.org/ito:ITO_34775,A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents
Pubmed,https://identifiers.org/ito:ITO_34771,On Extractive and Abstractive Neural Document Summarization with Transformer Language Models
Pubmed,https://identifiers.org/ito:ITO_34763,PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization
Pubmed,https://identifiers.org/ito:ITO_56392,Sparsifying Transformer Models with Trainable Representation Pooling
Pubmed,https://identifiers.org/ito:ITO_49051,Hierarchical Learning for Generation with Long Source Sequences
Pubmed,https://identifiers.org/ito:ITO_56385,Long Document Summarization with Top-down and Bottom-up Inference
Pubmed,https://identifiers.org/ito:ITO_34768,Extractive Summarization of Long Documents by Combining Global and Local Context
Pubmed,https://identifiers.org/ito:ITO_26182,Big Bird: Transformers for Longer Sequences
Reddit TIFU,https://identifiers.org/ito:ITO_34718,Extractive Summarization as Text Matching
Reddit TIFU,https://identifiers.org/ito:ITO_28641,Better Fine-Tuning by Reducing Representational Collapse
Reddit TIFU,https://identifiers.org/ito:ITO_26086,Muppet: Massive Multi-task Representations with Pre-Finetuning
Gazeta,https://identifiers.org/ito:ITO_56397,Dataset for Automatic Summarization of Russian News
SAMSum Corpus,https://identifiers.org/ito:ITO_49051,Hierarchical Learning for Generation with Long Source Sequences
SAMSum Corpus,https://identifiers.org/ito:ITO_56401,Topic-Aware Contrastive Learning for Abstractive Dialogue Summarization
AMI,https://identifiers.org/ito:ITO_49051,Hierarchical Learning for Generation with Long Source Sequences
How2,https://identifiers.org/ito:ITO_34723,Multimodal Abstractive Summarization for How2 Videos
How2,https://identifiers.org/ito:ITO_34725,Abstractive Summarization of Spoken andWritten Instructions with BERT
arXiv Summarization Dataset,https://identifiers.org/ito:ITO_50953,PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization
arXiv Summarization Dataset,https://identifiers.org/ito:ITO_56392,Sparsifying Transformer Models with Trainable Representation Pooling
BBC XSum,https://identifiers.org/ito:ITO_34718,Extractive Summarization as Text Matching
GigaWord-10k,https://identifiers.org/ito:ITO_26946,ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation
GigaWord,https://identifiers.org/ito:ITO_13324,Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond
GigaWord,https://identifiers.org/ito:ITO_34800,Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization
GigaWord,https://identifiers.org/ito:ITO_05230,Attention Is All You Need
GigaWord,https://identifiers.org/ito:ITO_34852,Entity Commonsense Representation for Neural Abstractive Summarization
GigaWord,https://identifiers.org/ito:ITO_13313,Unified Language Model Pre-training for Natural Language Understanding and Generation
GigaWord,https://identifiers.org/ito:ITO_34844,BiSET: Bi-directional Selective Encoding with Template for Abstractive Summarization
GigaWord,https://identifiers.org/ito:ITO_23026,Rethinking Perturbations in Encoder-Decoders for Fast Training
GigaWord,https://identifiers.org/ito:ITO_50108,"OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"
GigaWord,https://identifiers.org/ito:ITO_13352,A Neural Attention Model for Abstractive Sentence Summarization
GigaWord,https://identifiers.org/ito:ITO_34763,PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization
GigaWord,https://identifiers.org/ito:ITO_34842,ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training
GigaWord,https://identifiers.org/ito:ITO_28641,Better Fine-Tuning by Reducing Representational Collapse
GigaWord,https://identifiers.org/ito:ITO_56410,"Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization"
GigaWord,https://identifiers.org/ito:ITO_34846,Controlling the Amount of Verbatim Copying in Abstractive Summarization
CL-SciSumm,https://identifiers.org/ito:ITO_34815,ScisummNet: A Large Annotated Corpus and Content-Impact Models for Scientific Paper Summarization with Citation Networks
Klexikon,https://identifiers.org/ito:ITO_56415,Klexikon: A German Dataset for Joint Summarization and Simplification
Yelp,https://identifiers.org/ito:ITO_56522,Convex Aggregation for Opinion Summarization
Amazon,https://identifiers.org/ito:ITO_56522,Convex Aggregation for Opinion Summarization
Helsinki Prosody Corpus,https://identifiers.org/ito:ITO_04651,Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations
LJSpeech,https://identifiers.org/ito:ITO_21350,Neural Speech Synthesis with Transformer Network
LJSpeech,https://identifiers.org/ito:ITO_45434,Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search
LJSpeech,https://identifiers.org/ito:ITO_45432,Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech
LJSpeech,https://identifiers.org/ito:ITO_45429,NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality
LJSpeech,https://identifiers.org/ito:ITO_21354,Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis
20000 utterances,https://identifiers.org/ito:ITO_45443,MIA-Prognosis: A Deep Learning Framework to Predict Therapy Response
CMUDict 0.7b,https://identifiers.org/ito:ITO_04640,Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion
RST-DT,https://identifiers.org/ito:ITO_61509,A Novel Discourse Parser Based on Support Vector Machine Classification
RST-DT,https://identifiers.org/ito:ITO_61506,A Linear-Time Bottom-Up Discourse Parser with Constraints and Post-Editing
RST-DT,https://identifiers.org/ito:ITO_61505,A Two-Stage Parsing Method for Text-Level Discourse Analysis
RST-DT,https://identifiers.org/ito:ITO_41083,Top-Down RST Parsing Utilizing Granularity Levels in Documents
RST-DT,https://identifiers.org/ito:ITO_61503,Improving Neural RST Parsing Model with Silver Agreement Subtrees
RST-DT,https://identifiers.org/ito:ITO_61507,Transition-based Neural RST Parsing with Implicit Syntax Features
RACE,https://identifiers.org/ito:ITO_07499,RoBERTa: A Robustly Optimized BERT Pretraining Approach
RACE,https://identifiers.org/ito:ITO_09881,Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism
RACE,https://identifiers.org/ito:ITO_25497,Improving Machine Reading Comprehension with Single-choice Decision and Transfer Learning
RACE,https://identifiers.org/ito:ITO_25500,DUMA: Reading Comprehension with Transposition Thinking
ReClor,https://identifiers.org/ito:ITO_25527,DAGN: Discourse-Aware Graph Network for Logical Reasoning
ReClor,https://identifiers.org/ito:ITO_49057,Logic-Driven Context Extension and Data Augmentation for Logical Reasoning of Text
ReClor,https://identifiers.org/ito:ITO_49054,MERIt: Meta-Path Guided Contrastive Learning for Logical Reasoning
AdversarialQA,https://identifiers.org/ito:ITO_25492,Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension
CrowdSource QA,https://identifiers.org/ito:ITO_25511,Predicting Subjective Features of Questions of QA Websites using BERT
MuSeRC,https://identifiers.org/ito:ITO_25462,mT5: A massively multilingual pre-trained text-to-text transformer
CLUTRR (k=3),https://identifiers.org/ito:ITO_28035,Learning Reasoning Strategies in End-to-End Differentiable Proving
TabFact,https://identifiers.org/ito:ITO_31953,TabFact: A Large-scale Dataset for Table-based Fact Verification
TabFact,https://identifiers.org/ito:ITO_31951,Understanding tables with intermediate pre-training
TabFact,https://identifiers.org/ito:ITO_53386,TAPEX: Table Pre-training via Learning a Neural SQL Executor
WNLI,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
WNLI,https://identifiers.org/ito:ITO_28250,A Surprisingly Robust Trick for Winograd Schema Challenge
WNLI,https://identifiers.org/ito:ITO_28248,A Hybrid Neural Network Model for Commonsense Reasoning
PDP60,https://identifiers.org/ito:ITO_07928,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
PDP60,https://identifiers.org/ito:ITO_28248,A Hybrid Neural Network Model for Commonsense Reasoning
LexGLUE,https://identifiers.org/ito:ITO_61598,LexGLUE: A Benchmark Dataset for Legal Language Understanding in English
CrowS-Pairs,https://identifiers.org/ito:ITO_51883,OPT: Open Pre-trained Transformer Language Models
MuLD (VLSP),https://identifiers.org/ito:ITO_49552,MuLD: The Multitask Long Document Benchmark
Pubmed,https://identifiers.org/ito:ITO_50064,Discourse-Aware Unsupervised Summarization of Long Scientific Documents
arXiv Summarization Dataset,https://identifiers.org/ito:ITO_34775,A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents
arXiv Summarization Dataset,https://identifiers.org/ito:ITO_50064,Discourse-Aware Unsupervised Summarization of Long Scientific Documents
FacetSum,https://identifiers.org/ito:ITO_50078,Bringing Structure into Summaries: a Faceted Summarization Dataset for Long Scientific Documents
COCO,https://identifiers.org/ito:ITO_05853,StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks
COCO,https://identifiers.org/ito:ITO_05967,AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks
COCO,https://identifiers.org/ito:ITO_05961,Generating Multiple Objects at Spatially Distinct Locations
COCO,https://identifiers.org/ito:ITO_05965,DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis
COCO,https://identifiers.org/ito:ITO_22640,Semantic Object Accuracy for Generative Text-to-Image Synthesis
COCO,https://identifiers.org/ito:ITO_43784,Lightweight Generative Adversarial Networks for Text-Guided Image Manipulation
COCO,https://identifiers.org/ito:ITO_43778,Cross-Modal Contrastive Learning for Text-to-Image Generation
COCO,https://identifiers.org/ito:ITO_43776,LAFITE: Towards Language-Free Training for Text-to-Image Generation
COCO,https://identifiers.org/ito:ITO_43774,Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding
COCO,https://identifiers.org/ito:ITO_43772,Scaling Autoregressive Models for Content-Rich Text-to-Image Generation
COCO,https://identifiers.org/ito:ITO_22642,VICTR: Visual Information Captured Text Representation for Text-to-Image Multimodal Tasks
COCO,https://identifiers.org/ito:ITO_43792,Improving Text-to-Image Synthesis Using Contrastive Learning
COCO,https://identifiers.org/ito:ITO_43794,FuseDream: Training-Free Text-to-Image Generation with Improved CLIP+GAN Space Optimization
COCO,https://identifiers.org/ito:ITO_43800,CogView: Mastering Text-to-Image Generation via Transformers
GeNeVA (i-CLEVR),https://identifiers.org/ito:ITO_05954,"Tell, Draw, and Repeat: Generating and Modifying Images Based on Continual Linguistic Instruction"
COCO 256 x 256,https://identifiers.org/ito:ITO_43809,NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion
CUB,https://identifiers.org/ito:ITO_05987,Learning What and Where to Draw
CUB,https://identifiers.org/ito:ITO_05853,StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks
CUB,https://identifiers.org/ito:ITO_43784,Lightweight Generative Adversarial Networks for Text-Guided Image Manipulation
CUB,https://identifiers.org/ito:ITO_05979,StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks
CUB,https://identifiers.org/ito:ITO_05967,AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks
CUB,https://identifiers.org/ito:ITO_05971,MirrorGAN: Learning Text-to-image Generation by Redescription
CUB,https://identifiers.org/ito:ITO_05965,DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis
CUB,https://identifiers.org/ito:ITO_43812,ManiGAN: Text-Guided Image Manipulation
Multi-Modal-CelebA-HQ,https://identifiers.org/ito:ITO_05967,AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks
Multi-Modal-CelebA-HQ,https://identifiers.org/ito:ITO_05973,Controllable Text-to-Image Generation
Multi-Modal-CelebA-HQ,https://identifiers.org/ito:ITO_22635,TediGAN: Text-Guided Diverse Face Image Generation and Manipulation
Multi-Modal-CelebA-HQ,https://identifiers.org/ito:ITO_22633,Towards Open-World Text-Guided Face Image Generation and Manipulation
Multi-Modal-CelebA-HQ,https://identifiers.org/ito:ITO_43776,LAFITE: Towards Language-Free Training for Text-to-Image Generation
Multi-Modal-CelebA-HQ,https://identifiers.org/ito:ITO_05965,DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis
Multi-Modal-CelebA-HQ,https://identifiers.org/ito:ITO_43813,DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis
"1,002 Hours – Changsha Dialect Speech Data by Mobile Phone",https://identifiers.org/ito:ITO_20144,"(0,4) brane box models"
Oxford 102 Flowers,https://identifiers.org/ito:ITO_05853,StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks
Oxford 102 Flowers,https://identifiers.org/ito:ITO_43786,Vector Quantized Diffusion Model for Text-to-Image Synthesis
Oxford 102 Flowers,https://identifiers.org/ito:ITO_05979,StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks
Oxford 102 Flowers,https://identifiers.org/ito:ITO_43788,Recurrent Affine Transformation for Text-to-image Synthesis
GeNeVA (CoDraw),https://identifiers.org/ito:ITO_05954,"Tell, Draw, and Repeat: Generating and Modifying Images Based on Continual Linguistic Instruction"
