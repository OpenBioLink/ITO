<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script src="https://cdn.plot.ly/plotly-2.8.3.min.js"></script>                <div id="54249619-5470-44d0-a639-ca6ceecc1522" class="plotly-graph-div" style="height:1782.0000000000002px; width:1500px;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("54249619-5470-44d0-a639-ca6ceecc1522")) {                    Plotly.newPlot(                        "54249619-5470-44d0-a639-ca6ceecc1522",                        [{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Computer code processing: Code Generation","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Computer code processing: Code Generation","orientation":"v","showlegend":true,"x":["2017-08","2018-03","2018-04","2018-10","2019-10"],"xaxis":"x","y":["Computer code processing: Code Generation","Computer code processing: Code Generation","Computer code processing: Code Generation","Computer code processing: Code Generation","Computer code processing: Code Generation"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Dialog process: Visual Dialog","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Dialog process: Visual Dialog","orientation":"v","showlegend":true,"x":["2018-09","2017-11","2017-09","2019-02","2019-04"],"xaxis":"x","y":["Dialog process: Visual Dialog","Dialog process: Visual Dialog","Dialog process: Visual Dialog","Dialog process: Visual Dialog","Dialog process: Visual Dialog"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Dialog process: Dialog State Tracking","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Dialog process: Dialog State Tracking","orientation":"v","showlegend":true,"x":["2018-10","2018-05"],"xaxis":"x","y":["Dialog process: Dialog State Tracking","Dialog process: Dialog State Tracking"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Dialog process: Dialog Act Classification","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Dialog process: Dialog Act Classification","orientation":"v","showlegend":true,"x":["2017-11","2017-09"],"xaxis":"x","y":["Dialog process: Dialog Act Classification","Dialog process: Dialog Act Classification"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Inference and reasoning: Common Sense Reasoning","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Inference and reasoning: Common Sense Reasoning","orientation":"v","showlegend":true,"x":["2018-10","2018-05","2019-02","2019-06","2019-07","2019-09"],"xaxis":"x","y":["Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Inference and reasoning: Natural Language Inference","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Inference and reasoning: Natural Language Inference","orientation":"v","showlegend":true,"x":["2019-09","2019-07","2019-06","2019-01","2018-10","2018-06","2018-05","2018-04","2017-12","2018-09","2017-09","2017-11","2014-08","2016-09","2017-02","2015-08"],"xaxis":"x","y":["Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Information extraction: Named Entity Recognition","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Information extraction: Named Entity Recognition","orientation":"v","showlegend":true,"x":["2019-06","2019-11","2019-03","2019-01","2019-08","2018-10","2018-08"],"xaxis":"x","y":["Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Information extraction: Joint Entity and Relation Extraction","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Information extraction: Joint Entity and Relation Extraction","orientation":"v","showlegend":true,"x":["2019-09","2019-04"],"xaxis":"x","y":["Information extraction: Joint Entity and Relation Extraction","Information extraction: Joint Entity and Relation Extraction"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Information extraction: Relation Extraction","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Information extraction: Relation Extraction","orientation":"v","showlegend":true,"x":["2019-09","2019-11","2019-06","2019-07","2019-05","2016-01","2020-03","2020-04","2017-07","2018-07","2018-08","2018-09","2018-10","2018-12","2019-02","2019-03","2019-04","2017-09"],"xaxis":"x","y":["Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Information extraction: Chinese Named Entity Recognition","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Information extraction: Chinese Named Entity Recognition","orientation":"v","showlegend":true,"x":["2019-11","2019-07","2019-04"],"xaxis":"x","y":["Information extraction: Chinese Named Entity Recognition","Information extraction: Chinese Named Entity Recognition","Information extraction: Chinese Named Entity Recognition"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Information retrieval: Conversational Response Selection","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Information retrieval: Conversational Response Selection","orientation":"v","showlegend":true,"x":["2019-01","2019-04","2018-03","2019-11"],"xaxis":"x","y":["Information retrieval: Conversational Response Selection","Information retrieval: Conversational Response Selection","Information retrieval: Conversational Response Selection","Information retrieval: Conversational Response Selection"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Machine translation: Unsupervised Machine Translation","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Machine translation: Unsupervised Machine Translation","orientation":"v","showlegend":true,"x":["2018-10","2019-01","2019-05","2019-02"],"xaxis":"x","y":["Machine translation: Unsupervised Machine Translation","Machine translation: Unsupervised Machine Translation","Machine translation: Unsupervised Machine Translation","Machine translation: Unsupervised Machine Translation"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Natural language generation: Text Summarization","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Natural language generation: Text Summarization","orientation":"v","showlegend":true,"x":["2019-05","2019-10","2019-04","2018-08","2018-07","2017-06","2016-06","2016-02","2015-09"],"xaxis":"x","y":["Natural language generation: Text Summarization","Natural language generation: Text Summarization","Natural language generation: Text Summarization","Natural language generation: Text Summarization","Natural language generation: Text Summarization","Natural language generation: Text Summarization","Natural language generation: Text Summarization","Natural language generation: Text Summarization","Natural language generation: Text Summarization"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Natural language generation: Machine Translation","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Natural language generation: Machine Translation","orientation":"v","showlegend":true,"x":["2019-10","2019-09","2019-06","2019-05","2019-01","2018-10","2018-09","2018-08","2018-06","2017-06","2018-02","2018-03","2014-09","2017-11","2016-03","2016-06","2017-05","2016-07","2017-01","2016-11","2016-10","2016-09","2016-08","2014-10"],"xaxis":"x","y":["Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Natural language generation: Question Generation","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Natural language generation: Question Generation","orientation":"v","showlegend":true,"x":["2019-05","2018-06"],"xaxis":"x","y":["Natural language generation: Question Generation","Natural language generation: Question Generation"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Natural language generation: Text Generation","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Natural language generation: Text Generation","orientation":"v","showlegend":true,"x":["2017-05","2017-09","2018-02","2019-01"],"xaxis":"x","y":["Natural language generation: Text Generation","Natural language generation: Text Generation","Natural language generation: Text Generation","Natural language generation: Text Generation"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Natural language generation: Document Summarization","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Natural language generation: Document Summarization","orientation":"v","showlegend":true,"x":["2019-08","2019-05","2019-03","2018-08","2017-05"],"xaxis":"x","y":["Natural language generation: Document Summarization","Natural language generation: Document Summarization","Natural language generation: Document Summarization","Natural language generation: Document Summarization","Natural language generation: Document Summarization"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Natural language generation: Language Modelling","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Natural language generation: Language Modelling","orientation":"v","showlegend":true,"x":["2016-09","2016-12","2018-03","2018-09","2014-12"],"xaxis":"x","y":["Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Other NLP task: Text-to-Image Generation","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Other NLP task: Text-to-Image Generation","orientation":"v","showlegend":true,"x":["2016-12","2019-09","2019-03","2019-01","2017-11","2017-10","2019-04"],"xaxis":"x","y":["Other NLP task: Text-to-Image Generation","Other NLP task: Text-to-Image Generation","Other NLP task: Text-to-Image Generation","Other NLP task: Text-to-Image Generation","Other NLP task: Text-to-Image Generation","Other NLP task: Text-to-Image Generation","Other NLP task: Text-to-Image Generation"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Pragmatics analysis: Sentiment Analysis","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Pragmatics analysis: Sentiment Analysis","orientation":"v","showlegend":true,"x":["2018-01","2017-12","2017-08","2017-07","2018-02","2018-04","2017-04","2018-05","2017-02","2016-02","2015-11","2015-06","2015-02","2014-08","2014-06","2013-10","2018-10","2016-07","2019-01","2019-06","2019-05","2019-09","2019-07"],"xaxis":"x","y":["Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Pragmatics analysis: Coreference Resolution","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Pragmatics analysis: Coreference Resolution","orientation":"v","showlegend":true,"x":["2018-02","2019-08","2019-07","2018-04","2017-07","2016-09","2016-06"],"xaxis":"x","y":["Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Coreference Resolution"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Pragmatics analysis: Intent Detection","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Pragmatics analysis: Intent Detection","orientation":"v","showlegend":true,"x":["2019-12","2019-06"],"xaxis":"x","y":["Pragmatics analysis: Intent Detection","Pragmatics analysis: Intent Detection"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Pragmatics analysis: Fake News Detection","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Pragmatics analysis: Fake News Detection","orientation":"v","showlegend":true,"x":["2018-11","2017-12"],"xaxis":"x","y":["Pragmatics analysis: Fake News Detection","Pragmatics analysis: Fake News Detection"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Pragmatics analysis: Emotion Recognition in Conversation","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Pragmatics analysis: Emotion Recognition in Conversation","orientation":"v","showlegend":true,"x":["2019-09","2019-04","2018-11","2018-10","2019-08","2018-06"],"xaxis":"x","y":["Pragmatics analysis: Emotion Recognition in Conversation","Pragmatics analysis: Emotion Recognition in Conversation","Pragmatics analysis: Emotion Recognition in Conversation","Pragmatics analysis: Emotion Recognition in Conversation","Pragmatics analysis: Emotion Recognition in Conversation","Pragmatics analysis: Emotion Recognition in Conversation"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Pragmatics analysis: Paraphrase Identification","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Pragmatics analysis: Paraphrase Identification","orientation":"v","showlegend":true,"x":["2013-10","2017-04","2018-07","2019-01","2019-06","2017-09"],"xaxis":"x","y":["Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Paraphrase Identification"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Question answering: Visual Question Answering","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Question answering: Visual Question Answering","orientation":"v","showlegend":true,"x":["2020-02","2019-09","2019-08","2019-07","2019-06","2019-05","2019-04","2019-02","2017-07","2018-03","2017-08","2016-12","2016-11","2016-06","2016-03","2017-05","2017-04","2018-05","2016-05"],"xaxis":"x","y":["Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Question answering: Question Answering","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Question answering: Question Answering","orientation":"v","showlegend":true,"x":["2016-08","2019-09","2018-08","2018-07","2018-06","2018-05","2018-04","2018-01","2017-12","2017-10","2017-08","2017-07","2017-06","2017-05","2017-04","2017-03","2016-11","2016-10","2016-09","2016-02","2016-03","2018-09","2018-10","2018-11","2019-01","2019-02","2019-05","2019-06","2015-11","2015-06","2014-12","2014-06","2019-08","2019-07","2016-06"],"xaxis":"x","y":["Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Semantic analysis: Word Sense Disambiguation","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Semantic analysis: Word Sense Disambiguation","orientation":"v","showlegend":true,"x":["2018-11","2018-05","2018-02","2016-06","2016-03","2017-09","2019-05","2019-09"],"xaxis":"x","y":["Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Semantic analysis: Entity Disambiguation","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Semantic analysis: Entity Disambiguation","orientation":"v","showlegend":true,"x":["2019-09","2017-05"],"xaxis":"x","y":["Semantic analysis: Entity Disambiguation","Semantic analysis: Entity Disambiguation"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Semantic analysis: Semantic Textual Similarity","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Semantic analysis: Semantic Textual Similarity","orientation":"v","showlegend":true,"x":["2019-05","2018-03","2019-06","2019-07","2019-09"],"xaxis":"x","y":["Semantic analysis: Semantic Textual Similarity","Semantic analysis: Semantic Textual Similarity","Semantic analysis: Semantic Textual Similarity","Semantic analysis: Semantic Textual Similarity","Semantic analysis: Semantic Textual Similarity"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Semantic analysis: Semantic Parsing","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Semantic analysis: Semantic Parsing","orientation":"v","showlegend":true,"x":["2017-04","2018-10"],"xaxis":"x","y":["Semantic analysis: Semantic Parsing","Semantic analysis: Semantic Parsing"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Semantic analysis: Semantic Role Labeling","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Semantic analysis: Semantic Role Labeling","orientation":"v","showlegend":true,"x":["2017-12","2018-02","2018-05","2018-10"],"xaxis":"x","y":["Semantic analysis: Semantic Role Labeling","Semantic analysis: Semantic Role Labeling","Semantic analysis: Semantic Role Labeling","Semantic analysis: Semantic Role Labeling"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Sentence embedding: Sentence Compression","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Sentence embedding: Sentence Compression","orientation":"v","showlegend":true,"x":["2018-07","2017-07"],"xaxis":"x","y":["Sentence embedding: Sentence Compression","Sentence embedding: Sentence Compression"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Syntactic analysis: Dependency Parsing","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Syntactic analysis: Dependency Parsing","orientation":"v","showlegend":true,"x":["2016-03","2018-07","2016-11"],"xaxis":"x","y":["Syntactic analysis: Dependency Parsing","Syntactic analysis: Dependency Parsing","Syntactic analysis: Dependency Parsing"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Syntactic analysis: Constituency Parsing","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Syntactic analysis: Constituency Parsing","orientation":"v","showlegend":true,"x":["2017-07","2016-11","2019-03","2018-05"],"xaxis":"x","y":["Syntactic analysis: Constituency Parsing","Syntactic analysis: Constituency Parsing","Syntactic analysis: Constituency Parsing","Syntactic analysis: Constituency Parsing"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Syntactic analysis: Chunking","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Syntactic analysis: Chunking","orientation":"v","showlegend":true,"x":["2016-11","2018-08"],"xaxis":"x","y":["Syntactic analysis: Chunking","Syntactic analysis: Chunking"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Syntactic analysis: Constituency Grammar Induction","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Syntactic analysis: Constituency Grammar Induction","orientation":"v","showlegend":true,"x":["2019-06","2019-04","2018-10","2018-08"],"xaxis":"x","y":["Syntactic analysis: Constituency Grammar Induction","Syntactic analysis: Constituency Grammar Induction","Syntactic analysis: Constituency Grammar Induction","Syntactic analysis: Constituency Grammar Induction"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Syntactic analysis: Grammatical Error Detection","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Syntactic analysis: Grammatical Error Detection","orientation":"v","showlegend":true,"x":["2016-07","2016-11","2018-11","2017-07","2017-04"],"xaxis":"x","y":["Syntactic analysis: Grammatical Error Detection","Syntactic analysis: Grammatical Error Detection","Syntactic analysis: Grammatical Error Detection","Syntactic analysis: Grammatical Error Detection","Syntactic analysis: Grammatical Error Detection"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Syntactic analysis: Linguistic Acceptability Assessment","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Syntactic analysis: Linguistic Acceptability Assessment","orientation":"v","showlegend":true,"x":["2019-09","2019-06"],"xaxis":"x","y":["Syntactic analysis: Linguistic Acceptability Assessment","Syntactic analysis: Linguistic Acceptability Assessment"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Text classification: Citation Intent Classification","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Text classification: Citation Intent Classification","orientation":"v","showlegend":true,"x":["2018-02","2016-06","2018-01"],"xaxis":"x","y":["Text classification: Citation Intent Classification","Text classification: Citation Intent Classification","Text classification: Citation Intent Classification"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Text classification: Text Classification","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Text classification: Text Classification","orientation":"v","showlegend":true,"x":["2019-06","2019-05","2019-02","2019-01","2018-09","2018-08","2017-02","2018-03","2020-02","2018-05","2015-11","2019-09","2018-07"],"xaxis":"x","y":["Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Text classification: Document Classification","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Text classification: Document Classification","orientation":"v","showlegend":true,"x":["2017-10","2016-09","2016-03","2020-02","2019-08","2019-04","2018-08","2016-11"],"xaxis":"x","y":["Text classification: Document Classification","Text classification: Document Classification","Text classification: Document Classification","Text classification: Document Classification","Text classification: Document Classification","Text classification: Document Classification","Text classification: Document Classification","Text classification: Document Classification"],"yaxis":"y","type":"scatter"},{"hovertemplate":"task=%{y}<br>date=%{x}<extra></extra>","legendgroup":"Text classification: Sentence Classification","line":{"color":"black","dash":"solid","width":0},"marker":{"symbol":"circle","line":{"color":"black","width":1}},"mode":"lines","name":"Text classification: Sentence Classification","orientation":"v","showlegend":true,"x":["2019-03","2018-10"],"xaxis":"x","y":["Text classification: Sentence Classification","Text classification: Sentence Classification"],"yaxis":"y","type":"scatter"},{"hovertemplate":["<BR>task: Computer code processing: Code Generation<BR>date: 2017-08<BR>Anchor.<BR>benchmarks:<BR>  WikiSQL - Code Generation benchmarking: Exact Match Accuracy<BR>  WikiSQL - Code Generation benchmarking: Execution Accuracy<BR>","<BR>task: Computer code processing: Code Generation<BR>date: 2018-10<BR>Anchor.<BR>benchmarks:<BR>  CoNaLa - Code Generation benchmarking: BLEU<BR>  CoNaLa-Ext - Code Generation benchmarking: BLEU<BR>","<BR>task: Computer code processing: Code Generation<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  Android Repos - Code Generation benchmarking: Perplexity<BR>","<BR>task: Computer code processing: Code Generation<BR>date: 2017-05<BR>Anchor.<BR>benchmarks:<BR>  100 sleep nights of 8 caregivers - Code Generation benchmarking: 14 gestures accuracy<BR>","<BR>task: Computer code processing: Code Generation<BR>date: 2016-03<BR>Anchor.<BR>benchmarks:<BR>  Django - Code Generation benchmarking: Accuracy<BR>","<BR>task: Dialog process: Dialog Act Classification<BR>date: 2016-03<BR>Anchor.<BR>benchmarks:<BR>  Switchboard corpus - Dialog Act Classification benchmarking: Accuracy<BR>","<BR>task: Dialog process: Dialog State Tracking<BR>date: 2016-06<BR>Anchor.<BR>benchmarks:<BR>  Second dialogue state tracking challenge - Dialog State Tracking benchmarking: Area<BR>  Second dialogue state tracking challenge - Dialog State Tracking benchmarking: Food<BR>  Second dialogue state tracking challenge - Dialog State Tracking benchmarking: Joint<BR>  Second dialogue state tracking challenge - Dialog State Tracking benchmarking: Price<BR>  Second dialogue state tracking challenge - Dialog State Tracking benchmarking: Request<BR>  Wizard-of-Oz - Dialog State Tracking benchmarking: Joint<BR>  Wizard-of-Oz - Dialog State Tracking benchmarking: Request<BR>","<BR>task: Dialog process: Visual Dialog<BR>date: 2016-05<BR>Anchor.<BR>benchmarks:<BR>  VisDial v0.9 val - Visual Dialog benchmarking: MRR<BR>  VisDial v0.9 val - Visual Dialog benchmarking: Mean Rank<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-10<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-1<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-5<BR>","<BR>task: Dialog process: Visual Dialog<BR>date: 2017-04<BR>Anchor.<BR>benchmarks:<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: MRR (x 100)<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: Mean<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: NDCG (x 100)<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-10<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-1<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-5<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2018-06<BR>Anchor.<BR>benchmarks:<BR>  V-SNLI - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2018-09<BR>Anchor.<BR>benchmarks:<BR>  XNLI French - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2019-05<BR>Anchor.<BR>benchmarks:<BR>  QNLI - Natural Language Inference benchmarking: Accuracy<BR>  RTE - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2019-04<BR>Anchor.<BR>benchmarks:<BR>  XNLI Chinese - Natural Language Inference benchmarking: Accuracy<BR>  XNLI Chinese Dev - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2018-03<BR>Anchor.<BR>benchmarks:<BR>  MultiNLI - Natural Language Inference benchmarking: Matched<BR>  MultiNLI - Natural Language Inference benchmarking: Mismatched<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2019-06<BR>Anchor.<BR>benchmarks:<BR>  ANLI test - Natural Language Inference benchmarking: A1<BR>  ANLI test - Natural Language Inference benchmarking: A2<BR>  ANLI test - Natural Language Inference benchmarking: A3<BR>  WNLI - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2018-12<BR>Anchor.<BR>benchmarks:<BR>  Quora Question Pairs - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2017-12<BR>Anchor.<BR>benchmarks:<BR>  SciTail - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2015-08<BR>Anchor.<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Train Accuracy<BR>  SNLI - Natural Language Inference benchmarking: Parameters<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2018-09<BR>Anchor.<BR>benchmarks:<BR>  Visual Dialog v0.9 - Common Sense Reasoning benchmarking: 1 in 10 R-at-5<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2014-04<BR>Anchor.<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2019-09<BR>Anchor.<BR>benchmarks:<BR>  Visual Dialog  v0.9 - Common Sense Reasoning benchmarking: 1 in 10 R-at-5<BR>  Visual Dialog  v0.9 - Common Sense Reasoning benchmarking: Recall-at-10<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2018-11<BR>Anchor.<BR>benchmarks:<BR>  CommonsenseQA - Common Sense Reasoning benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2018-10<BR>Anchor.<BR>benchmarks:<BR>  ReCoRD - Common Sense Reasoning benchmarking: EM<BR>  ReCoRD - Common Sense Reasoning benchmarking: F1<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  Event2Mind dev - Common Sense Reasoning benchmarking: Average Cross-Ent<BR>  Event2Mind test - Common Sense Reasoning benchmarking: Average Cross-Ent<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  SWAG - Common Sense Reasoning benchmarking: Dev<BR>  SWAG - Common Sense Reasoning benchmarking: Test<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2018-06<BR>Anchor.<BR>benchmarks:<BR>  Winograd Schema Challenge - Common Sense Reasoning benchmarking: Score<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  CoNLL 2000 - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Joint Entity and Relation Extraction<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  SciERC - Joint Entity and Relation Extraction benchmarking: Entity F1<BR>  SciERC - Joint Entity and Relation Extraction benchmarking: Relation F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2014-06<BR>Anchor.<BR>benchmarks:<BR>  ACE 2004 - Relation Extraction benchmarking: NER Micro F1<BR>  ACE 2004 - Relation Extraction benchmarking: RE Micro F1<BR>  ACE 2004 - Relation Extraction benchmarking: RE+ Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: NER Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: RE Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: RE+ Micro F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2014-10<BR>Anchor.<BR>benchmarks:<BR>  CoNLL04 - Relation Extraction benchmarking: NER Micro F1<BR>  CoNLL04 - Relation Extraction benchmarking: RE+ Micro F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2016-08<BR>Anchor.<BR>benchmarks:<BR>  NYT Corpus - Relation Extraction benchmarking: P-at-10%<BR>  NYT Corpus - Relation Extraction benchmarking: P-at-30%<BR>  SemEval-2010 Task 8 - Relation Extraction benchmarking: F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2017-09<BR>Anchor.<BR>benchmarks:<BR>  Long-tail emerging entities - Named Entity Recognition benchmarking: F1 (surface form)<BR>  Long-tail emerging entities - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2014-09<BR>Anchor.<BR>benchmarks:<BR>  SciERC - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2019-01<BR>Anchor.<BR>benchmarks:<BR>  JNLPBA - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2018-10<BR>Anchor.<BR>benchmarks:<BR>  ACE 2004 - Named Entity Recognition benchmarking: F1<BR>  NCBI-disease - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2017-06<BR>Anchor.<BR>benchmarks:<BR>  NYT - Relation Extraction benchmarking: F1<BR>  NYT-single - Relation Extraction benchmarking: F1<BR>  WebNLG - Relation Extraction benchmarking: F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2019-04<BR>Anchor.<BR>benchmarks:<BR>  WLPC - Named Entity Recognition benchmarking: F1<BR>  WetLab - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2019-08<BR>Anchor.<BR>benchmarks:<BR>  LINNAEUS - Named Entity Recognition benchmarking: F1<BR>  Species-800 - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2019-09<BR>Anchor.<BR>benchmarks:<BR>  Code-Switching English-Spanish NER - Named Entity Recognition benchmarking: F1<BR>  ontontoes chinese v5 - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2020-03<BR>Anchor.<BR>benchmarks:<BR>  SoSciSoCi - Named Entity Recognition benchmarking: F1<BR>  SoSciSoCi - Named Entity Recognition benchmarking: Precision<BR>  SoSciSoCi - Named Entity Recognition benchmarking: Recall<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2018-09<BR>Anchor.<BR>benchmarks:<BR>  BC5CDR - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2017-09<BR>Anchor.<BR>benchmarks:<BR>  Re-TACRED - Relation Extraction benchmarking: F1<BR>  TACRED - Relation Extraction benchmarking: F1<BR>  Wikipedia-Wikidata relations - Relation Extraction benchmarking: Error rate<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2018-06<BR>Anchor.<BR>benchmarks:<BR>  ACE 2005 - Named Entity Recognition benchmarking: F1<BR>  GENIA - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-01<BR>Anchor.<BR>benchmarks:<BR>  ChemProt - Relation Extraction benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2018-04<BR>Anchor.<BR>benchmarks:<BR>  ADE Corpus - Relation Extraction benchmarking: NER Macro F1<BR>  ADE Corpus - Relation Extraction benchmarking: RE+ Macro F1<BR>  CoNLL04 - Relation Extraction benchmarking: NER Macro F1<BR>  CoNLL04 - Relation Extraction benchmarking: RE+ Macro F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-11<BR>Anchor.<BR>benchmarks:<BR>  NYT24 - Relation Extraction benchmarking: F1<BR>  NYT29 - Relation Extraction benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-06<BR>Anchor.<BR>benchmarks:<BR>  DocRED - Relation Extraction benchmarking: F1<BR>  DocRED - Relation Extraction benchmarking: Ign F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-05<BR>Anchor.<BR>benchmarks:<BR>  FewRel - Relation Extraction benchmarking: F1<BR>  FewRel - Relation Extraction benchmarking: Precision<BR>  FewRel - Relation Extraction benchmarking: Recall<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-03<BR>Anchor.<BR>benchmarks:<BR>  JNLPBA - Relation Extraction benchmarking: F1<BR>  SciERC - Relation Extraction benchmarking: F1<BR>","<BR>task: Information extraction: Chinese Named Entity Recognition<BR>date: 2018-10<BR>Anchor.<BR>benchmarks:<BR>  SighanNER - Chinese Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Chinese Named Entity Recognition<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  MSRA - Chinese Named Entity Recognition benchmarking: F1<BR>  OntoNotes 4 - Chinese Named Entity Recognition benchmarking: F1<BR>  Resume NER - Chinese Named Entity Recognition benchmarking: F1<BR>  Weibo NER - Chinese Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-04<BR>Anchor.<BR>benchmarks:<BR>  WLPC - Relation Extraction benchmarking: F1<BR>","<BR>task: Information extraction: Chinese Named Entity Recognition<BR>date: 2019-04<BR>Anchor.<BR>benchmarks:<BR>  MSRA Dev - Chinese Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information retrieval: Conversational Response Selection<BR>date: 2018-12<BR>Anchor.<BR>benchmarks:<BR>  DSTC7 Ubuntu - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>","<BR>task: Information retrieval: Conversational Response Selection<BR>date: 2018-02<BR>Anchor.<BR>benchmarks:<BR>  PolyAI Reddit - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>","<BR>task: Information retrieval: Conversational Response Selection<BR>date: 2019-01<BR>Anchor.<BR>benchmarks:<BR>  Advising Corpus - Conversational Response Selection benchmarking: R-at-10<BR>  Advising Corpus - Conversational Response Selection benchmarking: R-at-1<BR>  Advising Corpus - Conversational Response Selection benchmarking: R@50<BR>","<BR>task: Information retrieval: Conversational Response Selection<BR>date: 2019-04<BR>Anchor.<BR>benchmarks:<BR>  PolyAI AmazonQA - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>  PolyAI OpenSubtitles - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>","<BR>task: Machine translation: Unsupervised Machine Translation<BR>date: 2019-01<BR>Anchor.<BR>benchmarks:<BR>  WMT2014 English-German - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2014 German-English - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 Romanian-English - Unsupervised Machine Translation benchmarking: BLEU<BR>","<BR>task: Machine translation: Unsupervised Machine Translation<BR>date: 2018-04<BR>Anchor.<BR>benchmarks:<BR>  WMT2014 English-French - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2014 French-English - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 English-German - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 German-English - Unsupervised Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2017-11<BR>Anchor.<BR>benchmarks:<BR>  WMT2014 German-English - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2016-07<BR>Anchor.<BR>benchmarks:<BR>  IWSLT2014 German-English - Machine Translation benchmarking: BLEU score<BR>  IWSLT2015 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-03<BR>Anchor.<BR>benchmarks:<BR>  WMT 2017 English-Chinese - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2016-06<BR>Anchor.<BR>benchmarks:<BR>  IWSLT2015 Thai-English - Machine Translation benchmarking: BLEU score<BR>  WMT2016 Czech-English - Machine Translation benchmarking: BLEU score<BR>  WMT2016 English-Czech - Machine Translation benchmarking: BLEU score<BR>  WMT2016 English-German - Machine Translation benchmarking: BLEU score<BR>  WMT2016 English-Romanian - Machine Translation benchmarking: BLEU score<BR>  WMT2016 English-Russian - Machine Translation benchmarking: BLEU score<BR>  WMT2016 German-English - Machine Translation benchmarking: BLEU score<BR>  WMT2016 Romanian-English - Machine Translation benchmarking: BLEU score<BR>  WMT2016 Russian-English - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2015-12<BR>Anchor.<BR>benchmarks:<BR>  IWSLT2015 English-Vietnamese - Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2017-09<BR>Anchor.<BR>benchmarks:<BR>  20NEWS - Machine Translation benchmarking: 1-of-100 Accuracy<BR>  WMT 2017 Latvian-English - Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  ACCURAT balanced test corpus for under resourced languages Estonian-Russian - Machine Translation benchmarking: BLEU<BR>  ACCURAT balanced test corpus for under resourced languages Russian-Estonian - Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-06<BR>Anchor.<BR>benchmarks:<BR>  WMT2016 Finnish-English - Machine Translation benchmarking: BLEU<BR>  WMT2017 Finnish-English - Machine Translation benchmarking: BLEU<BR>  WMT2019 Finnish-English - Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-09<BR>Anchor.<BR>benchmarks:<BR>  WMT2014 French-English - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-10<BR>Anchor.<BR>benchmarks:<BR>  WMT 2017 English-Latvian - Machine Translation benchmarking: BLEU<BR>  WMT 2018 English-Estonian - Machine Translation benchmarking: BLEU<BR>  WMT 2018 English-Finnish - Machine Translation benchmarking: BLEU<BR>  WMT 2018 Estonian-English - Machine Translation benchmarking: BLEU<BR>  WMT 2018 Finnish-English - Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-01<BR>Anchor.<BR>benchmarks:<BR>  WMT2014 English-Czech - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2015-08<BR>Anchor.<BR>benchmarks:<BR>  20NEWS - Machine Translation benchmarking: Accuracy<BR>  WMT2014 English-German - Machine Translation benchmarking: BLEU score<BR>  WMT2015 English-German - Machine Translation benchmarking: BLEU score<BR>  WMT2015 English-Russian - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-07<BR>Anchor.<BR>benchmarks:<BR>  WMT2019 English-German - Machine Translation benchmarking: BLEU score<BR>  WMT2019 English-German - Machine Translation benchmarking: SacreBLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-10<BR>Anchor.<BR>benchmarks:<BR>  IWSLT2017 Arabic-English - Machine Translation benchmarking: Cased sacreBLEU<BR>  IWSLT2017 English-Arabic - Machine Translation benchmarking: Cased sacreBLEU<BR>  IWSLT2017 English-French - Machine Translation benchmarking: Cased sacreBLEU<BR>  IWSLT2017 French-English - Machine Translation benchmarking: Cased sacreBLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-11<BR>Anchor.<BR>benchmarks:<BR>  IWSLT2015 Chinese-English - Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  WMT2014 English-French - Machine Translation benchmarking: SacreBLEU<BR>  WMT2014 English-German - Machine Translation benchmarking: SacreBLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2014-09<BR>Anchor.<BR>benchmarks:<BR>  IWSLT2015 German-English - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2018-07<BR>Anchor.<BR>benchmarks:<BR>  LAMBADA - Language Modelling benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2019-08<BR>Anchor.<BR>benchmarks:<BR>  X-Sum - Text Summarization benchmarking: ROUGE-1<BR>  X-Sum - Text Summarization benchmarking: ROUGE-2<BR>  X-Sum - Text Summarization benchmarking: ROUGE-3<BR>","<BR>task: Natural language generation: Document Summarization<BR>date: 2017-09<BR>Anchor.<BR>benchmarks:<BR>  CNN / Daily Mail - Document Summarization benchmarking: PPL<BR>","<BR>task: Natural language generation: Document Summarization<BR>date: 2017-05<BR>Anchor.<BR>benchmarks:<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-1<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-2<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-L<BR>","<BR>task: Natural language generation: Question Generation<BR>date: 2017-04<BR>Anchor.<BR>benchmarks:<BR>  SQuAD1.1 - Question Generation benchmarking: BLEU-4<BR>","<BR>task: Natural language generation: Text Generation<BR>date: 2016-09<BR>Anchor.<BR>benchmarks:<BR>  COCO Captions - Text Generation benchmarking: BLEU-2<BR>  COCO Captions - Text Generation benchmarking: BLEU-3<BR>  COCO Captions - Text Generation benchmarking: BLEU-4<BR>  COCO Captions - Text Generation benchmarking: BLEU-5<BR>  Chinese Poems - Text Generation benchmarking: BLEU-2<BR>  EMNLP2017 WMT - Text Generation benchmarking: BLEU-2<BR>  EMNLP2017 WMT - Text Generation benchmarking: BLEU-3<BR>  EMNLP2017 WMT - Text Generation benchmarking: BLEU-4<BR>  EMNLP2017 WMT - Text Generation benchmarking: BLEU-5<BR>","<BR>task: Natural language generation: Text Generation<BR>date: 2017-02<BR>Anchor.<BR>benchmarks:<BR>  Yahoo Questions - Text Generation benchmarking: KL<BR>  Yahoo Questions - Text Generation benchmarking: NLL<BR>  Yahoo Questions - Text Generation benchmarking: Perplexity<BR>","<BR>task: Natural language generation: Text Generation<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  LDC2016E25 - Text Generation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2014-06<BR>Anchor.<BR>benchmarks:<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2015-09<BR>Anchor.<BR>benchmarks:<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-1<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-2<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-L<BR>  GigaWord - Text Summarization benchmarking: ROUGE-1<BR>","<BR>task: Natural language generation: Text Generation<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  DailyDialog - Text Generation benchmarking: BLEU-1<BR>  DailyDialog - Text Generation benchmarking: BLEU-2<BR>  DailyDialog - Text Generation benchmarking: BLEU-3<BR>  DailyDialog - Text Generation benchmarking: BLEU-4<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2017-04<BR>Anchor.<BR>benchmarks:<BR>  Pubmed - Text Summarization benchmarking: ROUGE-1<BR>  arXiv - Text Summarization benchmarking: ROUGE-1<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2013-12<BR>Anchor.<BR>benchmarks:<BR>  One Billion Word - Language Modelling benchmarking: PPL<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2016-02<BR>Anchor.<BR>benchmarks:<BR>  Text8 - Language Modelling benchmarking: Bit per Character (BPC)<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2016-07<BR>Anchor.<BR>benchmarks:<BR>  Hutter Prize - Language Modelling benchmarking: Bit per Character (BPC)<BR>  enwik8 - Language Modelling benchmarking: Bit per Character (BPC)<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2016-11<BR>Anchor.<BR>benchmarks:<BR>  WikiText-2 - Language Modelling benchmarking: Test perplexity<BR>  WikiText-2 - Language Modelling benchmarking: Validation perplexity<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2016-12<BR>Anchor.<BR>benchmarks:<BR>  WikiText-103 - Language Modelling benchmarking: Test perplexity<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2018-03<BR>Anchor.<BR>benchmarks:<BR>  WikiText-103 - Language Modelling benchmarking: Validation perplexity<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2018-09<BR>Anchor.<BR>benchmarks:<BR>  One Billion Word - Language Modelling benchmarking: Validation perplexity<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2019-02<BR>Anchor.<BR>benchmarks:<BR>  The Pile - Language Modelling benchmarking: Bits per byte<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2019-11<BR>Anchor.<BR>benchmarks:<BR>  PTB - Language Modelling benchmarking: PPL<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2016-02<BR>Anchor.<BR>benchmarks:<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-1<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-2<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-L<BR>  GigaWord - Text Summarization benchmarking: ROUGE-2<BR>  GigaWord - Text Summarization benchmarking: ROUGE-L<BR>","<BR>task: Natural language generation: Question Generation<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  Visual Question Generation - Question Generation benchmarking: BLEU-1<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2016-10<BR>Anchor.<BR>benchmarks:<BR>  CUB - Text-to-Image Generation benchmarking: FID<BR>  CUB - Text-to-Image Generation benchmarking: Inception score<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2016-12<BR>Anchor.<BR>benchmarks:<BR>  COCO - Text-to-Image Generation benchmarking: Inception score<BR>  Oxford 102 Flowers - Text-to-Image Generation benchmarking: Inception score<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2017-10<BR>Anchor.<BR>benchmarks:<BR>  COCO - Text-to-Image Generation benchmarking: FID<BR>  Oxford 102 Flowers - Text-to-Image Generation benchmarking: FID<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2017-11<BR>Anchor.<BR>benchmarks:<BR>  COCO - Text-to-Image Generation benchmarking: SOA-C<BR>  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking: Acc<BR>  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking: FID<BR>  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking: LPIPS<BR>  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking: Real<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2017-02<BR>Anchor.<BR>benchmarks:<BR>  Quora Question Pairs - Paraphrase Identification benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2018-06<BR>Anchor.<BR>benchmarks:<BR>  2017_test set - Paraphrase Identification benchmarking: 10 fold Cross validation<BR>","<BR>task: Pragmatics analysis: Fake News Detection<BR>date: 2017-07<BR>Anchor.<BR>benchmarks:<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Agree)<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Disagree)<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Discuss)<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Unrelated)<BR>  FNC-1 - Fake News Detection benchmarking: Weighted Accuracy<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2013-10<BR>Anchor.<BR>benchmarks:<BR>  MSRP - Paraphrase Identification benchmarking: Accuracy<BR>  MSRP - Paraphrase Identification benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2016-07<BR>Anchor.<BR>benchmarks:<BR>  Amazon Review Full - Sentiment Analysis benchmarking: Accuracy<BR>  Amazon Review Polarity - Sentiment Analysis benchmarking: Accuracy<BR>  Sogou News - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2016-04<BR>Anchor.<BR>benchmarks:<BR>  OntoNotes - Coreference Resolution benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2019-08<BR>Anchor.<BR>benchmarks:<BR>  GAP - Coreference Resolution benchmarking: Bias (F/M)<BR>  GAP - Coreference Resolution benchmarking: Feminine F1 (F)<BR>  GAP - Coreference Resolution benchmarking: Masculine F1 (M)<BR>  GAP - Coreference Resolution benchmarking: Overall F1<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2017-07<BR>Anchor.<BR>benchmarks:<BR>  CoNLL 2012 - Coreference Resolution benchmarking: Avg F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2017-02<BR>Anchor.<BR>benchmarks:<BR>  MR - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2015-09<BR>Anchor.<BR>benchmarks:<BR>  Yelp Binary classification - Sentiment Analysis benchmarking: Error<BR>  Yelp Fine-grained classification - Sentiment Analysis benchmarking: Error<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2019-08<BR>Anchor.<BR>benchmarks:<BR>  ASTD - Sentiment Analysis benchmarking: Average Recall<BR>  ArSAS - Sentiment Analysis benchmarking: Average Recall<BR>  FiQA - Sentiment Analysis benchmarking: MSE<BR>  FiQA - Sentiment Analysis benchmarking: R^2<BR>  Financial PhraseBank - Sentiment Analysis benchmarking: Accuracy<BR>  Financial PhraseBank - Sentiment Analysis benchmarking: F1 score<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2019-01<BR>Anchor.<BR>benchmarks:<BR>  Quora Question Pairs - Paraphrase Identification benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2019-02<BR>Anchor.<BR>benchmarks:<BR>  Twitter - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2017-04<BR>Anchor.<BR>benchmarks:<BR>  SemEval - Sentiment Analysis benchmarking: F1-score<BR>  SemEval 2017 Task 4-A - Sentiment Analysis benchmarking: Average Recall<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2019-06<BR>Anchor.<BR>benchmarks:<BR>  ChnSentiCorp - Sentiment Analysis benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2014-12<BR>Anchor.<BR>benchmarks:<BR>  IMDb - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2015-05<BR>Anchor.<BR>benchmarks:<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Average<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Books<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: DVD<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Electronics<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Kitchen<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2017-12<BR>Anchor.<BR>benchmarks:<BR>  CR - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2013-10<BR>Anchor.<BR>benchmarks:<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>  SST-5 Fine-grained classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Intent Detection<BR>date: 2019-06<BR>Anchor.<BR>benchmarks:<BR>  ATIS - Intent Detection benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Emotion Recognition in Conversation<BR>date: 2019-09<BR>Anchor.<BR>benchmarks:<BR>  DailyDialog - Emotion Recognition in Conversation benchmarking: Micro-F1<BR>  EmoryNLP - Emotion Recognition in Conversation benchmarking: Weighted Macro-F1<BR>","<BR>task: Pragmatics analysis: Intent Detection<BR>date: 2019-12<BR>Anchor.<BR>benchmarks:<BR>  ASOS.com user intent - Intent Detection benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Emotion Recognition in Conversation<BR>date: 2019-03<BR>Anchor.<BR>benchmarks:<BR>  EC - Emotion Recognition in Conversation benchmarking: Micro-F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2018-03<BR>Anchor.<BR>benchmarks:<BR>  MPQA - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Intent Detection<BR>date: 2018-12<BR>Anchor.<BR>benchmarks:<BR>  ATIS - Intent Detection benchmarking: Accuracy<BR>  SNIPS - Intent Detection benchmarking: Intent Accuracy<BR>  SNIPS - Intent Detection benchmarking: Slot F1 Score<BR>","<BR>task: Pragmatics analysis: Emotion Recognition in Conversation<BR>date: 2017-07<BR>Anchor.<BR>benchmarks:<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Accuracy<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Macro-F1<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Weighted-F1<BR>  MELD - Emotion Recognition in Conversation benchmarking: Accuracy<BR>  MELD - Emotion Recognition in Conversation benchmarking: Weighted-F1<BR>  SEMAINE - Emotion Recognition in Conversation benchmarking: MAE (Arousal)<BR>  SEMAINE - Emotion Recognition in Conversation benchmarking: MAE (Expectancy)<BR>  SEMAINE - Emotion Recognition in Conversation benchmarking: MAE (Power)<BR>  SEMAINE - Emotion Recognition in Conversation benchmarking: MAE (Valence)<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-03<BR>Anchor.<BR>benchmarks:<BR>  RACE - Question Answering benchmarking: RACE-h<BR>  RACE - Question Answering benchmarking: RACE-m<BR>  RACE - Question Answering benchmarking: RACE<BR>","<BR>task: Question answering: Question Answering<BR>date: 2020-04<BR>Anchor.<BR>benchmarks:<BR>  SCDE - Question Answering benchmarking: BA<BR>  SCDE - Question Answering benchmarking: DE<BR>  SCDE - Question Answering benchmarking: PA<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-07<BR>Anchor.<BR>benchmarks:<BR>  NaturalQA - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-05<BR>Anchor.<BR>benchmarks:<BR>  HotpotQA - Question Answering benchmarking: JOINT-F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-04<BR>Anchor.<BR>benchmarks:<BR>  CODAH - Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-01<BR>Anchor.<BR>benchmarks:<BR>  JD Product Question Answer - Question Answering benchmarking: BLEU<BR>  Natural Questions - Question Answering benchmarking: F1 (Long)<BR>  Natural Questions - Question Answering benchmarking: F1 (Short)<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-10<BR>Anchor.<BR>benchmarks:<BR>  QuAC - Question Answering benchmarking: F1<BR>  QuAC - Question Answering benchmarking: HEQD<BR>  QuAC - Question Answering benchmarking: HEQQ<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  CoQA - Question Answering benchmarking: In-domain<BR>  CoQA - Question Answering benchmarking: Out-of-domain<BR>  CoQA - Question Answering benchmarking: Overall<BR>  SQuAD2.0 dev - Question Answering benchmarking: EM<BR>  SQuAD2.0 dev - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  Quora Question Pairs - Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-11<BR>Anchor.<BR>benchmarks:<BR>  SQuAD2.0 - Question Answering benchmarking: EM<BR>  SQuAD2.0 - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-03<BR>Anchor.<BR>benchmarks:<BR>  NewsQA - Question Answering benchmarking: EM<BR>  NewsQA - Question Answering benchmarking: F1<BR>  Quasart-T - Question Answering benchmarking: EM<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-08<BR>Anchor.<BR>benchmarks:<BR>  AI2 Kaggle Dataset - Question Answering benchmarking: P-at-1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-08<BR>Anchor.<BR>benchmarks:<BR>  VizWiz 2018 - Visual Question Answering benchmarking: number<BR>  VizWiz 2018 - Visual Question Answering benchmarking: other<BR>  VizWiz 2018 - Visual Question Answering benchmarking: unanswerable<BR>  VizWiz 2018 - Visual Question Answering benchmarking: yes/no<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-07<BR>Anchor.<BR>benchmarks:<BR>  GQA test-dev - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-04<BR>Anchor.<BR>benchmarks:<BR>  VizWiz 2018 - Visual Question Answering benchmarking: overall<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-02<BR>Anchor.<BR>benchmarks:<BR>  GQA test-std - Visual Question Answering benchmarking: Accuracy<BR>  TDIUC - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2018-10<BR>Anchor.<BR>benchmarks:<BR>  100 sleep nights of 8 caregivers - Visual Question Answering benchmarking: 14 gestures accuracy<BR>  HowmanyQA - Visual Question Answering benchmarking: Accuracy<BR>  TallyQA - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  CLEVR - Visual Question Answering benchmarking: Accuracy<BR>  VQA-CP - Visual Question Answering benchmarking: Score<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2017-07<BR>Anchor.<BR>benchmarks:<BR>  GQA Test2019 - Visual Question Answering benchmarking: Accuracy<BR>  GQA Test2019 - Visual Question Answering benchmarking: Binary<BR>  GQA Test2019 - Visual Question Answering benchmarking: Consistency<BR>  GQA Test2019 - Visual Question Answering benchmarking: Distribution<BR>  GQA Test2019 - Visual Question Answering benchmarking: Open<BR>  GQA Test2019 - Visual Question Answering benchmarking: Plausibility<BR>  GQA Test2019 - Visual Question Answering benchmarking: Validity<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2017-04<BR>Anchor.<BR>benchmarks:<BR>  MSRVTT-QA - Visual Question Answering benchmarking: Accuracy<BR>  MSVD-QA - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2016-12<BR>Anchor.<BR>benchmarks:<BR>  VQA v2 test-std - Visual Question Answering benchmarking: overall<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2016-06<BR>Anchor.<BR>benchmarks:<BR>  VQA v2 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  Visual7W - Visual Question Answering benchmarking: Percentage correct<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-10<BR>Anchor.<BR>benchmarks:<BR>  WikiHop - Question Answering benchmarking: Test<BR>","<BR>task: Question answering: Question Answering<BR>date: 2014-04<BR>Anchor.<BR>benchmarks:<BR>  Reverb - Question Answering benchmarking: Accuracy<BR>  WebQuestions - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2014-05<BR>Anchor.<BR>benchmarks:<BR>  QASent - Question Answering benchmarking: MAP<BR>  QASent - Question Answering benchmarking: MRR<BR>  WikiQA - Question Answering benchmarking: MAP<BR>  WikiQA - Question Answering benchmarking: MRR<BR>","<BR>task: Question answering: Question Answering<BR>date: 2014-12<BR>Anchor.<BR>benchmarks:<BR>  TrecQA - Question Answering benchmarking: MAP<BR>  TrecQA - Question Answering benchmarking: MRR<BR>","<BR>task: Question answering: Question Answering<BR>date: 2015-03<BR>Anchor.<BR>benchmarks:<BR>  SemEvalCQA - Question Answering benchmarking: MAP<BR>  SemEvalCQA - Question Answering benchmarking: P-at-1<BR>  bAbi - Question Answering benchmarking: Accuracy (trained on 10k)<BR>  bAbi - Question Answering benchmarking: Accuracy (trained on 1k)<BR>  bAbi - Question Answering benchmarking: Mean Error Rate<BR>","<BR>task: Question answering: Question Answering<BR>date: 2015-06<BR>Anchor.<BR>benchmarks:<BR>  CNN / Daily Mail - Question Answering benchmarking: CNN<BR>  CNN / Daily Mail - Question Answering benchmarking: Daily Mail<BR>  SimpleQuestions - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-02<BR>Anchor.<BR>benchmarks:<BR>  YahooCQA - Question Answering benchmarking: MRR<BR>  YahooCQA - Question Answering benchmarking: P-at-1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-06<BR>Anchor.<BR>benchmarks:<BR>  Story Cloze Test - Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-08<BR>Anchor.<BR>benchmarks:<BR>  SQuAD1.1 - Question Answering benchmarking: EM<BR>  SQuAD1.1 - Question Answering benchmarking: F1<BR>  SQuAD1.1 dev - Question Answering benchmarking: EM<BR>  SQuAD1.1 dev - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-11<BR>Anchor.<BR>benchmarks:<BR>  MS MARCO - Question Answering benchmarking: BLEU-1<BR>  MS MARCO - Question Answering benchmarking: Rouge-L<BR>  NarrativeQA - Question Answering benchmarking: BLEU-1<BR>  NarrativeQA - Question Answering benchmarking: BLEU-4<BR>  NarrativeQA - Question Answering benchmarking: Rouge-L<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-05<BR>Anchor.<BR>benchmarks:<BR>  TriviaQA - Question Answering benchmarking: EM<BR>  TriviaQA - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-07<BR>Anchor.<BR>benchmarks:<BR>  COMPLEXQUESTIONS - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2015-11<BR>Anchor.<BR>benchmarks:<BR>  VQA v1 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  VQA v1 test-std - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-03<BR>Anchor.<BR>benchmarks:<BR>  Children's Book Test - Question Answering benchmarking: Accuracy-CN<BR>  Children's Book Test - Question Answering benchmarking: Accuracy-NE<BR>  MCTest-160 - Question Answering benchmarking: Accuracy<BR>  MCTest-500 - Question Answering benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Semantic Textual Similarity<BR>date: 2018-03<BR>Anchor.<BR>benchmarks:<BR>  STS Benchmark - Semantic Textual Similarity benchmarking: Pearson Correlation<BR>","<BR>task: Semantic analysis: Semantic Parsing<BR>date: 2019-10<BR>Anchor.<BR>benchmarks:<BR>  WikiSQL - Semantic Parsing benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2015-05<BR>Anchor.<BR>benchmarks:<BR>  SensEval 2 Lexical Sample - Word Sense Disambiguation benchmarking: F1<BR>  SensEval 3 Lexical Sample - Word Sense Disambiguation benchmarking: F1<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2016-03<BR>Anchor.<BR>benchmarks:<BR>  SemEval 2007 Task 17 - Word Sense Disambiguation benchmarking: F1<BR>  SemEval 2007 Task 7 - Word Sense Disambiguation benchmarking: F1<BR>  SemEval 2013 Task 12 - Word Sense Disambiguation benchmarking: F1<BR>  SensEval 2 - Word Sense Disambiguation benchmarking: F1<BR>  SensEval 3 Task 1 - Word Sense Disambiguation benchmarking: F1<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2017-09<BR>Anchor.<BR>benchmarks:<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2013<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2015<BR>  Supervised: - Word Sense Disambiguation benchmarking: Senseval 2<BR>  Supervised: - Word Sense Disambiguation benchmarking: Senseval 3<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2018-01<BR>Anchor.<BR>benchmarks:<BR>  Knowledge-based: - Word Sense Disambiguation benchmarking: All<BR>  Knowledge-based: - Word Sense Disambiguation benchmarking: SemEval 2013<BR>  Knowledge-based: - Word Sense Disambiguation benchmarking: SemEval 2015<BR>","<BR>task: Semantic analysis: Semantic Textual Similarity<BR>date: 2017-05<BR>Anchor.<BR>benchmarks:<BR>  SentEval - Semantic Textual Similarity benchmarking: SICK-E<BR>  SentEval - Semantic Textual Similarity benchmarking: SICK-R<BR>","<BR>task: Semantic analysis: Semantic Textual Similarity<BR>date: 2013-10<BR>Anchor.<BR>benchmarks:<BR>  MRPC - Semantic Textual Similarity benchmarking: Accuracy<BR>  MRPC - Semantic Textual Similarity benchmarking: F1<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  SemEval 2015 Task 13 - Word Sense Disambiguation benchmarking: F1<BR>","<BR>task: Semantic analysis: Semantic Role Labeling<BR>date: 2018-04<BR>Anchor.<BR>benchmarks:<BR>  CoNLL 2005 - Semantic Role Labeling benchmarking: F1<BR>","<BR>task: Semantic analysis: Entity Disambiguation<BR>date: 2019-09<BR>Anchor.<BR>benchmarks:<BR>  AQUAINT - Entity Disambiguation benchmarking: Micro-F1<BR>","<BR>task: Semantic analysis: Semantic Parsing<BR>date: 2014-11<BR>Anchor.<BR>benchmarks:<BR>  ATIS - Semantic Parsing benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Semantic Parsing<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  Geo - Semantic Parsing benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Semantic Parsing<BR>date: 2018-09<BR>Anchor.<BR>benchmarks:<BR>  spider - Semantic Parsing benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2018-02<BR>Anchor.<BR>benchmarks:<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2007<BR>","<BR>task: Semantic analysis: Semantic Role Labeling<BR>date: 2017-07<BR>Anchor.<BR>benchmarks:<BR>  OntoNotes - Semantic Role Labeling benchmarking: F1<BR>","<BR>task: Semantic analysis: Entity Disambiguation<BR>date: 2016-01<BR>Anchor.<BR>benchmarks:<BR>  AIDA-CoNLL - Entity Disambiguation benchmarking: In-KB Accuracy<BR>  TAC2010 - Entity Disambiguation benchmarking: Micro Precision<BR>","<BR>task: Semantic analysis: Entity Disambiguation<BR>date: 2017-04<BR>Anchor.<BR>benchmarks:<BR>  ACE2004 - Entity Disambiguation benchmarking: Micro-F1<BR>  MSNBC - Entity Disambiguation benchmarking: Micro-F1<BR>  WNED-CWEB - Entity Disambiguation benchmarking: Micro-F1<BR>  WNED-WIKI - Entity Disambiguation benchmarking: Micro-F1<BR>","<BR>task: Sentence embedding: Sentence Compression<BR>date: 2015-09<BR>Anchor.<BR>benchmarks:<BR>  Google Dataset - Sentence Compression benchmarking: CR<BR>  Google Dataset - Sentence Compression benchmarking: F1<BR>","<BR>task: Syntactic analysis: Constituency Grammar Induction<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  PTB - Constituency Grammar Induction benchmarking: Mean F1 (WSJ10)<BR>","<BR>task: Syntactic analysis: Constituency Grammar Induction<BR>date: 2017-11<BR>Anchor.<BR>benchmarks:<BR>  PTB - Constituency Grammar Induction benchmarking: Max F1 (WSJ)<BR>  PTB - Constituency Grammar Induction benchmarking: Mean F1 (WSJ)<BR>","<BR>task: Syntactic analysis: Dependency Parsing<BR>date: 2015-06<BR>Anchor.<BR>benchmarks:<BR>  Penn Treebank - Dependency Parsing benchmarking: LAS<BR>  Penn Treebank - Dependency Parsing benchmarking: POS<BR>  Penn Treebank - Dependency Parsing benchmarking: UAS<BR>","<BR>task: Syntactic analysis: Dependency Parsing<BR>date: 2016-11<BR>Anchor.<BR>benchmarks:<BR>  CoNLL-2009 - Dependency Parsing benchmarking: LAS<BR>  CoNLL-2009 - Dependency Parsing benchmarking: UAS<BR>","<BR>task: Syntactic analysis: Dependency Parsing<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  GENIA - LAS - Dependency Parsing benchmarking: F1<BR>  GENIA - UAS - Dependency Parsing benchmarking: F1<BR>","<BR>task: Syntactic analysis: Chunking<BR>date: 2017-11<BR>Anchor.<BR>benchmarks:<BR>  CoNLL 2000 - Chunking benchmarking: Exact Span F1<BR>","<BR>task: Syntactic analysis: Chunking<BR>date: 2016-08<BR>Anchor.<BR>benchmarks:<BR>  Penn Treebank - Chunking benchmarking: F1 score<BR>","<BR>task: Syntactic analysis: Constituency Parsing<BR>date: 2014-12<BR>Anchor.<BR>benchmarks:<BR>  Penn Treebank - Constituency Parsing benchmarking: F1 score<BR>","<BR>task: Syntactic analysis: Grammatical Error Detection<BR>date: 2016-07<BR>Anchor.<BR>benchmarks:<BR>  CoNLL-2014 A1 - Grammatical Error Detection benchmarking: F0.5<BR>  CoNLL-2014 A2 - Grammatical Error Detection benchmarking: F0.5<BR>  FCE - Grammatical Error Detection benchmarking: F0.5<BR>","<BR>task: Syntactic analysis: Grammatical Error Detection<BR>date: 2018-11<BR>Anchor.<BR>benchmarks:<BR>  JFLEG - Grammatical Error Detection benchmarking: F0.5<BR>","<BR>task: Syntactic analysis: Linguistic Acceptability Assessment<BR>date: 2019-01<BR>Anchor.<BR>benchmarks:<BR>  CoLA - Linguistic Acceptability Assessment benchmarking: Accuracy<BR>","<BR>task: Syntactic analysis: Constituency Grammar Induction<BR>date: 2018-10<BR>Anchor.<BR>benchmarks:<BR>  PTB - Constituency Grammar Induction benchmarking: Max F1 (WSJ10)<BR>","<BR>task: Text classification: Sentence Classification<BR>date: 2018-08<BR>Anchor.<BR>benchmarks:<BR>  PubMed 20k RCT - Sentence Classification benchmarking: F1<BR>","<BR>task: Text classification: Sentence Classification<BR>date: 2019-03<BR>Anchor.<BR>benchmarks:<BR>  Paper Field - Sentence Classification benchmarking: F1<BR>  ScienceCite - Sentence Classification benchmarking: F1<BR>","<BR>task: Text classification: Document Classification<BR>date: 2014-10<BR>Anchor.<BR>benchmarks:<BR>  Reuters De-En - Document Classification benchmarking: Accuracy<BR>  Reuters En-De - Document Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Citation Intent Classification<BR>date: 2013-06<BR>Anchor.<BR>benchmarks:<BR>  ACL-ARC - Citation Intent Classification benchmarking: F1<BR>","<BR>task: Text classification: Sentence Classification<BR>date: 2018-01<BR>Anchor.<BR>benchmarks:<BR>  ACL-ARC - Sentence Classification benchmarking: F1<BR>  SciCite - Sentence Classification benchmarking: F1<BR>","<BR>task: Text classification: Citation Intent Classification<BR>date: 2019-03<BR>Anchor.<BR>benchmarks:<BR>  SciCite - Citation Intent Classification benchmarking: F1<BR>","<BR>task: Text classification: Document Classification<BR>date: 2019-06<BR>Anchor.<BR>benchmarks:<BR>  IMDb-M - Document Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Document Classification<BR>date: 2017-09<BR>Anchor.<BR>benchmarks:<BR>  WOS-11967 - Document Classification benchmarking: Accuracy<BR>  WOS-46985 - Document Classification benchmarking: Accuracy<BR>  WOS-5736 - Document Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2014-05<BR>Anchor.<BR>benchmarks:<BR>  IMDb - Text Classification benchmarking: Accuracy (2 classes)<BR>","<BR>task: Text classification: Text Classification<BR>date: 2015-04<BR>Anchor.<BR>benchmarks:<BR>  TREC-6 - Text Classification benchmarking: Error<BR>","<BR>task: Text classification: Text Classification<BR>date: 2015-09<BR>Anchor.<BR>benchmarks:<BR>  AG News - Text Classification benchmarking: Error<BR>  DBpedia - Text Classification benchmarking: Error<BR>","<BR>task: Text classification: Text Classification<BR>date: 2016-02<BR>Anchor.<BR>benchmarks:<BR>  RCV1 - Text Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2016-07<BR>Anchor.<BR>benchmarks:<BR>  Yahoo! Answers - Text Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2016-12<BR>Anchor.<BR>benchmarks:<BR>  TREC-50 - Text Classification benchmarking: Error<BR>","<BR>task: Text classification: Text Classification<BR>date: 2017-07<BR>Anchor.<BR>benchmarks:<BR>  Ohsumed - Text Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2018-05<BR>Anchor.<BR>benchmarks:<BR>  20NEWS - Text Classification benchmarking: Accuracy<BR>  LOCAL DATASET - Text Classification benchmarking: Accuracy (%)<BR>","<BR>task: Text classification: Text Classification<BR>date: 2018-06<BR>Anchor.<BR>benchmarks:<BR>  20NEWS - Text Classification benchmarking: F-measure<BR>  R8 - Text Classification benchmarking: Accuracy<BR>  R8 - Text Classification benchmarking: F-measure<BR>","<BR>task: Text classification: Document Classification<BR>date: 2019-08<BR>Anchor.<BR>benchmarks:<BR>  MPQA - Document Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2018-09<BR>Anchor.<BR>benchmarks:<BR>  R52 - Text Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-01<BR>Anchor.<BR>benchmarks:<BR>  Yelp-5 - Text Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-04<BR>Anchor.<BR>benchmarks:<BR>  IMDb - Text Classification benchmarking: Accuracy (10 classes)<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-05<BR>Anchor.<BR>benchmarks:<BR>  Yelp-2 - Text Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Document Classification<BR>date: 2019-04<BR>Anchor.<BR>benchmarks:<BR>  AAPD - Document Classification benchmarking: F1<BR>  Amazon - Document Classification benchmarking: Accuracy<BR>  BBCSport - Document Classification benchmarking: Accuracy<BR>  Classic - Document Classification benchmarking: Accuracy<BR>  Recipe - Document Classification benchmarking: Accuracy<BR>  Reuters-21578 - Document Classification benchmarking: Accuracy<BR>  Twitter - Document Classification benchmarking: Accuracy<BR>  Yelp-14 - Document Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-08<BR>Anchor.<BR>benchmarks:<BR>  RCV1 - Text Classification benchmarking: Macro F1<BR>  RCV1 - Text Classification benchmarking: Micro F1<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-11<BR>Anchor.<BR>benchmarks:<BR>  20NEWS - Text Classification benchmarking: Precision<BR>  20NEWS - Text Classification benchmarking: Recall<BR>","<BR>task: Text classification: Document Classification<BR>date: 2014-03<BR>Anchor.<BR>benchmarks:<BR>  Cora - Document Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Document Classification<BR>date: 2019-02<BR>Anchor.<BR>benchmarks:<BR>  Reuters-21578 - Document Classification benchmarking: F1<BR>","<BR>task: Text classification: Text Classification<BR>date: 2018-10<BR>Anchor.<BR>benchmarks:<BR>  Sogou News - Text Classification benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-06<BR>Anchor.<BR>benchmarks:<BR>  Amazon-2 - Text Classification benchmarking: Error<BR>  Amazon-5 - Text Classification benchmarking: Error<BR>  RCV1 - Text Classification benchmarking: P-at-1<BR>  RCV1 - Text Classification benchmarking: P-at-3<BR>  RCV1 - Text Classification benchmarking: P-at-5<BR>  RCV1 - Text Classification benchmarking: nDCG-at-1<BR>  RCV1 - Text Classification benchmarking: nDCG-at-3<BR>  RCV1 - Text Classification benchmarking: nDCG-at-5<BR>"],"marker":{"line":{"width":1,"color":"black"},"size":20,"symbol":42},"mode":"markers","x":["2017-08","2018-10","2018-05","2017-05","2016-03","2016-03","2016-06","2016-05","2017-04","2018-06","2018-09","2019-05","2019-04","2018-03","2019-06","2018-12","2017-12","2015-08","2018-09","2014-04","2019-09","2018-11","2018-10","2018-05","2018-08","2018-06","2018-05","2018-08","2014-06","2014-10","2016-08","2017-09","2014-09","2019-01","2018-10","2017-06","2019-04","2019-08","2019-09","2020-03","2018-09","2017-09","2018-06","2019-01","2018-04","2019-11","2019-06","2019-05","2019-03","2018-10","2018-05","2019-04","2019-04","2018-12","2018-02","2019-01","2019-04","2019-01","2018-04","2017-11","2016-07","2018-03","2016-06","2015-12","2017-09","2018-05","2019-06","2018-09","2018-10","2019-01","2015-08","2019-07","2019-10","2019-11","2018-08","2014-09","2018-07","2019-08","2017-09","2017-05","2017-04","2016-09","2017-02","2018-05","2014-06","2015-09","2018-08","2017-04","2013-12","2016-02","2016-07","2016-11","2016-12","2018-03","2018-09","2019-02","2019-11","2016-02","2018-08","2016-10","2016-12","2017-10","2017-11","2017-02","2018-06","2017-07","2013-10","2016-07","2016-04","2019-08","2017-07","2017-02","2015-09","2019-08","2019-01","2019-02","2017-04","2019-06","2014-12","2015-05","2017-12","2013-10","2019-06","2019-09","2019-12","2019-03","2018-03","2018-12","2017-07","2018-03","2020-04","2019-07","2019-05","2019-04","2019-01","2018-10","2018-08","2018-05","2017-11","2017-03","2017-08","2019-08","2019-07","2019-04","2019-02","2018-10","2018-08","2017-07","2017-04","2016-12","2016-06","2017-10","2014-04","2014-05","2014-12","2015-03","2015-06","2016-02","2016-06","2016-08","2016-11","2017-05","2017-07","2015-11","2016-03","2018-03","2019-10","2015-05","2016-03","2017-09","2018-01","2017-05","2013-10","2018-05","2018-04","2019-09","2014-11","2018-05","2018-09","2018-02","2017-07","2016-01","2017-04","2015-09","2018-08","2017-11","2015-06","2016-11","2018-08","2017-11","2016-08","2014-12","2016-07","2018-11","2019-01","2018-10","2018-08","2019-03","2014-10","2013-06","2018-01","2019-03","2019-06","2017-09","2014-05","2015-04","2015-09","2016-02","2016-07","2016-12","2017-07","2018-05","2018-06","2019-08","2018-09","2019-01","2019-04","2019-05","2019-04","2019-08","2019-11","2014-03","2019-02","2018-10","2019-06"],"y":["Computer code processing: Code Generation","Computer code processing: Code Generation","Computer code processing: Code Generation","Computer code processing: Code Generation","Computer code processing: Code Generation","Dialog process: Dialog Act Classification","Dialog process: Dialog State Tracking","Dialog process: Visual Dialog","Dialog process: Visual Dialog","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Natural Language Inference","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Natural Language Inference","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning","Inference and reasoning: Common Sense Reasoning","Information extraction: Named Entity Recognition","Information extraction: Joint Entity and Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Relation Extraction","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Named Entity Recognition","Information extraction: Relation Extraction","Information extraction: Named Entity Recognition","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Relation Extraction","Information extraction: Chinese Named Entity Recognition","Information extraction: Chinese Named Entity Recognition","Information extraction: Relation Extraction","Information extraction: Chinese Named Entity Recognition","Information retrieval: Conversational Response Selection","Information retrieval: Conversational Response Selection","Information retrieval: Conversational Response Selection","Information retrieval: Conversational Response Selection","Machine translation: Unsupervised Machine Translation","Machine translation: Unsupervised Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Natural language generation: Language Modelling","Natural language generation: Text Summarization","Natural language generation: Document Summarization","Natural language generation: Document Summarization","Natural language generation: Question Generation","Natural language generation: Text Generation","Natural language generation: Text Generation","Natural language generation: Text Generation","Natural language generation: Machine Translation","Natural language generation: Text Summarization","Natural language generation: Text Generation","Natural language generation: Text Summarization","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Language Modelling","Natural language generation: Text Summarization","Natural language generation: Question Generation","Other NLP task: Text-to-Image Generation","Other NLP task: Text-to-Image Generation","Other NLP task: Text-to-Image Generation","Other NLP task: Text-to-Image Generation","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Fake News Detection","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Intent Detection","Pragmatics analysis: Emotion Recognition in Conversation","Pragmatics analysis: Intent Detection","Pragmatics analysis: Emotion Recognition in Conversation","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Intent Detection","Pragmatics analysis: Emotion Recognition in Conversation","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Visual Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Question Answering","Question answering: Visual Question Answering","Question answering: Question Answering","Semantic analysis: Semantic Textual Similarity","Semantic analysis: Semantic Parsing","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Semantic Textual Similarity","Semantic analysis: Semantic Textual Similarity","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Semantic Role Labeling","Semantic analysis: Entity Disambiguation","Semantic analysis: Semantic Parsing","Semantic analysis: Semantic Parsing","Semantic analysis: Semantic Parsing","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Semantic Role Labeling","Semantic analysis: Entity Disambiguation","Semantic analysis: Entity Disambiguation","Sentence embedding: Sentence Compression","Syntactic analysis: Constituency Grammar Induction","Syntactic analysis: Constituency Grammar Induction","Syntactic analysis: Dependency Parsing","Syntactic analysis: Dependency Parsing","Syntactic analysis: Dependency Parsing","Syntactic analysis: Chunking","Syntactic analysis: Chunking","Syntactic analysis: Constituency Parsing","Syntactic analysis: Grammatical Error Detection","Syntactic analysis: Grammatical Error Detection","Syntactic analysis: Linguistic Acceptability Assessment","Syntactic analysis: Constituency Grammar Induction","Text classification: Sentence Classification","Text classification: Sentence Classification","Text classification: Document Classification","Text classification: Citation Intent Classification","Text classification: Sentence Classification","Text classification: Citation Intent Classification","Text classification: Document Classification","Text classification: Document Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Document Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Document Classification","Text classification: Text Classification","Text classification: Text Classification","Text classification: Document Classification","Text classification: Document Classification","Text classification: Text Classification","Text classification: Text Classification"],"type":"scatter","line":{"color":"black","width":0}},{"hovertemplate":["<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2013-10<BR>ratio: 0.1102<BR>benchmarks:<BR>  SST-5 Fine-grained classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2013-10<BR>ratio: 1.0<BR>benchmarks:<BR>  MSRP - Paraphrase Identification benchmarking: Accuracy<BR>  MSRP - Paraphrase Identification benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2014-06<BR>ratio: 0.3305<BR>benchmarks:<BR>  SST-5 Fine-grained classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2014-06<BR>ratio: 0.76<BR>benchmarks:<BR>  WebQuestions - Question Answering benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2014-08<BR>ratio: 0.2308<BR>benchmarks:<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2014-08<BR>ratio: 0.2549<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2014-09<BR>ratio: 0.0886<BR>benchmarks:<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2014-10<BR>ratio: 0.0904<BR>benchmarks:<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Question answering: Question Answering<BR>date: 2014-12<BR>ratio: 0.3032<BR>benchmarks:<BR>  QASent - Question Answering benchmarking: MAP<BR>  QASent - Question Answering benchmarking: MRR<BR>  WikiQA - Question Answering benchmarking: MAP<BR>  WikiQA - Question Answering benchmarking: MRR<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2014-12<BR>ratio: 1.0<BR>benchmarks:<BR>  One Billion Word - Language Modelling benchmarking: PPL<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2015-02<BR>ratio: 0.1186<BR>benchmarks:<BR>  SST-5 Fine-grained classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2015-06<BR>ratio: 0.0427<BR>benchmarks:<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2015-06<BR>ratio: 0.232<BR>benchmarks:<BR>  CNN / Daily Mail - Question Answering benchmarking: CNN<BR>  CNN / Daily Mail - Question Answering benchmarking: Daily Mail<BR>  WebQuestions - Question Answering benchmarking: F1<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2015-08<BR>ratio: 0.5<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Train Accuracy<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2015-09<BR>ratio: 0.1435<BR>benchmarks:<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-L<BR>  GigaWord - Text Summarization benchmarking: ROUGE-1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2015-11<BR>ratio: 0.2159<BR>benchmarks:<BR>  QASent - Question Answering benchmarking: MAP<BR>  QASent - Question Answering benchmarking: MRR<BR>  WikiQA - Question Answering benchmarking: MAP<BR>  WikiQA - Question Answering benchmarking: MRR<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2015-11<BR>ratio: 0.4025<BR>benchmarks:<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Books<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: DVD<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Electronics<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Kitchen<BR>","<BR>task: Text classification: Text Classification<BR>date: 2015-11<BR>ratio: 0.25<BR>benchmarks:<BR>  TREC-6 - Text Classification benchmarking: Error<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2016-01<BR>ratio: 0.483<BR>benchmarks:<BR>  ACE 2004 - Relation Extraction benchmarking: NER Micro F1<BR>  ACE 2004 - Relation Extraction benchmarking: RE+ Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: NER Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: RE+ Micro F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2016-02<BR>ratio: 0.3491<BR>benchmarks:<BR>  IMDb - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2016-02<BR>ratio: 0.3173<BR>benchmarks:<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-1<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-2<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-L<BR>  GigaWord - Text Summarization benchmarking: ROUGE-1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-02<BR>ratio: 0.0718<BR>benchmarks:<BR>  SemEvalCQA - Question Answering benchmarking: P-at-1<BR>  WikiQA - Question Answering benchmarking: MAP<BR>  WikiQA - Question Answering benchmarking: MRR<BR>  YahooCQA - Question Answering benchmarking: MRR<BR>  YahooCQA - Question Answering benchmarking: P-at-1<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2016-03<BR>ratio: 0.1323<BR>benchmarks:<BR>  SemEval 2007 Task 7 - Word Sense Disambiguation benchmarking: F1<BR>  SemEval 2013 Task 12 - Word Sense Disambiguation benchmarking: F1<BR>  SensEval 2 - Word Sense Disambiguation benchmarking: F1<BR>  SensEval 3 Task 1 - Word Sense Disambiguation benchmarking: F1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2016-03<BR>ratio: 0.2757<BR>benchmarks:<BR>  VQA v1 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  VQA v1 test-std - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-03<BR>ratio: 0.5335<BR>benchmarks:<BR>  CNN / Daily Mail - Question Answering benchmarking: CNN<BR>  CNN / Daily Mail - Question Answering benchmarking: Daily Mail<BR>  Children's Book Test - Question Answering benchmarking: Accuracy-CN<BR>  MCTest-500 - Question Answering benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2016-03<BR>ratio: 0.2<BR>benchmarks:<BR>  WMT2015 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Text classification: Document Classification<BR>date: 2016-03<BR>ratio: 0.5215<BR>benchmarks:<BR>  Cora - Document Classification benchmarking: Accuracy<BR>","<BR>task: Syntactic analysis: Dependency Parsing<BR>date: 2016-03<BR>ratio: 0.1966<BR>benchmarks:<BR>  Penn Treebank - Dependency Parsing benchmarking: LAS<BR>  Penn Treebank - Dependency Parsing benchmarking: POS<BR>  Penn Treebank - Dependency Parsing benchmarking: UAS<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2016-05<BR>ratio: 0.2762<BR>benchmarks:<BR>  VQA v1 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  VQA v1 test-std - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2016-06<BR>ratio: 0.542<BR>benchmarks:<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>  WMT2016 English-German - Machine Translation benchmarking: BLEU score<BR>  WMT2016 German-English - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Text classification: Citation Intent Classification<BR>date: 2016-06<BR>ratio: 0.7941<BR>benchmarks:<BR>  ACL-ARC - Citation Intent Classification benchmarking: F1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2016-06<BR>ratio: 0.2999<BR>benchmarks:<BR>  VQA v1 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  VQA v1 test-std - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2016-06<BR>ratio: 0.0702<BR>benchmarks:<BR>  OntoNotes - Coreference Resolution benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-06<BR>ratio: 0.3195<BR>benchmarks:<BR>  CNN / Daily Mail - Question Answering benchmarking: CNN<BR>  CNN / Daily Mail - Question Answering benchmarking: Daily Mail<BR>  Children's Book Test - Question Answering benchmarking: Accuracy-CN<BR>  Children's Book Test - Question Answering benchmarking: Accuracy-NE<BR>  SemEvalCQA - Question Answering benchmarking: MAP<BR>  TrecQA - Question Answering benchmarking: MAP<BR>  TrecQA - Question Answering benchmarking: MRR<BR>  WikiQA - Question Answering benchmarking: MAP<BR>  WikiQA - Question Answering benchmarking: MRR<BR>  bAbi - Question Answering benchmarking: Accuracy (trained on 10k)<BR>  bAbi - Question Answering benchmarking: Accuracy (trained on 1k)<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2016-06<BR>ratio: 0.0771<BR>benchmarks:<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-1<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2016-06<BR>ratio: 0.0678<BR>benchmarks:<BR>  SensEval 2 Lexical Sample - Word Sense Disambiguation benchmarking: F1<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2016-07<BR>ratio: 0.218<BR>benchmarks:<BR>  IWSLT2015 German-English - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2016-07<BR>ratio: 0.094<BR>benchmarks:<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Syntactic analysis: Grammatical Error Detection<BR>date: 2016-07<BR>ratio: 0.9481<BR>benchmarks:<BR>  CoNLL-2014 A2 - Grammatical Error Detection benchmarking: F0.5<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2016-08<BR>ratio: 0.1882<BR>benchmarks:<BR>  WMT2016 English-Romanian - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-08<BR>ratio: 0.3589<BR>benchmarks:<BR>  SQuAD1.1 - Question Answering benchmarking: EM<BR>  SQuAD1.1 - Question Answering benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2016-09<BR>ratio: 0.0286<BR>benchmarks:<BR>  OntoNotes - Coreference Resolution benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-09<BR>ratio: 0.101<BR>benchmarks:<BR>  SQuAD1.1 - Question Answering benchmarking: EM<BR>  SQuAD1.1 - Question Answering benchmarking: F1<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2016-09<BR>ratio: 0.098<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2016-09<BR>ratio: 0.2232<BR>benchmarks:<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2016-09<BR>ratio: 0.5<BR>benchmarks:<BR>  enwik8 - Language Modelling benchmarking: Bit per Character (BPC)<BR>","<BR>task: Text classification: Document Classification<BR>date: 2016-09<BR>ratio: 0.3558<BR>benchmarks:<BR>  Cora - Document Classification benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-10<BR>ratio: 0.6069<BR>benchmarks:<BR>  SQuAD1.1 dev - Question Answering benchmarking: F1<BR>  bAbi - Question Answering benchmarking: Mean Error Rate<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2016-10<BR>ratio: 0.8<BR>benchmarks:<BR>  WMT2015 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2016-11<BR>ratio: 0.5084<BR>benchmarks:<BR>  VQA v1 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  Visual7W - Visual Question Answering benchmarking: Percentage correct<BR>","<BR>task: Text classification: Document Classification<BR>date: 2016-11<BR>ratio: 0.0123<BR>benchmarks:<BR>  Cora - Document Classification benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2016-11<BR>ratio: 0.0632<BR>benchmarks:<BR>  IWSLT2015 German-English - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Question answering: Question Answering<BR>date: 2016-11<BR>ratio: 0.0853<BR>benchmarks:<BR>  SQuAD1.1 dev - Question Answering benchmarking: EM<BR>  SQuAD1.1 dev - Question Answering benchmarking: F1<BR>","<BR>task: Syntactic analysis: Dependency Parsing<BR>date: 2016-11<BR>ratio: 0.8096<BR>benchmarks:<BR>  Penn Treebank - Dependency Parsing benchmarking: LAS<BR>  Penn Treebank - Dependency Parsing benchmarking: UAS<BR>","<BR>task: Syntactic analysis: Chunking<BR>date: 2016-11<BR>ratio: 0.1739<BR>benchmarks:<BR>  Penn Treebank - Chunking benchmarking: F1 score<BR>","<BR>task: Syntactic analysis: Grammatical Error Detection<BR>date: 2016-11<BR>ratio: 0.0711<BR>benchmarks:<BR>  FCE - Grammatical Error Detection benchmarking: F0.5<BR>","<BR>task: Syntactic analysis: Constituency Parsing<BR>date: 2016-11<BR>ratio: 0.4857<BR>benchmarks:<BR>  Penn Treebank - Constituency Parsing benchmarking: F1 score<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2016-12<BR>ratio: 0.7801<BR>benchmarks:<BR>  VQA v2 test-std - Visual Question Answering benchmarking: overall<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2016-12<BR>ratio: 0.6667<BR>benchmarks:<BR>  WikiText-103 - Language Modelling benchmarking: Test perplexity<BR>  WikiText-2 - Language Modelling benchmarking: Test perplexity<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2016-12<BR>ratio: 0.0708<BR>benchmarks:<BR>  CUB - Text-to-Image Generation benchmarking: Inception score<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2017-01<BR>ratio: 0.0597<BR>benchmarks:<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2017-02<BR>ratio: 0.0392<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2017-02<BR>ratio: 0.2857<BR>benchmarks:<BR>  TREC-6 - Text Classification benchmarking: Error<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2017-02<BR>ratio: 0.1937<BR>benchmarks:<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Kitchen<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-03<BR>ratio: 0.033<BR>benchmarks:<BR>  CNN / Daily Mail - Question Answering benchmarking: CNN<BR>  SQuAD1.1 dev - Question Answering benchmarking: EM<BR>  SQuAD1.1 dev - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2017-04<BR>ratio: 0.1026<BR>benchmarks:<BR>  VQA v1 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  VQA v1 test-std - Visual Question Answering benchmarking: Accuracy<BR>  VQA v2 test-dev - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-04<BR>ratio: 0.0174<BR>benchmarks:<BR>  SQuAD1.1 dev - Question Answering benchmarking: EM<BR>  SQuAD1.1 dev - Question Answering benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2017-04<BR>ratio: 0.108<BR>benchmarks:<BR>  Quora Question Pairs - Paraphrase Identification benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2017-04<BR>ratio: 0.1795<BR>benchmarks:<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Semantic Parsing<BR>date: 2017-04<BR>ratio: 0.55<BR>benchmarks:<BR>  ATIS - Semantic Parsing benchmarking: Accuracy<BR>","<BR>task: Syntactic analysis: Grammatical Error Detection<BR>date: 2017-04<BR>ratio: 0.6016<BR>benchmarks:<BR>  FCE - Grammatical Error Detection benchmarking: F0.5<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2017-05<BR>ratio: 0.2253<BR>benchmarks:<BR>  IWSLT2015 English-German - Machine Translation benchmarking: BLEU score<BR>  IWSLT2015 German-English - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-German - Machine Translation benchmarking: BLEU score<BR>  WMT2016 English-Romanian - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-05<BR>ratio: 0.2429<BR>benchmarks:<BR>  SQuAD1.1 - Question Answering benchmarking: EM<BR>  SQuAD1.1 - Question Answering benchmarking: F1<BR>  SQuAD1.1 dev - Question Answering benchmarking: EM<BR>  SQuAD1.1 dev - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2017-05<BR>ratio: 0.2329<BR>benchmarks:<BR>  VQA v2 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  VQA v2 test-std - Visual Question Answering benchmarking: overall<BR>","<BR>task: Natural language generation: Text Generation<BR>date: 2017-05<BR>ratio: 0.3586<BR>benchmarks:<BR>  COCO Captions - Text Generation benchmarking: BLEU-2<BR>  COCO Captions - Text Generation benchmarking: BLEU-3<BR>  COCO Captions - Text Generation benchmarking: BLEU-4<BR>  COCO Captions - Text Generation benchmarking: BLEU-5<BR>  Chinese Poems - Text Generation benchmarking: BLEU-2<BR>  EMNLP2017 WMT - Text Generation benchmarking: BLEU-5<BR>","<BR>task: Natural language generation: Document Summarization<BR>date: 2017-05<BR>ratio: 0.2511<BR>benchmarks:<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-1<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-2<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-L<BR>","<BR>task: Semantic analysis: Entity Disambiguation<BR>date: 2017-05<BR>ratio: 0.921<BR>benchmarks:<BR>  AIDA-CoNLL - Entity Disambiguation benchmarking: In-KB Accuracy<BR>  TAC2010 - Entity Disambiguation benchmarking: Micro Precision<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2017-06<BR>ratio: 0.3615<BR>benchmarks:<BR>  GigaWord - Text Summarization benchmarking: ROUGE-1<BR>  GigaWord - Text Summarization benchmarking: ROUGE-2<BR>  GigaWord - Text Summarization benchmarking: ROUGE-L<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-06<BR>ratio: 0.1524<BR>benchmarks:<BR>  TriviaQA - Question Answering benchmarking: EM<BR>  TriviaQA - Question Answering benchmarking: F1<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2017-06<BR>ratio: 0.4788<BR>benchmarks:<BR>  IWSLT2014 German-English - Machine Translation benchmarking: BLEU score<BR>  IWSLT2015 English-German - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2017-07<BR>ratio: 0.1465<BR>benchmarks:<BR>  CoNLL 2012 - Coreference Resolution benchmarking: Avg F1<BR>  OntoNotes - Coreference Resolution benchmarking: F1<BR>","<BR>task: Syntactic analysis: Grammatical Error Detection<BR>date: 2017-07<BR>ratio: 0.3698<BR>benchmarks:<BR>  CoNLL-2014 A1 - Grammatical Error Detection benchmarking: F0.5<BR>  CoNLL-2014 A2 - Grammatical Error Detection benchmarking: F0.5<BR>  FCE - Grammatical Error Detection benchmarking: F0.5<BR>","<BR>task: Sentence embedding: Sentence Compression<BR>date: 2017-07<BR>ratio: 1.0<BR>benchmarks:<BR>  Google Dataset - Sentence Compression benchmarking: CR<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2017-07<BR>ratio: 0.0632<BR>benchmarks:<BR>  VQA v2 test-std - Visual Question Answering benchmarking: overall<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2017-07<BR>ratio: 1.0<BR>benchmarks:<BR>  Amazon Review Full - Sentiment Analysis benchmarking: Accuracy<BR>  Amazon Review Polarity - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-07<BR>ratio: 0.3933<BR>benchmarks:<BR>  SemEvalCQA - Question Answering benchmarking: MAP<BR>  SemEvalCQA - Question Answering benchmarking: P-at-1<BR>  TrecQA - Question Answering benchmarking: MAP<BR>  TrecQA - Question Answering benchmarking: MRR<BR>  WikiQA - Question Answering benchmarking: MAP<BR>  WikiQA - Question Answering benchmarking: MRR<BR>  YahooCQA - Question Answering benchmarking: MRR<BR>  YahooCQA - Question Answering benchmarking: P-at-1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2017-07<BR>ratio: 0.212<BR>benchmarks:<BR>  ACE 2004 - Relation Extraction benchmarking: RE Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: RE Micro F1<BR>","<BR>task: Syntactic analysis: Constituency Parsing<BR>date: 2017-07<BR>ratio: 0.2457<BR>benchmarks:<BR>  Penn Treebank - Constituency Parsing benchmarking: F1 score<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2017-08<BR>ratio: 0.3456<BR>benchmarks:<BR>  VQA v2 test-dev - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-08<BR>ratio: 0.5<BR>benchmarks:<BR>  AI2 Kaggle Dataset - Question Answering benchmarking: P-at-1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2017-08<BR>ratio: 0.2288<BR>benchmarks:<BR>  SST-5 Fine-grained classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Computer code processing: Code Generation<BR>date: 2017-08<BR>ratio: 0.4269<BR>benchmarks:<BR>  WikiSQL - Code Generation benchmarking: Exact Match Accuracy<BR>  WikiSQL - Code Generation benchmarking: Execution Accuracy<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2017-09<BR>ratio: 0.4385<BR>benchmarks:<BR>  ACE 2005 - Relation Extraction benchmarking: NER Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: RE+ Micro F1<BR>  CoNLL04 - Relation Extraction benchmarking: NER Micro F1<BR>  CoNLL04 - Relation Extraction benchmarking: RE+ Micro F1<BR>","<BR>task: Natural language generation: Text Generation<BR>date: 2017-09<BR>ratio: 0.6226<BR>benchmarks:<BR>  COCO Captions - Text Generation benchmarking: BLEU-2<BR>  COCO Captions - Text Generation benchmarking: BLEU-3<BR>  COCO Captions - Text Generation benchmarking: BLEU-4<BR>  COCO Captions - Text Generation benchmarking: BLEU-5<BR>  EMNLP2017 WMT - Text Generation benchmarking: BLEU-2<BR>  EMNLP2017 WMT - Text Generation benchmarking: BLEU-3<BR>  EMNLP2017 WMT - Text Generation benchmarking: BLEU-4<BR>  EMNLP2017 WMT - Text Generation benchmarking: BLEU-5<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2017-09<BR>ratio: 0.3099<BR>benchmarks:<BR>  Quora Question Pairs - Paraphrase Identification benchmarking: Accuracy<BR>","<BR>task: Dialog process: Dialog Act Classification<BR>date: 2017-09<BR>ratio: 0.7439<BR>benchmarks:<BR>  Switchboard corpus - Dialog Act Classification benchmarking: Accuracy<BR>","<BR>task: Dialog process: Visual Dialog<BR>date: 2017-09<BR>ratio: 0.3904<BR>benchmarks:<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-10<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-1<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-5<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2017-09<BR>ratio: 0.0196<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2017-09<BR>ratio: 0.0407<BR>benchmarks:<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2013<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2017-10<BR>ratio: 0.7021<BR>benchmarks:<BR>  CUB - Text-to-Image Generation benchmarking: FID<BR>  CUB - Text-to-Image Generation benchmarking: Inception score<BR>  Oxford 102 Flowers - Text-to-Image Generation benchmarking: Inception score<BR>","<BR>task: Text classification: Document Classification<BR>date: 2017-10<BR>ratio: 0.0798<BR>benchmarks:<BR>  Cora - Document Classification benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-10<BR>ratio: 0.6272<BR>benchmarks:<BR>  TriviaQA - Question Answering benchmarking: EM<BR>  TriviaQA - Question Answering benchmarking: F1<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2017-11<BR>ratio: 0.6346<BR>benchmarks:<BR>  COCO - Text-to-Image Generation benchmarking: Inception score<BR>  CUB - Text-to-Image Generation benchmarking: Inception score<BR>","<BR>task: Dialog process: Visual Dialog<BR>date: 2017-11<BR>ratio: 0.2578<BR>benchmarks:<BR>  VisDial v0.9 val - Visual Dialog benchmarking: MRR<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-10<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-1<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-5<BR>","<BR>task: Dialog process: Dialog Act Classification<BR>date: 2017-11<BR>ratio: 0.2561<BR>benchmarks:<BR>  Switchboard corpus - Dialog Act Classification benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2017-11<BR>ratio: 0.0459<BR>benchmarks:<BR>  IWSLT2015 German-English - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2017-11<BR>ratio: 0.0392<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Pragmatics analysis: Fake News Detection<BR>date: 2017-12<BR>ratio: 0.9439<BR>benchmarks:<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Agree)<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Disagree)<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Discuss)<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Unrelated)<BR>  FNC-1 - Fake News Detection benchmarking: Weighted Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2017-12<BR>ratio: 0.1476<BR>benchmarks:<BR>  IMDb - Sentiment Analysis benchmarking: Accuracy<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Semantic Role Labeling<BR>date: 2017-12<BR>ratio: 0.1887<BR>benchmarks:<BR>  OntoNotes - Semantic Role Labeling benchmarking: F1<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2017-12<BR>ratio: 0.0392<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2017-12<BR>ratio: 0.0571<BR>benchmarks:<BR>  SQuAD2.0 - Question Answering benchmarking: EM<BR>  SQuAD2.0 - Question Answering benchmarking: F1<BR>","<BR>task: Text classification: Citation Intent Classification<BR>date: 2018-01<BR>ratio: 0.0882<BR>benchmarks:<BR>  ACL-ARC - Citation Intent Classification benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-01<BR>ratio: 0.4672<BR>benchmarks:<BR>  NewsQA - Question Answering benchmarking: EM<BR>  NewsQA - Question Answering benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2018-01<BR>ratio: 0.0809<BR>benchmarks:<BR>  IMDb - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Semantic Role Labeling<BR>date: 2018-02<BR>ratio: 0.3585<BR>benchmarks:<BR>  OntoNotes - Semantic Role Labeling benchmarking: F1<BR>","<BR>task: Natural language generation: Text Generation<BR>date: 2018-02<BR>ratio: 0.8333<BR>benchmarks:<BR>  Yahoo Questions - Text Generation benchmarking: Perplexity<BR>","<BR>task: Text classification: Citation Intent Classification<BR>date: 2018-02<BR>ratio: 0.1176<BR>benchmarks:<BR>  ACL-ARC - Citation Intent Classification benchmarking: F1<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2018-02<BR>ratio: 0.0238<BR>benchmarks:<BR>  Supervised: - Word Sense Disambiguation benchmarking: Senseval 3<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2018-02<BR>ratio: 0.2079<BR>benchmarks:<BR>  OntoNotes - Coreference Resolution benchmarking: F1<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-02<BR>ratio: 0.4381<BR>benchmarks:<BR>  WMT2014 German-English - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2018-02<BR>ratio: 0.3667<BR>benchmarks:<BR>  MR - Sentiment Analysis benchmarking: Accuracy<BR>  SST-5 Fine-grained classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Information retrieval: Conversational Response Selection<BR>date: 2018-03<BR>ratio: 0.541<BR>benchmarks:<BR>  PolyAI Reddit - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2018-03<BR>ratio: 0.0357<BR>benchmarks:<BR>  TREC-6 - Text Classification benchmarking: Error<BR>","<BR>task: Computer code processing: Code Generation<BR>date: 2018-03<BR>ratio: 0.2009<BR>benchmarks:<BR>  WikiSQL - Code Generation benchmarking: Exact Match Accuracy<BR>  WikiSQL - Code Generation benchmarking: Execution Accuracy<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2018-03<BR>ratio: 0.1587<BR>benchmarks:<BR>  MSRVTT-QA - Visual Question Answering benchmarking: Accuracy<BR>  MSVD-QA - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2018-03<BR>ratio: 1.0<BR>benchmarks:<BR>  WikiText-103 - Language Modelling benchmarking: Validation perplexity<BR>","<BR>task: Semantic analysis: Semantic Textual Similarity<BR>date: 2018-03<BR>ratio: 1.0<BR>benchmarks:<BR>  SentEval - Semantic Textual Similarity benchmarking: SICK-E<BR>  SentEval - Semantic Textual Similarity benchmarking: SICK-R<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-03<BR>ratio: 0.0152<BR>benchmarks:<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-04<BR>ratio: 0.5921<BR>benchmarks:<BR>  WikiHop - Question Answering benchmarking: Test<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2018-04<BR>ratio: 0.2234<BR>benchmarks:<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Books<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: DVD<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Electronics<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2018-04<BR>ratio: 0.245<BR>benchmarks:<BR>  CoNLL 2012 - Coreference Resolution benchmarking: Avg F1<BR>  OntoNotes - Coreference Resolution benchmarking: F1<BR>","<BR>task: Computer code processing: Code Generation<BR>date: 2018-04<BR>ratio: 0.137<BR>benchmarks:<BR>  WikiSQL - Code Generation benchmarking: Execution Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2018-04<BR>ratio: 0.0412<BR>benchmarks:<BR>  MultiNLI - Natural Language Inference benchmarking: Matched<BR>  MultiNLI - Natural Language Inference benchmarking: Mismatched<BR>","<BR>task: Semantic analysis: Semantic Role Labeling<BR>date: 2018-05<BR>ratio: 0.1698<BR>benchmarks:<BR>  OntoNotes - Semantic Role Labeling benchmarking: F1<BR>","<BR>task: Syntactic analysis: Constituency Parsing<BR>date: 2018-05<BR>ratio: 0.1343<BR>benchmarks:<BR>  Penn Treebank - Constituency Parsing benchmarking: F1 score<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2018-05<BR>ratio: 0.1569<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Dialog process: Dialog State Tracking<BR>date: 2018-05<BR>ratio: 0.8365<BR>benchmarks:<BR>  Second dialogue state tracking challenge - Dialog State Tracking benchmarking: Joint<BR>  Second dialogue state tracking challenge - Dialog State Tracking benchmarking: Request<BR>  Wizard-of-Oz - Dialog State Tracking benchmarking: Joint<BR>  Wizard-of-Oz - Dialog State Tracking benchmarking: Request<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2018-05<BR>ratio: 0.0536<BR>benchmarks:<BR>  SemEval 2015 Task 13 - Word Sense Disambiguation benchmarking: F1<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2013<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2015<BR>  Supervised: - Word Sense Disambiguation benchmarking: Senseval 2<BR>  Supervised: - Word Sense Disambiguation benchmarking: Senseval 3<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2018-05<BR>ratio: 1.0<BR>benchmarks:<BR>  Event2Mind test - Common Sense Reasoning benchmarking: Average Cross-Ent<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-05<BR>ratio: 0.7182<BR>benchmarks:<BR>  MS MARCO - Question Answering benchmarking: BLEU-1<BR>  MS MARCO - Question Answering benchmarking: Rouge-L<BR>  NewsQA - Question Answering benchmarking: EM<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2018-05<BR>ratio: 0.2896<BR>benchmarks:<BR>  MPQA - Sentiment Analysis benchmarking: Accuracy<BR>  MR - Sentiment Analysis benchmarking: Accuracy<BR>  SST-5 Fine-grained classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2018-05<BR>ratio: 0.3299<BR>benchmarks:<BR>  TREC-6 - Text Classification benchmarking: Error<BR>  Yahoo! Answers - Text Classification benchmarking: Accuracy<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2018-05<BR>ratio: 0.0126<BR>benchmarks:<BR>  VQA v2 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  VQA v2 test-std - Visual Question Answering benchmarking: overall<BR>","<BR>task: Pragmatics analysis: Emotion Recognition in Conversation<BR>date: 2018-06<BR>ratio: 0.7567<BR>benchmarks:<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Accuracy<BR>  SEMAINE - Emotion Recognition in Conversation benchmarking: MAE (Expectancy)<BR>  SEMAINE - Emotion Recognition in Conversation benchmarking: MAE (Power)<BR>  SEMAINE - Emotion Recognition in Conversation benchmarking: MAE (Valence)<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-06<BR>ratio: 0.154<BR>benchmarks:<BR>  IWSLT2015 English-Vietnamese - Machine Translation benchmarking: BLEU<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-06<BR>ratio: 0.3862<BR>benchmarks:<BR>  RACE - Question Answering benchmarking: RACE-h<BR>  RACE - Question Answering benchmarking: RACE-m<BR>  RACE - Question Answering benchmarking: RACE<BR>  Story Cloze Test - Question Answering benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2018-06<BR>ratio: 0.6132<BR>benchmarks:<BR>  MultiNLI - Natural Language Inference benchmarking: Matched<BR>  MultiNLI - Natural Language Inference benchmarking: Mismatched<BR>  SciTail - Natural Language Inference benchmarking: Accuracy<BR>  V-SNLI - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Question Generation<BR>date: 2018-06<BR>ratio: 0.0673<BR>benchmarks:<BR>  SQuAD1.1 - Question Generation benchmarking: BLEU-4<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-07<BR>ratio: 1.0<BR>benchmarks:<BR>  Quasart-T - Question Answering benchmarking: EM<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2018-07<BR>ratio: 0.0282<BR>benchmarks:<BR>  Quora Question Pairs - Paraphrase Identification benchmarking: Accuracy<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2018-07<BR>ratio: 0.3122<BR>benchmarks:<BR>  NYT - Relation Extraction benchmarking: F1<BR>  WebNLG - Relation Extraction benchmarking: F1<BR>","<BR>task: Sentence embedding: Sentence Compression<BR>date: 2018-07<BR>ratio: 1.0<BR>benchmarks:<BR>  Google Dataset - Sentence Compression benchmarking: F1<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2018-07<BR>ratio: 0.0553<BR>benchmarks:<BR>  GigaWord - Text Summarization benchmarking: ROUGE-2<BR>","<BR>task: Syntactic analysis: Dependency Parsing<BR>date: 2018-07<BR>ratio: 0.791<BR>benchmarks:<BR>  Penn Treebank - Dependency Parsing benchmarking: POS<BR>","<BR>task: Text classification: Text Classification<BR>date: 2018-07<BR>ratio: 0.5132<BR>benchmarks:<BR>  Yahoo! Answers - Text Classification benchmarking: Accuracy<BR>","<BR>task: Syntactic analysis: Chunking<BR>date: 2018-08<BR>ratio: 0.913<BR>benchmarks:<BR>  CoNLL 2000 - Chunking benchmarking: Exact Span F1<BR>  Penn Treebank - Chunking benchmarking: F1 score<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2018-08<BR>ratio: 0.4463<BR>benchmarks:<BR>  ADE Corpus - Relation Extraction benchmarking: NER Macro F1<BR>  ADE Corpus - Relation Extraction benchmarking: RE+ Macro F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2018-08<BR>ratio: 1.0<BR>benchmarks:<BR>  Long-tail emerging entities - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Syntactic analysis: Constituency Grammar Induction<BR>date: 2018-08<BR>ratio: 0.0714<BR>benchmarks:<BR>  PTB - Constituency Grammar Induction benchmarking: Mean F1 (WSJ)<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-08<BR>ratio: 0.2718<BR>benchmarks:<BR>  CoQA - Question Answering benchmarking: In-domain<BR>  CoQA - Question Answering benchmarking: Out-of-domain<BR>  CoQA - Question Answering benchmarking: Overall<BR>  SQuAD2.0 - Question Answering benchmarking: EM<BR>  SQuAD2.0 - Question Answering benchmarking: F1<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2018-08<BR>ratio: 0.2449<BR>benchmarks:<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-1<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-2<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-L<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-1<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-2<BR>","<BR>task: Text classification: Document Classification<BR>date: 2018-08<BR>ratio: 0.0184<BR>benchmarks:<BR>  Cora - Document Classification benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Document Summarization<BR>date: 2018-08<BR>ratio: 0.5122<BR>benchmarks:<BR>  CNN / Daily Mail - Document Summarization benchmarking: PPL<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-1<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-2<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-L<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-08<BR>ratio: 0.226<BR>benchmarks:<BR>  IWSLT2015 English-Vietnamese - Machine Translation benchmarking: BLEU<BR>  IWSLT2015 German-English - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-French - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Text classification: Text Classification<BR>date: 2018-08<BR>ratio: 1.0<BR>benchmarks:<BR>  AG News - Text Classification benchmarking: Error<BR>","<BR>task: Dialog process: Visual Dialog<BR>date: 2018-09<BR>ratio: 0.1442<BR>benchmarks:<BR>  VisDial v0.9 val - Visual Dialog benchmarking: MRR<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-1<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: MRR (x 100)<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: Mean<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-10<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-1<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-5<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-09<BR>ratio: 0.0699<BR>benchmarks:<BR>  IWSLT2015 English-Vietnamese - Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Language Modelling<BR>date: 2018-09<BR>ratio: 1.0<BR>benchmarks:<BR>  One Billion Word - Language Modelling benchmarking: Validation perplexity<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2018-09<BR>ratio: 0.3185<BR>benchmarks:<BR>  Re-TACRED - Relation Extraction benchmarking: F1<BR>  TACRED - Relation Extraction benchmarking: F1<BR>","<BR>task: Text classification: Text Classification<BR>date: 2018-09<BR>ratio: 0.652<BR>benchmarks:<BR>  Ohsumed - Text Classification benchmarking: Accuracy<BR>  R8 - Text Classification benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2018-09<BR>ratio: 0.2353<BR>benchmarks:<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-09<BR>ratio: 0.2419<BR>benchmarks:<BR>  CoQA - Question Answering benchmarking: In-domain<BR>  CoQA - Question Answering benchmarking: Out-of-domain<BR>  CoQA - Question Answering benchmarking: Overall<BR>  NarrativeQA - Question Answering benchmarking: BLEU-1<BR>  NarrativeQA - Question Answering benchmarking: BLEU-4<BR>  NarrativeQA - Question Answering benchmarking: Rouge-L<BR>  WikiHop - Question Answering benchmarking: Test<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-10<BR>ratio: 0.196<BR>benchmarks:<BR>  CoQA - Question Answering benchmarking: In-domain<BR>  CoQA - Question Answering benchmarking: Out-of-domain<BR>  CoQA - Question Answering benchmarking: Overall<BR>  NarrativeQA - Question Answering benchmarking: BLEU-4<BR>  NarrativeQA - Question Answering benchmarking: Rouge-L<BR>  SQuAD1.1 - Question Answering benchmarking: EM<BR>  SQuAD1.1 - Question Answering benchmarking: F1<BR>  SQuAD1.1 dev - Question Answering benchmarking: EM<BR>  SQuAD1.1 dev - Question Answering benchmarking: F1<BR>  SQuAD2.0 - Question Answering benchmarking: EM<BR>  SQuAD2.0 - Question Answering benchmarking: F1<BR>  SQuAD2.0 dev - Question Answering benchmarking: EM<BR>  SQuAD2.0 dev - Question Answering benchmarking: F1<BR>  TriviaQA - Question Answering benchmarking: EM<BR>  TriviaQA - Question Answering benchmarking: F1<BR>","<BR>task: Computer code processing: Code Generation<BR>date: 2018-10<BR>ratio: 0.5481<BR>benchmarks:<BR>  Django - Code Generation benchmarking: Accuracy<BR>  WikiSQL - Code Generation benchmarking: Exact Match Accuracy<BR>","<BR>task: Dialog process: Dialog State Tracking<BR>date: 2018-10<BR>ratio: 0.327<BR>benchmarks:<BR>  Second dialogue state tracking challenge - Dialog State Tracking benchmarking: Joint<BR>  Wizard-of-Oz - Dialog State Tracking benchmarking: Joint<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2018-10<BR>ratio: 0.2054<BR>benchmarks:<BR>  ACE 2005 - Named Entity Recognition benchmarking: F1<BR>  GENIA - Named Entity Recognition benchmarking: F1<BR>  SciERC - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Machine translation: Unsupervised Machine Translation<BR>date: 2018-10<BR>ratio: 0.15<BR>benchmarks:<BR>  WMT2016 German-English - Unsupervised Machine Translation benchmarking: BLEU<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2018-10<BR>ratio: 0.3426<BR>benchmarks:<BR>  SciTail - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Syntactic analysis: Constituency Grammar Induction<BR>date: 2018-10<BR>ratio: 0.2123<BR>benchmarks:<BR>  PTB - Constituency Grammar Induction benchmarking: Max F1 (WSJ)<BR>  PTB - Constituency Grammar Induction benchmarking: Mean F1 (WSJ)<BR>  PTB - Constituency Grammar Induction benchmarking: Mean F1 (WSJ10)<BR>","<BR>task: Semantic analysis: Semantic Parsing<BR>date: 2018-10<BR>ratio: 0.45<BR>benchmarks:<BR>  ATIS - Semantic Parsing benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Emotion Recognition in Conversation<BR>date: 2018-10<BR>ratio: 0.2577<BR>benchmarks:<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Accuracy<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Macro-F1<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Weighted-F1<BR>","<BR>task: Semantic analysis: Semantic Role Labeling<BR>date: 2018-10<BR>ratio: 0.4277<BR>benchmarks:<BR>  CoNLL 2005 - Semantic Role Labeling benchmarking: F1<BR>  OntoNotes - Semantic Role Labeling benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2018-10<BR>ratio: 0.4178<BR>benchmarks:<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Books<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: DVD<BR>  Multi-Domain Sentiment Dataset - Sentiment Analysis benchmarking: Kitchen<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2018-10<BR>ratio: 0.6276<BR>benchmarks:<BR>  SWAG - Common Sense Reasoning benchmarking: Dev<BR>  SWAG - Common Sense Reasoning benchmarking: Test<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2018-10<BR>ratio: 1.0<BR>benchmarks:<BR>  WMT 2017 Latvian-English - Machine Translation benchmarking: BLEU<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2018-10<BR>ratio: 0.1963<BR>benchmarks:<BR>  ACE 2005 - Relation Extraction benchmarking: RE+ Micro F1<BR>","<BR>task: Text classification: Sentence Classification<BR>date: 2018-10<BR>ratio: 0.9057<BR>benchmarks:<BR>  SciCite - Sentence Classification benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Fake News Detection<BR>date: 2018-11<BR>ratio: 0.1404<BR>benchmarks:<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Agree)<BR>  FNC-1 - Fake News Detection benchmarking: Per-class Accuracy (Disagree)<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2018-11<BR>ratio: 0.2719<BR>benchmarks:<BR>  SemEval 2007 Task 17 - Word Sense Disambiguation benchmarking: F1<BR>  SemEval 2007 Task 7 - Word Sense Disambiguation benchmarking: F1<BR>  SemEval 2013 Task 12 - Word Sense Disambiguation benchmarking: F1<BR>  SemEval 2015 Task 13 - Word Sense Disambiguation benchmarking: F1<BR>  SensEval 2 - Word Sense Disambiguation benchmarking: F1<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2007<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2013<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2015<BR>  Supervised: - Word Sense Disambiguation benchmarking: Senseval 2<BR>","<BR>task: Syntactic analysis: Grammatical Error Detection<BR>date: 2018-11<BR>ratio: 0.2698<BR>benchmarks:<BR>  FCE - Grammatical Error Detection benchmarking: F0.5<BR>","<BR>task: Question answering: Question Answering<BR>date: 2018-11<BR>ratio: 0.1449<BR>benchmarks:<BR>  MS MARCO - Question Answering benchmarking: BLEU-1<BR>  MS MARCO - Question Answering benchmarking: Rouge-L<BR>  NarrativeQA - Question Answering benchmarking: BLEU-1<BR>  NarrativeQA - Question Answering benchmarking: BLEU-4<BR>  NewsQA - Question Answering benchmarking: EM<BR>  NewsQA - Question Answering benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Emotion Recognition in Conversation<BR>date: 2018-11<BR>ratio: 0.5661<BR>benchmarks:<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Accuracy<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Macro-F1<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Weighted-F1<BR>  MELD - Emotion Recognition in Conversation benchmarking: Accuracy<BR>  MELD - Emotion Recognition in Conversation benchmarking: Weighted-F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2018-12<BR>ratio: 1.0<BR>benchmarks:<BR>  CoNLL04 - Relation Extraction benchmarking: NER Macro F1<BR>  CoNLL04 - Relation Extraction benchmarking: RE+ Macro F1<BR>  NYT Corpus - Relation Extraction benchmarking: P-at-10%<BR>  NYT Corpus - Relation Extraction benchmarking: P-at-30%<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-01<BR>ratio: 0.2041<BR>benchmarks:<BR>  MS MARCO - Question Answering benchmarking: Rouge-L<BR>  NarrativeQA - Question Answering benchmarking: BLEU-1<BR>  NarrativeQA - Question Answering benchmarking: BLEU-4<BR>  NarrativeQA - Question Answering benchmarking: Rouge-L<BR>  WikiHop - Question Answering benchmarking: Test<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2019-01<BR>ratio: 1.0<BR>benchmarks:<BR>  NCBI-disease - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-01<BR>ratio: 0.6137<BR>benchmarks:<BR>  IMDb - Text Classification benchmarking: Accuracy (2 classes)<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2019-01<BR>ratio: 0.3456<BR>benchmarks:<BR>  MultiNLI - Natural Language Inference benchmarking: Matched<BR>  MultiNLI - Natural Language Inference benchmarking: Mismatched<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>  SciTail - Natural Language Inference benchmarking: Accuracy<BR>  XNLI French - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2019-01<BR>ratio: 1.0<BR>benchmarks:<BR>  COCO - Text-to-Image Generation benchmarking: FID<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-01<BR>ratio: 0.7765<BR>benchmarks:<BR>  IWSLT2014 German-English - Machine Translation benchmarking: BLEU score<BR>  WMT 2017 English-Chinese - Machine Translation benchmarking: BLEU score<BR>  WMT2014 English-Czech - Machine Translation benchmarking: BLEU score<BR>  WMT2016 Romanian-English - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Information retrieval: Conversational Response Selection<BR>date: 2019-01<BR>ratio: 0.3558<BR>benchmarks:<BR>  DSTC7 Ubuntu - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2019-01<BR>ratio: 0.2254<BR>benchmarks:<BR>  Quora Question Pairs - Paraphrase Identification benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2019-01<BR>ratio: 0.5299<BR>benchmarks:<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>  Yelp Fine-grained classification - Sentiment Analysis benchmarking: Error<BR>","<BR>task: Machine translation: Unsupervised Machine Translation<BR>date: 2019-01<BR>ratio: 0.4127<BR>benchmarks:<BR>  WMT2014 English-French - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2014 French-English - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 English-German - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 German-English - Unsupervised Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Text Generation<BR>date: 2019-01<BR>ratio: 0.1667<BR>benchmarks:<BR>  Yahoo Questions - Text Generation benchmarking: Perplexity<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-02<BR>ratio: 0.4587<BR>benchmarks:<BR>  GQA test-std - Visual Question Answering benchmarking: Accuracy<BR>  VQA-CP - Visual Question Answering benchmarking: Score<BR>","<BR>task: Dialog process: Visual Dialog<BR>date: 2019-02<BR>ratio: 0.1426<BR>benchmarks:<BR>  VisDial v0.9 val - Visual Dialog benchmarking: MRR<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-10<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-1<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-5<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: MRR (x 100)<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: Mean<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-10<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-1<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-5<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-02<BR>ratio: 0.3546<BR>benchmarks:<BR>  20NEWS - Text Classification benchmarking: Accuracy<BR>  Ohsumed - Text Classification benchmarking: Accuracy<BR>  R52 - Text Classification benchmarking: Accuracy<BR>  R8 - Text Classification benchmarking: Accuracy<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-02<BR>ratio: 0.8067<BR>benchmarks:<BR>  Children's Book Test - Question Answering benchmarking: Accuracy-CN<BR>  Children's Book Test - Question Answering benchmarking: Accuracy-NE<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2019-02<BR>ratio: 1.0<BR>benchmarks:<BR>  Winograd Schema Challenge - Common Sense Reasoning benchmarking: Score<BR>","<BR>task: Machine translation: Unsupervised Machine Translation<BR>date: 2019-02<BR>ratio: 0.397<BR>benchmarks:<BR>  WMT2014 English-French - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2014 English-German - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2014 French-English - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2014 German-English - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 English-German - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 German-English - Unsupervised Machine Translation benchmarking: BLEU<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-02<BR>ratio: 0.3333<BR>benchmarks:<BR>  SemEval-2010 Task 8 - Relation Extraction benchmarking: F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2019-03<BR>ratio: 0.666<BR>benchmarks:<BR>  BC5CDR - Named Entity Recognition benchmarking: F1<BR>  SciERC - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Syntactic analysis: Constituency Parsing<BR>date: 2019-03<BR>ratio: 0.1343<BR>benchmarks:<BR>  Penn Treebank - Constituency Parsing benchmarking: F1 score<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2019-03<BR>ratio: 0.1016<BR>benchmarks:<BR>  COCO - Text-to-Image Generation benchmarking: Inception score<BR>  CUB - Text-to-Image Generation benchmarking: Inception score<BR>","<BR>task: Text classification: Sentence Classification<BR>date: 2019-03<BR>ratio: 0.6981<BR>benchmarks:<BR>  ACL-ARC - Sentence Classification benchmarking: F1<BR>  SciCite - Sentence Classification benchmarking: F1<BR>  ScienceCite - Sentence Classification benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-03<BR>ratio: 1.0<BR>benchmarks:<BR>  ChemProt - Relation Extraction benchmarking: F1<BR>  SciERC - Relation Extraction benchmarking: F1<BR>","<BR>task: Natural language generation: Document Summarization<BR>date: 2019-03<BR>ratio: 0.3031<BR>benchmarks:<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-1<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-2<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-L<BR>","<BR>task: Pragmatics analysis: Emotion Recognition in Conversation<BR>date: 2019-04<BR>ratio: 1.0<BR>benchmarks:<BR>  EC - Emotion Recognition in Conversation benchmarking: Micro-F1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-04<BR>ratio: 0.3147<BR>benchmarks:<BR>  MSRVTT-QA - Visual Question Answering benchmarking: Accuracy<BR>  MSVD-QA - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Syntactic analysis: Constituency Grammar Induction<BR>date: 2019-04<BR>ratio: 0.1967<BR>benchmarks:<BR>  PTB - Constituency Grammar Induction benchmarking: Max F1 (WSJ)<BR>","<BR>task: Information extraction: Joint Entity and Relation Extraction<BR>date: 2019-04<BR>ratio: 0.2778<BR>benchmarks:<BR>  SciERC - Joint Entity and Relation Extraction benchmarking: Entity F1<BR>  SciERC - Joint Entity and Relation Extraction benchmarking: Relation F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-04<BR>ratio: 0.7252<BR>benchmarks:<BR>  ACE 2004 - Relation Extraction benchmarking: NER Micro F1<BR>  ACE 2004 - Relation Extraction benchmarking: RE Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: NER Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: RE Micro F1<BR>","<BR>task: Information extraction: Chinese Named Entity Recognition<BR>date: 2019-04<BR>ratio: 0.2995<BR>benchmarks:<BR>  MSRA - Chinese Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information retrieval: Conversational Response Selection<BR>date: 2019-04<BR>ratio: 0.2915<BR>benchmarks:<BR>  DSTC7 Ubuntu - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>  PolyAI Reddit - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2019-04<BR>ratio: 0.5876<BR>benchmarks:<BR>  COCO - Text-to-Image Generation benchmarking: Inception score<BR>  COCO - Text-to-Image Generation benchmarking: SOA-C<BR>  CUB - Text-to-Image Generation benchmarking: Inception score<BR>  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking: Acc<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2019-04<BR>ratio: 0.5763<BR>benchmarks:<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-1<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-2<BR>  DUC 2004 Task 1 - Text Summarization benchmarking: ROUGE-L<BR>","<BR>task: Text classification: Document Classification<BR>date: 2019-04<BR>ratio: 0.0123<BR>benchmarks:<BR>  Cora - Document Classification benchmarking: Accuracy<BR>","<BR>task: Dialog process: Visual Dialog<BR>date: 2019-04<BR>ratio: 0.4213<BR>benchmarks:<BR>  VisDial v0.9 val - Visual Dialog benchmarking: MRR<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-10<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-1<BR>  VisDial v0.9 val - Visual Dialog benchmarking: R-at-5<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: MRR (x 100)<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: Mean<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-10<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-1<BR>  Visual Dialog v1.0 test-std - Visual Dialog benchmarking: R-at-5<BR>","<BR>task: Natural language generation: Document Summarization<BR>date: 2019-05<BR>ratio: 0.0901<BR>benchmarks:<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-2<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-L<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-05<BR>ratio: 0.2987<BR>benchmarks:<BR>  IWSLT2014 German-English - Machine Translation benchmarking: BLEU score<BR>  WMT2016 English-German - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Machine translation: Unsupervised Machine Translation<BR>date: 2019-05<BR>ratio: 0.3157<BR>benchmarks:<BR>  WMT2014 English-French - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2014 French-English - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 English-German - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 German-English - Unsupervised Machine Translation benchmarking: BLEU<BR>  WMT2016 Romanian-English - Unsupervised Machine Translation benchmarking: BLEU<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2019-05<BR>ratio: 0.3432<BR>benchmarks:<BR>  IMDb - Sentiment Analysis benchmarking: Accuracy<BR>  MPQA - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Semantic Textual Similarity<BR>date: 2019-05<BR>ratio: 0.4748<BR>benchmarks:<BR>  MRPC - Semantic Textual Similarity benchmarking: Accuracy<BR>  STS Benchmark - Semantic Textual Similarity benchmarking: Pearson Correlation<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2019-05<BR>ratio: 0.6752<BR>benchmarks:<BR>  SemEval 2007 Task 17 - Word Sense Disambiguation benchmarking: F1<BR>  SemEval 2007 Task 7 - Word Sense Disambiguation benchmarking: F1<BR>  SemEval 2013 Task 12 - Word Sense Disambiguation benchmarking: F1<BR>  SemEval 2015 Task 13 - Word Sense Disambiguation benchmarking: F1<BR>  SensEval 2 - Word Sense Disambiguation benchmarking: F1<BR>  SensEval 3 Task 1 - Word Sense Disambiguation benchmarking: F1<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2007<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2013<BR>  Supervised: - Word Sense Disambiguation benchmarking: SemEval 2015<BR>  Supervised: - Word Sense Disambiguation benchmarking: Senseval 2<BR>  Supervised: - Word Sense Disambiguation benchmarking: Senseval 3<BR>","<BR>task: Natural language generation: Question Generation<BR>date: 2019-05<BR>ratio: 0.9327<BR>benchmarks:<BR>  SQuAD1.1 - Question Generation benchmarking: BLEU-4<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-05<BR>ratio: 0.4235<BR>benchmarks:<BR>  VQA-CP - Visual Question Answering benchmarking: Score<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-05<BR>ratio: 0.4549<BR>benchmarks:<BR>  IMDb - Text Classification benchmarking: Accuracy (2 classes)<BR>  Sogou News - Text Classification benchmarking: Accuracy<BR>  Yahoo! Answers - Text Classification benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2019-05<BR>ratio: 0.2911<BR>benchmarks:<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-1<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-2<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-L<BR>  GigaWord - Text Summarization benchmarking: ROUGE-1<BR>  GigaWord - Text Summarization benchmarking: ROUGE-2<BR>  GigaWord - Text Summarization benchmarking: ROUGE-L<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-05<BR>ratio: 0.4942<BR>benchmarks:<BR>  TrecQA - Question Answering benchmarking: MAP<BR>  TrecQA - Question Answering benchmarking: MRR<BR>  WikiQA - Question Answering benchmarking: MAP<BR>  WikiQA - Question Answering benchmarking: MRR<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-05<BR>ratio: 0.2659<BR>benchmarks:<BR>  ACE 2004 - Relation Extraction benchmarking: RE+ Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: RE+ Micro F1<BR>  ADE Corpus - Relation Extraction benchmarking: NER Macro F1<BR>  ADE Corpus - Relation Extraction benchmarking: RE+ Macro F1<BR>  CoNLL04 - Relation Extraction benchmarking: NER Micro F1<BR>  CoNLL04 - Relation Extraction benchmarking: RE+ Micro F1<BR>  SemEval-2010 Task 8 - Relation Extraction benchmarking: F1<BR>  TACRED - Relation Extraction benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Intent Detection<BR>date: 2019-06<BR>ratio: 1.0<BR>benchmarks:<BR>  ATIS - Intent Detection benchmarking: Accuracy<BR>  SNIPS - Intent Detection benchmarking: Slot F1 Score<BR>","<BR>task: Syntactic analysis: Linguistic Acceptability Assessment<BR>date: 2019-06<BR>ratio: 0.8571<BR>benchmarks:<BR>  CoLA - Linguistic Acceptability Assessment benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2019-06<BR>ratio: 0.5<BR>benchmarks:<BR>  MultiNLI - Natural Language Inference benchmarking: Matched<BR>  QNLI - Natural Language Inference benchmarking: Accuracy<BR>  RTE - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2019-06<BR>ratio: 0.0675<BR>benchmarks:<BR>  IMDb - Sentiment Analysis benchmarking: Accuracy<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-06<BR>ratio: 0.5346<BR>benchmarks:<BR>  IMDb - Text Classification benchmarking: Accuracy (2 classes)<BR>  R52 - Text Classification benchmarking: Accuracy<BR>  R8 - Text Classification benchmarking: Accuracy<BR>  Yelp-2 - Text Classification benchmarking: Accuracy<BR>","<BR>task: Syntactic analysis: Constituency Grammar Induction<BR>date: 2019-06<BR>ratio: 0.5765<BR>benchmarks:<BR>  PTB - Constituency Grammar Induction benchmarking: Max F1 (WSJ)<BR>  PTB - Constituency Grammar Induction benchmarking: Max F1 (WSJ10)<BR>  PTB - Constituency Grammar Induction benchmarking: Mean F1 (WSJ)<BR>  PTB - Constituency Grammar Induction benchmarking: Mean F1 (WSJ10)<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-06<BR>ratio: 0.5752<BR>benchmarks:<BR>  IWSLT2015 German-English - Machine Translation benchmarking: BLEU score<BR>  WMT 2018 Finnish-English - Machine Translation benchmarking: BLEU<BR>","<BR>task: Pragmatics analysis: Paraphrase Identification<BR>date: 2019-06<BR>ratio: 0.6643<BR>benchmarks:<BR>  Quora Question Pairs - Paraphrase Identification benchmarking: Accuracy<BR>  Quora Question Pairs - Paraphrase Identification benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-06<BR>ratio: 0.1145<BR>benchmarks:<BR>  DocRED - Relation Extraction benchmarking: F1<BR>  DocRED - Relation Extraction benchmarking: Ign F1<BR>  SemEval-2010 Task 8 - Relation Extraction benchmarking: F1<BR>  TACRED - Relation Extraction benchmarking: F1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-06<BR>ratio: 0.0469<BR>benchmarks:<BR>  VQA v2 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  VQA v2 test-std - Visual Question Answering benchmarking: overall<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-06<BR>ratio: 0.4897<BR>benchmarks:<BR>  Quora Question Pairs - Question Answering benchmarking: Accuracy<BR>  RACE - Question Answering benchmarking: RACE-h<BR>  RACE - Question Answering benchmarking: RACE-m<BR>  RACE - Question Answering benchmarking: RACE<BR>  SQuAD1.1 - Question Answering benchmarking: EM<BR>  SQuAD1.1 - Question Answering benchmarking: F1<BR>  SQuAD1.1 dev - Question Answering benchmarking: EM<BR>  SQuAD1.1 dev - Question Answering benchmarking: F1<BR>  SQuAD2.0 - Question Answering benchmarking: EM<BR>  SQuAD2.0 - Question Answering benchmarking: F1<BR>  SQuAD2.0 dev - Question Answering benchmarking: EM<BR>  SQuAD2.0 dev - Question Answering benchmarking: F1<BR>","<BR>task: Semantic analysis: Semantic Textual Similarity<BR>date: 2019-06<BR>ratio: 0.4252<BR>benchmarks:<BR>  MRPC - Semantic Textual Similarity benchmarking: Accuracy<BR>  STS Benchmark - Semantic Textual Similarity benchmarking: Pearson Correlation<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2019-06<BR>ratio: 0.4272<BR>benchmarks:<BR>  CommonsenseQA - Common Sense Reasoning benchmarking: Accuracy<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2019-06<BR>ratio: 0.3025<BR>benchmarks:<BR>  ACE 2004 - Named Entity Recognition benchmarking: F1<BR>  ACE 2005 - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Chinese Named Entity Recognition<BR>date: 2019-07<BR>ratio: 0.5266<BR>benchmarks:<BR>  MSRA - Chinese Named Entity Recognition benchmarking: F1<BR>  MSRA Dev - Chinese Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-07<BR>ratio: 0.6501<BR>benchmarks:<BR>  NYT-single - Relation Extraction benchmarking: F1<BR>  Re-TACRED - Relation Extraction benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2019-07<BR>ratio: 0.2915<BR>benchmarks:<BR>  CoNLL 2012 - Coreference Resolution benchmarking: Avg F1<BR>  OntoNotes - Coreference Resolution benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-07<BR>ratio: 0.3767<BR>benchmarks:<BR>  NewsQA - Question Answering benchmarking: F1<BR>  TriviaQA - Question Answering benchmarking: F1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-07<BR>ratio: 0.5481<BR>benchmarks:<BR>  GQA test-std - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2019-07<BR>ratio: 0.4801<BR>benchmarks:<BR>  ANLI test - Natural Language Inference benchmarking: A1<BR>  MultiNLI - Natural Language Inference benchmarking: Mismatched<BR>  QNLI - Natural Language Inference benchmarking: Accuracy<BR>  RTE - Natural Language Inference benchmarking: Accuracy<BR>  XNLI Chinese - Natural Language Inference benchmarking: Accuracy<BR>  XNLI Chinese Dev - Natural Language Inference benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Semantic Textual Similarity<BR>date: 2019-07<BR>ratio: 0.0577<BR>benchmarks:<BR>  MRPC - Semantic Textual Similarity benchmarking: Accuracy<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2019-07<BR>ratio: 0.2347<BR>benchmarks:<BR>  IMDb - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2019-07<BR>ratio: 0.2383<BR>benchmarks:<BR>  CommonsenseQA - Common Sense Reasoning benchmarking: Accuracy<BR>  SWAG - Common Sense Reasoning benchmarking: Test<BR>","<BR>task: Pragmatics analysis: Emotion Recognition in Conversation<BR>date: 2019-08<BR>ratio: 0.3309<BR>benchmarks:<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Accuracy<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Macro-F1<BR>  IEMOCAP - Emotion Recognition in Conversation benchmarking: Weighted-F1<BR>  MELD - Emotion Recognition in Conversation benchmarking: Weighted-F1<BR>","<BR>task: Text classification: Document Classification<BR>date: 2019-08<BR>ratio: 1.0<BR>benchmarks:<BR>  BBCSport - Document Classification benchmarking: Accuracy<BR>  Reuters-21578 - Document Classification benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Document Summarization<BR>date: 2019-08<BR>ratio: 0.1081<BR>benchmarks:<BR>  CNN / Daily Mail - Document Summarization benchmarking: ROUGE-1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-08<BR>ratio: 0.4554<BR>benchmarks:<BR>  GQA Test2019 - Visual Question Answering benchmarking: Accuracy<BR>  GQA Test2019 - Visual Question Answering benchmarking: Binary<BR>  GQA Test2019 - Visual Question Answering benchmarking: Consistency<BR>  GQA Test2019 - Visual Question Answering benchmarking: Distribution<BR>  GQA Test2019 - Visual Question Answering benchmarking: Open<BR>  GQA Test2019 - Visual Question Answering benchmarking: Plausibility<BR>  GQA Test2019 - Visual Question Answering benchmarking: Validity<BR>  VQA v2 test-dev - Visual Question Answering benchmarking: Accuracy<BR>  VQA v2 test-std - Visual Question Answering benchmarking: overall<BR>  VizWiz 2018 - Visual Question Answering benchmarking: overall<BR>","<BR>task: Pragmatics analysis: Coreference Resolution<BR>date: 2019-08<BR>ratio: 0.0358<BR>benchmarks:<BR>  CoNLL 2012 - Coreference Resolution benchmarking: Avg F1<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2019-08<BR>ratio: 0.4151<BR>benchmarks:<BR>  ACE 2004 - Named Entity Recognition benchmarking: F1<BR>  ACE 2005 - Named Entity Recognition benchmarking: F1<BR>  BC5CDR - Named Entity Recognition benchmarking: F1<BR>  GENIA - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-08<BR>ratio: 0.0067<BR>benchmarks:<BR>  SQuAD2.0 - Question Answering benchmarking: EM<BR>  SQuAD2.0 - Question Answering benchmarking: F1<BR>","<BR>task: Other NLP task: Text-to-Image Generation<BR>date: 2019-09<BR>ratio: 1.0<BR>benchmarks:<BR>  Multi-Modal-CelebA-HQ - Text-to-Image Generation benchmarking: FID<BR>","<BR>task: Question answering: Question Answering<BR>date: 2019-09<BR>ratio: 0.0784<BR>benchmarks:<BR>  SQuAD2.0 - Question Answering benchmarking: EM<BR>  SQuAD2.0 - Question Answering benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Sentiment Analysis<BR>date: 2019-09<BR>ratio: 0.0085<BR>benchmarks:<BR>  SST-2 Binary classification - Sentiment Analysis benchmarking: Accuracy<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2019-09<BR>ratio: 0.1111<BR>benchmarks:<BR>  VQA-CP - Visual Question Answering benchmarking: Score<BR>","<BR>task: Text classification: Text Classification<BR>date: 2019-09<BR>ratio: 0.8833<BR>benchmarks:<BR>  20NEWS - Text Classification benchmarking: F-measure<BR>  Amazon-2 - Text Classification benchmarking: Error<BR>  Amazon-5 - Text Classification benchmarking: Error<BR>  R8 - Text Classification benchmarking: Accuracy<BR>  R8 - Text Classification benchmarking: F-measure<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-09<BR>ratio: 0.4834<BR>benchmarks:<BR>  ACE 2005 - Relation Extraction benchmarking: NER Micro F1<BR>  ACE 2005 - Relation Extraction benchmarking: RE Micro F1<BR>  DocRED - Relation Extraction benchmarking: F1<BR>  DocRED - Relation Extraction benchmarking: Ign F1<BR>  NYT - Relation Extraction benchmarking: F1<BR>  NYT-single - Relation Extraction benchmarking: F1<BR>  WebNLG - Relation Extraction benchmarking: F1<BR>","<BR>task: Inference and reasoning: Common Sense Reasoning<BR>date: 2019-09<BR>ratio: 0.2136<BR>benchmarks:<BR>  CommonsenseQA - Common Sense Reasoning benchmarking: Accuracy<BR>","<BR>task: Semantic analysis: Word Sense Disambiguation<BR>date: 2019-09<BR>ratio: 0.9661<BR>benchmarks:<BR>  SensEval 2 Lexical Sample - Word Sense Disambiguation benchmarking: F1<BR>  SensEval 3 Lexical Sample - Word Sense Disambiguation benchmarking: F1<BR>","<BR>task: Semantic analysis: Semantic Textual Similarity<BR>date: 2019-09<BR>ratio: 0.0846<BR>benchmarks:<BR>  MRPC - Semantic Textual Similarity benchmarking: Accuracy<BR>","<BR>task: Inference and reasoning: Natural Language Inference<BR>date: 2019-09<BR>ratio: 0.0427<BR>benchmarks:<BR>  MultiNLI - Natural Language Inference benchmarking: Matched<BR>  QNLI - Natural Language Inference benchmarking: Accuracy<BR>  RTE - Natural Language Inference benchmarking: Accuracy<BR>  SNLI - Natural Language Inference benchmarking: % Test Accuracy<BR>","<BR>task: Semantic analysis: Entity Disambiguation<BR>date: 2019-09<BR>ratio: 0.6447<BR>benchmarks:<BR>  ACE2004 - Entity Disambiguation benchmarking: Micro-F1<BR>  AIDA-CoNLL - Entity Disambiguation benchmarking: In-KB Accuracy<BR>  AQUAINT - Entity Disambiguation benchmarking: Micro-F1<BR>  MSNBC - Entity Disambiguation benchmarking: Micro-F1<BR>  WNED-CWEB - Entity Disambiguation benchmarking: Micro-F1<BR>  WNED-WIKI - Entity Disambiguation benchmarking: Micro-F1<BR>","<BR>task: Pragmatics analysis: Emotion Recognition in Conversation<BR>date: 2019-09<BR>ratio: 0.046<BR>benchmarks:<BR>  MELD - Emotion Recognition in Conversation benchmarking: Weighted-F1<BR>","<BR>task: Syntactic analysis: Linguistic Acceptability Assessment<BR>date: 2019-09<BR>ratio: 0.1429<BR>benchmarks:<BR>  CoLA - Linguistic Acceptability Assessment benchmarking: Accuracy<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-09<BR>ratio: 0.2846<BR>benchmarks:<BR>  WMT2014 German-English - Machine Translation benchmarking: BLEU score<BR>  WMT2016 English-Romanian - Machine Translation benchmarking: BLEU score<BR>","<BR>task: Information extraction: Joint Entity and Relation Extraction<BR>date: 2019-09<BR>ratio: 0.7221<BR>benchmarks:<BR>  SciERC - Joint Entity and Relation Extraction benchmarking: Entity F1<BR>  SciERC - Joint Entity and Relation Extraction benchmarking: Relation F1<BR>","<BR>task: Natural language generation: Machine Translation<BR>date: 2019-10<BR>ratio: 0.2671<BR>benchmarks:<BR>  IWSLT2015 English-Vietnamese - Machine Translation benchmarking: BLEU<BR>","<BR>task: Natural language generation: Text Summarization<BR>date: 2019-10<BR>ratio: 0.6089<BR>benchmarks:<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-1<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-2<BR>  CNN / Daily Mail - Abstractive Text Summarization benchmarking: ROUGE-L<BR>  X-Sum - Text Summarization benchmarking: ROUGE-1<BR>  X-Sum - Text Summarization benchmarking: ROUGE-2<BR>  X-Sum - Text Summarization benchmarking: ROUGE-3<BR>","<BR>task: Computer code processing: Code Generation<BR>date: 2019-10<BR>ratio: 0.1871<BR>benchmarks:<BR>  WikiSQL - Code Generation benchmarking: Exact Match Accuracy<BR>  WikiSQL - Code Generation benchmarking: Execution Accuracy<BR>","<BR>task: Information retrieval: Conversational Response Selection<BR>date: 2019-11<BR>ratio: 0.4096<BR>benchmarks:<BR>  DSTC7 Ubuntu - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>  PolyAI AmazonQA - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>  PolyAI Reddit - Conversational Response Selection benchmarking: 1-of-100 Accuracy<BR>","<BR>task: Information extraction: Named Entity Recognition<BR>date: 2019-11<BR>ratio: 0.1815<BR>benchmarks:<BR>  BC5CDR - Named Entity Recognition benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2019-11<BR>ratio: 0.2333<BR>benchmarks:<BR>  SemEval-2010 Task 8 - Relation Extraction benchmarking: F1<BR>","<BR>task: Information extraction: Chinese Named Entity Recognition<BR>date: 2019-11<BR>ratio: 0.5604<BR>benchmarks:<BR>  MSRA - Chinese Named Entity Recognition benchmarking: F1<BR>  Resume NER - Chinese Named Entity Recognition benchmarking: F1<BR>","<BR>task: Pragmatics analysis: Intent Detection<BR>date: 2019-12<BR>ratio: 1.0<BR>benchmarks:<BR>  ASOS.com user intent - Intent Detection benchmarking: F1<BR>","<BR>task: Question answering: Visual Question Answering<BR>date: 2020-02<BR>ratio: 0.5266<BR>benchmarks:<BR>  MSRVTT-QA - Visual Question Answering benchmarking: Accuracy<BR>  MSVD-QA - Visual Question Answering benchmarking: Accuracy<BR>","<BR>task: Text classification: Document Classification<BR>date: 2020-02<BR>ratio: 1.0<BR>benchmarks:<BR>  Reuters-21578 - Document Classification benchmarking: F1<BR>","<BR>task: Text classification: Text Classification<BR>date: 2020-02<BR>ratio: 1.0<BR>benchmarks:<BR>  RCV1 - Text Classification benchmarking: Micro F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2020-03<BR>ratio: 0.3066<BR>benchmarks:<BR>  DocRED - Relation Extraction benchmarking: F1<BR>","<BR>task: Information extraction: Relation Extraction<BR>date: 2020-04<BR>ratio: 0.2667<BR>benchmarks:<BR>  SemEval-2010 Task 8 - Relation Extraction benchmarking: F1<BR>"],"marker":{"color":[0.1102,1.0,0.3305,0.76,0.2308,0.2549,0.0886,0.0904,0.3032,1.0,0.1186,0.0427,0.232,0.5,0.1435,0.2159,0.4025,0.25,0.483,0.3491,0.3173,0.0718,0.1323,0.2757,0.5335,0.2,0.5215,0.1966,0.2762,0.542,0.7941,0.2999,0.0702,0.3195,0.0771,0.0678,0.218,0.094,0.9481,0.1882,0.3589,0.0286,0.101,0.098,0.2232,0.5,0.3558,0.6069,0.8,0.5084,0.0123,0.0632,0.0853,0.8096,0.1739,0.0711,0.4857,0.7801,0.6667,0.0708,0.0597,0.0392,0.2857,0.1937,0.033,0.1026,0.0174,0.108,0.1795,0.55,0.6016,0.2253,0.2429,0.2329,0.3586,0.2511,0.921,0.3615,0.1524,0.4788,0.1465,0.3698,1.0,0.0632,1.0,0.3933,0.212,0.2457,0.3456,0.5,0.2288,0.4269,0.4385,0.6226,0.3099,0.7439,0.3904,0.0196,0.0407,0.7021,0.0798,0.6272,0.6346,0.2578,0.2561,0.0459,0.0392,0.9439,0.1476,0.1887,0.0392,0.0571,0.0882,0.4672,0.0809,0.3585,0.8333,0.1176,0.0238,0.2079,0.4381,0.3667,0.541,0.0357,0.2009,0.1587,1.0,1.0,0.0152,0.5921,0.2234,0.245,0.137,0.0412,0.1698,0.1343,0.1569,0.8365,0.0536,1.0,0.7182,0.2896,0.3299,0.0126,0.7567,0.154,0.3862,0.6132,0.0673,1.0,0.0282,0.3122,1.0,0.0553,0.791,0.5132,0.913,0.4463,1.0,0.0714,0.2718,0.2449,0.0184,0.5122,0.226,1.0,0.1442,0.0699,1.0,0.3185,0.652,0.2353,0.2419,0.196,0.5481,0.327,0.2054,0.15,0.3426,0.2123,0.45,0.2577,0.4277,0.4178,0.6276,1.0,0.1963,0.9057,0.1404,0.2719,0.2698,0.1449,0.5661,1.0,0.2041,1.0,0.6137,0.3456,1.0,0.7765,0.3558,0.2254,0.5299,0.4127,0.1667,0.4587,0.1426,0.3546,0.8067,1.0,0.397,0.3333,0.666,0.1343,0.1016,0.6981,1.0,0.3031,1.0,0.3147,0.1967,0.2778,0.7252,0.2995,0.2915,0.5876,0.5763,0.0123,0.4213,0.0901,0.2987,0.3157,0.3432,0.4748,0.6752,0.9327,0.4235,0.4549,0.2911,0.4942,0.2659,1.0,0.8571,0.5,0.0675,0.5346,0.5765,0.5752,0.6643,0.1145,0.0469,0.4897,0.4252,0.4272,0.3025,0.5266,0.6501,0.2915,0.3767,0.5481,0.4801,0.0577,0.2347,0.2383,0.3309,1.0,0.1081,0.4554,0.0358,0.4151,0.0067,1.0,0.0784,0.0085,0.1111,0.8833,0.4834,0.2136,0.9661,0.0846,0.0427,0.6447,0.046,0.1429,0.2846,0.7221,0.2671,0.6089,0.1871,0.4096,0.1815,0.2333,0.5604,1.0,0.5266,1.0,1.0,0.3066,0.2667],"colorbar":{"len":500,"lenmode":"pixels","thickness":10,"title":{"text":"ratio"}},"colorscale":[[0.0,"rgb(255,255,229)"],[0.125,"rgb(247,252,185)"],[0.25,"rgb(217,240,163)"],[0.375,"rgb(173,221,142)"],[0.5,"rgb(120,198,121)"],[0.625,"rgb(65,171,93)"],[0.75,"rgb(35,132,67)"],[0.875,"rgb(0,104,55)"],[1.0,"rgb(0,69,41)"]],"opacity":0.7,"showscale":true,"size":19,"symbol":"circle","line":{"color":"black","width":1}},"mode":"markers","x":["2013-10","2013-10","2014-06","2014-06","2014-08","2014-08","2014-09","2014-10","2014-12","2014-12","2015-02","2015-06","2015-06","2015-08","2015-09","2015-11","2015-11","2015-11","2016-01","2016-02","2016-02","2016-02","2016-03","2016-03","2016-03","2016-03","2016-03","2016-03","2016-05","2016-06","2016-06","2016-06","2016-06","2016-06","2016-06","2016-06","2016-07","2016-07","2016-07","2016-08","2016-08","2016-09","2016-09","2016-09","2016-09","2016-09","2016-09","2016-10","2016-10","2016-11","2016-11","2016-11","2016-11","2016-11","2016-11","2016-11","2016-11","2016-12","2016-12","2016-12","2017-01","2017-02","2017-02","2017-02","2017-03","2017-04","2017-04","2017-04","2017-04","2017-04","2017-04","2017-05","2017-05","2017-05","2017-05","2017-05","2017-05","2017-06","2017-06","2017-06","2017-07","2017-07","2017-07","2017-07","2017-07","2017-07","2017-07","2017-07","2017-08","2017-08","2017-08","2017-08","2017-09","2017-09","2017-09","2017-09","2017-09","2017-09","2017-09","2017-10","2017-10","2017-10","2017-11","2017-11","2017-11","2017-11","2017-11","2017-12","2017-12","2017-12","2017-12","2017-12","2018-01","2018-01","2018-01","2018-02","2018-02","2018-02","2018-02","2018-02","2018-02","2018-02","2018-03","2018-03","2018-03","2018-03","2018-03","2018-03","2018-03","2018-04","2018-04","2018-04","2018-04","2018-04","2018-05","2018-05","2018-05","2018-05","2018-05","2018-05","2018-05","2018-05","2018-05","2018-05","2018-06","2018-06","2018-06","2018-06","2018-06","2018-07","2018-07","2018-07","2018-07","2018-07","2018-07","2018-07","2018-08","2018-08","2018-08","2018-08","2018-08","2018-08","2018-08","2018-08","2018-08","2018-08","2018-09","2018-09","2018-09","2018-09","2018-09","2018-09","2018-09","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-10","2018-11","2018-11","2018-11","2018-11","2018-11","2018-12","2019-01","2019-01","2019-01","2019-01","2019-01","2019-01","2019-01","2019-01","2019-01","2019-01","2019-01","2019-02","2019-02","2019-02","2019-02","2019-02","2019-02","2019-02","2019-03","2019-03","2019-03","2019-03","2019-03","2019-03","2019-04","2019-04","2019-04","2019-04","2019-04","2019-04","2019-04","2019-04","2019-04","2019-04","2019-04","2019-05","2019-05","2019-05","2019-05","2019-05","2019-05","2019-05","2019-05","2019-05","2019-05","2019-05","2019-05","2019-06","2019-06","2019-06","2019-06","2019-06","2019-06","2019-06","2019-06","2019-06","2019-06","2019-06","2019-06","2019-06","2019-06","2019-07","2019-07","2019-07","2019-07","2019-07","2019-07","2019-07","2019-07","2019-07","2019-08","2019-08","2019-08","2019-08","2019-08","2019-08","2019-08","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-09","2019-10","2019-10","2019-10","2019-11","2019-11","2019-11","2019-11","2019-12","2020-02","2020-02","2020-02","2020-03","2020-04"],"y":["Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Sentiment Analysis","Question answering: Question Answering","Pragmatics analysis: Sentiment Analysis","Inference and reasoning: Natural Language Inference","Natural language generation: Machine Translation","Natural language generation: Machine Translation","Question answering: Question Answering","Natural language generation: Language Modelling","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Sentiment Analysis","Question answering: Question Answering","Inference and reasoning: Natural Language Inference","Natural language generation: Text Summarization","Question answering: Question Answering","Pragmatics analysis: Sentiment Analysis","Text classification: Text Classification","Information extraction: Relation Extraction","Pragmatics analysis: Sentiment Analysis","Natural language generation: Text Summarization","Question answering: Question Answering","Semantic analysis: Word Sense Disambiguation","Question answering: Visual Question Answering","Question answering: Question Answering","Natural language generation: Machine Translation","Text classification: Document Classification","Syntactic analysis: Dependency Parsing","Question answering: Visual Question Answering","Natural language generation: Machine Translation","Text classification: Citation Intent Classification","Question answering: Visual Question Answering","Pragmatics analysis: Coreference Resolution","Question answering: Question Answering","Natural language generation: Text Summarization","Semantic analysis: Word Sense Disambiguation","Natural language generation: Machine Translation","Pragmatics analysis: Sentiment Analysis","Syntactic analysis: Grammatical Error Detection","Natural language generation: Machine Translation","Question answering: Question Answering","Pragmatics analysis: Coreference Resolution","Question answering: Question Answering","Inference and reasoning: Natural Language Inference","Natural language generation: Machine Translation","Natural language generation: Language Modelling","Text classification: Document Classification","Question answering: Question Answering","Natural language generation: Machine Translation","Question answering: Visual Question Answering","Text classification: Document Classification","Natural language generation: Machine Translation","Question answering: Question Answering","Syntactic analysis: Dependency Parsing","Syntactic analysis: Chunking","Syntactic analysis: Grammatical Error Detection","Syntactic analysis: Constituency Parsing","Question answering: Visual Question Answering","Natural language generation: Language Modelling","Other NLP task: Text-to-Image Generation","Natural language generation: Machine Translation","Inference and reasoning: Natural Language Inference","Text classification: Text Classification","Pragmatics analysis: Sentiment Analysis","Question answering: Question Answering","Question answering: Visual Question Answering","Question answering: Question Answering","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Sentiment Analysis","Semantic analysis: Semantic Parsing","Syntactic analysis: Grammatical Error Detection","Natural language generation: Machine Translation","Question answering: Question Answering","Question answering: Visual Question Answering","Natural language generation: Text Generation","Natural language generation: Document Summarization","Semantic analysis: Entity Disambiguation","Natural language generation: Text Summarization","Question answering: Question Answering","Natural language generation: Machine Translation","Pragmatics analysis: Coreference Resolution","Syntactic analysis: Grammatical Error Detection","Sentence embedding: Sentence Compression","Question answering: Visual Question Answering","Pragmatics analysis: Sentiment Analysis","Question answering: Question Answering","Information extraction: Relation Extraction","Syntactic analysis: Constituency Parsing","Question answering: Visual Question Answering","Question answering: Question Answering","Pragmatics analysis: Sentiment Analysis","Computer code processing: Code Generation","Information extraction: Relation Extraction","Natural language generation: Text Generation","Pragmatics analysis: Paraphrase Identification","Dialog process: Dialog Act Classification","Dialog process: Visual Dialog","Inference and reasoning: Natural Language Inference","Semantic analysis: Word Sense Disambiguation","Other NLP task: Text-to-Image Generation","Text classification: Document Classification","Question answering: Question Answering","Other NLP task: Text-to-Image Generation","Dialog process: Visual Dialog","Dialog process: Dialog Act Classification","Natural language generation: Machine Translation","Inference and reasoning: Natural Language Inference","Pragmatics analysis: Fake News Detection","Pragmatics analysis: Sentiment Analysis","Semantic analysis: Semantic Role Labeling","Inference and reasoning: Natural Language Inference","Question answering: Question Answering","Text classification: Citation Intent Classification","Question answering: Question Answering","Pragmatics analysis: Sentiment Analysis","Semantic analysis: Semantic Role Labeling","Natural language generation: Text Generation","Text classification: Citation Intent Classification","Semantic analysis: Word Sense Disambiguation","Pragmatics analysis: Coreference Resolution","Natural language generation: Machine Translation","Pragmatics analysis: Sentiment Analysis","Information retrieval: Conversational Response Selection","Text classification: Text Classification","Computer code processing: Code Generation","Question answering: Visual Question Answering","Natural language generation: Language Modelling","Semantic analysis: Semantic Textual Similarity","Natural language generation: Machine Translation","Question answering: Question Answering","Pragmatics analysis: Sentiment Analysis","Pragmatics analysis: Coreference Resolution","Computer code processing: Code Generation","Inference and reasoning: Natural Language Inference","Semantic analysis: Semantic Role Labeling","Syntactic analysis: Constituency Parsing","Inference and reasoning: Natural Language Inference","Dialog process: Dialog State Tracking","Semantic analysis: Word Sense Disambiguation","Inference and reasoning: Common Sense Reasoning","Question answering: Question Answering","Pragmatics analysis: Sentiment Analysis","Text classification: Text Classification","Question answering: Visual Question Answering","Pragmatics analysis: Emotion Recognition in Conversation","Natural language generation: Machine Translation","Question answering: Question Answering","Inference and reasoning: Natural Language Inference","Natural language generation: Question Generation","Question answering: Question Answering","Pragmatics analysis: Paraphrase Identification","Information extraction: Relation Extraction","Sentence embedding: Sentence Compression","Natural language generation: Text Summarization","Syntactic analysis: Dependency Parsing","Text classification: Text Classification","Syntactic analysis: Chunking","Information extraction: Relation Extraction","Information extraction: Named Entity Recognition","Syntactic analysis: Constituency Grammar Induction","Question answering: Question Answering","Natural language generation: Text Summarization","Text classification: Document Classification","Natural language generation: Document Summarization","Natural language generation: Machine Translation","Text classification: Text Classification","Dialog process: Visual Dialog","Natural language generation: Machine Translation","Natural language generation: Language Modelling","Information extraction: Relation Extraction","Text classification: Text Classification","Inference and reasoning: Natural Language Inference","Question answering: Question Answering","Question answering: Question Answering","Computer code processing: Code Generation","Dialog process: Dialog State Tracking","Information extraction: Named Entity Recognition","Machine translation: Unsupervised Machine Translation","Inference and reasoning: Natural Language Inference","Syntactic analysis: Constituency Grammar Induction","Semantic analysis: Semantic Parsing","Pragmatics analysis: Emotion Recognition in Conversation","Semantic analysis: Semantic Role Labeling","Pragmatics analysis: Sentiment Analysis","Inference and reasoning: Common Sense Reasoning","Natural language generation: Machine Translation","Information extraction: Relation Extraction","Text classification: Sentence Classification","Pragmatics analysis: Fake News Detection","Semantic analysis: Word Sense Disambiguation","Syntactic analysis: Grammatical Error Detection","Question answering: Question Answering","Pragmatics analysis: Emotion Recognition in Conversation","Information extraction: Relation Extraction","Question answering: Question Answering","Information extraction: Named Entity Recognition","Text classification: Text Classification","Inference and reasoning: Natural Language Inference","Other NLP task: Text-to-Image Generation","Natural language generation: Machine Translation","Information retrieval: Conversational Response Selection","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Sentiment Analysis","Machine translation: Unsupervised Machine Translation","Natural language generation: Text Generation","Question answering: Visual Question Answering","Dialog process: Visual Dialog","Text classification: Text Classification","Question answering: Question Answering","Inference and reasoning: Common Sense Reasoning","Machine translation: Unsupervised Machine Translation","Information extraction: Relation Extraction","Information extraction: Named Entity Recognition","Syntactic analysis: Constituency Parsing","Other NLP task: Text-to-Image Generation","Text classification: Sentence Classification","Information extraction: Relation Extraction","Natural language generation: Document Summarization","Pragmatics analysis: Emotion Recognition in Conversation","Question answering: Visual Question Answering","Syntactic analysis: Constituency Grammar Induction","Information extraction: Joint Entity and Relation Extraction","Information extraction: Relation Extraction","Information extraction: Chinese Named Entity Recognition","Information retrieval: Conversational Response Selection","Other NLP task: Text-to-Image Generation","Natural language generation: Text Summarization","Text classification: Document Classification","Dialog process: Visual Dialog","Natural language generation: Document Summarization","Natural language generation: Machine Translation","Machine translation: Unsupervised Machine Translation","Pragmatics analysis: Sentiment Analysis","Semantic analysis: Semantic Textual Similarity","Semantic analysis: Word Sense Disambiguation","Natural language generation: Question Generation","Question answering: Visual Question Answering","Text classification: Text Classification","Natural language generation: Text Summarization","Question answering: Question Answering","Information extraction: Relation Extraction","Pragmatics analysis: Intent Detection","Syntactic analysis: Linguistic Acceptability Assessment","Inference and reasoning: Natural Language Inference","Pragmatics analysis: Sentiment Analysis","Text classification: Text Classification","Syntactic analysis: Constituency Grammar Induction","Natural language generation: Machine Translation","Pragmatics analysis: Paraphrase Identification","Information extraction: Relation Extraction","Question answering: Visual Question Answering","Question answering: Question Answering","Semantic analysis: Semantic Textual Similarity","Inference and reasoning: Common Sense Reasoning","Information extraction: Named Entity Recognition","Information extraction: Chinese Named Entity Recognition","Information extraction: Relation Extraction","Pragmatics analysis: Coreference Resolution","Question answering: Question Answering","Question answering: Visual Question Answering","Inference and reasoning: Natural Language Inference","Semantic analysis: Semantic Textual Similarity","Pragmatics analysis: Sentiment Analysis","Inference and reasoning: Common Sense Reasoning","Pragmatics analysis: Emotion Recognition in Conversation","Text classification: Document Classification","Natural language generation: Document Summarization","Question answering: Visual Question Answering","Pragmatics analysis: Coreference Resolution","Information extraction: Named Entity Recognition","Question answering: Question Answering","Other NLP task: Text-to-Image Generation","Question answering: Question Answering","Pragmatics analysis: Sentiment Analysis","Question answering: Visual Question Answering","Text classification: Text Classification","Information extraction: Relation Extraction","Inference and reasoning: Common Sense Reasoning","Semantic analysis: Word Sense Disambiguation","Semantic analysis: Semantic Textual Similarity","Inference and reasoning: Natural Language Inference","Semantic analysis: Entity Disambiguation","Pragmatics analysis: Emotion Recognition in Conversation","Syntactic analysis: Linguistic Acceptability Assessment","Natural language generation: Machine Translation","Information extraction: Joint Entity and Relation Extraction","Natural language generation: Machine Translation","Natural language generation: Text Summarization","Computer code processing: Code Generation","Information retrieval: Conversational Response Selection","Information extraction: Named Entity Recognition","Information extraction: Relation Extraction","Information extraction: Chinese Named Entity Recognition","Pragmatics analysis: Intent Detection","Question answering: Visual Question Answering","Text classification: Document Classification","Text classification: Text Classification","Information extraction: Relation Extraction","Information extraction: Relation Extraction"],"type":"scatter","line":{"color":"black","width":0}}],                        {"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"Year"},"showgrid":true,"gridcolor":"lightBlue","tickmode":"auto"},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{},"categoryorder":"array","categoryarray":["Text classification: Sentence Classification","Text classification: Document Classification","Text classification: Text Classification","Text classification: Citation Intent Classification","Syntactic analysis: Linguistic Acceptability Assessment","Syntactic analysis: Grammatical Error Detection","Syntactic analysis: Constituency Grammar Induction","Syntactic analysis: Chunking","Syntactic analysis: Constituency Parsing","Syntactic analysis: Dependency Parsing","Sentence embedding: Sentence Compression","Semantic analysis: Semantic Role Labeling","Semantic analysis: Semantic Parsing","Semantic analysis: Semantic Textual Similarity","Semantic analysis: Entity Disambiguation","Semantic analysis: Word Sense Disambiguation","Question answering: Question Answering","Question answering: Visual Question Answering","Pragmatics analysis: Paraphrase Identification","Pragmatics analysis: Emotion Recognition in Conversation","Pragmatics analysis: Fake News Detection","Pragmatics analysis: Intent Detection","Pragmatics analysis: Coreference Resolution","Pragmatics analysis: Sentiment Analysis","Other NLP task: Text-to-Image Generation","Natural language generation: Language Modelling","Natural language generation: Document Summarization","Natural language generation: Text Generation","Natural language generation: Question Generation","Natural language generation: Machine Translation","Natural language generation: Text Summarization","Machine translation: Unsupervised Machine Translation","Information retrieval: Conversational Response Selection","Information extraction: Chinese Named Entity Recognition","Information extraction: Relation Extraction","Information extraction: Joint Entity and Relation Extraction","Information extraction: Named Entity Recognition","Inference and reasoning: Natural Language Inference","Inference and reasoning: Common Sense Reasoning","Dialog process: Dialog Act Classification","Dialog process: Dialog State Tracking","Dialog process: Visual Dialog","Computer code processing: Code Generation"],"showgrid":true,"gridcolor":"lightBlue","side":"left"},"legend":{"title":{"text":"task"},"tracegroupgap":0},"margin":{"t":60},"title":{"text":"Natural Language Processing","y":0.995},"font":{"size":21},"showlegend":false,"plot_bgcolor":"white","height":1782.0000000000002,"width":1500},                        {"responsive": true}                    )                };                            </script>        </div>
</body>
</html>